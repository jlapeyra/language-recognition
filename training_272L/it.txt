Sarah Bernhardt, nata Henriette Rosine Bernard[1] (Parigi, 22 ottobre 1844 – Parigi, 26 marzo 1923), è stata una celebre attrice teatrale e cinematografica francese.
Soprannominata La voix d'or ("La voce d'oro") e La divina, Sarah Bernhardt è considerata una delle più grandi attrici teatrali del XIX secolo.
Protetta dal Duca de Morny, fratellastro di Napoleone III, amante di sua zia e poi di sua madre, Sarah terminò gli studi al Conservatorio nel 1862, ed entrò nella Comédie-Française che poi abbandonò nel 1866 per l'Odéon. Venne scoperta sulle scene de Le Passant di François Coppée nel 1869 e trionfò come Maria di Neuburg nel Ruy Blas di Victor Hugo, nel 1872; tali interpretazioni la portarono ad essere richiamata dalla Comédie Française dove interpretò Phèdre nel 1874 e Hernani tre anni dopo, nel 1877.
Nel 1880, dopo aver schiaffeggiato un'attrice, si dimise con un certo scandalo del «Français» e creò la propria compagnia teatrale, con la quale partì per l'estero, dove riuscì a far fortuna. A New York incontrò Thomas Edison e registrò su un cilindro sonoro un brano di Phèdre. Rientrata in Francia, dal 1893 diresse il Teatro del Rinascimento, e successivamente il Teatro delle Nazioni, dove interpretò La signora delle camelie. Allo scoppiare dell'Affare Dreyfus l'attrice diede il suo sostegno ad Émile Zola.
Nel dicembre del 1894 chiese a Alfons Mucha di disegnare i propri manifesti. I successivi sei anni di collaborazione diedero un secondo momento di splendore alla sua carriera che, verso la fine, la vide impegnata anche come attrice per il cinema muto. Il primo film in cui recitò fu Il duello di Amleto nel 1900. Ne girò otto, di cui due autobiografici. L'ultimo, Sarah Bernhardt a Belle Isle (1912) descrive la sua vita quotidiana. Nel 1914 le venne conferita la Legione d'Onore. L'amputazione di una gamba, a seguito di un incidente, nel 1915, quando l'attrice aveva settant'anni, non le impedì di continuare a recitare da seduta. 
Sarah Bernhardt pubblicò diversi libri e opere teatrali; fu tra le figure principali che ispirarono il personaggio della Berma, la grande attrice descritta da Marcel Proust in Alla ricerca del tempo perduto. L'influenza fu così netta che nelle sue lettere lo scrittore francese chiamò spesso il personaggio col nome di "Haras", l'inverso di Sarah.
A vent'anni, da una relazione con un nobile belga, Charles-Joseph Eugène Henri Georges Lamoral de Ligne (1837-1914), figlio di Eugenio, VIII Principe di Ligne, ebbe il suo unico figlio, Maurice Bernhardt, che diventerà scrittore. Successivamente, ebbe diversi amanti, tra cui artisti come Gustave Doré e Georges Clairin, e attori come Mounet-Sully e Lou Tellegen. Inoltre si pensa che sia stata l'amante di Victor Hugo (quando lei aveva 27 anni, mentre lo scrittore 70 anni). Inoltre, sembra sia stata l'amante del Principe di Galles. 
Nel 1882 si sposò a Londra con un collega di origini greche, Aristides Damala, più giovane di lei di undici anni, che era però dipendente dalla morfina, così la loro turbolenta convivenza durò pochissimo. Sarah restò comunque legalmente sua moglie sino alla morte del giovane attore, che avvenne nel 1889 all'età di 34 anni. Corteggiata da Ida Rubinštejn e Anna de Noailles, visse con la pittrice Louise Abbéma, che l'accompagnò in tournée, professando pubblicamente la sua bisessualità.
Possedeva molti animali esotici, in particolare un ghepardo e un alligatore.
L'attrice ebbe un intenso rapporto con Gabriele D'Annunzio. Nel libro Sarah Bernhardt e Gabriele D'Annunzio. Carteggio inedito 1896-1919 (2005) è raccolta parte del loro epistolario. Prima ancora di avviare il sodalizio con Eleonora Duse, l'intesa con la Bernhardt rappresentò per il poeta abruzzese la prova inaugurale della sua lunga avventura sulle scene: un'avventura che favorì il rinnovamento radicale dello spettacolo di prosa.
Morì a Parigi il 26 marzo 1923 all'età di 79 anni e fu sepolta al cimitero di Père Lachaise. La sua tomba riporta solo il suo nome, senza altre iscrizioni.  
Autobiografia
Castelvecchi ritratti
Altri progetti
Frank Lloyd Wright (Richland Center, 8 giugno 1867 – Phoenix, 9 aprile 1959) è stato un architetto statunitense, tra i più importanti del XX secolo.
Tra le figure più influenti della storia dell'architettura contemporanea viene ricordato, assieme a Ludwig Mies van der Rohe, Le Corbusier, Walter Gropius e Alvar Aalto, come maestro del Movimento Moderno. Romanticamente legato all'ideologia individualistica del "pionierismo" statunitense, si volse all'approfondimento del rapporto fra l'individuo e lo spazio architettonico e fra questo e la natura, assunta come fondamentale riferimento esterno. Questi suoi interessi lo portarono a prediligere come tema le case d'abitazione unifamiliari ("prairie houses"), che costituirono l'aspetto determinante del suo primo periodo di attività.
Nel suo volume Architettura organica del 1939 Frank Lloyd Wright espresse compiutamente la sua idea di architettura, che si fondava sul rifiuto della mera ricerca estetica o del semplice gusto superficiale così come una società organica dovrebbe essere indipendente da ogni imposizione esterna contrastante con la natura dell'uomo. La progettazione architettonica dovrebbe creare un'armonia tra l'uomo e la natura, costruire un nuovo sistema in equilibrio tra ambiente costruito e ambiente naturale attraverso l'integrazione dei vari elementi artificiali propri dell'uomo (costruzioni, arredi) e naturali dell'intorno ambientale del sito. Tutti divengono parte di un unico interconnesso organismo, spazio architettonico. La casa sulla cascata del 1936 è l'esempio più pragmatico ed eccezionale di questo modo wrightiano di fare ed intendere gli spazi, la cosiddetta architettura organica, insignito nel 2019 con l'iscrizione di otto dei progetti di Wright nella lista dei patrimoni dell'umanità, con la seguente motivazione:
«All the buildings reflect the ‘organic architecture’ developed by Wright, which includes an open plan, a blurring of the boundaries between exterior and interior and the unprecedented use of materials such as steel and concrete. Each of these buildings offers innovative solutions to the needs for housing, worship, work or leisure. Wright's work from this period had a strong impact on the development of modern architecture in Europe»
«Questi edifici riflettono “l’architettura organica” sviluppata da Wright, che comprende un piano aperto, una delicata delimitazione dei confini tra l'esterno e l'interno, e l'uso di materiali come acciaio e cemento. Ognuno di questi edifici offre soluzioni innovative alle esigenze di alloggio, culto, lavoro o tempo libero. Il lavoro di Wright di questo periodo ha avuto un forte impatto sullo sviluppo dell'architettura moderna anche in Europa»
(UNESCO[1])Frank Lincoln Wright nacque nel villaggio di Richland Center, nel Wisconsin, Stati Uniti, l'8 giugno 1867. Il padre, William Cary Wright (1825–1904), era laureato in legge ma era attivo come oratore, insegnante di musica e pastore;[2][3] verso il padre il piccolo Frank palesò un atteggiamento di amore-odio, apprezzandone la passione contagiosa per la musica (soprattutto Johann Sebastian Bach) ma deprecandone i modi autoritari, distanti, quasi aggressivi nella loro indifferenza.
La madre di Frank, Anna Lloyd Jones, apparteneva ad un'illustre famiglia gallese emigrata nel Wisconsin nel 1845, ed era figlia di Richard Lloyd Jones e Mary Thomas James. Stando all'autobiografia di Wright, la stessa Anne era sicura che il suo primogenito sarebbe cresciuto costruendo «edifici belli»: per stimolare la creatività del figlio era solita decorare la sua cameretta con incisioni raffiguranti imponenti cattedrali inglesi.[4] Si trattava, insomma, di una figura decisamente più amorevole e protettiva, oltre che determinante nella formazione del piccolo: fu accompagnato da Anna, infatti, che il giovane Frank, nel 1876, si recò all'esposizione internazionale indetta per il centenario di Philadelphia, dove scoprì i giochi fröbeliani. Ideati dal pedagogo tedesco Friedrich Fröbel, erano cartoni e cubi di legno dalle forme geometricamente esatte, dipinti di colori primari, che guidavano i bambini alla conoscenza della composizione, della scomposizione di volumi principali in secondari e delle relazioni tra diverse forme. Questi giochi potevano infatti essere combinati in infiniti modi, in due o persino tre dimensioni, e, come sosteneva Fröbel, erano molto utili se impiegati per rappresentare con forme geometriche oggetti naturali. Molti anni dopo, famoso in tutto il mondo, Wright ebbe modo di dire: «I lisci triangoli di cartone e i levigati blocchetti di acero restarono impressi nella mia memoria infantile e costituirono una esperienza indimenticabile».
La giovinezza di Wright fu assai tumultuosa. Presto, infatti, si incrinarono i rapporti con il padre, che frattanto si separò con Anna, accusandola di aspre carenze sul piano affettivo: fu anche per questo motivo che, una volta compiuti i quattordici anni, Frank cambiò il suo secondo nome da Lincoln a Lloyd, in onore proprio della famiglia materna, i Lloyd Joneses. A questi anni risale anche la prima formazione di Wright, la quale fu condotta in maniera abbastanza deludente: dopo aver terminato la Madison High School, forse senza mai aver conseguito il diploma, fu ammesso all'Università di Wisconsin-Madison nel 1886, dove collaborò persino con l'ingegnere Allan D. Conover, senza tuttavia laurearsi. Fu questo quindi un periodo decisamente improduttivo, ma durante il quale Wright effettuò copiose letture, avvicinandosi al Dizionario ragionato di architettura di Eugène Viollet-le-Duc e a Le pietre di Venezia di John Ruskin.
Malgrado i tendenziali insuccessi accademici Wright era tutt'altro che disposto ad arrendersi: fu per questo motivo che, nel 1887, si avventurò a Chicago alla ricerca di un lavoro. La città era stata distrutta quasi completamente da un incendio scoppiato nel 1871, cui seguì tuttavia un forte sviluppo economico, demografico e tecnologico: Wright avrebbe poi ricordato che, seppure il primo impatto con la città fu tutt'altro che favorevole (ne disdegnava i quartieri degradati, le strade sovraffollate, e l'architettura tutto sommato deludente), era più che determinato nel trovare lavoro.
In pochi giorni, e dopo aver preso contatti con vari architetti celebrati, Wright fu assunto come progettista nello studio di Joseph Lyman Silsbee. In questo cenacolo architettonico fecondo, animato da futuri nomi come Cecil Corwin, George W. Maher, e George G. Elmslie, Wright lavorò ai progetti dell'All Souls Church a Chicago e dell'Hillside Home School I. Fu una collaborazione dunque fruttuosa, ma che lasciava insoddisfatto Wright, il quale non si sentiva gratificato dall'irrisorio salario (appena otto dollari settimanali). Pur apprezzandone lo stile «graziosamente pittoresco», più valente secondo il suo giudizio rispetto alle altre «brutalità» del periodo, Wright ambiva a lavori più soddisfacenti e progressisti.
Ben presto Wright apprese che lo studio di Chicago gestito dal duo architettonico Adler & Sullivan era «alla ricerca di un progettista per completare gli interni dell'auditorium di Chicago»: dopo una serie di interviste i due accettarono Wright nel proprio studio. Adler e Sullivan lasciarono un'impronta profonda nella fantasia creativa di Wright, il quale ammirava «nel primo - più anziano ed esperto - l'iniziativa imprenditoriale, la mente organizzativa, il tecnico sicuro e navigato, lo spirito razionale e la concretezza operativa; nell'altro il giovane di sicuro avvenire, l'artista geniale, dotato di una innata forza creativa e di un potere raziocinante, tipico della mente superiore, capace di rovesciare d'impulso gli irretenti parametri delle convenzioni e del comune buonsenso» (Marco Dezzi Bardeschi).[5] Nel Testamento Wright avrebbe ricordato: «un grande rivoluzionario, ingegnere nell'esercito confederato, costruttore e teorico, Dankmar Adler; e il suo giovane socio, un genio, reduce ribelle dell'Accademia parigina, Louis H. Sullivan, praticavano architettura, verso il 1887, appunto là, nella città di Chicago; [erano] allora gli unici architetti moderni, con i quali, per questo motivo, intendevo lavorare».
Con Sullivan in particolare, tra le figure architettoniche più interessanti e in controtendenza della Chicago di quei tempi, Wright saldò un fecondo rapporto non solo professionale, ma anche umano, alimentato dalla collaborazione per la progettazione di grandi edifici (come lo Schiller Building e l'auditorium di Chicago) e da incessanti discussioni sul rapporto tra ornamento e funzione e sul senso dell'architettura in generale: l'intesa stabilita tra i due era così vivida che Wright era solito riferirsi a Sullivan come «lieber Meister» (in tedesco, amato o vecchio maestro). Parallelamente alla felice collaborazione con il lieber Meister Wright condusse anche un'appagante vita sentimentale, coronata dalle nozze con Catherine Lee "Kitty" Tobin (1871-1959), celebrate il 1º luglio 1889.
Intanto, la pressione economica sortita dal neonato nucleo famigliare iniziò a farsi sentire, e i gusti dispendiosi dello stesso Wright in materia di vestiti e autoveicoli certamente non aiutavano. Furono queste contingenze a sollecitare Wright ad accettare committenze sotterranee, svolgendole in maniera autonoma rispetto allo studio Adler & Sullivan, al di fuori del regolare orario di lavoro. In questo modo Wright ebbe l'opportunità di approfondire il tema della casa unifamiliare, ponendo le basi per le future realizzazioni della maturità: ben presto, tuttavia, Sullivan si accorse di queste «case di contrabbando» (come furono soprannominate) e questo fu motivo di un'aspra disputa tra i due, che si risolse con l'allontanamento di Wright dallo studio, proprio in quanto le obbligazioni contrattuali gli imponevano di non svolgere incarichi indipendenti.
Non fu solo la collaborazione con il Sullivan a plasmare culturalmente Wright. Importante, in tal senso, è stata anche la visita alla Fiera Colombiana di Chicago nel 1893, celebrata per festeggiare il quattrocentenario dell'arrivo di Cristoforo Colombo sul Nuovo Continente. Questa terrificante «catastrofe», come ebbe a dire lo stesso Wright nel Testamento, servì a promuovere lo stile neoclassico e quello Beaux-Arts, all'epoca in piena fioritura, ed apparve agli occhi dell'architetto come una «mascherata tragica», una «ondata straripante di megalomania», un «sovvertimento insensato». Dalla tronfia estetica eclettica e classicista di quest'esposizione, paragonata da Wright ad uno «snervante artificio» che «mostrava il volto fiorito del formalismo teorico delle Accademie [e] il pervertimento di quanto di architettonicamente moderno era stato raggiunto attraverso la negazione», derivò una convulsa ubriacatura generale, in quanto furono in molti a convertirsi euforicamente ai modi revivalisti avallati dalla Fiera, come osservato dallo stesso Wright: «ogni ambizioso imbecille che esercitasse la professione di architetto, in tutta l'America, ne restò affascinato».[6]
Lo stesso Wright, tuttavia, trasse fecondo insegnamento dalla visita della Fiera Colombiana, la quale se, da una parte, confermò infaustamente i modi neomedievalisti e neoclassici che tanta risonanza ebbero nell'America di fine Ottocento, dall'altra servì a far scoprire al nostro l'architettura giapponese. Nel caos della fiera, infatti, si apriva un piccolo isolotto artificiale, il Wooded Island, all'interno del quale era stato ricavato un piccolo tempio giapponese, lo Ho-o-den, progettato da Masamichi Kuru: l'influenza che la tradizione giapponese, così distante dai canoni espositivi, ebbe su Wright fu immensa, e se ne discuterà con maggiore dettaglio nel paragrafo Stile. Significativo, dunque, appare che nello stesso anno della scoperta dell'architettura giapponese Wright debuttò per la prima volta in uno studio autonomo, locato all'ultimo piano dello Schiller Building, a Randolph Street, Chicago: «so che quando nel 1893 posi le lettere dorate Frank Lloyd Wright, Architetto sul pannello, in un'unica lastra di cristallo sull'uscio nello Schiller Building, le cause del ristagno culturale che riscontravo stavano nelle suggestioni esercitate sulla società dal classicismo che permeava sempre di più l'opera dell'AIAA. Frutto effimero di un'educazione architettonica inadeguata, sommergeva la qualità autentica della vita americana». Successivamente, grazie alla situazione economica migliorata, fu in grado di ampliare la propria residenza a Oak Park e insediare lì lo studio.
Mentre Sullivan era impegnato nella progettazione di grattacieli e grandi strutture, ubicati in contesti fortemente urbanizzati, Wright preferiva confrontarsi con il tema - solo apparentemente più modesto - dell'edilizia residenziale unifamiliare, studiata con i suggerimenti provenienti dal tirocinio con Sullivan, dalla ricezione dell'estetica giapponese e dalle reminescenze provenienti dai giochi froebeliani: da questo connubio di influenze sorsero la Winslow House, che armonizza ornamenti di ascendenza sullivaniana con una geometria fortemente semplificata, basata sull'impiego rigoroso di linee orizzontali, ma anche i Francis Apartments, la Rollin Furbeck House, la Husser House, oltre che creazioni più tradizionaliste (ma non per questo immuni dall'influenza del Giappone e di Sullivan), eseguite per i clienti più conservativi, come la Bagley House, la Moore House I, e la Charles E. Roberts House. Importante, nella parabola architettonica wrightiana, anche la casa che egli progettò per sé stesso presso Oak Park, vera e propria palestra e laboratorio per sperimentare «in prima persona» le proprie idee architettoniche, oltre che per offrire rifugio a una famiglia sempre più numerosa con la nascita di Catherine nel 1894, di David nel 1895 e di Frances nel 1898.
Di grande pregio sono anche le prairie houses, le «case della prateria» commissionate dall'agiata borghesia di Chicago inserite, malgrado il nome, nella lottizzazione extraurbana della città. Le realizzazioni prairie, come si vedrà in maniera più rigorosa nel paragrafo Stile, sono tendenti ad aprirsi verso il contesto naturale circostante e ad ispirarsi alla tradizione maya e precolombiana: sono, inoltre, caratterizzate da spazi organici, continui, che partendo dall'epicentro del camino (cui veniva assegnata una posizione preminente) si espandono secondo schemi precisi, oltre che da materiali edilizi tendenzialmente naturali (come il legno o la pietra), e rappresentano la prima risposta di rilievo alla meditazione wrightiana sul tema delle residenze unifamiliari. Queste riflessioni, già contenute nella Hickox House e nella Bradley House (trait d'union tra il Wright degli esordi e quello maturo), appaiono particolarmente evidenti nella Thomas House, nella Willits House e, soprattutto, in quelli che sono unanimemente considerati i capolavori della cultura prairie, ovverosia la Coonley House di Riverside e la Robie House di Chicago.
Nel frattempo, in questo periodo fecondo di realizzazioni di pregio, la progenie di Wright e Kitty era divenuta particolarmente numerosa - i due, infatti, avevano generato ben sei figli in dieci anni. Nell'ottobre del 1909, tuttavia, una donna sopraggiungerà nella biografia amorosa di Wright: era costei Mamah Borthwick, moglie dell'ingegner Edwin Cheney, committente di una villa che Wright stava progettando ad Oak Park. Mamah si invaghì subito di Wright, il quale la ricambiò in questa passione amorosa. Protofemminista dal notevole spessore intellettuale, sfiorita dopo il primo matrimonio, Mamah avrebbe poi scritto: «Sono rimasta ferma alle sponde della vita e l’ho guardata scorrere. Ora voglio tuffarmi e nuotare nel fiume. Voglio sentire la corrente». Le seguenti parole, invece, sono di Frank Lloyd Wright: «[Rivolgendosi a Mamah] Trovare te mi ha dato libertà, mi ha fatto credere che potesse esistere qualcosa di più vasto. Mi fai desiderare di essere migliore, come uomo e come artista. Sarei una persona così triste se non ti avessi incontrata ...».[7]
Era questo d'altronde un periodo delicato per Wright, che intendeva superare il modello residenziale proposto dalle case della prateria a favore di un'architettura più democratica. Complice anche questa instabilità stilistica, inquinata da umori sottili, nel 1909, quando il cantiere della Robie House non era neppure terminato, Mamah e Wright lasciarono le rispettive famiglie e partirono alla volta dell'Europa, dove l'architetto era atteso dal berlinese Ernst Wasmuth che intendeva raggrupparne le creazioni più significative in un portfolio, come esemplificazione del suo stile e delle sue capacità tecniche. L'opera, intitolata Ausgeführte Bauten und Entwürfe von Frank Lloyd Wright, finì per raggruppare più di cento litografie delle opere di Wright e fu pubblicata nel 1911: la risonanza che ebbe, insieme alla contemporanea mostra berlinese (completamente dedicata ai lavori di Wright) fu vastissima e contribuì a far riverberare la notorietà dell'architetto nei circoli culturali europei, mentre in America il suo nome era ricoperto di scandalistici vituperi e di pettegolezzi.
Terminato l'interludio berlinese Wright proseguì il suo «esilio volontario», come egli stesso lo definì nella propria autobiografia, prima a Firenze fra il novembre 1909 e il febbraio 1910 dove visse con il primogenito Lloyd Wright in una casa nella via dell'Erta Canina [8] e successivamente presso il villino Belvedere[9] «nell'antica Fiesole, più in alto della romantica città delle città, Firenze, in una piccola villa color crema di Via Verdi» [10], perfetta per cercare «riparo accanto a colei che l'impeto della ribellione, oltre all'amore, aveva portato nella mia vita». Durante il soggiorno fiesolano Wright effettuò lunghe passeggiate ed escursioni,[11] senza per questo estinguere le sue pulsioni progettuali, disegnando una casa studio-ideale, con un giardino mediterraneo recintato, aperta sui colli fiorentini, da destinare a residenza italiana di sé stesso e di Mamah. Wright, tuttavia, non voleva rimanere sul Vecchio Continente e perciò egli, una volta fatto ritorno in America, non rinunciò tuttavia a quest'ambizione e progettò nelle valli del Wisconsin una nuova dimora, battezzandola Taliesin.
Taliesin è stato il primo poeta celtico del VI secolo e con tale denominazione Wright intendeva nobilitare le proprie origini gallesi. Il significato di tale nome era «ciglio splendente»: tutt'altro che splendente, tuttavia, fu il destino della costruzione, destinata a collassare sotto l'effetto di un incendio appiccato da Julian Carlton, un servo delle Barbados, in data 15 agosto 1914.[12] Tra le fiamme, oltre che Taliesin, perirono anche Mamah, i due suoi bambini (John e Martha Cheney), il giardiniere David Lindblom, l'operaio Thomas Brunker, il progettista Emil Brodelle e il figlio di un altro operaio, Ernest Weston. Carlton, che dopo aver appiccato l'incendio tentò invano di suicidarsi, fu tradotto in carcere a Dodgeville. Wright fu devastato da questo tragico epilogo, che la stampa interpretò come fatale castigo dei suoi presunti misfatti non solo architettonici, ma anche morali, ma era pronto a ricominciare: «Ma io ricostruirò quella casa, affinché lo spirito dei mortali che l'hanno amata continui a vivere nello stesso luogo. La mia casa è ancora lì» avrebbe poi proclamato.[13] Dalle ceneri di Taliesin I e del rapporto con Mamah, in effetti, sorse poi Taliesin II, suggellata dalle nuove nozze con Olga «Olgivanna» Lazovich Hinzenburg (i rapporti con Kitty si erano ormai definitivamente raffreddati, tanto che i due poi si separarono).
Nel frattempo gli ultimi decenni di Wright furono densissimi di committenze e attività, nonostante il trauma economico subito dall'America con la Grande Recessione: forte di due significative pubblicazioni della sua oeuvre (in Olanda nel 1925 e in Germania nel 1926), Wright nel 1930 fu attivo come relatore nell'università di Princeton, e nel 1932 fu invitato dal Museum of Modern Art di New York in ragione del suo ruolo trainante all'interno dell'International Style. Wright, anche nell'anzianità, era un architetto vitale, se non esuberante, persuaso che «la giovinezza persiste in noi, e il miglior periodo della vita si trova dinanzi a noi»: ne sono testimoni l'invito a partecipare al Congresso Mondiale degli Architetti a Mosca nel 1937, la pubblicazione di una monografia a lui dedicata sull''Architectural Forum nel 1938, gli stimolanti dibattiti da lui tenuti a Londra nell'aprile del 1939, la mostra finalmente tenutasi al MoMA newyorchese nel 1951 e l'esposizione itinerante (con tappe a Filadelfia e Firenze) per i suoi Sessant'anni di architettura, fondamentale per esportare anche in Europa il mito di colui che, per citare le parole di Bruno Zevi, si dimostrò capace di conferire «forma architettonica a miti di libertà». Questa notorietà fu ancora più esplosiva con la progettazione di Fallingwater e del Solomon R. Guggenheim Museum, tuttora considerati fra i suoi maggiori capolavori.[14]
Il 4 aprile 1959 Wright fu ospedalizzato in seguito ad alcuni atroci dolori addominali, e poi sottoposto ad un'operazione il 6 aprile dello stesso anno. La sua salute era più che declinante, e già nel 1937 egli aveva patito una feroce polmonite: malgrado sembrasse presentare miglioramenti, egli spirò a Phoenix il 9 aprile 1959. Il suo corpo, inizialmente posto nel cimitero dei Lloyd-Jones, a fianco della Unity Chapel, nel Wisconsin, oggi riposa a Scottsdale, negli Stati Uniti.
È stato osservato più volte che Wright nasconde il paradosso di un architetto che, pur essendo tra i più grandi maestri del Modernismo novecentesco, era profondamente radicato nel contesto culturale dell'Ottocento: a notarlo fu soprattutto l'architetto Philip Johnson, il quale – non senza vene di perfidia – sentenziò che Wright era stato l'architetto più significativo del diciannovesimo (e, si badi, non del ventesimo) secolo.[15]
Wright, in realtà, è stato un architetto tutt'altro che obsoleto o antiquato, e questi suoi profondi legami con la cultura ottocentesca sono stati non solo legittimi, ma persino fecondi, come sottolineato dal critico William Cranon:
«Anche un genio deve parlare il linguaggio del suo tempo e lavorare con le risorse artistiche e culturali che esso offre. Si potrebbe affermare che è compito del genio captare idee che sono, per così dire, nell'aria e che costituiscono l'espressione profonda di un tempo e di un luogo, mostrandone le potenzialità in forme così lampanti e originali da apparire a un tempo innovative e ovvie. E questo Wright seppe indubbiamente fare con straordinario talento. Dimostrazione evidente della sua capacità di parlare al ventesimo secolo con il linguaggio del diciannovesimo è proprio il vocabolario da lui usato, tanto negli scritti che negli edifici. Quando adoperava termini come organico, individualismo, democrazia e natura, esprimeva valori del diciannovesimo secolo, sottilmente ma essenzialmente diversi dai nostri, perché ispirati dall'idealismo romantico»
(William Cranon[16])Ma a quali influenze ottocentesche ha attinto Frank Lloyd Wright? Quest'ultimo è da sempre stato ostinatamente deciso, salvo in alcuni casi episodici, nel negare la presenza di fonti che abbiano potuto influenzare in maniera determinante la sua opera:
«Chiunque sia impegnto nell'opera creativa è esposto alla persecuzione odiosa dei confronti. Gli odiosi confronti seguono la peste della creatività ovunque sia implicato il principio poetico, perché solo per confronti apprende la mente inferiore: confronti, spesso equivoci, compiuti l'uno per l'altro per momenti di utile»
(Frank Lloyd Wright[17])Egli, in realtà, nel corso di tutta la sua produzione si è ispirato a un vasto concorso di fonti, non necessariamente architettoniche, fra le quali le più significative sono indubbiamente i giochi froebeliani, le realizzazioni di Silsbee, Adler e Sullivan, l'estetica giapponese e, infine, il pensiero trascendentalista di Ralph Waldo Emerson e Walt Whitman.
La stessa tragica esigenza di doversi proporre come un genio individuale, superuomo iconoclasta in grado di farsi da sé, ingegno architettonico egoista e arrogante, unico e solo, e per questo irripetibile, affonda le proprie radici nel pensiero di Ralph Waldo Emerson, scrittore e filosofo statunitense di matrice trascendentalista. Indiscusso protagonista del pantheon intellettuale della famiglia di Wright, Emerson promuoveva anche l'ideale di un artista che, solitario di fronte alle malevolenze del mondo, non si perdeva dinanzi alle minacce degli intellettuali filistei, né imitava servilmente le creazioni altrui, bensì faceva splendere il proprio genio denunciando così la propria integralità e il proprio valore:
«Chi vuole essere un uomo deve essere non-conformista. Chi vuol conquistare allori immortali non deve farsi irretire dalla bontà, ma deve esplorare se si tratti di vera bontà. Nulla infine è sacro, se non l'integrità della tua mente»
(Ralph Waldo Emerson)«Vi consiglierò anzitutto di camminare da soli; di rifiutare i buoni modelli umani, anche quelli che sono sacri per il vostro immaginario, e di avere il coraggio di amare Dio senza veli e senza intermediari ... Ringraziamo Dio per questi uomini buoni, ma diciamo: 'Anche io sono un uomo'. L'imitazione non potrà mai superare il modello. L'imitatore condanna sé stesso a una mediocrità senza speranza»
(Ralph Waldo Emerson)«La ragione per cui non dovete conformarvi a usanze anacronistiche è che ciò vanifica i vostri sforzi, vi fa perdere tempo e confonde l'impronta del vostro carattere»
(Ralph Waldo Emerson)Anche Wright, d'altronde, suggeriva ai propri alunni di Taliesin di «credere con tutto il cuore e servire con tutte le forze ciò in cui si crede», senza «doversi conformare alle esigenze e alle condizioni di un altro» in quanto ne risulterebbe «un cattivo matrimonio e anche un cattivo architetto». Sempre da Emerson, inoltre, Wright desunse un sincero amore per la Natura, la quale veniva concepita come materia grezza, animata da profondi valori estetici e spirituali che riflettevano la grandiosità divina e che l'architetto aveva il compito di esplorare e distillare nelle proprie creazioni.
Se da Emerson Wright aveva appreso che un architetto doveva filtrare l'innata spiritualità intrinseca alla Natura, da Friedrich Fröbel trasse un altro insegnamento, ovvero che tale spiritualità era riconducibile alle forme elementari della geometria euclidea.
Friedrich Fröbel era un educatore e pedagogista tedesco che aveva ideato un gioco basato su «doni» didattici costituiti da blocchetti, sfere, piramidi, griglie modulari e strisce di carta colorata che il fanciullo aveva il compito di manipolare, combinare e ricombinare, sino a comporre dapprima forme geometriche elementari, e poi realtà spaziali più complesse: con quest'attività di composizione, inoltre, il bambino era avviato all'intuizione di verità e significati più profondi impossibili da cogliere mediante formulazioni e spiegazioni verbali. Dalla teoria dei doni, solo apparentemente infantile, Wright trasse secondo molti critici le sue capacità di interpretazione dei rapporti dimensionali fra le forme e manipolazione degli spazi architettonici, sia interni che esterni, e la sua tendenza verso l'astrazione geometrica, sincero atto di fedeltà verso gli insegnamenti di Fröbel, per il quale i bambini dovevano innanzitutto padroneggiare la rappresentazioni delle forme geometriche fondamentali, strumenti essenziali con cui cogliere l'esteriorità della natura, prima di approdare al disegno dal vero.
Di seguito si riportano alcune memorie dello stesso Wright:
«Un padiglione della mostra [...] era dedicato al Giardino d'infanzia froebeliano. Mia madre trovò i Doni: e doni erano in realtà. Collegato a questi doni era il sistema, inteso come base per il disegno e la geometria elementare che sottendono ogni nascita naturale della forma. [I doni erano] strisce di carta colorata, lucida e opaca, dai colori teneri e brillanti. Ecco il giuoco geometrico in attraenti combinazioni a scacchiera di colori! [...] I blocchetti da costruzioni in acero, dalle forme lisce e definite, il cui significato non abbandonerà mai più le dita: così la forma diventa sensazione ... lisce forme triangolari, con il dorso e con gli spigoli bianchi, disposte a romboidi, onde creare composizioni sulla superficie piana del tavolo. Quali forme creavano da sé stesse, solo a lasciarle in libertà [...] Le prime esperienze nel giardino d'infanzia: la linea retta, il piano, il quadrato, il triangolo, il cerchio! E, se volevo di più, il quadrato modificato dal triangolo dava l'esagono e la circonferenza modificata dalla linea retta poteva dare l'ottagono. Aggiungendo lo spessore, cioè entrando nel campo della plasticità, il quadrato diventava un cubo, il triangolo un tetraedro, il cerchio una sfera. Queste forme e segni elementari erano la base segreta di tutti gli effetti [...] sperimentati da sempre nell'architettura di tutto il mondo»
(Frank Lloyd Wright[18])Altra potente fonte d'ispirazione per l'architettura di Wright fu l'estetica del Giappone. L'architetto fu sempre restio ad ammettere l'influenza che l'architettura nipponica esercitò sulla sua opera, temendo forse che quest'ultima perdesse di originalità e conseguenzialmente si svalutasse: fu per questo motivo che egli preferì sempre parlare di stampe, e non costruzioni, giapponesi, in modo tale da ammetterne il debito senza per questo sacrificare la propria eccezionalità. Di seguito si riporta una citazione dello stesso Wright:
«Non vi ho mai confidato in quale ampia misura le stampe giapponesi in sé e per sé mi abbiano ispirato. Non ho mai cancellato quella mia prima esperienza e mai lo farò; almeno lo spero. È stato per me il grande vangelo della semplificazione, l'eliminazione del superfluo [...]. Un artista giapponese coglie la forma ricercando la geometria sottesa ... Egli conosce per esempio la forma nell'albero di pino (come in ogni oggetto naturale sulla terra), la geometria che sta alla base della forma e che costituisce il particolare carattere di pino di quell'albero - ciò che Platone chiamava l'idea eterna. Per lui l'invisibile è visibile»
(Frank Lloyd Wright[19])Subendo potentemente la fascinazione dello Ho-o-den, il tempietto giapponese filologicamente ricostruito in occasione della Fiera Colombiana di Chicago del 1893, oltre che della lettura de Il libro del tè di Okakura Kakuzo, scrittore che predicava la supremazia dell'Oriente sulla corrotta civiltà occidentale, Wright divenne un avido collezionista di stampe giapponesi e un fervente ammiratore della cultura nipponica in generale. Quest'ultima era già riuscita a conquistare il gusto occidentale, grazie alla mediazione di pittori come Whistler e di critici-commercianti come i fratelli de Goncourt, anche se la maggior parte dei suoi fruitori la recepiva in maniera ingenua, acritica, inscenando con essa «una raffinata ma effettiva forma di evasione esotica di netta impronta snobistica». Wright, al contrario, accoglie l'influenza della cultura figurativa nipponica in maniera non meramente citazionista, bensì assolutamente positiva, traendone profondi insegnamenti etici ed estetici: l'essenzialità lineare delle loro forme eleganti e stilizzate; il loro nitore visivo;, la loro tendenza a semplificare le forme e i colori, eliminando tutto ciò che risulta superfluo; la natura che in tali immagini, operando un'immersiva compenetrazione, informa di sé ogni sfaccettatura dell'agire umano sono tutte caratteristiche delle stampe giapponesi che Wright accolse entusiasticamente e che non esitò a trasporre in chiave architettonica nelle proprie realizzazioni.
Secondo Wright, in sintesi, la xilografia a colori giapponese è stata una lezione importante per l'Occidente proprio perché, depurata da ogni ricercatezza, riesce a cogliere grazie alla semplificazione, che non è banalizzazione (tanto che l'«eliminazione del superfluo» fu un tema su cui egli meditò spesso), la struttura della realtà oltre ogni diversificazione dell'apparenza, annullando così l'impercettibile opposizione tra il conoscitore e il conosciuto, tra l'oggetto e il soggetto: tutti concetti tradotti architettonicamente con una osmotica gestione dello spazio che in numerose opere wrightiane - come la Casa sulla cascata - dall'esterno fluisce verso l'interno senza interruzioni.
Dal proprio battesimo professionale, dalle stampe giapponesi, dal trascendentalismo e dalla didattica froebeliana Wright derivò insegnamenti irripetibili, che mise in essere nelle prairie houses, «case della prateria». Meditando a lungo sul problema dell'abitazione, infatti, Wright giunge a denunciare l'assoluta inadeguatezza dell'edilizia residenziale presente a Chicago, le cui praterie risultavano irrimediabilmente «irte di superfluo in ogni loro parte, con ogni espediente possibile [...] scatole bucherellate dappertutto per lasciar entrare la luce».[20]
Il netto e veemente rifiuto a questo modo di fare edilizia, frutto di anni di conformismo e di inerzia accademica, si traduce pertanto nell'esigenza di strutture residenziali nuove, semplici, prive di superfetazioni superflue, ispirate alle reali necessità dell'abitare quotidiano e generalmente rispondenti ai criteri di un'architettura che Wright battezzò organica. La nuova casa americana auspicata (e poi progettata) da Wright, pertanto, abolisce tutti quegli elementi superflui alla progettazione e per questo dannosi, a partire innanzitutto dalle partizioni interne: la prima vittoria di Wright, infatti, consisté proprio nella distruzione della scatola muraria, nell'annullamento della secolare schiavitù delle artificiose pareti divisorie ad angolo retto che, lacerando il volume edilizio in tante unità ambientali isolate e non comunicanti («celle di istituti carcerari» secondo l'architetto),[21] annullava quella reciproca interpenetrazione tra i singoli elementi funzionali necessaria per garantire buoni standard abitativi. La demolizione dell'involucro scatolare e la negazione dello spazio inteso come enfilade simmetrica coincidono per Wright con un nuovo modo di concepire la distribuzione interna, interpretata in maniera libera e fluida grazie alla rinuncia ai corridoi come dispositivo distributivo, a un calibrato dosaggio tra spazi compressi e spazi ampi, e al ricorso ad un'esigua quantità di tramezzi.
Fulcro fisico e ideale della distribuzione delle case della prateria wrightiane era infine il caminetto, archetipo del focolare domestico che anima in maniera quasi sacra la vita familiare, il quale con la sua stabile massa si impone al centro di queste abitazioni: «Vedere la fiamma vivida che arde tra i solidi muri della casa mi dava una sensazione di piacevole benessere; una sensazione che mi induceva al riposo», avrebbe ammesso lo stesso Wright.
Il nuovo modo di fare architettura promosso da Wright, mediante il rifiuto di ogni imbrigliante referenza accademica, era inoltre caratterizzato da un profondo legame con il sito in cui andava collocandosi. Per Wright, infatti, un prodotto architettonico non doveva semplicemente restituire un risultato estetico finale gradevole, bensì doveva integrarsi in maniera riuscita con il contesto circostante: forte del pensiero trascendentalista, Wright - oltre a promuovere un ritorno dall'artificio alla semplicità - nutriva un'autentica venerazione nei confronti della Natura, intesa come astrazione dal sapore settecentesco e come fonte di benessere personale, spirituale e anche fisico per chi si fosse dimostrato in grado di coglierne il lato mistico. Una rispettosa armonia tra ambiente costruito e ambiente naturale, dunque, avrebbe consentito al fruitore di essere protagonista delle gioie della Natura e di farle proprie: da queste istanze si sarebbe mossa quella che Wright battezzò «architettura organica».
Quello dell'«architettura organica» è un concetto spesso svilito da frequenti banalizzazioni che intendono rievocare forme arrotondate e avvolgenti presuntamente ispirate dalla Natura, o riallacciarsi all'utopia di una «architettura naturale» (concetto che non esiste in sé).[22][23] Lo stesso Wright era consapevole delle distorsioni a cui era soggetta la sua filosofia progettuale, e sentì la necessità di precisare personalmente il senso stesso della sua missione architettonica:
«Con l'architettura organica non si tratta di avere una forma naturale, confondendo le due cose, ma avere un principio vitale che prende forma e significato all'interno dell'opera»
Quando Wright si riferisce a un'architettura organica, pertanto, parla di un principio di armonia, sviluppo e coerenza analogo ai rapporti equilibrati e coordinati delle parti già presenti ad esempio nell'architettura classica:
«Organica è un'architettura che si sviluppi dall’interno all’esterno, in armonia con le condizioni del suo essere, distinta da un’architettura applicata dall’esterno. Ambiente ed edificio sono una cosa sola; piantare gli alberi nel terreno che circonda l’edificio, quanto arredare l’edificio stesso, acquistano un’importanza nuova, poiché divengono elementi in armonia con lo spazio interno nel quale si vive. Il luogo (la costruzione, l’arredamento) – e anche la decorazione, e anche gli alberi – tutto diviene una cosa sola nell’architettura organica. Tutti gli aspetti dell’abitare devono confluire in una sintesi con l’ambiente esterno»
(Frank Lloyd Wright[24])E ancora:
«Un'architettura organica promuove un'armonia tra interno ed esterno: il luogo, la decorazione, l'arredamento, la decorazione, gli alberi, tutto diviene una cosa sola nell'architettura organica, divenendo una sintesi facente parte di questa maniera dell'abitare»
(Frank Lloyd Wright)Da queste citazioni emerge come l'architettura organica proposta da Wright abiura dal ricorso a forme sterilmente organiciste, giudicandolo inerte per ricercare il radicamento al proprio contesto, e nega ad esempio l'antinaturalismo sia materico che spaziale del funzionalismo di Le Corbusier (di cui approva il concetto di pianta libera e l'impiego del cemento armato ma rifiuta la standardizzazione e l'esaltazione della macchina). Al contrario, un approccio propriamente organico sarà secondo Wright quello in cui «la forma e la funzione sono una cosa sola», citando sempre le parole dell'architetto,[25] e dove verrà fatta attenzione al rapporto armonico tra le parti e il tutto, tra l'abitante e l'abitato, tra l'edificio e il contesto, instaurandovi una dialettica di cui l'architettura può essere espressione.
Esempio paradigmatico, in tal senso, è la celebre Casa sulla cascata, che si rapporta armoniosamente al sottostante torrente con un sapiente gioco dialettico tra la gravità compressiva delle pareti verticali in pietra e la smaterializzazione leggera delle terrazze a sbalzo in cemento armato, quasi a voler estendere la stratificazione rocciosa su cui sorge la casa fin sopra la cascata. Gli stessi interni, parallelamente, costituiscono una polifonia di spazi che incorporano metaforicamente gli elementi dell'ambiente in cui la casa è collocata: l'aria, evocata nel lucernario; l'acqua, presenza sia fisica e visiva con l'aggetto sul torrente, che sonora con il suo scroscio che attraversa ritualmente gli spazi; il fuoco, nel consueto camino; la roccia, citata talora integralmente come nel grande masso antistante il focolare, talora subliminalmente nelle lastre litiche lavate e levigate della pavimentazione.[26] Similmente ai tanto amati maestri giapponesi come Hokusai, in questo modo, Wright riesce a cogliere l'essenza spirituale presente nel mondo esterno e a introiettarla nella propria opera, dando così vita a un'architettura intimamente coniugata con la natura in cui si colloca: il tema, in questo modo, non è il rispetto o meno dell'ambiente circostante, ma l'approccio organico con cui il manufatto diventa così radicato in un contesto per cui non si può più pensare tale luogo senza una simile relazione.
«[Io e Mamah] passeggiavamo assieme, la mano nella mano, lungo la strada che sale da Firenze all'antica cittadina, circondati lungo tutto il tragitto, alla luce del giorno, dalla vista e dal profumo delle rose. Percorrevamo sotto braccio la stessa antica strada, di notte, ascoltando l'usignolo nelle ombre fitte del bosco illuminato di luna, facendo del nostro meglio per udire il canto nel colmo della vita. Innumerevoli pellegrinaggi compimmo per raggiungere la piccola porta massiccia incassata nel muro compatto imbiancato a calce, e la più grande porta verde che si apriva sull'angusta via Verdi. Entrati, dopo aver chiuso la porta medievale sul mondo esterno, trovavamo il fuoco acceso sulla piccola griglia. Ester, in grembiule bianco, sorridente, impaziente di stupire la signora e il signore con l'incomparabile pranzetto: l'oca arrosto, perfetta, il vino dolce, la crème-caramel... superiori, ricordo, a tutte le oche arrosto, e i vini. e le crèmes-caramel mai serviti. Oppure, passeggiavamo nel parco cintato da alte mura, intorno alla villa, nel sole fiorentino, o nel giardinetto accanto alla fontana, nascosta da masse di gialle rose rampicanti. E vi furono lunghe escursioni per i sentieri di quelle dolci colline, più in alto, fra i papaveri che ammantavano i campi, verso Vallombrosa. E laggiù la cascata, che ritrovava, e smarriva la propria voce nei silenzi profondi di quella famosa pineta. Aspirando nel profondo dei polmoni il profumo dei grandi pini... Stanchi, dormivamo nella piccola solitaria locanda delle alture. E poi ancora il ritorno, la mano nella mano, per chilometri nel sole ardente, nella polvere fitta dell'antica serpeggiante strada: un'antica strada italiana, lungo il torrente. Quanto antica! Quanto pienamente romana!»
Molière, pseudonimo di Jean-Baptiste Poquelin (Parigi, prima del 15 gennaio 1622 – Parigi, 17 febbraio 1673), è stato un commediografo e attore teatrale francese.
Assieme a Corneille e Racine rappresenta uno degli autori più importanti del teatro classico francese del XVII secolo[1].
Il 15 gennaio 1622 venne battezzato nella chiesa di sant'Eustachio a Parigi[2]. Ben presto chiamato Jean-Baptiste per distinguerlo dal fratello minore Jean, solo in seguito, a ventidue anni, circa, scelse lo pseudonimo di "Molière" in onore dello scrittore François de Molière. Suo padre, Jean Poquelin, era un tappezziere, un artigiano agiato; la madre, morì l'anno dopo. 
In seguito, nel 1633, il padre sposò Catherine Fleurette, la quale morì nel 1636. L'infanzia del futuro commediografo fu dunque segnata da lutti e inquietudini, che però spiegano solo in parte il fondo di tristezza del suo umore e la rarità dei ruoli materni nel suo teatro. Nella fanciullezza furono, invece, fondamentali la vivacità popolare, l'animazione, il rumore, l'accanito lavoro oltre agli spettacoli con i quali da piccolo fu ogni giorno a contatto, grazie alla passione che gli fu data dal nonno materno, Louis Cressé, che spesso lo portava all'Hotel de Bourgogne e al Pont Neuf, dove si poteva assistere alle rappresentazioni dei comici italiani e alle tragedie dei comédien.
Nel quartier des Halles, dove visse, il vivace spirito di Poquelin poté impregnarsi del senso di una vita formicolante, dello scherzo pittoresco e della varietà della realtà umana. Il padre gli permise di frequentare scuole molto più prestigiose di quelle destinate ai bambini degli altri commercianti: Molière compì i suoi studi dal 1635 al 1639 al Collège de Clermont, collegio di gesuiti, considerato il migliore della capitale e frequentato da nobili e ricchi borghesi. Qui imparò la filosofia scolastica, in lingua latina, oltreché una perfetta padronanza della retorica. Nel 1637 prestò giuramento come futuro erede della carica di tappezziere del re, precedentemente ricoperta dal padre.
Nel 1641 porta a termine gli studi di diritto, ottenendo la Licenza a Orléans. Comincia a frequentare gli ambienti teatrali, conosce il famoso Scaramuccia (al secolo Tiberio Fiorilli) e intrattiene una relazione con la ventiduenne Madeleine Béjart, giovane attrice rossa di capelli, già madre di un bambino avuto dalla precedente relazione con Esprit de Raymond de Mormoiron. Molière e Madeleine fondarono così una loro compagnia. Il 6 gennaio 1643 Molière rinunciò alla carica di tappezziere reale; il mese successivo, Madeleine dette alla luce Armande Béjart la quale si sposerà poi con Molière.
Il 30 giugno 1643, Molière firmò il contratto che costituì una troupe teatrale di dieci membri, l'Illustre Théâtre, di cui facevano parte Madeleine Béjart (in qualità di prima attrice), il fratello Joseph e la sorella Geneviève. La piccola compagnia prese in affitto il Jeu de Paume des Métayers ("sala dei mezzadri") di Parigi, e, nell'attesa della conclusione dei lavori per adattare la sala alle rappresentazioni teatrali, si stabilì a Rouen, inscenando spettacoli di ogni tipo, dalle tragedie alle farse. Il 1º gennaio 1644 l'Illustre Théâtre esordì nella capitale.
Il pubblico tuttavia non rispose a dovere: iniziarono ad accumularsi debiti e si pervenne persino all'arresto di Molière per insolvenza, talché la compagnia nel 1645 si sciolse. Una volta liberato per l'interessamento del padre e di Madeleine, lui e alcuni membri della compagnia abbandonarono la capitale francese. Dal 1645 al 1658 con i suoi compagni lavorò come attore ambulante con la compagnia di Charles Dufresne, rinomata e finanziata dal duca di Épernon, governatore della Guienna. Nel 1650, Molière ottenne la direzione della troupe che iniziò a fare le sue rappresentazioni a Pézenas, dove ogni anno si tenevano gli Stati della Linguadoca, e nel Sud della Francia.
A partire dal 1652 la compagnia, ormai ben affermata, iniziò ad avere un pubblico regolare a Lione. Durante questo girovagare egli conobbe bene l'ambiente della provincia ma, soprattutto, imparò a fare l'attore e a capire i gusti del pubblico e le sue reazioni. In questo periodo iniziò a scrivere alcune farse e due commedie, ossia Lo stordito (L'Étourdi), commedia di intrigo, rappresentata a Lione nel 1655 e Il dispetto amoroso (Le dépit amoureux), opera non eccezionale, rappresentata a Narbona l'anno seguente.
Nel 1658 tornò a Parigi dopo un soggiorno a Rouen con la sua compagnia, la Troupe de Monsieur, nome accordatole da Filippo d'Orléans. Il 24 ottobre di quell'anno recitarono davanti al re Luigi XIV, il quale si entusiasmò solo con la farsa Il dottore amoroso (Le Docteur amoureux), scritta da Molière (il testo fu ritrovato e pubblicato nel 1960). La compagnia venne autorizzata a occupare, alternandosi con la troupe degli Italiani, il teatro del Petit-Bourbon, e, quando nel 1659 gli Italiani se ne andarono, lo stesso teatro fu a sua completa disposizione. Iniziò così a mettere in scena delle tragedie, ma con scarso successo.
Scrisse anche un'opera che non fu né una tragedia né una commedia, il Don Garcia de Navarre, incentrata sul tema della gelosia, ma fu un fiasco. Molière allora capì che la commedia era la sua aspirazione e in questo genere eccelse già con la prima opera Le preziose ridicole (Les précieuses ridicules), nel 1659. In questa farsa mise in luce gli effetti comici di una precisa realtà contemporanea e le bizzarrie tipiche della vita mondana, ridicolizzandone espressioni e linguaggio. Tutto ciò provocò l'interruzione delle rappresentazioni per qualche giorno, ma gli inviti a corte e nelle case dei grandi signori si susseguirono ugualmente.
Il 1660 registrò il gran successo di Sganarello o il cornuto immaginario, e fu il comico d'intrigo l'argomento principale, con il qui pro quo che regnava in un ambiente dove ognuno si preoccupava solo ed esclusivamente della propria situazione. Nel frattempo venne demolito il salone Petit-Bourbon, ma il re fece prontamente assegnare alla compagnia la sala del Palais-Royal, e in giugno vi fu la presentazione de La scuola dei mariti (École des maris). In questa commedia attraverso le buffonerie, vennero ancora presentati problemi gravi e scottanti come l'educazione dei figli e la libertà da concedere alle mogli.
In onore di una festa dedicata al re Luigi XIV, in quindici giorni Molière scrisse e mise in scena la commedia Gli importuni (Les Fâcheux). Il 20 febbraio 1662, sposò Armande Béjart ufficialmente sorella, ma quasi sicuramente figlia, di Madeleine. Armande entrò anch'essa a far parte della compagnia. Dall'unione nacquero due maschi e una femmina, l'unica che sopravvisse a Molière. In dicembre, venne rappresentata La scuola delle mogli (L'École des femmes) che superò in successo e in valore tutte le commedie precedenti. L'opera portò tuttavia allo scontro con i rigoristi cristiani e, nel 1663, Molière fu interamente occupato dalla querelle de La scuola delle mogli, parallelamente al suo successo. Il 12 maggio 1664 ci fu la prima rappresentazione de Il Tartuffo (Tartuffe ou l'Imposteur).
Tra il 1667 e 1668, ispirandosi alla commedia in prosa di Tito Maccio Plauto, Aulularia, e prendendo spunti anche da altre commedie (I suppositi dell'Ariosto; L'Avare dupé di Chappuzeau, del 1663; La Belle plaideuse di Boisrobert, del 1654; La Mère coquette di Donneau de Vizé, del 1666) scrisse L'avaro (L'Avare ou l'École du mensonge) che venne rappresentato per la prima volta a Parigi, al Palais-Royal il 9 settembre 1668 dalla "Troupe de Monsieur, frère unique du Roi", ovvero la compagnia di Molière stesso, che in quell'occasione recitava la parte di Harpagon. Seguirono altri lavori fortunati come Il borghese gentiluomo , comédie-ballet con le musiche di Lully, e Le intellettuali.
Molière morì il 17 febbraio 1673 di tubercolosi. Collassò mentre recitava Il malato immaginario; il decesso avvenne nella notte, tra le braccia di due suore che lo avevano accompagnato a casa. Una leggenda successiva racconta che morì dalle risate nel tentativo di recitare le sue battute. Quello stesso anno l'Illustre Théâtre assorbì i resti della compagnia del Teatro di Marais e nel 1680 il re, con un ordine speciale, sancì la fusione con l'Hôtel de Bourgogne, dando vita all'inizio della Comédie-Française, di stanza all'Hotel Guénégaud.
L'Accademia di Francia non accettò mai Molière tra gli immortali mentre era in vita, perché il "commediante", ancora definito "guitto", era considerato culturalmente inferiore. Riparò in seguito dedicandogli nel 1774 una statua con l'iscrizione Rien ne manque à sa gloire, il manquait à la nôtre (Nulla manca alla sua gloria, egli mancava alla nostra).
Nel 1769 inoltre autori come Chamfort e Jean Sylvain Bailly dedicarono degli elogi biografici al commediografo francese. In particolare, commentando l'Éloge de Molière di Bailly, il suo biografo François Arago, scrive: «Tuttavia [...] forse mi permetto di affermare che, nonostante una certa inferiorità di stile, il discorso di Bailly ha offerto un più ordinato, più vero e più filosofico apprezzamento dei pezzi principali di questo poeta immortale [rispetto all'elogio di Chamfort]».[3]
Il successo di Molière fu tale che nacque la locuzione Langue de Molière (lingua di Molière) per indicare la lingua francese e, per contaminazione, Pays de Molière (Paese di Molière) per indicare la Francia.
Molière, attore e allo stesso tempo drammaturgo, ricercò uno stile di scrittura e recitazione meno legato alle convenzioni dell'epoca, e proteso verso una naturalezza realistica, che descrivesse al meglio le situazioni e la psicologia dei personaggi. Queste idee, che si realizzeranno in seguito nel teatro borghese, cominciano a emergere con forza ne La scuola delle mogli e ne Il misantropo. Un nuovo stile che Molière accompagna con una critica feroce della morale dell'epoca, cosa che impedì a lungo alla commedia Il Tartuffo di essere rappresentata in pubblico. La sua acuta osservazione della realtà fu spesso per Molière fonte di guai, specialmente quando i nobili oggetto delle sue satire si riconoscevano nei suoi personaggi.
È nota la reazione del duca di La Feuillade che, riconosciutosi nel Marchese della Critica alla scuola delle mogli, gli strofinò sul viso con violenza i bottoni del suo vestito pronunciando la battuta del Marchese: «Torta alla crema! Torta alla crema!». Simili incidenti accaddero con Monsieur d'Armagnac, scudiero di Francia, e con il duca di Montausier, precettore del Delfino, che minacciò di bastonarlo a morte per averlo preso a modello nel creare il personaggio di Alceste, il misantropo, salvo poi cambiare idea e ringraziarlo dell'onore concessogli.
L'aspirazione di Molière, spesso costretto a scrivere commedie-balletto per compiacere i gusti del re, fu quella di dedicarsi a sviluppare un nuovo tipo di commedia, che porterà in seguito alla nascita della commedia di costume moderna, ispirata agli accadimenti quotidiani, scritta in prosa e che obbedisca alla verosimiglianza. Molière può essere considerato a tutti gli effetti il precursore di quel rinnovamento teatrale che comincerà a esprimersi compiutamente un secolo dopo, con Carlo Goldoni, fino a raggiungere la piena maturità nel teatro di Anton Čechov. Anche Dario Fo lo ha spesso indicato tra i suoi maestri e modelli.
Un luogo comune abbastanza diffuso consisterebbe nella presunta ossessione di Molière nei confronti della medicina e dei medici: basterebbe, infatti, una semplice lettura di alcune opere del drammaturgo per imbattersi diverse volte nel personaggio del medico, che sembra essere direttamente preso di mira da parte dell'autore (basti pensare a L'amore medico del 1665 o al successivo Il medico per forza sino al celebre Il malato immaginario). Per esempio, nella prima commedia menzionata l'autore non si limitava a moltiplicare il numero dei medici (addirittura cinque) ma sembra acquisizione definitiva che, dietro i nomi fittizi e "parlanti" dei personaggi, Molière satireggiasse celebri medici professionisti della Parigi di Luigi XIV, ognuno dei quali caratterizzato a suo modo[4].
La satira da parte dell'autore in quest'opera si manifesta nella rappresentazione, palesemente caricaturale, dell'atteggiamento dei medici in scena, i quali si esibiscono in duelli sulle reciproche conoscenze, assolutamente pomposi[5]. Ancora Molière insiste sul medico come professionista di scarsa qualità che agisce solo in funzione dei propri interessi. In particolare, tutti i dottori di Molière sono profondamente legati al denaro; i medici dimenticano del tutto il loro ruolo positivo e vengono dipinti in atteggiamenti arrivisti che hanno il solo scopo di "far fruttare la malattia, con la frode, con l'inganno"[6].
In generale, l'assiduità delle battute aspre e pungenti che Molière non lesina ai medici sembrerebbe insomma tradire una forma di astio personale, al limite del maniacale, forse espressione della personale esperienza dell'autore con la malattia e, quindi, con i medici (non si dimentichi la tubercolosi di cui soffrì il drammaturgo: egli ricevendo i medici, potrà rendersi personalmente conto della loro inadeguatezza e avrà subito modo di scriverne in Il medico per forza)[7].
Tuttavia, come afferma un importante studioso (Sandro Bajini) la critica all'imperizia dei medici, di per sé, si potrebbe giustificare sullo sfondo della più ampia disamina delle illusioni umane, che, com'è noto, rappresenterebbe la dimensione più profonda del teatro del commediografo. C'è dunque da notare che un'attenta lettura delle scene in cui Molière inserisce la "maschera" del dottore porta alla conclusione che il drammaturgo non nutre mai alcuna seria ostilità nei confronti dei medici. La stessa biografia dell'autore può risultare in questo senso illuminante: con Monsieur Mauvillain, suo medico personale, Molière avrebbe intrattenuto rapporti quanto meno cordiali, sia pure nella professata ironia da parte dell'autore verso la necessità di assumere i farmaci suggeritigli dal medico[8].
L'opera di Molière fu conosciuta molto presto in Italia: fin dal XVII secolo gli attori comici francesi recitarono a Torino le sue commedie; in breve tempo furono tradotte e accolte positivamente dal pubblico.
Oltre a numerose traduzioni di singole commedie, le opere di Molière furono pubblicate integralmente, curate da padre Biagio Augustelli a fine Seicento (pubblicate sotto lo pseudonimo di Nic. di Castelli, quattro volumi, Lipsia, 1696-1698, 2ª edizione 1739-1740).[9]
Altre versioni (lista parziale): 
Wolfgang Amadeus Mozart (al battesimo Joannes Chrysostomus Wolfgangus Theophilus; Salisburgo, 27 gennaio 1756 – Vienna, 5 dicembre 1791) è stato un compositore austriaco.
È annoverato tra i massimi geni della storia della musica e tra i compositori più prolifici, versatili e influenti di ogni epoca.[1][2] Fu il primo fra i musicisti più importanti a intraprendere una carriera come libero professionista, parallela comunque ai suoi impegni come Hofkomponist ("compositore di corte") alla Corte Imperiale Viennese. Franz Joseph Haydn ebbe a dire che i posteri non avrebbero visto un talento paragonabile per i successivi 100 anni.[3]
Dotato di raro e precoce talento,[4] iniziò a comporre all'età di cinque anni e morì a trentacinque, lasciando pagine che influenzarono profondamente tutti i principali generi musicali della sua epoca, tra cui musica sinfonica, sacra, da camera e operistica, tanto da essere definito dal Grove Dictionary come "il compositore più universale nella storia della musica occidentale".[5] La sua musica esercitò un'influenza molto profonda su numerosi compositori, tra cui Ludwig van Beethoven.
Incluso nei massimi esponenti del classicismo musicale settecentesco, insieme a Franz Joseph Haydn e Ludwig van Beethoven costituisce la triade alla quale, nella letteratura musicologica, alcuni autori fanno riferimento come prima scuola di Vienna.
Il nome di battesimo di Mozart era Joannes Chrysostomus Wolfgangus Theophilus Mozart:
Il padre Leopold chiamava familiarmente suo figlio Wolferl.[12] Il nome Amadeus è la traduzione latina del nome Theophilus (dal greco Θεόφιλος Theophilos, cioè «colui che ama Dio» o anche «colui che è amato da Dio»);[13] successivamente (dal 1771) fu chiamato anche Amadé o Amadè.[8] Nei primi anni il padre usò inoltre, in alcune lettere, la versione tedesca del nome, ossia Gottlieb.[8][14] Sembra che Mozart patisse una certa insofferenza per la desinenza '-us' apposta alla fine dei suoi nomi, tanto che a volte si firmava con enfasi scherzosa: Wolfgangus Amadeus Mozartus.[15]
Wolfgang Amadeus Mozart nacque il 27 gennaio 1756 alle ore 20:00 al numero 9 di Getreidegasse a Salisburgo,[16] capitale del principato arcivescovile di Salisburgo, all'epoca territorio sovrano appartenente al Sacro Romano Impero nel Circolo Bavarese. Wolfgang fu battezzato il giorno dopo la nascita presso la cattedrale di San Ruperto.
La notizia della nascita di Wolfgang venne data dal padre Leopold (1719-1787) in una lettera del 9 febbraio 1756 a un amico di Augusta, Johann Jakob Lotter: «Ti informo che il 27 gennaio, alle otto della sera, la mia cara moglie ha dato felicemente alla luce un bambino. Si era dovuta rimuovere la placenta e perciò ella era estremamente debole. Ora invece, grazie a Dio, sia il bimbo che la madre stanno bene. Il bambino porta i nomi di Joannes Chrysostomus, Wolfgang, Gottlieb.[17]»
I genitori di Wolfgang avevano quasi la stessa età (la madre differiva dal marito di un solo anno) ed erano persone molto conosciute e attive all'epoca della sua nascita: il padre Leopold, compositore e insegnante di musica,[18] ricopriva l'incarico di vice Kapellmeister[19] presso la corte dell'arcivescovo Anton von Firmian; la madre Anna Maria Pertl[20] (1720 – 1778) era figlia di un prefetto e già vedova quando sposò il suo secondo marito.
Dei sette figli di Leopold e Anna Maria, Wolfgang a parte, l'unica non morta durante l'infanzia era la sorella maggiore Maria Anna (1751 – 1829),[21] detta Nannerl o Nannette.[22] Familiarmente, il piccolo Mozart era noto coi nomignoli di Wolferl o Woferl.
Il bambino dimostrò un talento per la musica tanto precoce quanto straordinario, un vero e proprio bambino prodigio: a tre anni batteva i tasti del clavicembalo, a quattro suonava brevi pezzi e a cinque era già autore di alcune composizioni come, ad esempio, un "Andante e Allegro" o come l'"Allegro" e il "Minuetto" scritti tra l'11 e il 16 dicembre 1761, composizioni oggi note col nome "Wolfgangerl Compositiones".[23] Esistono vari aneddoti riguardanti la sua memoria prodigiosa, la composizione di un concerto all'età di cinque anni, la sua gentilezza e sensibilità e la sua paura per il suono della tromba.[24] Aveva inoltre la capacità di riconoscere l'altezza dei suoni (il cosiddetto orecchio assoluto).[25]
Leopold definiva suo figlio come "il miracolo che Dio ha fatto nascere a Salisburgo" ed è ragionevole ritenere che il grandissimo talento mostrato dal piccolo Wolfgang abbia motivato nel padre una responsabilità molto grande, oltre quella di un semplice genitore o insegnante. Contrariamente a quanto riportato da alcuni, tra cui la figlia Nannerl, Leopold continuò a svolgere con cura i suoi servizi a corte, ma dedicò grandissima energia, molto tempo e denaro nell'educazione musicale dei figli, anche con diversi viaggi in Europa che, oltre a segnarlo fisicamente, hanno probabilmente arrestato l'avanzamento della sua carriera professionale a corte.[26]
Quando non aveva neppure sei anni, nel 1762, il padre portò Wolfgang e la sorella, pure lei assai dotata, a Monaco, affinché suonassero per la corte del principe elettore bavarese Massimiliano III nel loro primo concerto ufficiale; alcuni mesi dopo si recarono a Vienna, dove furono presentati alla corte imperiale e dove proseguirono le loro esibizioni in varie abitazioni nobiliari.
Verso la metà del 1763, egli ottenne il permesso di assentarsi dal suo posto di vice Kapellmeister presso la corte del principe arcivescovo di Salisburgo.
Tutta la famiglia intraprese così un lungo viaggio nel continente, che durò più di tre anni. I Mozart soggiornarono nei principali centri musicali dell'Europa occidentale della seconda metà del Settecento: Monaco di Baviera, Augusta, Stoccarda, Mannheim, Ludwigsburg, Schwetzingen, Heidelberg, Magonza, Francoforte, Coblenza, Colonia, Aquisgrana, Bruxelles, Parigi (giungendovi il 18 novembre 1763 e trascorrendovi il primo inverno), Versailles (dove soggiornarono e si esibirono nella prestigiosa Reggia), poi la lunga sosta a Londra fino al luglio del 1765, quindi di ritorno attraverso Dover, L'Aia, Amsterdam, Utrecht, Malines, Parigi (arrivo il 10 maggio 1766), Digione, Lione, Ginevra, Losanna, Berna, Zurigo, Donaueschingen, Ulma, nuovamente Monaco di Baviera e infine il rientro a Salisburgo il 29 novembre 1766.
Mozart suonò nella maggior parte di queste città, da solo o con la sorella, o presso una corte, o in pubblico, o in una chiesa. Le lettere che Leopold scrisse agli amici di Salisburgo raccontano l'universale ammirazione riscossa dai prodigi di suo figlio.
A Parigi incontrarono molti compositori tedeschi e qui furono pubblicate le prime composizioni di Mozart (sonate per clavicembalo e violino, dedicate a una principessa reale; cfr. KV 6-9).
A Londra conobbero, tra gli altri, Johann Christian Bach, il figlio più giovane di Johann Sebastian e una delle figure di primo piano della vita musicale londinese; sotto la sua influenza, Mozart compose le sue prime sinfonie (n. 1, n. 4 e K 19a). Seguì un'altra sinfonia durante il soggiorno a L'Aia, nel viaggio di ritorno (Sinfonia n. 5).
Dopo poco più di nove mesi trascorsi a Salisburgo, i Mozart partirono per Vienna nel settembre 1767, dove restarono per quindici mesi, escluso un intervallo di dieci settimane trascorse a Brno (Brünn) e Olomouc (Olmütz) durante un'epidemia di vaiolo. Mentre a Salisburgo Mozart aveva composto la prima parte di un singspiel sacro in tedesco, Die Schuldigkeit des ersten Gebots, (K 35), rappresentato nel palazzo dell'arcivescovo, un intermezzo in latino, Apollo et Hyacinthus (K 38), rappresentato all'università, e una cantata per la Passione, Grabmusik (K 42), rappresentata nel Duomo, a Vienna compose un altro singspiel tedesco in un atto, Bastien und Bastienne (K 50), che fu rappresentato privatamente. Maggiori speranze furono riposte nella prospettiva di vedere rappresentata nel teatro di corte un'opera buffa italiana, La finta semplice (K 51), che tuttavia vennero deluse, con grande indignazione di Leopold.
Una grande messa solenne (probabilmente la Messa solenne in Do minore "Weisenhausmesse", K 139) fu invece eseguita alla presenza della corte imperiale in occasione della consacrazione della chiesa dell'Orfanotrofio. La finta semplice venne rappresentata l'anno seguente, 1769, nel palazzo dell'arcivescovo a Salisburgo. Nel mese di ottobre, Mozart fu nominato Konzertmeister senza stipendio presso la corte salisburghese.
Appena tredicenne, Mozart aveva acquisito una notevole familiarità con il linguaggio musicale del suo tempo. Le prime sonate di Parigi e Londra, i cui autografi includono l'ausilio della mano di Leopold, mostrano un piacere ancora infantile nel modellare le note e la tessitura musicale. Le sinfonie di Londra e de L'Aia attestano la rapida e originale acquisizione da parte di Mozart della musica che aveva incontrato. Analoghe dimostrazioni provengono dalle sinfonie composte a Vienna (come la Sinfonia n.6 e, specialmente, n. 8), caratterizzate da una tessitura più ricca e da uno sviluppo più approfondito. La sua prima opera italiana, poi, mostra un veloce apprendimento delle tecniche dello stile buffo.
«La nostra musica da chiesa è assai differente di quella d'Italia, e sempre più, che una Messa con tutto il Kyrie, Gloria, Credo, la Sonata all'Epistola, l'offertorio ò sia Mottetto, Sanctus ed Agnus Dei e anche la più Solenne, quando dice la Messa il Principe stesso non ha da durare che al più longo tre quarti d'ora. Ci vuole uno studio particolare per questa sorta di composizione, e che deve però essere una Messa con tutti strumenti - Trombe di guerra, Tympani etc.»
(Wolfgang Amadeus Mozart, 1776[27])Fu la ricerca di nuove committenze l'origine dei numerosi viaggi dei Mozart, di cui tre in Italia. Dal 1769 al 1773 Wolfgang effettuò con il padre tre viaggi in Italia, durante i quali suonò e ascoltò musica nelle varie città.
Primo viaggio (1769-1771):
Secondo viaggio (1771):
Terzo viaggio (1772-1773):
La sosta più lunga fu di due settimane trascorse a Verona, dove la stampa riferì entusiasticamente del concerto pianistico di Wolfgang del 5 gennaio 1770 per l'Accademia Filarmonica di Verona nella Sala Maffeiana del Teatro Filarmonico. Padre e figlio assistettero il 3 gennaio a una rappresentazione di Ruggiero di Pietro Alessandro Guglielmi al Teatro Filarmonico che Wolfgang descrisse in modo sprezzante in una lettera a sua sorella Maria Anna Mozart. Il ragazzo ebbe anche il suo ritratto dipinto da un artista locale, Saverio Dalla Rosa e il 7 gennaio tenne un concerto organistico nella Chiesa di San Tomaso Cantuariense.
I soggiorni milanesi sarebbero diventati un'importante esperienza formativa: Mozart (talvolta chiamato "Volgango Amadeo") rimase a Milano complessivamente per quasi un anno della sua breve vita. Incontrò musicisti (Johann Adolph Hasse, Niccolò Piccinni, Giovanni Battista Sammartini, Johann Christian Bach e forse anche Giovanni Paisiello), cantanti (Caterina Gabrielli) e scrittori (Giuseppe Parini, che scrisse per lui alcuni libretti).
Hasse rimase molto colpito dalle capacità del ragazzo, tanto che disse: "Questo ragazzo ci farà dimenticare tutti".[28]
Tra le più importanti conoscenze che fece Mozart spicca quella del conte trentino Carlo Giuseppe Firmian, descritto come il "re di Milano", un colto e influente mecenate. Il suo supporto fu vitale per il successo dell'intero viaggio in Italia.[29]
Lasciò Milano il 15 marzo 1770, per tornarci più volte in seguito. Arrivato a Lodi, sulla strada per Parma, scrisse le prime tre parti (adagio, allegretto e minuetto) del Quartetto per archi n. 1, K 80, completato con il Rondò che avrebbe scritto più tardi, forse a Vienna (1773) o a Salisburgo (1774). Tornò a Milano per rappresentare le sue opere liriche. L'ultima a esordire in un teatro italiano fu il Lucio Silla, nel 1772.
Un altro importante soggiorno fu quello a Bologna (in due riprese, da marzo a ottobre 1770). Ospite del conte Gian Luca Pallavicini, ebbe l'opportunità di incontrare musicisti e studiosi (dal celebre castrato Farinelli ai compositori Vincenzo Manfredini e Josef Mysliveček, fino allo storico della musica inglese Charles Burney e padre Giovanni Battista Martini). A Parma ebbe l'occasione di assistere a un concerto privato del celebre soprano Lucrezia Agujari, detta La Bastardella.
Wolfgang prese lezioni di contrappunto da padre Giovanni Battista Martini, all'epoca considerato come il più grande teorico musicale e il più grande esperto d'Europa nel contrappunto rinascimentale e barocco.[31]
Da lui Mozart apprese soprattutto i precetti del contrappunto nello stile di Palestrina ed approfondì l'arte violinistica ed orchestrale di autori come Corelli, Tartini e Torelli.
A Firenze, grazie alla raccomandazione del conte Pallavicini, la famiglia Mozart ottenne udienza presso Palazzo Pitti con il granduca e futuro imperatore Leopoldo II.[32] Ritrovarono a Firenze anche il violinista Pietro Nardini, già incontrato all'inizio del viaggio in Italia.[33] Nardini e Wolfgang suonarono insieme in un lungo concerto serale al palazzo estivo del Granduca.[32]
Mozart diede una straordinaria prova delle sue capacità a Roma: ascoltò nella Cappella Sistina il Miserere di Gregorio Allegri e riuscì nell'impresa di trascriverlo interamente a memoria dopo solo due ascolti. Si trattava di una composizione a nove voci, apprezzata a tal punto da essere proprietà esclusiva della cappella pontificia, tanto da essere intimata la scomunica a chi se ne fosse impossessato al di fuori delle mura vaticane. La portata del fatto sta nell'età del giovanissimo compositore e all'incredibile capacità mnemonica nel ricordare un brano che riassume nel proprio finale nove parti vocali. La notizia dell'impresa raggiunse anche papa Clemente XIV.[34]
Il soggiorno a Roma vide Mozart impegnato in un'intensa attività compositiva: infatti, è durante questo periodo che scrisse opere come la Contraddanza K 123 (K6 73g) e l'aria Se ardire, se speranza K 82 (K6 73o).[35]
Dopo tale impresa i salisburghesi, passando per Sessa Aurunca (nel cui edificio vanvitelliano alloggiò) e Capua, si recarono a Napoli, dove arrivarono il 14 maggio 1770 e soggiornarono per sei settimane. Qui ebbero un incontro con il segretario di Stato Bernardo Tanucci e con l'ambasciatore britannico William Hamilton, che avevano già conosciuto a Londra.[36] Mozart tenne anche un concerto al conservatorio della Pietà dei Turchini, durante il quale qualcuno attribuì all'anello che portava al dito la genesi delle sue incredibili capacità musicali; Wolfgang se lo tolse e lo posò sulla tastiera, dimostrando che il suo talento non derivava da virtù magiche.[37]
Napoli nel 1770 era una delle capitali europee della musica, oltre che quella di un regno e i Mozart ebbero modo di venire direttamente a contatto con il mondo del teatro d'opera della città. Wolfgang era attratto dagli innovatori dell'opera italiana: Domenico Cimarosa, Tommaso Traetta, Pasquale Cafaro, Gian Francesco de Majo e principalmente Giovanni Paisiello.  Secondo il musicologo Hermann Abert, da Paisiello il giovane Mozart doveva apprendere diversi aspetti "[...] sia per i nuovi mezzi espressivi sia per l'uso drammatico-psicologico degli strumenti".[38].
Ferdinando IV di Borbone, all'epoca diciottenne, non lo ricevette a corte ma soltanto in una visita di cortesia presso la reggia di Portici. Mozart fu invitato a scrivere un’opera per la successiva stagione del San Carlo, ma fu costretto a rifiutare a causa di un precedente impegno preso con il teatro Ducale di Milano. Della difficoltà di emergere a Napoli come operista, a causa della concorrenza di numerosi e affermati musicisti locali attivi in quella città, Wolfgang si ricorderà in una lettera al padre Leopold del 23 febbraio 1778:[39] «Adesso la questione è solo: dove posso avere più speranza di emergere? forse in Italia, dove solo a Napoli ci sono sicuramente 300 Maestri [...] o a Parigi, dove circa due o tre persone scrivono per il teatro e gli altri compositori si possono contare sulle punte delle dita?»
Il viaggio di ritorno verso la casa natale iniziò con una nuova sosta a Roma, dove papa Clemente XIV gli conferì lo Speron d'Oro.[40] Quindi lasciarono Roma per recarsi sulla costa adriatica, fermandosi ad Ancona e Loreto; questo soggiorno colpì il giovane Mozart, tanto che, subito dopo il ritorno, scrisse una composizione sacra dedicata alla Madonna di Loreto dal titolo Litaniae Lauretanae Beatae Mariae Virginis, seguita tre anni più tardi, nel 1774, da una seconda.
In seguito, i Mozart si fermarono nuovamente a Bologna, dove sostarono per qualche tempo a causa di un infortunio alla gamba di Leopold.[41] Durante questo periodo, Wolfgang compose il Minuetto per orchestra K 122 (K673t)[42] e un Miserere in La minore, K 85 (K6 73s).[43] Nello stesso periodo gli fu recapitato il libretto dell'opera seria Mitridate, re di Ponto (scritto da Vittorio Amedeo Cigna-Santi), sul quale iniziò a lavorare.[44]
Fu probabilmente all'inizio di ottobre del 1770 che Mozart iniziò gli studi sotto Giovanni Battista Martini.[45] Fu presso di lui che sostenne l'esame per l'aggregazione all'Accademia Filarmonica di Bologna (allora titolo ambitissimo dai musicisti europei). La prova consisteva nella redazione di un'antifona di canto fermo (Mozart presentò la sua opera Quaerite primum regnum, K. 86/73v). Il difficile e rigido esame dell'ancora giovane Mozart non fu particolarmente brillante (al musicista venne assegnato un "6"); tuttavia, esistono prove del fatto che lo stesso Martini lo abbia aiutato in sede d'esame per favorirne la promozione. A riprova del travagliato esito, infatti, del cosiddetto compito di Mozart esistono oggi due copie, la prima esposta al Museo internazionale e biblioteca della musica e quella "definitiva" all'Accademia Filarmonica di Bologna.[46]
La famiglia giunse in seguito a Milano, dove il 26 dicembre, al Teatro Regio Ducale, fu eseguita la prima rappresentazione dell'opera Mitridate, che vide Wolfgang al clavicembalo.[47] L'evento fu un clamoroso successo, al punto che furono organizzate ventidue repliche.[48]
La tappa successiva fu costituita da un breve soggiorno a Torino, dove Mozart ebbe occasione di incontrare alcuni importanti musicisti, come il violinista Gaetano Pugnani e il quindicenne bambino prodigio Giovanni Battista Viotti. A Padova, Don Giuseppe Ximenes, Principe di Aragona e mecenate della musica, commissionò a Mozart un oratorio, La Betulia Liberata K 118 (K6 74c), che rimane l'unica opera di questo genere che il compositore abbia realizzato.
Nel marzo del 1771[49] i Mozart tornarono a Salisburgo, dove rimasero fino ad agosto, quando ripartirono per un secondo viaggio in Italia, di quattro mesi.
Il 23 settembre 1771 a Milano[50] venne rappresentata l'opera seria Ascanio in Alba su libretto di Giuseppe Parini per celebrare le nozze dell'arciduca Ferdinando d'Asburgo-Este d'Austria con la principessa Maria Beatrice Ricciarda d'Este di Modena. Nonostante il fitto programma di impegni, Mozart riuscì comunque a comporre la Sinfonia n. 13, K 112.[51] Anche un'altra sinfonia, K 96, fu probabilmente scritta in questo periodo, nonostante rimangano ancora dubbi sulla datazione.[52]
Nel dicembre dello stesso anno i Mozart tornarono a Salisburgo. Dopo pochi giorni morì l'arcivescovo Sigismund III von Schrattenbach, sostituito successivamente da Hieronymus von Colloredo, al quale Wolfgang dedicò l'opera seria Il sogno di Scipione.[53] Il padre Leopold, intuendo che con il nuovo arcivescovo le possibilità di promozione si sarebbero ridotte notevolmente, organizzò un terzo viaggio in Italia per sperare di trovare una degna occupazione al figlio.[54]
Il terzo e ultimo viaggio in Italia durò dall'ottobre del 1772 fino al marzo del 1773, periodo in cui di rilievo è la composizione e la rappresentazione dell'opera Lucio Silla a Milano. Dopo un iniziale insuccesso, questa opera seria divenne ancor più rappresentata e apprezzata della precedente e applaudita Mitridate, re di Ponto.
Stante questo successo, Leopold sperò di ottenere un posto per il figlio Wolfgang presso la corte del granduca Leopoldo I di Toscana.[55] Nell'attesa di avere udienza presso il granduca, Wolfgang compose i cosiddetti sei Quartetti Milanesi (dal K 155/134a al K 160/159a) e il famoso mottetto Exsultate, jubilate, K 165.[56] Tuttavia, la risposta del granduca fu negativa.[55] Per tale motivo, i Mozart ritornarono a Salisburgo e né Wolfgang né Leopold sarebbero più rientrati in Italia.[57]
Dopo il ritorno dal viaggio in Italia, Mozart svolse regolarmente l'incarico, che gli era stato assegnato l'anno precedente, di konzertmeister con stipendio annuo di 150 fiorini presso la corte dell'arcivescovo Colloredo. Il compositore aveva un gran numero di amici e ammiratori a Salisburgo,[58] perciò ebbe l'opportunità di concentrare la sua attività compositiva su numerosi generi, tra cui varie sinfonie (alcune delle quali appunto chiamate da Alfred Einstein Sinfonie Salisburghesi: la n. 22, n. 23, n. 24, n. 26 e n. 27),[59] messe, serenate e alcune opere minori. Dopo la composizione dell'opera seria Il re pastore, tra il giugno e il dicembre del 1775, Mozart sviluppò un certo entusiasmo per i concerti per violino e orchestra (poi rimasti gli unici di questo genere concepiti dal musicista), componendone quattro di seguito, dopo il primo composto nel 1773. Gli ultimi tre (n. 3 K 216, n. 4 K 218, n. 5 K 219) sono attualmente tra i più eseguiti del repertorio mozartiano.
Nel 1776 il suo interesse si spostò sui concerti per pianoforte, tra i quali è degno di rilievo il concerto per pianoforte e orchestra n. 9 "Jeunehomme", considerato dai critici un'opera cardine dell'evoluzione stilistica del compositore.[60]
Nonostante il successo artistico, lo scontento di Mozart verso Salisburgo crebbe sempre di più e aumentarono gli sforzi per la ricerca di una posizione alternativa: una delle ragioni si può ricercare nel basso stipendio che percepiva (150 fiorini all'anno);[61] un altro motivo era l'assenza di commissioni per opere, genere a cui invece Mozart amava dedicarsi. La situazione peggiorò con la chiusura del teatro di corte nel 1775.[62]
Due viaggi interruppero il lungo periodo salisburghese, entrambi con lo scopo di trovare una nuova occupazione: Mozart visitò Vienna con il padre dal 14 luglio al 26 settembre 1773, dove compose la serie dei cosiddetti sei Quartetti viennesi K 168-173, e Monaco di Baviera dal 6 dicembre 1774 al 7 marzo del 1775. Nessuno dei due soggiorni fu fruttifero, nonostante il successo dell'anteprima dell'opera buffa La finta giardiniera, a Monaco.[63] Al soggiorno monacense risalgono le sue prime sei sonate per pianoforte (K 279, K 280, K 281, K 282, K 283 e K 284).
Nell'agosto 1777 Mozart chiese all'arcivescovo il permesso di assentarsi da Salisburgo[64] e il 23 settembre, accompagnato dalla madre, partì alla ricerca di nuove opportunità, in un viaggio che lo avrebbe portato a visitare Augusta, Mannheim, Parigi e Monaco di Baviera.[65]
Mozart e la madre si recarono in primo luogo ad Augusta, facendo visita ai parenti paterni; qui Wolfgang iniziò una vivace amicizia con la cugina Maria Anna Thekla (con la quale in seguito tenne una corrispondenza piena di umorismo allegro e osceno con frequenti riferimenti coprofili e coprofagi).[66][67]
Alla fine di ottobre, Mozart e la madre giunsero a Mannheim, la cui corte dell'Elettore Palatino Carlo Teodoro era una delle più famose ed evolute in Europa sul piano musicale con la sua scuola. Mozart vi soggiornò per più di quattro mesi, durante i quali divenne amico di vari musicisti, insegnò musica e suonò. Fu a Mannheim che Mozart si innamorò di Aloysia Weber, un soprano, seconda delle quattro figlie di un copista di musica. In questa città si dedicò anche alla composizione, con la stesura delle sonate per pianoforte n. 7 e n. 9, delle sonate per violino e pianoforte K. 301, K. 302, K. 303 e K. 305, dei concerti per flauto e orchestra n. 1 e n. 2 e di altre composizioni minori.
A Mannheim, però, Mozart non riuscì a trovare impiego malgrado le pressioni dell'amico drammaturgo Otto Heinrich von Gemmingen-Hornberg,[68] per cui partì per Parigi, insieme a sua madre, il 14 marzo 1778.[69]
In una delle sue lettere si cita un possibile incarico da organista presso la reggia di Versailles, ma Mozart non si mostrò disponibile ad accettarlo.[70] Presto si ritrovò nei debiti e dovette impegnare alcuni suoi oggetti di valore.[71]
Tra le composizioni più famose scritte durante il viaggio a Parigi si ricordano la sonata per pianoforte n. 8 K. 310/300d, le sonate per violino e pianoforte K. 304/300c e K. 306/300l, il balletto Les petits riens K. 299b, il concerto per flauto, arpa e orchestra K. 299/297c e la Sinfonia n. 31 (anche chiamata, appunto, Parigi): quest'ultima fu eseguita per la prima volta a Parigi privatamente il 12 giugno 1778 e pubblicamente il 18 dello stesso mese.[72]
Il giorno della prima della sinfonia, il 18 giugno, sua madre era seriamente malata. Secondo Halliwell, si ritardò a chiamare un medico a causa della mancanza di liquidità.[73] Anna Maria Pertl coniugata Mozart, morì il 3 luglio 1778[74] e fu sepolta nel cimitero di Saint Eustache; al suo funerale erano presenti solo il figlio Wolfgang e l'amico Heina.[75]
Durante il soggiorno a Parigi, Leopold negoziava con l'arcivescovo la riassunzione del figlio alla corte di Salisburgo.[76] Con l'aiuto della nobiltà locale, fu offerto a Wolfgang un posto come organista di corte, con un salario annuo di 450 fiorini.[77] Dopo aver lasciato Parigi nel settembre 1778, sostò a Mannheim e a Monaco, serbando ancora qualche speranza di ottenere qualche incarico al di fuori di Salisburgo. A Monaco, in particolare, incontrò nuovamente Aloysia, nel frattempo divenuta una cantante di successo, che però non si dimostrò più interessata al compositore.[78]
Nella metà di gennaio del 1779, Mozart tornò a Salisburgo e il 17 accettò la nomina a organista di corte; nel periodo 1779-80 la sua attività compositiva fu regolare e la sua produzione musicale manifestò una maggiore maturità acquisita grazie all'esperienza fatta durante l'ultimo viaggio all'estero.[79] Fra le sue opere più notevoli di questo periodo si trovano tre importanti sinfonie (Sinfonia n. 32 in sol maggiore K 318, Sinfonia n. 33 in si bemolle maggiore K 319 e Sinfonia n. 34 in do maggiore K 338), oltre alla cosiddetta serenata "Posthorn" K 320, alla sinfonia concertante per violino, viola e orchestra in mi bemolle maggiore K 364 e alla Messa in do maggiore K 317 detta "dell'Incoronazione"; al di là delle apparenze, tuttavia, lo stato d'animo del compositore non era affatto tranquillo.[80]
Il suo datore di lavoro, l'arcivescovo Hieronymus von Colloredo, non era propriamente un oscurantista: aderiva al programma di riforme promosse dall'imperatore Giuseppe II, favoriva la cultura e la ricerca e il suo governo manifestava una certa apertura sul piano politico e religioso.[81] Attuò però una politica di tagli e di riduzioni di spese nell'ambito delle istituzioni musicali cittadine, fra l'altro chiudendo gli spazi riservati al teatro musicale; negli anni precedenti Mozart si era lamentato più volte, nelle sue lettere, della scarsa considerazione in cui Colloredo teneva la musica e i musicisti e del fatto che a Salisburgo non si potessero rappresentare né ascoltare opere liriche.[82]
Dopo il suo ritorno a Salisburgo, il massimo desiderio di Mozart era quello di comporre melodrammi e in particolare opere italiane, un genere musicale per il quale egli si sentiva particolarmente portato; era dai tempi della Finta giardiniera, cioè da sei anni, che Mozart non si cimentava in questo tipo di opere.[83] Dopo il ritorno da Parigi, però, e fino all'estate del 1780, il catalogo mozartiano registra due soli tentativi nel campo della musica per il teatro: l'incompiuto singspiel Zaide e le musiche di scena per il dramma Thamos, re d'Egitto.[84]
Verso la fine dell'estate 1780, la corte di Monaco di Baviera commissionò a Mozart la realizzazione dell'opera seria Idomeneo, re di Creta ossia Ilia e Idamante; Mozart iniziò a comporla nel mese di ottobre e il 5 novembre 1780 partì per Monaco, con il permesso, da parte dell'arcivescovo, di rimanervi sei settimane allo scopo di ultimare l'opera e curarne l'allestimento.[85]
Il 29 gennaio 1781 Idomeneo andò in scena; nulla si sa di certo sul suo esito (l'opera fu comunque replicata il 3 febbraio e il 3 marzo); nemmeno si conosce il motivo per il quale Mozart, contrariamente alle sue aspettative, non riuscì a ottenere un impiego come compositore presso la corte di Monaco.[86]
Mozart partì da Monaco il 12 marzo alla volta di Vienna, obbedendo a un ordine dell'arcivescovo che proprio in quel periodo si era recato nella capitale e desiderava ora farvi esibire i propri musicisti di corte; in tal modo l'arcivescovo contava di accrescere il proprio prestigio nei confronti dell'aristocrazia viennese.[87]
Il 16 marzo 1781 Mozart giunse a Vienna,[87] dove accusò apertamente l'avarizia e l'ingiustizia dell'arcivescovo, chiedendo rispetto per la sua dignità d'artista e soprattutto non intendendo più accettare che Colloredo lo trattasse come un servo; agli inizi di maggio, dopo un litigio con l'arcivescovo, Mozart presentò per iscritto a quest'ultimo le proprie dimissioni.[88] Sulle prime, le dimissioni non furono accettate; il camerlengo dell'arcivescovo (conte Karl Joseph Felix Arco), d'accordo con Leopold Mozart, tentò più volte di convincere Wolfgang a ritirare le proprie dimissioni, ma senza successo; alla fine, in un ultimo, teso colloquio, lo spazientito conte Arco buttò letteralmente fuori Mozart con una pedata nel fondoschiena.[89] Mozart narrò l'episodio al proprio padre in una risentita lettera datata 9 giugno:
«Questo dunque è il conte che (stando alla sua ultima lettera) mi ha tanto sinceramente a cuore, questa è dunque la corte dove dovrei servire, una corte in cui uno che intende presentare una supplica per iscritto, invece di essere agevolato nell'inoltrarla, viene trattato in questo modo? [...] Ora non ho più bisogno di mandare nessuna supplica, essendo la cosa ormai chiusa. Su tutta questa faccenda non voglio più scrivere nulla ed anche se ora l'arcivescovo mi pagasse 1.200 fiorini, dopo un trattamento simile proprio non andrei da lui. Quanto sarebbe stato facile convincermi! Ma con le buone maniere, senza arroganza e senza villania. Al conte Arco ho fatto sapere che non ho più nulla da dirgli, dopo quella prima volta in cui mi ha aggredito in quel modo, trattandomi come un farabutto, cosa che non ha alcun diritto di fare. [...] Che gliene importa se voglio avere il mio congedo? E se è davvero tanto ben intenzionato nei miei confronti, cerchi allora di convincermi con dei motivi fondati, oppure lasci che le cose seguano il loro corso. Ma non si azzardi a chiamarmi zotico e furfante e non mi metta alla porta con un calcio nel culo; ma dimenticavo che forse l'ha fatto per ordine di Sua grazia.»
(Wolfgang Amadeus Mozart, lettera del 9 giugno 1781[90].)Nei primi giorni del maggio 1781, Mozart andò ad abitare in una stanza in affitto a casa della madre di Aloysia Weber, la signora Maria Caecilia Stamm vedova Weber; quest'ultima viveva a Vienna assieme alle tre figlie nubili, Josepha, Sophie e Constanze; con Constanze Weber, allora diciannovenne, Mozart di lì a poco si fidanzò.[91] La coppia, nonostante la contrarietà di Leopold Mozart, si sposò a Vienna, nella cattedrale di Santo Stefano, il 4 agosto 1782.[92] Constanze ebbe numerose gravidanze, ma solo due figli sopravvissero fino all'età adulta, Carl Thomas e Franz Xaver Wolfgang.
Nel corso del 1781, Mozart completò una serie di sei importanti sonate per violino e pianoforte (K 296, K 376, K 377, K 378, K 379 e K 380), dedicate alla sua allieva Josepha Auernhammer e pubblicate dall'editore Artaria & C. alla fine di novembre.[93] Fra le altre composizioni di quest'anno spiccano due serie di variazioni per pianoforte, rispettivamente K 265 e K 353, nonché la Serenata in mi bemolle maggiore K 375.[94] È incerto se la Serenata in si bemolle maggiore K 361 "Gran Partita" sia stata composta quasi del tutto a Monaco prima del marzo 1781 e poi completata a Vienna, oppure se appartenga interamente al periodo viennese.[86]
Il 16 luglio 1782, al Burgtheater di Vienna, ebbe luogo con successo la prima rappresentazione de Il ratto dal serraglio, primo importante capolavoro nel genere del Singspiel.[95] Il libretto, ambientato in Turchia, è venato di comicità popolare e, in una certa misura, attinge agli stereotipi sul mondo musulmano diffusi nell'Europa dell'epoca; tuttavia, nella vicenda (particolarmente nella figura del magnanimo pascià Selim) trovano espressione le idee umanitarie e cosmopolitiche, improntate alla tolleranza, proprie dell'Illuminismo.[96] Con quest'opera, Mozart conferì per la prima volta a un Singspiel un'eccezionale e inedita abbondanza e complessità di contenuti musicali, specialmente nella scrittura delle parti per l'orchestra. Ciò forse impressionò il pubblico dell'epoca, se è vero l'aneddoto tradizionale secondo cui l'imperatore Giuseppe II avrebbe rimproverato a Mozart di avere adoperato "troppe note", suscitando così l'orgogliosa risposta del compositore: "neanche una più del necessario, Maestà".[97]
La composizione del Ratto dal serraglio diede l'occasione a Mozart di enunciare, in una lettera a suo padre, quello che viene considerato un principio cardine della sua poetica teatrale.[98] A proposito dell'aria di Osmin (personaggio negativo, che in questo brano esprime sentimenti di rabbia e di odio), Mozart scrisse:
«Un uomo in preda a una collera tanto violenta oltrepassa ogni norma, ogni misura, ogni limite, non è più in sé e allora anche la musica non deve essere più in sé. Ma [...] le passioni, violente o no, non devono mai essere espresse fino al punto da suscitare disgusto e la musica, anche nella situazione più terribile, non deve mai offendere l'orecchio, ma piuttosto dilettarlo e restare pur sempre musica [...].»
(Wolfgang Amadeus Mozart, lettera del 26 settembre 1781[99])All'estate del 1782 risale l'importante Sinfonia in re maggiore K 385 "Haffner"; dello stesso anno è anche la Serenata in do minore K 388.[100]
Nel periodo fra l'agosto e l'ottobre 1783, Mozart e sua moglie furono ospiti a Salisburgo, dove però la coppia non riuscì a conquistarsi la benevolenza del padre e della sorella del compositore. Nella sua città natale (dove, dopo di allora, il compositore non tornò mai più) Mozart fece eseguire, il 25 agosto 1783, l'incompiuta Messa in do minore K 427, in cui la parte di soprano fu cantata dalla stessa Constanze; tornando a Vienna, Wolfgang e Constanze passarono da Linz, dove si fermarono un mese e dove Mozart scrisse la Sinfonia in do maggiore K 425 (3 novembre 1783), fortemente influenzata da Joseph Haydn, soprattutto nel movimento finale.[101]
Fra l'agosto e il novembre 1783 (la datazione è tuttavia incerta), Mozart compose quattro importanti sonate per pianoforte: la Sonata n. 10 in do maggiore K 330, la Sonata n. 11 in la maggiore K 331 (il cui movimento finale è la celeberrima Marcia turca), la Sonata n. 12 in fa maggiore K 332[102] e la Sonata n. 13 in si bemolle maggiore K 333, quest'ultima scritta molto probabilmente a Linz nel mese di novembre.[103]
Alla primavera del 1782 risale l'incontro di Mozart con il barone Gottfried van Swieten, un facoltoso cultore di musica barocca. Grazie a lui, Mozart poté studiare importanti composizioni di Bach e di Haendel, poco conosciute all'epoca di Mozart, ma di cui van Swieten possedeva le partiture nella sua biblioteca; la conoscenza approfondita dei maestri del contrappunto arricchì in modo significativo il bagaglio tecnico ed espressivo del Mozart maturo.[104] Su impulso di van Swieten, Mozart, fra l'altro, trascrisse per quartetto d'archi cinque fughe de Il clavicembalo ben temperato di Bach;[105] più tardi, nominato direttore musicale della Società di musica antica promossa dallo stesso van Swieten, Mozart riorchestrò e condusse Aci e Galatea, il Messiah, Alexander's Feast e l'Ode per il giorno di Santa Cecilia di Haendel.[106]
La rinnovata familiarità con il contrappunto si manifestò inizialmente attraverso una serie di composizioni pianistiche in stile dotto: preludi, fughe, fantasie e suite (K 394, K 396, K 397, K 399 e K 401), la cui composizione avvenne spesso su impulso della moglie Constanze, che aveva una particolare predilezione per questo stile musicale ed esortava spesso Wolfgang a scrivere fughe.[107] La perfetta assimilazione del contrappunto bachiano si manifesta pienamente nell'Adagio e fuga in do minore per quartetto d'archi K 546 (giugno 1788), che è la trascrizione di una precedente fuga per due pianoforti.[108]
Fra le opere che attestano il più alto livello di maturità raggiunto in questi anni dall'arte mozartiana, oltre alla già ricordata Messa in do minore K 427, si possono annoverare i sei quartetti per archi dedicati a Haydn (K 387, K 421, K 428, K 458, K 464 e K 465).[109]
Nel periodo compreso fra l'inverno 1782-83 e la primavera del 1786, i concerti per pianoforte e orchestra furono la più rilevante fonte di introiti per Mozart.[110] In tale arco di tempo, Mozart ne compose quattordici, che lui stesso eseguì a Vienna, in veste di pianista e direttore d'orchestra, in una serie di concerti su sottoscrizione da lui stesso organizzati, riscuotendo notevole successo; nel marzo 1784 la lista degli abbonati ai suoi concerti comprendeva 106 persone, fra cui molti esponenti dell'aristocrazia grande e piccola, vari alti burocrati statali nonché gli intellettuali più importanti della città.[111] Questo periodo di fortuna, anche economica, si interruppe dopo il maggio 1786, in coincidenza con l'allestimento viennese de Le nozze di Figaro: tale opera infatti, con i suoi fermenti di critica sociale, alienò a Mozart i favori del pubblico aristocratico e alto-borghese della capitale, il quale, da allora, iniziò a preferirgli musicisti magari meno geniali, ma artisticamente e politicamente meno inquietanti (come ad esempio Leopold Kozeluch).[112]
I più alti capolavori della serie sono il concerto in re minore n. 20 K 466, il concerto in do minore n. 24 K 491 e il concerto in la maggiore n. 23 K 488; particolarmente importanti sono anche il concerto in sol maggiore n. 17 K 453, il concerto in fa maggiore n. 19 K 459 e il concerto in do maggiore n. 25 K 503.[113] Il concerto in re maggiore n. 26 K 537, composto nel febbraio 1788,[114] è detto "dell'incoronazione" in quanto fu eseguito dal suo autore a Francoforte il 15 ottobre 1790[115] in occasione dei festeggiamenti per l'incoronazione di Leopoldo II.
Il concerto in re minore K 466, eseguito per la prima volta a Vienna l'11 febbraio 1785, è oggi il più conosciuto dei concerti mozartiani ed è in assoluto fra i più eseguiti di tutto il repertorio pianistico; la sua spiccata dialettica tematica e la sua intensità di sentimento ebbero una forte influenza su Beethoven, il quale, dopo la morte di Mozart, fu uno dei primi interpreti di questo concerto e per esso scrisse anche due cadenze (rispettivamente per il primo movimento e per il finale)[116].
Fra le principali opere cameristiche di questo periodo vi sono il quartetto per pianoforte e archi in sol minore K 478, del 1785, e il quartetto per pianoforte e archi in mi bemolle maggiore K 493, del 1786; quest'ultimo è caratterizzato da un particolare slancio innovativo che fu apprezzato anche dai contemporanei; notevole anche il trio per pianoforte, viola e clarinetto in mi bemolle maggiore K 498, detto "delle boccette" in quanto, secondo la tradizione, sarebbe stato composto durante una partita a boccette fra amici.[108] Il quintetto per pianoforte, oboe, clarinetto, corno e fagotto in mi bemolle maggiore K 452 era altamente stimato dallo stesso Mozart, che lo considerò la sua migliore composizione fino ad allora.[117]
In questi anni si collocano anche le ultime quattro sonate per violino e pianoforte: la sonata in si bemolle maggiore K 454 (21 aprile 1784) è dedicata alla violinista italiana Regina Strinasacchi; la sonata in mi bemolle maggiore K 481 (12 dicembre 1785) è notevole per il suo lirismo; a esse fanno seguito l'appassionata sonata in la maggiore K 526 (24 agosto 1787) e la sonata in fa maggiore K 547 (26 giugno 1788).[118]
La Fantasia in do minore K 475 per pianoforte solo e la sonata per pianoforte n. 14 in do minore K 457 risalgono entrambe al 1785.[119] La sonata per pianoforte n. 15 in fa maggiore, pubblicata nel 1788, si compone di un allegro e di un andante K 533 composti nel gennaio 1788 e di un rondò K 494 composto nel 1786.[120] La sonata per pianoforte n. 16 in do maggiore K 545 è del 26 giugno 1788,[121] mentre la sonata per pianoforte n. 17 in si bemolle maggiore K 570 e la sonata per pianoforte n. 18 in re maggiore K 576 risalgono rispettivamente al febbraio e all'estate del 1789.[122]
Dopo aver dato impulso, con Il ratto dal serraglio, allo sviluppo del genere Singspiel, Mozart offrì un altro importante contributo alla vocalità tedesca, e in particolare austriaca, con una serie di importanti Lied per voce e pianoforte, composti in gran parte dopo il 1784.[123] Il migliore di essi è considerato Das Veilchen K 476, del 1785, su testo di Goethe; gli altri Lieder, benché penalizzati dal divario qualitativo fra la musica di Mozart e i testi (spesso mediocri) dei letterati austriaci dell'epoca, comprendono comunque alcuni capolavori come Abendempfindung K 523, Traumbild K 530, entrambi del 1787, e Sehnsucht nach dem Frühling K 596.[124] Il tema di quest'ultimo è sostanzialmente lo stesso che appare nel rondò finale del concerto per pianoforte e orchestra n. 27 in si bemolle maggiore K 595.[125]
Dopo il Ratto dal serraglio, e per alcuni anni, Mozart trascurò la propria vocazione di operista per dedicarsi in prevalenza alla musica strumentale; rimasero incompiute due opere buffe, L'oca del Cairo e Lo sposo deluso, entrambe del 1783.[126]
Al carnevale del 1786 risale la messa in scena del singspiel in un atto Der Schauspieldirektor, commissionato a Mozart dall'imperatore Giuseppe II – assieme all'atto unico di Antonio Salieri Prima la musica e poi le parole – con l'intento esplicito di mettere a confronto i due compositori.[127] Le due opere furono infatti eseguite l'una dopo l'altra la sera del 7 febbraio 1786 nella tenuta imperiale di Schönbrunn, entrambe con successo.[128]
In quel periodo Mozart stava già lavorando alla composizione della commedia per musica Le nozze di Figaro, in collaborazione con il librettista Lorenzo Da Ponte (che nel 1783 era stato nominato poeta di corte per il teatro italiano).[129] Il soggetto era stato scelto dallo stesso Mozart, il quale aveva chiesto a Da Ponte di preparare un libretto dalla commedia omonima di Beaumarchais; Da Ponte riuscì a vincere le resistenze opposte dalla censura imperiale solo attenuando i toni della polemica sociale, che nel testo di Beaumarchais è forte ed esplicita contro la classe nobiliare e a favore del ceto borghese emergente, mentre nel libretto di Da Ponte risulta molto più sfumata e indiretta.[130] Nel luglio 1785 il libretto era pronto; la prima rappresentazione dell'opera si ebbe a Vienna il 1º maggio 1786 con un successo buono, ma non eccezionale;[131] l'opera non convinse la totalità del pubblico e la sera della prima si ebbero sia applausi sia fischi.[132] Fra il 1786 e il 1791, le Nozze di Figaro totalizzarono a Vienna 38 rappresentazioni (per avere un termine di paragone, si consideri che Il barbiere di Siviglia di Paisiello, considerata l'opera di maggior successo nella Vienna dell'epoca, ebbe in tale città 70 repliche fra il 1783 e il 1791).[133] Tuttavia, gli incassi di Mozart come operista durante tutto il 1786 non bastarono a compensare i mancati introiti derivanti dalla drastica riduzione della sua attività concertistica; inoltre, laddove come pianista Mozart era stato economicamente del tutto autonomo, adesso non lo era più come compositore di opere, in quanto doveva dipendere, per il loro allestimento, da impresari e direttori teatrali.[133]
Le nozze di Figaro costituiscono un momento decisivo nella storia del teatro in musica: con esse giunse a compimento l'evoluzione (avviata da Pergolesi e proseguita da Piccinni, Paisiello e Cimarosa) in virtù della quale l'opera buffa, da genere musicale considerato inferiore e popolaresco (in confronto alla pretesa superiorità artistica dell'opera seria), assurse a piena dignità estetica e divenne la più importante forma di teatro musicale, soppiantando l'opera seria grazie alla sua superiore efficacia drammatica, alla sua capacità di introspezione psicologica e alla perfetta integrazione fra testo e musica; qualità tutte che appunto in Mozart si trovano al massimo grado.[134]
Mentre a Vienna, come si è detto, l'esordio delle nozze di Figaro fu contrastato, l'opera ebbe un immediato e travolgente successo a Praga, dove fu allestita, presso il locale teatro italiano, dalla compagnia dell'impresario Guardasoni, nel dicembre 1786.[135] Mozart, l'11 gennaio 1787, giunse assieme alla moglie nella capitale boema, dove poté vedere di persona la grande popolarità raggiunta dalla sua opera, la cui musica veniva eseguita anche nelle sale da ballo, come egli stesso narrò in una vivace lettera a un amico viennese:
«Alle sei sono andato con il conte Canal al cosiddetto ballo di Bretfeld, dove è solito riunirsi il fior fiore delle bellezze praghesi [...] Io non ho ballato e non ho mangiato. La prima cosa perché ero stanco e la seconda per la mia innata stupidità. Ho però guardato con sommo piacere tutta questa gente saltarmi intorno, piena di autentica allegria, sulle note del mio figaro, trasformato in contraddanze e in allemande. Perché d'altro non si parla se non di figaro, altro non si suona, intona, canta e fischietta se non figaro. Non si assiste ad altra opera se non a figaro e sempre figaro. È certo un grande onore per me.»
(Wolfgang Amadeus Mozart, lettera del 15 gennaio 1787[136])A questo periodo dell'arte mozartiana appartengono il Quartetto per archi n. 20 K 499 e la Sinfonia in re maggiore K 504 (6 dicembre 1786), detta anche Sinfonia di Praga, capolavoro che precorre Beethoven.[137]
Il 28 maggio 1787 morì a Salisburgo Leopold Mozart; benché il suo testamento non ci sia pervenuto, appare probabile che egli abbia lasciato la quasi totalità delle sue sostanze alla figlia Maria Anna, praticamente diseredando Wolfgang.[138]
Da Praga, Mozart rientrò a Vienna nel febbraio 1787, avendo firmato il contratto con Guardasoni per una nuova opera; della stesura del testo poetico si incaricò Lorenzo Da Ponte, il quale si basò principalmente sul libretto che poco tempo prima Giovanni Bertati aveva scritto per un'opera del compositore italiano Giuseppe Gazzaniga, avente lo stesso soggetto; Da Ponte completò il libretto del dramma giocoso Il Dissoluto punito ossia il Don Giovanni probabilmente nel giugno 1787; Mozart ne compose la musica fra l'estate e l'autunno; la storica prima rappresentazione ebbe luogo a Praga il 29 ottobre 1787.[139]
All'anno 1787 appartengono due capolavori nel genere della serenata: Uno scherzo musicale in fa maggiore K 522 (14 giugno) è una brillante satira musicale che prende di mira la mediocrità e l'incompetenza dei compositori alla moda nella Vienna dell'epoca; la Piccola serenata notturna in sol maggiore K 525 (agosto) è oggi una delle composizioni mozartiane più popolari e più universalmente note.[140] Degno di menzione è anche l'ammirevole Divertimento per violino, viola e violoncello in mi bemolle maggiore K 563 del 1788.[141]
Il 7 dicembre 1787 l'imperatore Giuseppe II nominò Mozart kammermusicus, con una retribuzione di 800 fiorini l'anno (il suo predecessore Gluck, da poco deceduto, ne aveva presi 2000).[142] Si trattò comunque, per Mozart, di un incarico poco impegnativo, che consistette principalmente nella fornitura periodica di musica per i balli di corte.[143]
Ancora una volta, all'entusiastica accoglienza di un'opera mozartiana da parte del pubblico praghese fece da contrappeso un assai più tiepido riscontro a Vienna, dove il Don Giovanni, allestito il 7 maggio 1788, fu un sostanziale insuccesso; l'opinione del pubblico fu che si trattasse di una musica troppo difficile, anche se parte della critica ne riconobbe subito la qualità superiore.[144]
Il Don Giovanni è comunemente considerato uno dei massimi capolavori, non solo dell'arte musicale, di tutti i tempi.[145] Una sua caratteristica consiste nella prodigiosa compresenza di comicità e tragedia;[146] il protagonista, Don Giovanni, figura inizialmente negativa, raggiunge in modo paradossale una statura eroica nelle ultime scene del dramma, dove il suo ostinato e coraggioso rifiuto di pentirsi (pur di fronte alla imminente prospettiva della dannazione eterna, minacciatagli dalla sovrannaturale apparizione della statua semovente del commendatore) può apparire quale emblema di rivolta laica e illuministica contro il trascendente.[147] Il finale del secondo atto supera i limiti formali dell'opera settecentesca, realizzando l'assoluta adeguazione della musica all'azione drammatica e aprendo in questo modo la via al teatro musicale del Romanticismo.[148]
A partire dal biennio 1786-87, Mozart iniziò ad avere crescenti problemi economici; le sue entrate diminuirono complessivamente di circa un terzo rispetto al 1784, per poi calare ulteriormente nel 1788 e nel 1789; Mozart cominciò allora a chiedere denaro in prestito, come è attestato da una drammatica serie di lettere (una ventina) che il compositore scrisse al commerciante Michael Puchberg fra il 1788 e il 1791.[149] Va detto che le finanze di Mozart scontarono anche l'effetto di una congiuntura economica sfavorevole: la guerra contro la Turchia ebbe pesanti ripercussioni sulla vita musicale viennese fra il 1788 e il 1791, portando, fra l'altro, a una drastica diminuzione generale dell'attività concertistica.[150] Di fatto, non risulta che Mozart abbia più tenuto concerti a Vienna dopo l'estate 1788; calarono fortemente anche i guadagni che Mozart traeva dalla pubblicazione delle sue composizioni.[151]
All'estate 1788 risale la composizione dei tre ultimi capolavori sinfonici: la Sinfonia in mi bemolle maggiore K. 543 (26 giugno), la Sinfonia in sol minore K. 550 (25 luglio) e la Sinfonia in do maggiore K. 551 (10 agosto).[152] Questa trilogia costituisce il vertice artistico del sinfonismo settecentesco; la Sinfonia in do maggiore si distingue per le sue vaste proporzioni e per l'imponenza architettonica del suo finale fugato.[153]
L'8 aprile 1789 Mozart partì da Vienna per un lungo viaggio verso la Germania settentrionale, alla ricerca di nuovi incarichi e di nuovi introiti. Fu il 10 aprile a Praga; il 12 a Dresda, dove tenne alcuni concerti in forma privata; il 20 a Lipsia, dove ebbe modo di leggere alcune partiture di Bach conservate nella Thomaskirche; il 26 fu a Potsdam, dove, a quanto sembra, non riuscì a ottenere udienza dal re Federico Guglielmo II; l'8 maggio ritornò a Lipsia, città nella quale, il 12 maggio, diede un concerto pubblico alla Gewandhaus, in cui furono eseguite due sinfonie non identificate, due concerti per pianoforte e orchestra, due arie con orchestra, cantate dal soprano Josepha Duschek, e dove probabilmente improvvisò al pianoforte; ma gli incassi della serata non furono per nulla buoni.[154] Mozart era da tempo particolarmente legato alla Duschek, ed è possibile che fra i due ci sia stato, durante questo viaggio, qualcosa di più di una semplice amicizia.[155]
Il 19 maggio fu a Berlino, città in cui forse assistette a una rappresentazione del Ratto dal serraglio e dalla quale scrisse alla moglie di aver ricevuto incarico dalla corte di scrivere sei quartetti per archi e sei sonate facili per pianoforte (ma la circostanza che egli abbia realmente ricevuto tale commissione regia è posta in dubbio da alcuni studiosi, dato che di tale incarico non si trova traccia in nessun altro documento che non sia di mano dello stesso Mozart).[154] Il musicista, comunque, completò solo tre quartetti per archi, i suoi ultimi, conosciuti come Quartetti prussiani (K. 575, K. 589 e K 590), che furono pubblicati postumi e senza alcuna dedica, e una sola sonata, l'ultima, la K 576.[156] Tornò a Vienna il 4 giugno 1789; il suo viaggio era stato infruttuoso dal punto di vista economico e aveva forse avuto l'effetto di intaccare la serenità del suo matrimonio.[157]
Il 1790 fu un anno particolarmente difficile per Mozart: la sua reputazione di eccellente compositore era ormai consolidata a livello europeo, ma in patria una parte di quello che era stato il suo pubblico ormai non lo seguiva più, anche perché Mozart non si preoccupava affatto di compiacerlo; raramente e malvolentieri, infatti, acconsentiva a scrivere musica banale, finalizzata al solo successo commerciale.[158] La sua produzione, benché mantenesse un livello qualitativo sempre molto elevato, ebbe inoltre un vero e proprio crollo quantitativo nel corso del 1790, un'epoca relativamente alla quale il suo catalogo registra non più di una dozzina di nuove composizioni, in quello che fu il periodo di minore produttività in tutta la sua maturità di compositore.[159] Si è ipotizzato che in questo periodo egli fosse affetto da depressione.[160]
Il 26 gennaio, al Burgtheater di Vienna, ebbe luogo la prima rappresentazione di Così fan tutte ossia La scuola degli amanti, dramma giocoso su libretto di Lorenzo Da Ponte; l'opera fu replicata nove volte nel corso dell'anno.[122] Basata su un soggetto originale dello stesso Da Ponte, essa esprime due differenti aspetti del razionalismo illuminista: da una parte, l'amara ironia e lo scetticismo riguardo al cuore umano propri di Voltaire; dall'altra, la rivendicazione del sentimento erotico nella sua genuina naturalità, al di là delle convenzioni sociali, derivante da Rousseau.[161]
Il 20 febbraio moriva l'imperatore Giuseppe II, che era stato il più importante dei sostenitori di Mozart: con l'insediamento del suo successore, Leopoldo II, il compositore non fu più tra i favoriti presso la corte, dove le sue richieste di nuovi incarichi non furono accolte.[162]
Nel 1790 fu uno dei cinque compositori che realizzarono il Singspiel La pietra filosofale, su libretto di Emanuel Schikaneder; l'opera venne musicata, oltre che da Mozart, dallo stesso Schikaneder, da Franz Xaver Gerl, Johann Baptist Henneberg e Benedikt Schack; la prima si ebbe al Theater auf der Wieden l'11 settembre 1790.[163] A lungo si è ritenuto che il contributo di Mozart a tale opera si fosse limitato a un solo duetto; un manoscritto ritrovato nel 1996, però, fa supporre che l'apporto del musicista di Salisburgo sia stato più consistente.[164]
Mozart non fu tra i compositori invitati a presenziare alla cerimonia di incoronazione del nuovo imperatore, che doveva aver luogo in ottobre a Francoforte; decise comunque di parteciparvi a proprie spese; nella città tedesca tenne un concerto il 15 ottobre, il cui cartellone comprendeva una sinfonia non identificata, due concerti per pianoforte e orchestra (K 459 e K 537), alcune arie e un'improvvisazione pianistica; l'esito, dal punto di vista economico, ancora una volta non fu buono.[165] Mozart proseguì comunque il viaggio, toccando Magonza il 16 ottobre, Mannheim il 23, Monaco di Baviera il 29; in quest'ultima città, il 4 o 5 novembre suonò a un concerto in onore di re Ferdinando IV di Napoli; il 10 novembre (senza essere passato da Salisburgo) era di nuovo a Vienna; il viaggio non aveva migliorato la sua situazione economica, ma l'avere incontrato molti vecchi amici a Mannheim e a Monaco lo aveva forse aiutato a uscire dal suo stato depressivo.[166]
Alla fine di ottobre del 1790, l'impresario britannico Robert May O' Reilly offrì a Mozart l'opportunità di soggiornare a Londra fino all'estate successiva con il compito di comporre almeno due opere teatrali, dietro un compenso equivalente a circa 3000 fiorini; non si sa per quale motivo Mozart abbia rifiutato tale vantaggiosa offerta, che avrebbe risolto gran parte dei suoi problemi finanziari: forse perché ciò avrebbe comportato una lunga separazione da Constanze (la quale, a causa della sua salute malferma, non avrebbe potuto seguire il marito a Londra), o forse perché a quell'epoca Mozart contava già con certezza su future opportunità di guadagno rimanendo a Vienna;[167] forse, più semplicemente, Mozart non se la sentiva di emigrare all'estero, sconvolgendo la sua vita e le sue abitudini solo per inseguire delle prospettive di carriera, per quanto allettanti.[168]
L'inizio del 1791 vide Mozart superare la propria crisi creativa e tornare ai suoi abituali livelli di produttività, come è attestato dalla serie di capolavori che costellano il suo ultimo anno: fra essi il concerto per pianoforte e orchestra n. 27 in si bemolle maggiore K 595 (5 gennaio), il quintetto per archi in mi bemolle maggiore K 614 (12 aprile), il mottetto Ave verum corpus K 618 (giugno), il Concerto per clarinetto e orchestra K 622 (7 ottobre).[169] Anche la sua situazione economica cominciò a migliorare: fra l'altro, alcuni mecenati ungheresi e olandesi sottoscrissero in suo favore, impegnandosi ad acquistare sue composizioni per cifre ragguardevoli; il 9 maggio la città di Vienna lo nominò assistente Kapellmeister di Leopold Hofmann presso la cattedrale di Santo Stefano, incarico onorifico che però preludeva alla nomina a maestro di cappella (retribuito 2000 fiorini annui) non appena il posto si fosse reso vacante.[170]
Fu probabilmente all'inizio di maggio che Mozart iniziò a comporre Il flauto magico, Singspiel su libretto di Emanuel Schikaneder; intorno alla metà di luglio gli pervenne, dall'impresario Guardasoni, la commissione per un'opera seria italiana da mettere in scena a Praga, La clemenza di Tito.[171]
Sempre nell'estate del 1791 un aristocratico musicista dilettante, un certo conte Franz von Walsegg, tramite un suo emissario, commissionò a Mozart una messa da requiem, alla condizione che l'incarico dovesse rimanere segreto e che il committente restasse anonimo; ciò in quanto era intenzione del conte Walsegg di far passare l'opera come propria. Non è chiaro se Mozart conoscesse l'identità e le intenzioni del suo committente; in ogni caso egli, già impegnato nella composizione del Flauto magico e della Clemenza di Tito, non poté dedicarsi subito a scrivere il Requiem.[172]
Fra il 28 agosto e il 15 settembre Mozart fu a Praga, dove si svolgevano le cerimonie per l'incoronazione di Leopoldo II a re di Boemia; il 6 settembre, al teatro nazionale, ebbe luogo la prima rappresentazione della Clemenza di Tito, alla presenza della coppia imperiale e con la direzione dell'autore, ma con esito non molto favorevole; è rimasto tristemente famoso il rozzo giudizio dell'imperatrice Maria Luisa, che definì l'opera "una porcheria tedesca in lingua italiana" e in una sua lettera affermò che "la musica era così brutta che ci addormentammo tutti".[173]
Immediato, vasto e crescente successo ottenne invece Il flauto magico: alla prima rappresentazione, che si svolse, sotto la direzione del compositore, al Freihaustheater di Vienna il 30 settembre 1791, seguirono centinaia di repliche nel corso degli anni novanta. L'euforia di Mozart per il successo della sua opera è testimoniata dalle ultime lettere che il compositore scrisse alla moglie, che in quel periodo si trovava in villeggiatura a Baden.[174]
La musica dell'ultimo Mozart sembra mostrare una tendenza ad allontanarsi dalle forme codificate del classicismo (come la sinfonia, la sonata e il quartetto), per indirizzarsi invece verso brani d'occasione, apparentemente minori, a volte alquanto anomali dal punto di vista timbrico e formale; è il caso della Fantasia in fa minore K 608 e dell'Andante in fa maggiore K 616, entrambi per organo meccanico; dell'Adagio e rondò in do minore K 617 per glassarmonica, flauto, oboe, viola e violoncello, scritto per la virtuosa cieca Marianne Kirchgessner; dello stesso Ave verum corpus K 618, scritto per il coro della scuola elementare di Baden[175]. Nel Flauto magico questa attenzione dell'ultimo Mozart per l'umile e il marginale trova la sua più compiuta realizzazione; scritto per un teatro di periferia e rivolto a un pubblico popolare, Il flauto magico esprime, in un linguaggio musicale trasparente e accessibile a tutti, la stessa filosofia giusnaturalistica che già aveva ispirato opere come Il ratto dal serraglio e Le nozze di Figaro: la fede nella bontà originaria degli esseri umani e nella felicità da raggiungere attraverso l'affetto e la solidarietà fra le persone, è la fondamentale filosofia mozartiana che nel Flauto magico si manifesta attraverso (e a volte nonostante) i complessi simboli dell'ideologia massonica cui è improntato il libretto di Schikaneder[176].
Prima del 15 novembre 1791 Mozart mise da parte il Requiem e scrisse l'ultima sua opera compiuta, la Piccola cantata massonica K 623; il 20 novembre cadde malato.[177]
Mozart entrò nella massoneria dopo il proprio trasferimento a Vienna, mentre la sua carriera di musicista era al culmine del successo. Venne iniziato come "apprendista" il 14 dicembre 1784, nella loggia "Zur Wohltätigkeit" ("Alla beneficenza") grazie alla mediazione dell'amico drammaturgo e massone Otto Heinrich von Gemmingen-Hornberg.[178] Il compositore, in poco tempo, percorse tutto il cammino iniziatico della massoneria: il 7 gennaio del 1785 fu elevato al grado di "compagno" e forse il 13 gennaio (la data non è certa) divenne "maestro".[179] Suo padre Leopold venne iniziato nella stessa loggia il 6 aprile 1785, il 16 aprile passò al grado di "compagno" e il 22 divenne "maestro".[180]
L'11 dicembre 1785 l'imperatore Giuseppe II fece emanare un decreto, il Freimaurerpatent, in virtù del quale le otto logge massoniche di Vienna furono accorpate in sole due, denominate rispettivamente "Alla nuova speranza incoronata" e "Alla verità" e assoggettate a uno stringente controllo da parte del governo; in seguito a questo provvedimento Mozart venne a far parte della loggia "Alla nuova speranza incoronata".[181]
Fra gli scopi dichiarati di tale decreto vi era quello di limitare l'influenza dell'ordine dei Rosacroce, di tendenza mistica ed esoterica; perciò i massoni di tendenza razionalista inizialmente accolsero con favore il Freimaurerpatent; tuttavia, in seguito apparve chiaro che l'assoggettamento della massoneria al controllo governativo aveva anche l'obiettivo di frenare l'attività dell'ala più illuminista e più anticlericale, che faceva capo all'ordine degli Illuminati, considerato pericoloso per l'ordine costituito.[182] Difatti dopo il Freimaurerpatent l'ordine degli Illuminati cessò praticamente di esistere a Vienna, molti di loro (fra cui alcuni cari amici di Mozart) uscirono dalla massoneria e la stessa loggia "Alla verità" fu ufficialmente chiusa nel 1789.[183]
La loggia "Alla beneficenza", di cui faceva parte Mozart prima del Freimaurerpatent, era praticamente dominata dagli Illuminati, ed egli stesso ebbe stretti legami con appartenenti a tale ordine, come Ignaz von Born e Joseph von Sonnenfels.[184] Sembra che Mozart abbia avuto simpatie per gli Illuminati, anche se molto probabilmente non entrò mai a far parte del loro ordine.[185] Mozart continuò comunque a far parte della massoneria anche dopo che ne furono usciti gli Illuminati, sebbene, a quanto pare, la sua partecipazione alle attività della loggia sia diminuita fra il gennaio 1786 e il gennaio 1791.[185]
L'appartenenza massonica di Mozart non fu solo per adesione formale, ma trasse fondamento in profondi convincimenti esoterici e spirituali, che egli tradusse in musica, nelle opere che più si riallacciano ai simboli e agli ideali massonici: fra questi, resta impareggiabile la simbologia del Flauto magico.[186] È simbolico il carattere di progressione delle terze parallele, che contraddistingue la parte finale dell'opera K 623. Il carattere massonico di tali composizioni si esprime a volte nella scelta delle tonalità (con predilezione di mi bemolle) e nei timbri, dove è predominante la presenza di strumenti a fiato e voci maschili.
All'universo della musica massonica appartengono, fra le altre opere, la cantata K 471 del 1785, l'adagio per due clarinetti e tre corni di bassetto K 411 dello stesso anno e la musica funebre massonica K 477 (pure questa del 1785), oltre alla piccola cantata massonica K 623 del 1791.[187]
Nel suo ultimo anno di vita, Mozart riprese a comporre molta musica d'ispirazione massonica; oltre al Flauto magico e alla Piccola cantata massonica, sopra citati, è degna di nota la cantata per tenore e pianoforte Die ihr des unermeßlichen Weltalls Schöpfer ehrt ("Voi che onorate il creatore dell'universo infinito") K 619, su testo di Franz Heinrich Ziegenhagen.[188] Ziegenhagen era un socialista utopista, esponente dell'Illuminismo radicale ed egualitario; il suo testo (messo in musica da Mozart nel luglio 1791) è un'appassionata perorazione a favore della tolleranza religiosa, contro il fanatismo, contro il militarismo e a favore della pace fra i popoli:[189]
«Voi che onorate il creatore dell'universo infinito,che si chiami Geova, o Dio,che si chiami Fu o Brahmā, udite![...]Spogliatevi della veste che impedisceall'umanità di vedere il maleficio della superstizione!Nel coltro viene riforgiato il ferroche ha sparso finora il sangue degli uomini e dei fratelli!Fate scoppiare la roccia con la polvere nerache spesso ha diretto il piombonel cuore del fratello, uccidendolo!»
(F. H. Ziegenhagen[190])Mozart morì nella sua casa a Vienna il 5 dicembre 1791, cinque minuti prima dell'una di notte.[191] La salma fu portata alla cattedrale di Santo Stefano il 6 dicembre; il corpo venne poi sepolto, lo stesso giorno o forse la mattina del 7, in una fossa comune del Cimitero di St. Marx. Le notizie riguardo al fatto che nessuno della famiglia di Mozart, né dei suoi amici o conoscenti, fosse presente (le testimonianze dei contemporanei tentano di giustificare questo fatto asserendo che al momento del funerale ci fosse maltempo) sono state confutate da studi recenti.[192]  Si trattò di un funerale di terza classe, il più economico possibile, come suggerito alla vedova dal barone van Swieten, protettore di Mozart, che pagò le esequie; forse tale tipo di funerale era stato anche scelto dallo stesso Mozart, seguendo le sue convinzioni illuministiche che potrebbero averlo indotto a disprezzare, alla stregua di un retaggio della superstizione, sia le cerimonie funebri troppo sfarzose sia il conforto della Chiesa (fra l'altro, Mozart non aveva chiesto, né ricevuto, l'estrema unzione).[193] Nonostante quanto tramandato si è appurato che il feretro, partito dalla casa del compositore, era sostenuto da quattro portatori, preceduti da un crocifero e da quattro giovani con dei ceri; seguirono la vedova Constanze, alcuni membri della famiglia Weber, fra cui le sorelle, il barone van Swieten, Franz Xaver Süßmayr, Jakob Freiständler e Otto Hatwig, allievi del musicista, alcuni amici e Antonio Salieri.[194] 
L'esatto luogo di sepoltura di Mozart non è stato mai identificato: vi sono a Vienna due monumenti funerari del compositore in due diversi cimiteri, uno presso il Cimitero di St. Marx e un altro presso il Cimitero centrale (Zentralfriedhof).
La malattia e la morte di Mozart sono state e sono tuttora un difficile argomento di studio, oscurato da leggende romantiche e farcito di teorie contrastanti. Gli studiosi sono in disaccordo sul corso del declino della salute di Mozart, in particolare sul momento in cui Mozart divenne conscio della sua morte imminente e se questa consapevolezza influenzò le sue ultime opere.
Anche l'effettiva causa del decesso di Mozart è argomento dibattuto: il suo certificato di morte riporta hitziges Frieselfieber ("febbre miliare acuta", che allora era considerata contagiosa, o "esantema febbrile"), una definizione insufficiente a identificare la corrispettiva diagnosi nella medicina odierna. Sono state avanzate diverse ipotesi, dalla trichinosi all'avvelenamento da mercurio o acqua tofana (avvelenamento da arsenico e antimonio), alla febbre reumatica o, più recentemente, la sifilide. La pratica terapeutica del salasso, all'epoca diffusa, è menzionata come concausa della morte. Una serie di ricerche epidemiologiche eseguite nel 2009 da un gruppo di patologi austriaci e olandesi, che si sono soffermati a studiare tutte le principali cause di decesso della popolazione negli ultimi anni di vita di Mozart, porta a ritenere che – con grande probabilità – il compositore sia morto per una nefrite acuta conseguente a una glomerulonefrite a eziologia streptococcica.[195]
Mozart morì lasciando incompiuto il Requiem, il cui completamento fu affidato dalla moglie del compositore in un primo tempo al musicista Joseph Eybler, il quale, tuttavia, ben presto si fece indietro. Fu allora chiamato il giovane compositore Franz Xaver Süssmayr, allievo e amico di Mozart che terminò il lavoro, completando le parti non finite e scrivendo ex novo quelle inesistenti.
Nel 1809 Constanze Weber, la vedova, si risposò col diplomatico danese Georg Nikolaus von Nissen (1761 – 1826), grande ammiratore di Mozart e autore di una delle prime biografie dedicate al musicista. Per questo lavoro di sicuro Nissen attinse a testimonianze di Constanze, la quale, però, non può essere considerata una fonte del tutto attendibile. Ad esempio, dalle lettere scritte da Mozart ad amici e familiari (alla stessa Constanze, ad esempio) Nissen e Constanze cancellarono spesso le parti più scurrili e ciò nel chiaro intento di idealizzare la figura del compositore.[196]
La scelta di Mozart, nel maggio 1781, di abbandonare il servizio presso la corte dell'arcivescovo di Salisburgo fu gravida di conseguenze non solo per lui, ma anche per la condizione sociale dei musicisti in generale: infatti era la prima volta (perlomeno nell'ambiente musicale di lingua tedesca) che un compositore della sua statura si affrancava dal vincolo di sudditanza feudale alla Chiesa o alla classe nobiliare e decideva di lavorare come libero professionista, soggetto solamente alla legge della domanda e dell'offerta; di lì a poco, tale nuova posizione sociale costituì il presupposto indispensabile per l'affermarsi in musica dell'individualismo romantico.[197]
Fino all'epoca di Mozart, infatti, in tutti i territori che già avevano fatto parte dell'antico Sacro Romano Impero, musicisti di estrazione borghese come lui (e come suo padre Leopold) potevano trovare una degna collocazione sociale solamente impiegandosi in pianta stabile presso una delle molte corti aristocratiche o delle istituzioni a esse collegate; il loro ruolo sociale era dunque subalterno all'aristocrazia di corte, ed era sostanzialmente equiparato a quello del personale di servizio.[198] Leopold Mozart, anche se malvolentieri, si era alla fine adattato a questo tipo di collocazione sociale e si aspettava che anche suo figlio facesse carriera come musicista di corte, tutt'al più in una corte più grande e più ricca di quella di Salisburgo; ma Wolfgang, da quando fu maggiorenne, non poté più accettare interiormente tale condizione di sudditanza, che gli appariva umiliante in modo intollerabile e che sviluppò in lui un permanente stato d'animo di rancore profondo nei confronti della nobiltà di corte.[199] La personale rivolta di Mozart contro le costrizioni derivanti dal servizio a corte trovò infine espressione nella sua decisione di dimettersi dal suo impiego e di guadagnarsi da vivere come libero artista.[200]
Circa l'effettivo successo economico della carriera di Mozart nei suoi ultimi dieci anni di vita si trovano, nella letteratura biografica, valutazioni molto contrastanti: la visione prevalente per tutto l'Ottocento e per gran parte del Novecento fu che Mozart, sostanzialmente, perse la sua partita e che concluse la propria avventura umana e professionale con un fallimento e nella più nera miseria. Tale è la versione che appare, ad esempio, negli scritti di Massimo Mila[201] e che si trova sintetizzata da una diffusa enciclopedia la quale, ancora nel 1995, scriveva che Mozart morì "senza mai conoscere il vero successo".[2]
Secondo il sociologo Norbert Elias, Mozart intraprese il suo rischioso progetto di vita come libero artista in un momento, e in un luogo, in cui non esistevano ancora le condizioni storiche per la sua riuscita: non esisteva ancora un mercato musicale pienamente sviluppato; l'editoria musicale era ai suoi inizi, così come lo era l'attività concertistica modernamente intesa (nella maggior parte del territorio di lingua tedesca, i concerti e le opere erano finanziati e allestiti da esponenti della classe nobiliare e per un pubblico composto per lo più da invitati).[202] Tutte queste condizioni non sussistevano ancora nella Vienna di Mozart, ma vennero a realizzarsi in gran parte solo pochi anni dopo la sua morte, quando ebbe inizio la carriera del giovane Beethoven.[203]
«Da outsider borghese al servizio della corte, Mozart combatté fino in fondo, con incredibile coraggio, una battaglia di affrancamento dai suoi padroni e committenti aristocratici. Lo fece di propria iniziativa, per amore della propria dignità di uomo e del proprio lavoro di musicista. E perse la battaglia – come era da prevedere, aggiungeremmo con la presunzione dei posteri.»
(Norbert Elias[204])È stato anche osservato che, nei suoi primi anni viennesi, Mozart aderì al programma di modernizzazione dello Stato e della società asburgica promosso dall'imperatore Giuseppe II; l'imperatore intendeva fra l'altro (secondo i canoni del dispotismo illuminato) limitare i poteri dell'aristocrazia feudale, i cui abusi Mozart condannò ne Le nozze di Figaro.[205] Tuttavia, il consenso e la protezione, accordati entro certi limiti a Mozart dalla corte viennese, non costituirono – secondo questa interpretazione – una base sufficientemente solida per l'attività professionale del compositore; inoltre, la novità e la complessità del suo linguaggio musicale non furono pienamente compresi nemmeno dalla corte dell'imperatore, abituata a musiche di più facile accessibilità (pochi mesi dopo la morte di Mozart trionfò a Vienna Il matrimonio segreto di Cimarosa) e al minore impegno compositivo profuso da musicisti di secondaria importanza come Martín y Soler e Dittersdorf.[205]
A partire dagli anni settanta del Novecento, la visione tradizionale di un Mozart morto in miseria fu corretta da una serie di studi i quali puntualizzarono come il compositore guadagnasse in realtà nei suoi anni viennesi cifre sempre considerevoli (pur dilapidandone gran parte nel gioco d'azzardo).[206] La valutazione di Maynard Solomon è che Mozart ebbe un momentaneo declino di popolarità tra il 1788 e il 1790 e che in particolare nel 1790 la crisi delle sue finanze si accentuò fino a sfiorare il crollo definitivo; tuttavia, dice Solomon, tali difficoltà finirono nel 1791, ma la ripresa della fortuna anche economica di Mozart fu troncata dalla morte.[207]
Le composizioni di Mozart spaziano in tutti i generi musicali del suo tempo: l'opera, la messa, l'oratorio, la cantata, il Lied, la sonata da chiesa, la sinfonia, il concerto per strumento solista e orchestra, il quartetto d'archi, il quintetto d'archi, la sonata per pianoforte, la sonata per violino, la serenata, il divertimento, la musica per organo e la musica massonica. Mozart è fra i musicisti maggiormente eseguiti non solo in Austria (in particolare a Salisburgo),[208] ma anche nelle sale da concerto di tutto il mondo.
L'elenco in ordine cronologico di tutte le composizioni musicali di Mozart è il cosiddetto "Catalogo Köchel". Esso prende il nome da Ludwig von Köchel, che ne pubblicò la prima edizione nel 1862. A essa hanno fatto seguito numerose edizioni rivedute. Ogni opera di Mozart viene dunque comunemente designata con un numero preceduto dall'abbreviazione K o KV, in entrambi i casi indicante Köchel Verzeichnis (Catalogo Köchel in tedesco).
Sebbene alcuni dei primi brani di Mozart siano stati scritti per clavicembalo, nei suoi primi anni conobbe i pianoforti realizzati da un costruttore di Regensburg Franz Jakob Späth.[209] Più tardi, quando Mozart visitò Augusta, rimase colpito dai pianoforti Stein e lo scrisse in una lettera a suo padre.[209] Il 22 ottobre del 1777 Mozart fece la prima esecuzione del suo Triplo concerto K. 242 su strumenti forniti da Stein.[210] L'organista della Cattedrale di Augusta, Demmler suonava la prima parte, Mozart la seconda e Stein la terza.[211] Nel 1783, quando viveva a Vienna, acquistò uno strumento di Walter.[212] Leopold Mozart ha confermato l'attaccamento di Mozart con il suo fortepiano Walter: “È impossibile descrivere il trambusto. Il pianoforte di tuo fratello è stato spostato almeno dodici volte da casa sua a teatro o a casa di qualcun altro”.[213]
Le composizioni di Mozart e di Haydn appartengono a un periodo storico – la seconda metà del XVIII secolo – durante il quale avvenne nella musica occidentale l'evoluzione dal cosiddetto stile galante a un nuovo stile, detto in seguito classico, che avrebbe accolto in sé anche gli elementi contrappuntistici, che caratterizzavano la tarda musica barocca e proprio in reazione alla cui "complessità" si era sviluppato lo stile galante.
Lo stile della musica di Mozart non solo segue da vicino lo sviluppo dello stile classico, ma senza dubbio contribuisce in modo fondamentale a definirne le caratteristiche, in modo tale da poter essere considerato esso stesso l'archetipo. Mozart fu uno straordinario compositore che si dedicò con apparente semplicità a tutti i principali generi dell'epoca: scrisse un gran numero di sinfonie, opere, concerti per strumento solista, musica da camera (fra cui quartetti e quintetti d'archi) e sonate per pianoforte. Benché per nessuno di questi generi si possa affermare che egli fu il "primo autore", per quanto riguarda il concerto per pianoforte si deve riconoscere che esso deve a Mozart, autore e interprete delle proprie composizioni, il grandioso sviluppo formale e di contenuti che avrebbe caratterizzato questo genere nel secolo successivo. Lo stesso Beethoven nutriva grande ammirazione per i concerti per pianoforte mozartiani, che furono il modello dei suoi concerti, in modo particolare i primi tre per pianoforte.[214][215]
Mozart rinnovò il genere musicale del concerto: il discorso musicale si svolge come dialogo paritario fra due soggetti di uguale importanza, il solista e l'orchestra. Mozart scrisse concerti per pianoforte, violino, flauto, oboe, corno, clarinetto, fagotto. Mozart scrisse anche un gran numero di composizioni sacre, fra cui messe, e composizioni più "leggere", risalenti per lo più al periodo salisburghese, come le marce, le danze, i divertimenti, le serenate e le cassazioni.
I tratti caratteristici dello stile classico possono essere ritrovati senza difficoltà nella musica di Mozart: chiarezza, equilibrio e trasparenza sono elementi distintivi di ogni sua composizione. Tuttavia, l'insistenza che a volte viene data agli elementi di delicatezza e di grazia[216] della sua musica non riesce a nascondere la potenza eccezionale di alcuni dei suoi capolavori, quali il concerto per pianoforte n. 24 in do minore K. 491, la Sinfonia n. 40 in sol minore K. 550 e l'opera Don Giovanni. A questo proposito, Charles Rosen ha scritto:[217] «Solamente riconoscendo che la violenza e la sensualità è al centro dell'opera di Mozart è possibile fare il primo passo verso la comprensione delle sue strutture e della sua magnificenza. In un modo paradossale, la caratterizzazione superficiale di Schumann della sinfonia K. 550 in sol minore[216][218] può aiutarci a comprendere il demone di Mozart in modo più completo. Nell'opera di Mozart ogni suprema espressione di sofferenza e terrore ha qualcosa di sorprendentemente voluttuoso.»
Soprattutto nell'ultimo decennio di vita Mozart esplorò l'armonia cromatica con una intensità raramente ritrovata in altri compositori del suo tempo. Scrive Hermann Abert:[219] «Neppure l'uomo normale si dà pena di imitare alcuna cosa di cui non rechi già in sé l'embrione. Nel genio questa scelta reca già l'impronta dell'atto creativo. Essa è infatti il primo tentativo di una presa di posizione, d'un affermarsi nei confronti della tradizione: tentativo che dovrà agguerrirlo a rifiutare ciò che gli sia estraneo o d'intoppo e non soltanto a imitare ma a "ricreare" e assimilare ogni elemento congeniale. Non dovremo quindi mai dimenticare che la grandezza di Mozart sta nel suo "io", nella sua forza creativa; non nel materiale col quale si è cimentato.»
Fin da fanciullo Mozart aveva mostrato che era capace di ricordare e imitare senza alcuna difficoltà la musica che aveva l'occasione di ascoltare. I suoi numerosi viaggi consentirono al giovane compositore di far sua una rara collezione di esperienze attraverso le quali Mozart creò il suo unico linguaggio compositivo.[220]
La ricerca critica e musicologica sull'opera di Mozart è al centro del monumentale lavoro in cinque volumi Mozart - Sa vie musicale et son oeuvre (1912-1946) di Teodor de Wyzewa e Georges de Saint-Foix. Attraverso un metodo di analisi scrupolosa delle influenze dovute all'ambiente musicale col quale Mozart si confrontò nel corso della sua breve vita, i due musicologi arrivarono a suddividere l'opera di Mozart in 34 fasi stilistiche diverse, ciascuna di esse sotto l'influenza di un dato modello. Questo "approccio riduttivo", tuttavia, è stato in seguito criticato e messo in discussione, fra gli altri da Paumgartner:[221] «Nella compiaciuta infatuazione di quei confronti critico-stilistici, si tralasciò anzitutto di cercar di scoprire in virtù di quali leggi più profonde la musica di Mozart, nonostante le innegabili reminiscenze dei modelli contemporanei, risulti così sostanzialmente diversa da questi e, appunto perciò abbia potuto svilupparsi assumendo forme proprie, originali e durature»
Mozart era ancora bambino durante il soggiorno a Londra quando incontrò Johann Christian Bach e ascoltò la sua musica. A Parigi, Mannheim e Vienna, egli ascoltò i lavori dei compositori attivi in quei luoghi così come la famosa orchestra di Mannheim. In Italia ebbe modo di conoscere e approfondire la ouverture italiana e l'opera buffa dei grandi maestri italiani del Settecento e questa esperienza sarebbe stata di fondamentale importanza nello sviluppo successivo della sua musica. Sia a Londra sia in Italia, lo stile galante dominava la scena: uno stile semplice, quasi da "musica leggera", caratterizzato da una predilezione per le cadenze, da una enfasi sulle frasi nella tonalità fondamentale-dominante-sottodominante (escludendo così altri accordi) e dall'uso di frasi simmetriche e di strutture articolate in modo chiaro.[222]
Lo stile galante, che fu l'origine dello stile classico, era nato come reazione alla "eccessiva complessità" della tarda musica barocca. Alcune delle sinfonie giovanili di Mozart hanno la forma di ouverture in tre movimenti nello stile italiano; molte di queste sono "omotonali", ossia tutti i tre movimenti sono nella stessa tonalità, essendo il movimento lento centrale nella relativa tonalità minore. Altri lavori "imitano" lo stile di Johann Christian Bach, mentre altri ancora mostrano la semplice forma bipartita in uso fra i compositori viennesi.
Passando dalla giovinezza alla prima maturità, Mozart iniziò a inserire alcune delle caratteristiche fondamentali dello stile barocco all'interno delle proprie composizioni: per esempio, la Sinfonia n. 29 in la maggiore K 201 impiega nel primo movimento un tema principale in forma contrappuntistica e sono presenti anche sperimentazioni con frasi di lunghezza irregolare. A partire dal 1773 appaiono nei quartetti dei movimenti conclusivi in forma di fuga, probabilmente influenzati da Haydn, che aveva incluso finali in questa forma nei quartetti dell'opera 20. L'influenza dello stile Sturm und Drang, che preannuncia col suo carattere la futura era romantica è evidente in alcune delle composizioni di quel periodo di entrambi gli autori, fra cui spicca la Sinfonia n. 25 in sol minore K 183, la prima delle due uniche sinfonie in tonalità minore scritte da Mozart.[223]
«Mozart infuse negli strumenti il nostalgico afflato della voce umana per la quale nutriva uno specialissimo amore. Orientò verso il cuore della melodia l'inesauribile fiumana d'una ricca armonia, dando sempre alla voce degli strumenti quella fervida intensità di sentimento propria della voce umana: inesauribile fonte dell'espressione racchiusa nel fondo del cuore.[224]»
(Richard Wagner)Mozart fu anche uno dei grandi autori di opere; egli passava con grande facilità e naturalezza dalla scrittura strumentale a quella vocale. Le sue opere appartengono ai tre generi principali in voga alla fine del Settecento: l'opera buffa (Le nozze di Figaro, Don Giovanni e Così fan tutte), l'opera seria (Idomeneo e La clemenza di Tito) e il Singspiel (Il ratto dal serraglio e Il flauto magico). In tutte le sue grandi opere Mozart impiega la scrittura strumentale per sottolineare lo stato psicologico dei personaggi e i cambiamenti di situazione drammatica. La scrittura operistica e quella strumentale si influenzano a vicenda: l'orchestrazione via via più sofisticata che Mozart adotta per le composizioni strumentali (sinfonie e concerti in primo luogo) viene adottata anche per le opere, mentre l'uso particolare che egli fa del colore strumentale per evidenziare gli stati d'animo ritorna anche nelle ultime composizioni non operistiche.[225]
Una grande amicizia e reciproca stima contraddistingue il legame che unisce Mozart a Haydn, nonostante quest'ultimo fosse di ventiquattro anni più anziano. Non è possibile stabilire con certezza quando Mozart entrò in rapporti di amicizia con Haydn, ma di certo si sa che nel 1785 i due musicisti erano intimi amici, tanto da darsi del tu, ed ebbero diversi incontri in casa dei fratelli Storace, avendo occasione e di parlare di musica e di eseguire insieme musica cameristica.
Mozart ebbe come intimo amico il fratello Michael Haydn e ciò fu importante per la conoscenza di Joseph. Haydn, dalla residenza degli Esterházy dove prestava servizio, si recava spesso a Vienna dove Mozart si era definitivamente trasferito nel 1781.
A Haydn non poteva sfuggire la grandezza di Mozart ma non concepì questo fatto oggettivo con ostilità e invidia, bensì ne raccolse i suggerimenti compositivi. E ciò avvenne anche per Mozart che pubblicamente rese nota la sua riconoscenza a Haydn dedicandogli sei quartetti (K 387, K 421, K 428, K 458, K 464 e K 465)[226] e apprezzò per tutta la vita il compositore più di ogni altro musicista del passato o contemporaneo.
Mozart compose i citati quartetti tra il 1782 e il 1785, un'eccezione per un compositore che più volte aveva scritto concerti in poche ore e che a volte mandava a memoria la propria parte, presente solo nella sua testa ma non ancora riportata su uno spartito.
La ragione è semplice: i quartetti furono scritti nel modo rivoluzionario inventato da Haydn, pubblicando proprio nel 1771 i sei quartetti russi op. 33, la cui modalità di composizione fu da Haydn stesso definita "nuova e speciale maniera". La "nuova e speciale maniera" era costituita dall'abbandono dei principi compositivi del settecento della melodia con accompagnamento per dare invece un ugual risalto alle quattro voci dell'organico che si trovavano ora a colloquiare in modo paritetico.
Mozart aveva quindi due problemi da risolvere: imparare a comporre nel nuovo modo e trovare un proprio modo espressivo. Quale conseguenza della reciproca amicizia e stima, furono tramandate due opere parallele e immortali. La stima che Haydn aveva di Mozart è ben descritta nelle parole che Haydn dice al padre: «Vi dico innanzi a Dio, da galantuomo, che vostro figlio è il più grande compositore che io conosca, di nome e di persona. Ha gusto e possiede al sommo grado l'arte del comporre».
Quando Mozart morì a trentacinque anni, Haydn era a Londra. Seppe della morte dell'amico e collega solo al suo rientro a Vienna (1792), rimanendone rattristato.
Pochi altri autori musicali hanno suggestionato la fantasia del pubblico come Mozart. Già bambino prodigio noto nelle maggiori corti d'Europa, in seguito compositore di genio e infine protagonista di una precoce e misteriosa morte: la sua vita è stata interpretata, sin dall'Ottocento, come simbolo stesso della genialità e della perfezione apollinea, idealizzando la sua figura come nessun altro autore prima o dopo di lui. Creando quindi un mito di Mozart, genio assoluto, che tuttora nell'immaginario collettivo è probabilmente più popolare delle sue stesse opere. Non deve quindi stupire che siano fioriti aneddoti di ogni tipo sulla sua figura, miranti a sottolineare (rare volte a sproposito, ma spesso in modo esagerato) la sua genialità e la sua "unicità". 
Nel vasto repertorio di aneddoti che circondano il giovane Mozart, particolare è quello che riguarda la sua visita a Roma a Pasqua 1770: l'allora quattordicenne Mozart ascoltò il celebre Miserere di Gregorio Allegri, di proprietà esclusiva della Schola Cantorum della Cappella Sistina, che la custodiva gelosamente. L'esecuzione avveniva solo nella Settimana Santa a luci spente e lo spartito non poteva essere copiato né letto, pena la scomunica.
Si racconta (e lo affermò per primo il padre Leopold in una lettera alla moglie) che il giovane Mozart, dopo averlo ascoltato una sola volta, sia stato in grado di trascriverlo a memoria, nota per nota. A questa leggenda si aggiunge un secondo aneddoto: Felix Mendelssohn Bartholdy, in visita a Roma, per scommessa volle ripetere l'impresa di Mozart e, dopo un solo ascolto, fu anch'egli in grado di trascrivere fedelmente la composizione. La ricerca storiografica ha scoperto che Mozart ascoltò quest'opera due volte prima della trascrizione, mentre al meno celebrato Mendelssohn fu sufficiente un solo ascolto; Mozart però ascoltò il Miserere a 14 anni, mentre Mendelssohn ne aveva più di 20.[227]
Si racconta inoltre che Mozart bambino, durante uno dei suoi concerti alla corte dell'imperatrice Maria Teresa, rese omaggio a una piccola dama del reale seguito, chiedendola anche in moglie. Quella damina sarebbe diventata la regina di Francia Maria Antonietta.[228]
Il 12 gennaio 1782, Mozart scrisse al padre: "Clementi suona bene, fino a che guardiamo alla mano destra. La sua potenza sono i passaggi di terza. A parte questo, egli non ha un centesimo di gusto o sensibilità; in pratica è solo un puro meccanico". In una lettera successiva si spinse oltre: "Clementi è un ciarlatano, come tutti gli italiani". Per contro, le opinioni di Clementi su Mozart furono sempre entusiasticamente positive.
Mozart era particolarmente bravo a scrivere da destra a sinistra; infatti alcune righe delle sue lettere erano scritte al contrario.
Un altro aspetto del suo carattere era un senso dell'umorismo a tratti osceno. Ne rimangono testimonianze nelle lettere alla cugina Maria Anna Thekla, ai parenti e agli amici.[229] Compose persino una serie di canoni scatologici che intonava in compagnia degli amici, i più noti dei quali sono:
Nel corso degli anni nacque e si diffuse la leggenda secondo cui Mozart sarebbe stato avvelenato, per invidia, dal compositore italiano Antonio Salieri. Questa diceria, priva di fondamento, ha ispirato diversi artisti nel corso dei secoli.
Il poeta e scrittore russo Aleksandr Sergeevič Puškin diede credito a queste voci e nel 1830 scrisse Mozart e Salieri (precedentemente intitolato Invidia), un brevissimo dramma in versi, in cui un Salieri roso dall'invidia fa commissionare da Mozart un'opera, il Requiem, per poi ucciderlo, spacciare il brano per suo, suonarlo al funerale di Mozart e dover sentire: «Anche Salieri è stato toccato da Dio». Per la trovata, l'autore russo si ispirò probabilmente al fatto che il Requiem di Mozart fu commissionato dal conte Franz von Walsegg, che voleva spacciarlo per suo in occasione dell'anniversario della morte della moglie.
Di Puškin si disse: «Se Salieri non ha ucciso Mozart, di sicuro Puškin ha ucciso Salieri.[230]»
Il 6 (18) novembre 1898, al Teatro Solodovnikov di Mosca, andò in scena la prima dell'opera Mozart e Salieri di Nikolaj Andreevič Rimskij-Korsakov. La musica è ispirata e dedicata al compositore Dargomyžškij, mentre il libretto è scritto dallo stesso Rimskij-Korsakov basandosi sulla tragedia di Puškin, e come questa l'opera si divide in due sole scene.
La sera della prima, le variazioni sulla musica di Mozart furono eseguite dal pianista e compositore Sergej Rachmaninov.[senza fonte].
Nel 1978 un successivo adattamento della leggenda sulla fine di Mozart: Amadeus, del drammaturgo Peter Shaffer, conquista i teatri di Londra. La vicenda prende le basi da Puškin e ne amplia la portata. Rimane l'invidia di Salieri e il Requiem commissionato da un uomo vestito di nero (Salieri mascherato), ma il tutto è approfondito e narrato da Salieri stesso. Il testo subisce diverse modifiche, fino alla versione definitiva del 1981.
Nel 1984 il dramma di Shaffer fu portato al cinema da Miloš Forman con Amadeus, ma i lati negativi del personaggio di Salieri sono ammorbiditi rispetto a Puskin: anche se nella versione rimasterizzata del film del 2002 sono ripristinate alcune scene più dure, il Salieri cinematografico di F. Murray Abraham, che vinse l'Oscar per il miglior attore, è decisamente meno negativo di quello di Shaffer e per sua decisione, dato che il drammaturgo aveva curato anche la sceneggiatura del film. Nel film, a parte alcuni avvenimenti realmente accaduti a Mozart, gran parte della trama è una libera ricostruzione del personaggio, molto lontana dalla realtà.
Pur nell'inconfutabilità del genio mozartiano, un capitolo a parte meritano, nella sua vasta produzione artistica, i "prestiti" e le citazioni di opere altrui che si possono riscontrare nei suoi lavori. Nel noto Requiem, sono rintracciabili intere frasi musicali tratte da composizioni di Georg Friedrich Händel e di molti altri, tra cui Michael Haydn.[231] Mozart in alcune occasioni rielabora temi di Muzio Clementi: Ludwig Berger, allievo di Clementi, su Caecilia del 1829 stampa l'incipit della sonata Op. 24 n. 2 del suo maestro e osserva ironicamente che "forse è a questo tema che dobbiamo il geniale Allegro dell'ouverture della Zauberflöte, un'opera insuperata nel suo genere."[232]
Il musicologo Carlo Ballola su Gente del 1982 arrivò ad affermare che "se Mozart fosse vissuto ai nostri tempi, per i suoi plagi avrebbe dovuto passare molto tempo in Pretura".[233] È stata enorme l'influenza di Mozart sugli operisti napoletani e italiani, compreso il grande Rossini, in gioventù soprannominato "il tedeschino"  per lo studio di Mozart e altri grandi sinfonisti. Anche in ambito tedesco (dunque fondamentalmente sinfonico) Mozart fu "plagiato" da musicisti come Beethoven, che utilizzò due temi musicali mozartiani (sonate K 332 e K 135; Fuga della fantasia K 394) nella sua sinfonia pastorale e Felix Mendelssohn che sfruttò in diverse composizioni temi ispirati a Mozart.
Nel 1856 lo scrittore tedesco Eduard Mörike scrisse il racconto romantico Mozart in viaggio verso Praga, che narra il viaggio compiuto da Wolfgang e dalla moglie Constanze verso Praga per allestire la prima rappresentazione del Don Giovanni (29 ottobre 1787).
A Mozart sono dedicati il cratere Mozart su Mercurio[234] e l'asteroide 1034 Mozartia.
«He may thus be regarded as the most universal composer in the history of Western music.»
«Egli può dunque essere ritenuto il più universale compositore della storia della musica occidentale.»
()«Nun vergleiche man die Mozart'sche G moll-Symphonie (diese griechisch schwebende, wenn auch etwas blasse Grazie) oder das G moll-Concert von Moscheles und sehe zu! - Daß durch Versetzung der ursprünglichen Tonart einer Composition in eine andere, eine verschiedene Wirkung erreicht wird, und daß daraus eine Verschiedenheit des Charakters der Tonarten hervorgeht, ist ausgemacht.»
«Si confronti ora la sinfonia in sol minore di Mozart, questa aleggiante Grazia greca, o il concerto in sol minore di Moscheles e vedete un po'! – Che mediante il cambiamento della tonalità originaria di una composizione in un'altra, venga raggiunto un altro effetto e che ne risulti una differenza di carattere delle tonalità, è cosa fuori discussione.»
(Robert Schumann, Charakteristik der Tonarten)Altri progetti
Marco Polo (Venezia, 15 settembre 1254 – Venezia, 8 gennaio 1324) è stato un viaggiatore, scrittore, ambasciatore e mercante italiano, cittadino della Repubblica di Venezia.
La relazione dei suoi viaggi in Estremo Oriente è raccolta nell'opera letteraria Il Milione, una vera e propria enciclopedia geografica che riunisce le conoscenze essenziali sull'Asia in Europa alla fine del XIII secolo.
Membro del patriziato veneziano, viaggiò con il padre Niccolò e lo zio paterno Matteo attraverso l'Asia lungo la Via della seta fino alla Cina, allora Catai, dal 1271 al 1295. Consigliere e ambasciatore alla corte del Gran Khan Kubilai, tornò a Venezia nel 1295 con una discreta fortuna che investì nell'impresa commerciale di famiglia. Prigioniero dei genovesi dal 1296 al 1299, dettò le memorie dei suoi viaggi a Rustichello da Pisa, forse suo compagno di cella, che le scrisse in lingua franco-veneta[1] con il titolo "Divisiment dou monde".[2] Ormai ricco e famoso, sposò la patrizia Donata Badoer, dalla quale ebbe tre figlie: Moretta, Bellela, Fantina.[3] Morì nel 1324 e venne sepolto nella chiesa di San Lorenzo a Venezia.
Seppur non sia stato il primo europeo a raggiungere la Cina, fu il primo a redigere un dettagliato resoconto del viaggio, Il Milione, che fu ispirazione per generazioni di viaggiatori europei, come Cristoforo Colombo,[4] e fornì spunti e materiali alla cartografia occidentale, in primis al mappamondo di Fra Mauro.[5][6]
Nato a Venezia il 15 settembre 1254, Marco Polo è considerato uno dei più grandi viaggiatori ed esploratori di tutti i tempi.
Marco Polo è menzionato negli Archivi della Repubblica di Venezia come «Marco Paulo de confinio Sancti Iohannis Grisostomi»,[7] cioè Marco Polo della contrada di San Giovanni Grisostomo.
Il titolo dell'opera "Il libro di Marco Polo detto il Milione", però, era ambiguo: secondo alcuni studiosi "Il Milione" non era il soprannome del libro, bensì dello stesso Marco Polo.
Infatti l'umanista del XV secolo Ramusio scrive che:[8]
«nel continuo raccontare ch'egli faceva più e più volte della grandezza del Gran Cane, dicendo l'entrata di quello essere da 10 in 15 milioni d'oro, e così di molte altre ricchezze di quei paesi riferiva tutto a milioni, lo cognominarono "messer Marco Milioni".»
Il letterato del XIX secolo Luigi Foscolo Benedetto, "persuaso che 'Milione' sia il nomiglio dell'autore" lo considera un'apocope del diminutivo "Emilione".[9][10] Fra Iacopo da Acqui parla di "dominus Marcus Venetus (...) qui dictus est Milionus". "In ogni caso, il nomigliolo ricorre negli atti pubblici della Repubblica; dove invero, almeno una volta, viene impiegato anche per il padre di Marco."[11] Non è chiaro se tutti i membri della famiglia Polo del ramo detto Milion appartenessero al patriziato veneziano, certamente lo furono i mercanti Marco "il vecchio", i suoi fratelli e i suoi discendenti.[12]
La Corte Seconda del Milion a Venezia si trova accanto alla casa di Niccolò e Matteo Polo, su cui è stato costruito poi l'attuale Teatro Malibran.
Il primo avo di cui si abbia notizia è l'omonimo prozio, che prese del denaro in prestito e comandò una nave a Costantinopoli.[13][14] Il nonno di Marco, Andrea, abitava in contrada San Felice ed ebbe tre figli: Marco "il Vecchio", Matteo e Niccolò, padre di Marco.[13][15]
Nel 1260, Niccolò e Matteo, a quel tempo in affari a Costantinopoli (allora parte dell'Impero latino d'Oriente e controllata dai veneziani), cambiarono i loro averi in gemme e partirono per un viaggio attraverso l'Asia. Passando per Bukhara e il Turkestan cinese, raggiunsero la Cina, arrivando alla corte del neo-nominato Khagan (imperatore mongolo) Kubilai Khan (regno 1260-1294). L'azzardo dei fratelli Polo fu per loro provvidenziale: nel 1261, infatti, Michele VIII Paleologo riconquistò Costantinopoli, rifondando l'Impero bizantino, ed epurò la città dai Veneziani.[16] Niccolò e Matteo ripartirono per l'Occidente nel 1266, arrivando a Roma nel 1269 con un'ambasciata del Gran Khan, che richiedeva al Papa missionari per la Mongolia.[17]
Nulla si sa della sua infanzia, tranne che quasi certamente la passò a Venezia.[14][18] Restato orfano di madre (il padre si sarebbe poi risposato con Floradisa Trevisan[19]), venne cresciuto dagli zii.[17] Ricevette un'educazione consona al suo status, imparando a navigare, a far di conto (anche con valuta straniera) e a commerciare.[17] Non è chiaro se conoscesse o meno il latino.
I fratelli Niccolò e Matteo Polo ripartirono nel 1271 portandosi dietro Marco, "di età variamente indicata da dodici a diciannove anni, secondo le fonti",[20] ma che probabilmente aveva 17 anni.
Durante le prime tappe del viaggio si trattennero alcuni mesi ad Acri e poterono parlare con l'arcidiacono Tedaldo Visconti, futuro papa Gregorio X, che Marco chiama "Tedaldo da Piagenza".[21] I Polo, in quell'occasione, gli avevano espresso il loro rammarico per la lunga mancanza di un papa, poiché nel loro precedente viaggio in Cina avevano ricevuto da Kublai Khan una lettera per il pontefice, ed erano così dovuti ripartire per la Cina delusi.[22] Durante il viaggio, però, ebbero notizia che, dopo ben 33 mesi di vacanza, finalmente il Conclave aveva eletto il nuovo papa e questi altri non era che l'arcidiacono di Acri.[23] I tre dunque si affrettarono a ritornare in Terrasanta, dove il nuovo papa affidò loro lettere per il Gran Khan, invitandolo a mandare suoi emissari a Roma. Per dare maggior peso a questa missione, mandò con i Polo, come suoi legati, due padri domenicani, Guglielmo da Tripoli e Nicola da Piacenza.[24][25]
Da quanto riportato poi nel suo resoconto di viaggio, Il Milione, i tre Polo seguirono le varie tappe di quella che solo alcuni secoli dopo sarà chiamata la "Via della seta".
A conclusione di questo viaggio, durato tre anni e mezzo, arrivarono infine a Chemeinfu,[26] l'odierna Xanadu, città che il Khagan Kublai stava facendo costruire proprio in quegli anni. Una volta arrivato nel Catai, Marco ottenne i favori di Kubilai Khan, divenendone consigliere e in seguito anche ambasciatore, imparando a conoscere la lingua e i costumi dei tartari:[27]
«Quando gli due fratelli e Marco giunsero alla gran città ov'era il Gran Cane, andarono al mastro palagio, ov'egli era con molti baroni, e inginocchiaronsi dinanzi da lui, cioè al Gran Cane, e molto si umigliarono a lui. Egli li fece levare suso, e molto mostrò grande allegrezza, e domandò loro chi era quello giovane ch'era con loro. Disse messer Nicolò: "Egli è vostro uomo e mio figliuolo". Disse il Gran Cane: "Egli sia il ben venuto, e molto mi piace".»
(Il Milione di Marco Polo Vol. I, p. 6, Baldelli Boni, Firenze, 1827[28])Onorati e investiti di cariche governative, Marco in particolare "per le sue missioni ufficiali si spinse in India,[29] nel Yunnan, nel Tibet, in Birmania, lungo tragitti che ancora oggi presentano difficoltà per nulla lievi, anche prescindendo dalle condizioni politiche."[30]
Marco Polo fece ritorno a Venezia solo 24 anni dopo essere partito, il 9 novembre 1295.[31] Secondo Ramusio, a convincere i parenti, increduli dell'identità dei tre, furono i preziosi nascosti tra gli abiti.[32]
Secondo una diffusa leggenda, il 5 settembre 1298 Marco Polo si trovava su una delle novanta navi veneziane sconfitte dai genovesi nella battaglia di Curzola. Di sicuro fu catturato dai genovesi, anche se non nei pressi di Curzola, come sostenuto da alcuni studiosi influenzati dal Ramusio,[33] ma più probabilmente a Laiazzo in Cilicia, dopo uno scontro navale nel golfo di Alessandretta. Durante la prigionia incontrò Rustichello da Pisa; che fosse "in prigione da quattordici anni o vi venisse come libero frequentatore, fu quasi sicuramente lui a dare forma scritta alle memorie del veneziano"[34][35] che ebbero rapida fortuna in tutta Europa.
Polo fu finalmente rilasciato dalla prigionia nell'agosto 1299 e ritornò nuovamente a casa a Venezia, dove, nel frattempo, il padre e lo zio avevano acquistato un grande palazzo in Contrada San Giovanni Crisostomo (sestiere di Cannaregio), nota come "Corte del Milion", acquisto reso probabilmente possibile con i proventi del commercio e della vendita delle gemme portate dall'Oriente. La Compagnia Polo continuò le sue attività commerciali e Marco divenne presto un ricco commerciante. Marco e lo zio Matteo finanziarono altre spedizioni, ma probabilmente non abbandonarono mai le province veneziane né tornarono sulla Via della seta o in Asia.
Nel 1300 sposò la patrizia Donata Badoer, figlia di Vitale Badoer, commerciante, dalla quale ebbe tre figlie: Fantina (sposò Marco Bragadin[36]), Belella (sposò Bertuccio Querini[36]) e Moreta.[3]
Il 7 febbraio 2022 un documento d'archivio scoperto da Marcello Bolognari dell'Università Ca' Foscari dimostra l'esistenza di una figlia sconosciuta di nome Agnese, nata prima del matrimonio con Donata Badoer e che alla sua prematura morte, nel suo testamento redatto il 7 luglio 1319 fa riferimento al padre Marco Polo affidandogli il compito di far pervenire le sue ultime volontà principalmente al marito Nicolò detto Nicoletto, ed ai figli Barbarella, Papon e Franceschino.[37][38]
Pietro d'Abano, filosofo, medico e astrologo padovano, riferisce di avere parlato con Marco Polo di quello che aveva osservato nella volta celeste durante i suoi viaggi. Marco raccontò che, durante il suo viaggio di ritorno nel Mar Cinese Meridionale, aveva avvistato quella che descrive in un disegno come una stella "a forma di sacco" (ut sacco) con una grande coda (magna habet caudam). Pietro d'Abano interpretò questa informazione come una conferma che nell'emisfero sud si potesse osservare una stella analoga alla stella polare,[39][40] ma si trattava con ogni probabilità di una cometa. Gli astronomi sono concordi nell'affermare che non ci furono comete avvistate in Europa alla fine del 1200, ma ci sono testimonianze che una cometa venne avvistata in Cina e in Indonesia nel 1293.[39] Questa circostanza non compare nel Milione. Pietro D'Abano conservò il disegno nel suo volume Conciliator Differentiarum, quæ inter Philosophos et Medicos Versantur. Sempre nello stesso documento, si riporta la descrizione di un animale di grossa stazza con un corno sul muso, identificato oggi con il rinoceronte di Sumatra; Pietro d'Albano non riferisce un nome particolare assegnato da Marco a questo animale; si pensa invece che fu Rustichello a identificarlo con l'unicorno nel Milione.[40]
Mentre Pietro d'Abano era entusiasta delle parole di Marco Polo, che apparentemente confermavano le sue teorie,[40] il racconto del viaggio di Marco Polo non venne sempre accolto con favore, ma suscitò anche molta incredulità. Il frate domenicano Francesco Pipino, autore della prima traduzione latina fra il 1302 e il 1314,[41] si sentì evidentemente in dovere di affermare che il racconto era degno di fede: 
«affermò solennemente la veridicità del suo libro e lo disse "prudente, onorato, fedelissimo uomo"»
(Rinaldo Fulin)La stessa cosa fece il frate Jacopo d'Acqui[41]
«dopo di aver chiarito le ragioni dell'incredulità di cui i contemporanei circondavano i suoi racconti, narra che il Polo prima di morire assicurò “ di non aver detto che metà delle cose che “ aveva visto»
(Rinaldo Fulin)Il suo rapporto molto stretto con i frati domenicani ha fatto supporre che essi[7]
«forse collaborarono alla revisione dell'opera da parte di Marco, quasi come dei moderni editori»
(Antonio Montefusco)Nel 1305 Marco Polo viene menzionato in un documento veneziano, tra i capitani di mare locali, in merito al pagamento delle tasse. I dati relativi a questo periodo sono comunque oscuri: non è chiara la relazione tra Marco e un omonimo coinvolto nei moti anti-aristocratici del 1300, data in cui rischiò la pena capitale, e del 1310 (la congiura del Tiepolo alla quale parteciparono effettivamente dei Polo, ma di un ramo secondario: Jacobello e Francesco).
Nel 1307 Carlo di Valois, fratello minore del re di Francia Filippo il Bello è di passaggio a Venezia. Quando Carlo gli chiede una copia del suo libro, Marco Polo gli offre la "prima copia", consegnandola a Théobald de Cepoy, un nobile al suo servizio.
«Veez-ci le livre que monseigneur Thiebault, chevalier, seigneur de Cepoy, requist que il en eust la coppie à Sire Marc-Pol, bourgeois et habitans la cité de Venise. Et ledit sire Marc-Pol (...) bailla et donna au dessus dit seigneur de Cepoy la première coppie de son dit livre. (...) Et fut celle copie baillée dudit sire Marc-Pol audit seigneur de Cepoy quand il alla en Venise pour monseigneur de Valois et pour madame l'Empereris sa fame (...) Ce fut fait en l'an de l'incarnation N.S.J.C. mil trois cent et sept, mois d'aoust.»
«Vedete il libro che sire Thibault, cavaliere, signore di Cepoy, richiese di averne copia al signor Marc-Pol, borghese abitante la città di Venezia. E il detto signor Marc-Pol preparò e donò al detto sire di Cepoy la prima copia del suo libro. E fu questa copia preparata dal detto signor Marc-Pol al detto sire di Cepoy quando andò a Venezia per il sire di Valois e per la signora Imperatrice sua moglie. Ciò accadde nell'anno del Signore Gesù Cristo mille trecento e sette, al mese di agosto.»
Nel 1309-1310 Marco partecipò alla spartizione dei beni del defunto zio Matteo. Nel 1319 entrò in possesso di alcune tenute del padre defunto e nel 1321 acquistò parte della proprietà di famiglia della moglie Donata.[19] Nel 1323 figura come testimone per l’accettazione di alcuni lasciti testamentari di Giovanni dalle Boccole da parte dei frati domenicani del convento veneziano dei SS. Giovanni e Paolo.[7]
Nel 1323 era malato e inabilitato a muoversi dal letto.[42] L'8 gennaio 1324, in punto di morte, dettò le sue ultime volontà al sacerdote Giovanni Giustiniani di San Procolo, convocato dalle donne di casa.[43] Marco divise i suoi averi tra la famiglia, diversi istituti religiosi (tra cui la chiesa di San Procolo e la chiesa di San Lorenzo presso la quale sarebbe stato sepolto) nonché gilde e confraternite a cui apparteneva. Tra le altre cose, compensò con 200 soldi il notaio Giustiniani e affrancò e dotò di 100 lire veneziane un servo tartaro che si era portato dall'Asia, tale Pietro.[44] La data della morte non è certa: la Biblioteca Marciana, presso la quale è conservato il suo testamento (non firmato autografo dall'interessato, ma semplicemente confermato dai testimoni in accordo alla prassi del signum manus), data al 9 giugno il documento e post 9 giugno il decesso; secondo alcuni, invece, morì il giorno stesso in cui il testamento venne redatto.[45]
Le spoglie andarono perdute durante la ricostruzione della chiesa di San Lorenzo alla fine del XVI secolo.
La casa dei Polo andò distrutta durante un incendio nel 1598. Al suo posto, circa un secolo dopo, fu costruito il Teatro San Giovanni Grisostomo, noto oggi come Teatro Malibran.[46] Gli scavi archeologici condotti nel 1998 dalla soprintendenza ai Beni archeologici del Veneto hanno riportato alla luce diversi materiali, fra cui un eccezionale reperto di vetro viola di Murano.[47][48]
Più volte trascritto e tradotto, sono almeno centocinquanta i manoscritti documentati prima della diffusione della stampa e in seguito le edizioni non si contano.
Codici del Milione sono conservati in tutto il mondo.
Celebre per le squisite miniature è il 2810 "Libro delle meraviglie", conservato alla Biblioteca Nazionale di Francia.[50] L'esemplare in latino all'Alcázar di Siviglia[51] esibisce le presunte postille di Cristoforo Colombo.
La fortuna del testo negli ambienti scientifici ebbe inizio nel XV secolo.[52]
Il testo traccia dettagliatamente l'itinerario che i tre Polo seguirono attraverso la Via della seta. Procedettero verso l'interno del continente eurasiatico, attraversando l'Anatolia e l'Armenia.[53] Scesero quindi verso il fiume Tigri, toccando probabilmente Mosul[53][54] e Baghdad.[55]
Dopo avere attraversato la città di Tabriz in Iran[56] e poi la città di Yazd in Persia,[57] giunsero fino al porto di Ormuz,[58] forse con l'intenzione di proseguire il viaggio via mare. Continuarono invece a seguire la via terrestre entrando nel deserto del Gobi,[59] per giungere poi nel Khorasan.[60] In questa regione entrarono in contatto con la setta islamica degli "ismailiyyah", seguaci di Ḥasan-i Ṣabbāḥ, che Marco chiama il Veglio della Montagna.[61]
Nell'odierno Afghanistan descrive la città di Supunga, identificata come l'attuale Sheberghan, poi Tahican, forse l'attuale Taloqan, poi Balkh e il "Balasciam" (Badakhshan).[62][63] Attraversarono il Kashmir,[64] quindi il Wakhan;[65] superando con questo il Pamir, si diressero verso Samarcanda[66] in Uzbekistan ed entrarono nella "Gran Turchia" (Turkestan).[67] Discesero quindi verso il bacino del Tarim e giunsero nel Tangut,[68] ai confini con il Catai.
Qui arrivarono nella provincia di "Chingitalas", dove assistettero alla lavorazione di materiale ignifugo.[69] Arrivarono quindi a Zhangye,[70] poi a Caracorum.[71] Quindi proseguirono lungo la parte settentrionale dell'ansa del Fiume Giallo e raggiunsero Xanadu,[72] città che il Gran Khan Kubilai aveva fondato da poco.
L'isola di Curzola (oggi in Croazia, ma all'epoca possedimento della Serenissima) è a volte indicata come luogo di nascita di Marco Polo.[73] L'affermazione è basata su di una leggenda che appare per la prima volta nel 1856, in un'opera dello storico dalmata Simeone Gliubich.[74] Non solo non esistono degli adeguati studi storici che abbiano comprovato tale tesi[73][74] (la quale risulta quindi priva di fondamento),[73] ma nel 2013 uno studio scientifico ha analizzato l'affermazione e ne ha respinto l'autenticità, descrivendola come un caso di tradizione inventata e affermando che essa «può essere vista come una falsificazione pura, o anche come un furto di patrimonio culturale».[73]
La rivendicazione croata ha suscitato accese polemiche; svariati commentatori hanno evidenziato l'inconsistenza della tesi e rimarcato il fatto che in Croazia sia in atto un processo di revisionismo storico di matrice nazionalistica, che porta a negare l'ultrasecolare presenza italiana nell'Adriatico orientale, la quale viene arbitrariamente e sistematicamente negata, presentando come esclusivamente croato il patrimonio storico culturale ivi presente.[73][74][75][76][77][78][79][80][81][82][83] 
La rivendicazione è stata sostenuta anche per la sua efficacia nel pubblicizzare l'isola di Curzola come località turistica.[73]  Dal 1996, si tiene ogni estate a Curzola, il Marko Polo Fest, festival musicale ed enologico, che intende celebrare il famoso "curzolano".[84] L'Ente Nazionale del Turismo Croato, dal 2008 pubblicizza la Croazia come "Patria di Marco Polo".[85][86] Nel 2011, l'ex presidente croato Stipe Mesić  ha inaugurato un museo dedicato a "Marko Polo" nella città cinese di Yangzhou.[75]
Viene spesso citata una possibile origine dalmata della famiglia Polo, più precisamente da Sebenico. Questa tesi è stata proposta dal genealogista cinquecentesco Marco Barbaro, ma, come evidenziato dallo storico veneziano Alvise Zorzi, è infondata: la famiglia Polo era infatti presente a Venezia fin dall’anno 971.[87]
Gli scettici si sono a lungo chiesti se Marco Polo abbia scritto il suo libro sulla base di dicerie e hanno argomentato il loro scetticismo sulla base di alcune omissioni su pratiche e strutture degne di nota della Cina, così come la mancanza di dettagli su alcuni luoghi importanti. Per esempio, mentre Polo descrive la carta moneta e la combustione del carbone, non menziona la Grande Muraglia. Questa omissione è stata notata per la prima volta a metà del XVII secolo, e a metà del XVIII secolo è stato suggerito che potrebbe non aver mai raggiunto la Cina.[88] Più tardi, studiosi come John W. Haeger hanno sostenuto che Marco Polo potrebbe non aver visitato la Cina meridionale a causa della mancanza di dettagli nella sua descrizione delle città cinesi meridionali rispetto a quelle settentrionali, mentre il tedesco Herbert Franke ha ipotizzato che Marco Polo potesse non essere stato in Cina affatto e si è chiesto se potesse avere basato il suo racconto su fonti persiane.[89] Fra gli scettici, primeggiano Frances Wood[90] (curatrice della sezione cinese della British Library) e David Selbourne (filosofo politico britannico, commentatore sociale e storico). In particolare Frances Wood fa notare che Marco dichiara di avere avuto una funzione governativa, ma i Polo non vengano menzionati da nessuna fonte documentale cinese; che nel Milione, oltre alla Muraglia cinese, manchino le usanze cinesi più comuni: la tradizione del tè, il sistema di scrittura verticale, l’invenzione della stampa, la porcellana, l’uso delle bacchette per mangiare o i piedi fasciati delle donne. Inoltre, poiché i nomi delle località non sarebbero quelli utilizzati in cinese o mongolo, come ci si aspetterebbe, ma in persiano, questo indicherebbe che Marco Polo non aveva mai imparato il cinese. Il fatto che Marco Polo possa non avere mai imparato il cinese sarebbe stato avallato dal sinologo tedesco Wolfgang Franke[senza fonte] e da Daniele Petrella[senza fonte], archeologo dell’università di Napoli, secondo cui Polo avrebbe utilizzato fonti persiane per redigere il suo testo, trascorrendo alcuni anni all'interno delle comunità turche e persiane presenti nella zona. Infine, Frances Wood sottolinea alcuni particolari del Milione in cui i dettagli storici non corrispondono: le arcate del ponte oggi denominato "Marco Polo" erano 11 e non, come ricordava Marco Polo, 24; il viaggio di ritorno in Persia menziona una principessa mongola di nome Kökechin, di cui però non c'è traccia nei documenti della dinastia Yuan.
Fra gli interventi scientifici più rilevanti per ristabilire l'attendibilità del Milione vanno citati: uno studio dei cinesi Yang Chih-chiu e Ho Yung-Chi del 1945[91] e di nuovo uno studio del solo Yang Chih-chiu del 1985, considerato come la prova definitiva della presenza di Marco Polo in Cina.[92] In risposta agli interrogativi della Wood, sono intervenuti il danese Jørgen Jensen,[39] il filologo Igor de Rachewiltz (Università di Canberra),[93][94] lo storico economico Ugo Tucci (Università di Venezia)[95] e il sinologo Lionello Lanciotti (Università di Venezia).[96] A questi esperti si sono associati lo storico inglese Stephen G. Haw, il filologo francese Philippe Ménard (Università di Parigi-Sorbonne Paris IV), che in più occasioni è intervenuto a sottolineare come le occorrenze geopolitiche espresse in Marco Polo siano troppo peculiari per risultare menzognere,[97] e più di recente il sinologo tedesco Hans Ulrich Vogel dell'Università di Tubinga, autore di un monumentale volume[98] che per la prima volta confronta le affermazioni di Marco Polo con fonti sia europee sia asiatiche.
In particolare Chih-chiu e Yung-Chi nel loro articolo del 1945 riferiscono di avere scoperto alcuni documenti storici dell'epoca Yvan, in cui si riferisce di un'ambasceria mongola in Persia che includeva tre ambasciatori, Oulatay, Apusca e Coja.[99] Non si menziona invece la principessa. Gli studiosi hanno confrontato questa informazione con il resoconto di uno storico persiano coevo di Marco Polo Rashid al-Din Hamadani: Hamadani parla di un'ambasceria arrivata in Persia dalla Mongolia, e menziona un ambasciatore di nome Coja nonché una principessa mongola, pur senza precisarne il nome.[99][100] Questo coincide con l'affermazione di Marco, secondo cui di seicento persone che componevano l'equipaggio iniziale arrivarono a destinazione in diciotto, e in particolare "Di tre ambasciatori di Argon si salvò uno solo, quello chiamato Cogia".[99] Secondo gli studiosi cinesi, il fatto che Marco Polo non sia menzionato nella fonte cinese né in quella persiana non è strano, dato che nella fonte cinese non è citata nemmeno la principessa. Questa omissione, secondo loro, si giustifica con la relativa poca importanza attribuita a Marco Polo, che verosimilmente faceva parte della scorta, e con la delicatezza della missione diplomatica che riguardava una principessa reale. Quello che conta veramente, secondo gli autori della ricerca, è che la versione di Marco Polo permette di riconciliare le due fonti, fornendo un'informazione che non avrebbe potuto conoscere altrimenti che trovandosi sul luogo di persona.
Un altro particolare interessante è menzionato dal danese Jørgen Jensen:[39] il fisico e astrologo padovano Pietro D'Abano (1250-1316) riporta nel suo "Conciliator Differentiarum" una conversazione da lui avuta con Marco Polo, in cui questo aveva disegnato una stella "a forma di sacco" (ut sacco) con una lunga coda (magna habens caudam) da lui vista durante uno dei suoi viaggi nel mare d'Indonesia. Gli astronomi sono concordi che in Europa non c'era stato nessun avvistamento particolare di stelle alla fine del 1300 e che però una cometa era stata avvistata in Cina e in Indonesia nel 1293. Altri diversi dettagli astronomici forniti da Marco a D'Abano si possono spiegare secondo Jensen solo ammettendo che Marco sia stato effettivamente in Cina. Cosa più interessante, né la cometa né i dettagli astronomici sono menzionati nel Milione.
Igor de Rachewiltz[93][94] critica aspramente il volume di Frances Wood e risponde a vario titolo su molti punti. Argomenta fra le altre cose che la mancanza di riscontri scritti sul nome dei Polo negli archivi cinesi è molto probabilmente dovuta al fatto che i tre europei erano considerati come del tutto insignificanti dal governo locale, anche se loro tendevano a pensare il contrario. Analogamente, Marco Polo era molto probabilmente indifferente alle particolarità della cultura cinese, in quanto all'epoca del suo viaggio i Cinesi erano dominati dai Mongoli e quindi componevano uno degli strati sociali più bassi, per cui non valeva la pena né di informarsi sulla loro cultura, né sulla loro lingua. Quindi non è affatto strano che Marco comunicasse in persiano, la "lingua franca" della zona all'epoca. Più in generale, secondo Rachewiltz, le omissioni che Wood imputa a Marco Polo sono dovute al fatto che determinate località oppure usi e costumi non erano così importanti all'epoca di Marco quanto lo siano state dopo: la Grande Muraglia per esempio non era ancora stata completata.
Lo storico inglese Stephen G. Haw sottolinea che molte critiche rivolte al "Milione" sono iniziate nel 1600 e sono anacronistiche, mentre il racconto di Marco Polo ha la caratteristica di essere notevolmente accurato. "Se Marco era un bugiardo, era un bugiardo meticoloso al limite del plausibile".[101]
Di recente il sinologo tedesco Hans Ulrich Vogel[102] ha pubblicato un volume in cui esamina dettagliatamente le descrizioni che Marco Polo fornisce delle valute, della produzione di sale, della circolazione della moneta. Vogel ha osservato che nessun'altra fonte occidentale, araba o persiana ha fornito dettagli così accurati e unici sulle valute cinesi, ad esempio la forma e le dimensioni della carta, l'uso dei sigilli, i vari tagli di carta moneta e le variazioni nell'uso della moneta nelle diverse regioni della Cina, come l'uso di conchiglie di cipree nello Yunnan. Anche i suoi resoconti sulla produzione del sale e sui ricavi del monopolio del sale sono accurati e sono in accordo con i documenti cinesi dell'era Yuan. Per esempio, il resoconto che Marco fa nel capitolo 95 della preparazione della carta moneta è notevolmente preciso e meticoloso. Tutti questi dettagli sono stati suffragati da documenti e reperti archeologici ritrovati molto tempo dopo il rientro di Marco a Venezia: egli dunque non poteva avere avuto accesso a queste informazioni da fonti coeve.
«"Coment le Gran Kaan fait despendre charchre por monoie"  
"Come il Gran Khan fa usare della carta come moneta"»
(Le devisement dou monde, XCV, ed. Mario Eusebi)Il volume di Vogel del 2013 ha il pregio di riunire per la prima volta fonti occidentali e cinesi. Lo storico dell'economia Mark Elvin, nella prefazione alla monografia di Vogel, conclude che il testo "dimostra con esempi specifici, la probabilità, in ultima analisi, di un'ampia autenticità" del resoconto di Polo. Mark Elvin conclude che il libro è, "in sostanza, autentico e, se usato con cura, in termini generali da considerare come un testimone serio anche se ovviamente non sempre definitivo".[103]
Nel "Milione", Polo sostiene di essere stato un amico intimo e consigliere di Kublai Khan. Inoltre, si è letto che è stato "il governatore" della città di Yangui o Yangiu[104] (odierna Yangzhou) e poi di Chinsai (odierna Hangzhou).
«Et meser Marc Pol meisme, celui de cui trate ceste livre, seingneurie ceste cité por trois anz.»
«E lo stesso Marco Polo, colui di cui tratta questo libro, governò questa città per tre anni»
(Le devisement dou monde, CXLII, ed. Mario Eusebi, p. 162)Questa affermazione ha suscitato molte controversie.
Il sinologo francese Paul Pelliot ipotizzò che Polo avrebbe potuto servire come ufficiale del monopolio governativo del sale a Yangzhou: questa era una posizione di una certa importanza.[105]
Lo storico britannico David O. Morgan, esperto in storia dei Mongoli, pensava che Marco Polo fosse con ogni probabilità vissuto in Cina, ma che avesse esagerato o mentito sul suo status in Cina,[105] mentre Ronald Latham credeva che tali esagerazioni fossero abbellimenti inseriti da Rustichello da Pisa.[106] L'argomento a favore di questa tesi è che nessuna fonte dell'epoca lo menziona come amico dell'imperatore o come governatore di Yangzhou - anzi nessuna fonte cinese menziona Marco Polo.[105]
Negli anni 1960 il tedesco Herbert Franke notava che tutte le occorrenze di Po-lo o Bolod (parola altaica che significa "acciaio") nei testi Yuan erano nomi di persone di estrazione mongola o turca.[89]
Lo storico e sinologo Stephen G. Haw, contesta l'idea che Polo abbia esagerato la propria importanza, scrivendo che, "contrariamente a quanto è stato spesso detto... Marco non rivendica alcuna posizione molto altolocata nell'impero Yuan". Egli sottolinea che Marco non ha mai affermato di essere un ministro di alto rango, un darughachi, il capo di un tumen (cioè 10.000 uomini), nemmeno il capo di 1.000 uomini, ma solo che era un emissario per il khan e aveva ricoperto una posizione d'onore. Haw vede questo come una ragionevole pretesa se Marco era un kheshig: all'epoca i kheshig erano circa quattordicimila uomini. Haw spiega come i primi manoscritti del Milione forniscano informazioni contraddittorie sul suo ruolo a Yangzhou, alcuni affermando che era solo un semplice residente, altri affermando che era un governatore, mentre il manoscritto di Ramusio afferma che stava semplicemente tenendo quella carica come sostituto temporaneo per qualcun altro, ma tutti i manoscritti concordano sul fatto che egli abbia lavorato come stimato emissario per il khan. Haw si oppose anche all'approccio impiegato da molti studiosi per trovare la menzione di Marco Polo nei testi cinesi, sostenendo che gli europei contemporanei avevano poca considerazione per l'uso dei cognomi, e una trascrizione cinese diretta del nome "Marco" ignora la possibilità che egli abbia assunto un nome cinese o addirittura mongolo che non avesse alcuna attinenza o somiglianza con il suo nome latino.[107]
Tuttavia, esiste documentazione nello Yuanshi, "Cronache della dinastia Yuan", riguardante un certo Boluo, cortigiano dell'imperatore, che venne fatto arrestare nel 1274 da un dignitario imperiale di nome Saman: l'accusa era quella di avere camminato dallo stesso lato della strada di una cortigiana, contravvenendo all'ordine che ingiungeva a uomini e donne di camminare su lati opposti della strada.[99] Lo studioso cinese Peng Hai in un volume del 2010 ha identificato questo Boluo con Marco Polo.[108] Boluo fu liberato su richiesta dell'imperatore in persona, e venne poi trasferito nella regione di Ningxia, nel nord-est dell'attuale Cina, nella primavera del 1275. La data potrebbe corrispondere alla prima missione di cui parla Marco al cap. 15.[99]
Può sembrare inverosimile che uno straniero potesse raggiungere una posizione di un certo rilievo nell'Impero mongolo, ma alcuni documenti provano che Marco non era né il primo né l'unico. Nel cap. 62 del Milione, Marco cita un funzionario di nome "Mar Sarchis" (scritto "Marsarchis" o "Masarchim" in alcuni manoscritti),[109] un cristiano nestoriano, e afferma che era stato "signore" per il Khan della città di "Cinghiafu" (Zhenjiang)[110] per tre anni, e che in questo periodo aveva fondato due chiese cristiane. L'identità di questo Mar Sarchis è stata per molto tempo un mistero. "Mar" è l'appellativo che nella Chiesa siriaca si dà ai vescovi e corrisponde al latino "Don", mentre "Sarchis" dovrebbe corrispondere a "Sergius".[111] Questo funzionario è, effettivamente, menzionato nella gazzetta locale Zhishun Zhenjian zhi con il nome di "Ma Xuelijisi" e la qualifica di "generale di terza classe":[112] nella gazzetta si afferma che Ma Xuelijisi aveva lavorato per tre anni come "assistente supervisore" nella provincia di Zhenjiang e che durante questo periodo aveva fondato due chiese cristiane. La provincia di Zhenjiang è confinante con quella di Yangzhou in cui si trovava Marco.[99]
Queste congetture sembrano avvalorate dal fatto che oltre al dignitario imperiale Saman (quello che aveva fatto arrestare il funzionario Boluo), i documenti parlano anche del fratello di questi, Xiangwei. Secondo le fonti, Saman morì poco dopo l'episodio, mentre Xiangwei viene trasferito a Yangzhou nel 1282-1283. Marco Polo nel Milione riferisce di essere stato spostato a Hangzhou l'anno dopo, nel 1284.[99] Si è ipotizzato che questi spostamenti siano dovuti alla volontà di evitare ulteriori conflitti fra i due.
Un'altra affermazione controversa è la seguente: nel cap. 145, si sostiene che i tre Polo avrebbero fornito ai Mongoli consigli tecnici sulla costruzione di manganelle durante l'assedio di Saianfu (Xiangyang):
«Adonc distrent les .II. freres et lor filz meser Marc. "Grant Sire, nos avon avech nos en nostre mesnie homes qe firont tielz mangan qe giteront si grant pieres qe celes de la cité ne poront sofrir mes se renderont maintenant.»
«Allora dissero i due fratelli e il loro figlio messer Marco "Gran Signore, abbiamo con noi nel nostro seguito degli uomini che fabbricheranno delle manganelle che getteranno delle pietre così grandi che gli abitanti della città non potranno sopportare ma si arrenderanno subito»
(Le devisement dou monde, CXLV, ed. Mario Eusebi, p. 163)Quest'affermazione è stata messa in discussione, in quanto l'assedio era durato dal 1268 al 1273, ed era quindi terminato prima che Marco Polo fosse arrivato in Cina. L'esercito mongolo che assediò Xiangyang aveva ingegneri militari stranieri, ma sono stati menzionati in fonti cinesi come provenienti da Baghdad e avevano nomi arabi.[89] Sempre Igor de Rachewiltz[93][94] ricorda che l'affermazione secondo cui i tre Polo erano tutti presenti non si trova in tutti i manoscritti. È dunque possibile che la frase "et lor filz meser Marc" sia un'aggiunta successiva, e non è privo di logica il fatto che Niccolò e Matteo, prima di ripartire per l'Europa, abbiano fornito indicazioni tecniche e militari di qualche tipo al Gran Khan.
Lo storico dell'economia Mark Elvin, nella prefazione alla monografia di Vogel del 2013, sottolinea come molti problemi furono causati dal proliferare di manoscritti copiati a mano, significativamente diversi: per esempio si può dubitare del fatto che Marco Polo abbia esercitato una "autorità politica" (seignora) a Yangzhou o vi abbia semplicemente fatto un "soggiorno" (sejourna).[103]
Una leggenda parla di un matrimonio che Marco Polo avrebbe contratto in Cina con una delle figlie dell'Imperatore, Hao Dong, la quale lo avrebbe seguito nel suo primo rientro a Venezia, nel 1295. Hao Dong avrebbe vissuto a Venezia fino alla notizia della cattura di Marco da parte dei Genovesi nel 1298, fatto questo che l'avrebbe spinta al suicidio.[113][114] Di questa figura non c'è traccia scritta, né alcun reperto archeologico.
È vero però che alla morte di Marco Polo si fece un inventario dei suoi beni, fra cui compare "una bochta doro con piere et perle".[99] La "bochta", in mongolo bogtak, era un copricapo che portavano le donne tatare sposate (di cui parla fra gli altri Guglielmo di Rubruck[115]).
Poiché sembra improbabile che una donna sposata avesse fatto dono del proprio copricapo a Marco, i filologi hanno ipotizzato che durante il suo soggiorno in Catai, Marco si sia effettivamente sposato con una donna del posto. A rafforzare questa ipotesi è il cap. IV del Milione, in cui Marco spiega la lunga "procedura" con cui venivano selezionate le mogli e concubine dell'imperatore, reclutate presso la tribù degli "Ungrat" (Qongirat[99]). Secondo Marco, le candidate che non superavano la "selezione" venivano fatte sposare ai baroni oppure imparavano a servire alla corte imperiale.
Nessun documento parla di questa moglie, ragion per cui è probabilmente deceduta prima che Marco rientrasse a Venezia.[99]
Nel 1997 gli venne dedicato l'asteroide 29457 Marcopolo. Autore della scoperta e della intitolazione fu l'astronomo Vittorio Goretti.
Nel 1961 è stato inaugurato l'aeroporto di Venezia, intitolato a Marco Polo.
Dal 1982 Marco Polo è stato raffigurato sulla banconota da 1.000 lire italiane che hanno avuto corso legale fino al 1995.[119]
A Marco Polo sono intitolate strade e piazze di molte città italiane.
«Era innamorato della natura misteriosa come l'amante dell'amata lontana»
(Albert Einstein, da una lettera a Gertrud Warschauer, 27 dicembre 1952)Michael Faraday (IPA: /ˈfærədeɪ/; Southwark, 22 settembre 1791 – Hampton Court, 25 agosto 1867) è stato un chimico, fisico e divulgatore scientifico britannico.
Ha contribuito in maniera determinante allo studio dell'elettromagnetismo e dell'elettrochimica: tra le sue invenzioni, la gabbia di Faraday e il becco di Bunsen, mentre tra le sue scoperte si annoverano le leggi di Faraday dell'elettrochimica, l'elettrolisi, il diamagnetismo e l'effetto Faraday, ovvero l'induzione elettromagnetica. A titolo di onore, è stato dato il suo nome all'unità di misura della capacità, il farad, e al cratere Faraday sulla Luna.
Michael Faraday nacque a Newington Butts, vicino all'odierna Elephant and Castle, nell'allora borgo londinese di Southwark. La sua famiglia era estremamente povera; suo padre, James Faraday, era un fabbro che soffrì di salute cagionevole per tutta la vita; nel corso del tempo abbracciarono le credenze religiose dei sandemaniani, una corrente del cristianesimo protestante: in effetti, Michael Faraday fu un fervente cristiano fino all'ultimo dei suoi giorni[1]. Michael Faraday iniziò a lavorare a 13 anni come fattorino nella bottega di un libraio. A quattordici anni divenne apprendista rilegatore presso la stessa libreria locale e, durante i suoi sette anni di apprendistato, lesse molti libri, incluso The Improvement of the Mind di Isaac Watts, di cui applicò entusiasticamente i principi e i suggerimenti. Sviluppò un interesse per le scienze e specificamente per ciò che riguardava l'elettricità. In particolare, fu ispirato dal libro Conversations in Chemistry di Jane Marcet[2].
Da autodidatta studiò chimica fino a quando, grazie a eventi fortuiti, dal 1810 poté iniziare a frequentare lezioni regolari, negategli fino ad allora per il suo stato sociale, alla Royal Institution.
All'età di vent'anni, nel 1812, Faraday iniziò, su consiglio di un cliente, a seguire le lezioni dell'eminente chimico e fisico britannico Humphry Davy, della Royal Institution e Royal Society, e di John Tatum, fondatore della City Philosophical Society.
Molti inviti per queste lezioni furono forniti a Faraday da William Dance (uno dei fondatori della Royal Philharmonic Society). In seguito Faraday inviò a Davy un libro di 300 pagine basato sulle annotazioni prese durante le lezioni. La reazione di Davy non si fece attendere: essendosi danneggiato la vista in un incidente con il tricloruro di azoto, ed evidentemente colpito dalla passione di Faraday, decise di prenderlo come suo assistente.
Quando poi John Payne, uno degli assistenti della Royal Institution, fu licenziato, al neo-nominato Sir Humphry Davy fu chiesto di trovare un sostituto. Egli nominò Faraday come assistente di chimica alla Royal Institution il 1º marzo 1813.
Nella società classista del Regno Unito dell'epoca, Faraday non era purtroppo considerato un gentleman. Quando Davy compì un lungo viaggio in Europa tra il 1813 e il 1815, il suo cameriere non volle andare. Faraday andò come assistente scientifico di Davy e gli fu chiesto di fungere da cameriere fino a che non si fosse trovato un rimpiazzo a Parigi. Dal momento che non si riuscì a trovare un sostituto, Faraday dovette svolgere per tutto il viaggio le mansioni di cameriere, più che di assistente.
La moglie di Davy, Jane Apreece, rifiutò di trattare Faraday come un parigrado e rese la condizione di Faraday così miserevole che egli considerò l'idea di tornare da solo nel Regno Unito e di rinunciare completamente alle scienze.
Il viaggio, tuttavia, gli diede accesso all'élite scientifica europea e a una serie di idee stimolanti.
Faraday pubblicò il suo primo articolo scientifico nel 1816 e nel 1823 diventò membro della Royal Society. Divenne direttore di laboratorio nel 1825 e nel 1833 fu nominato professore fulleriano a vita di chimica nell'istituto, senza l'obbligo di tenere lezioni.
I primi lavori di chimica di Faraday risalgono alla sua collaborazione con Davy. Fece uno studio speciale sul cloro, scoprendo due nuovi cloruri del carbonio. Fece anche i primi esperimenti sulla diffusione dei gas, un fenomeno teorizzato per la prima volta da John Dalton, la cui importanza nel campo fisico fu pienamente portata alla luce da Thomas Graham e Joseph Loschmidt. Riuscì a liquefare vari gas; indagò sulle leghe dell'acciaio e produsse molti nuovi tipi di vetro con scopi ottici. Un campione di uno di questi vetri pesanti divenne storicamente importante come la sostanza in cui Faraday trovò la rotazione del piano di polarizzazione della luce quando il vetro è posto in un campo magnetico e anche come la sostanza che fu per prima respinta dai poli del magnete. Tentò anche, con un certo successo, di creare dei metodi generali della chimica come distinti dai loro risultati, la materia di studi speciali e di esposizione pubblica.
Inventò una forma arcaica di quello che poi divenne il becco di Bunsen, che è stato utilizzato in quasi tutti i laboratori scientifici come una fonte di calore conveniente.[5]
Faraday lavorò estensivamente nel campo della chimica, scoprendo sostanze chimiche quali il benzene (che chiamò bicarburo di idrogeno), inventando il sistema dei numeri di ossidazione e liquefacendo gas come il cloro.
Preparò il primo clatrato idrato. Faraday scoprì anche le leggi dell'elettrolisi e rese popolari termini come anodo, catodo, elettrodo, e ione, termini in gran parte introdotti da William Whewell. Per questi successi, molti chimici moderni guardano a Faraday come a uno dei massimi scienziati sperimentali della storia. Le leggi dell'elettrolisi vennero, pochi anni dopo, riscoperte per via indipendente, e quindi confermate, da Carlo Matteucci, scienziato con cui Faraday entrò in relazione di amicizia, al punto da imparare l'italiano per corrispondere con lui.
Il suo maggior impegno fu nel campo dell'elettricità. Il primo esperimento che condusse fu la costruzione di una pila di Volta con sette pezzi di mezzo penny, tenuti insieme con sette dischi di fogli in zinco e sei pezzi di carta immersa in una soluzione salina. Con questa pila decompose il solfato di magnesio (prima lettera ad Abbott, 12 luglio, 1812). Nel 1821, poco dopo che il fisico e chimico danese Hans Christian Ørsted aveva scoperto il fenomeno dell'elettromagnetismo, Davy e lo scienziato britannico William Hyde Wollaston tentarono senza successo di progettare un motore elettrico. Faraday, dopo aver discusso il problema con i due, costruì due dispositivi per produrre quello che chiamava rotazione elettromagnetica: un moto circolare continuo causato dalla forza magnetica attorno a un filo: un filo che s'immerge in un bagno di mercurio con un magnete posto all'interno ruoterà attorno al magnete se alimentato con corrente da una batteria chimica. Questi esperimenti e invenzioni formeranno la base della moderna tecnologia elettromagnetica. Avventatamente, Faraday pubblicò i suoi risultati senza riconoscere il suo debito verso Wollaston e Davy, e la controversia che ne seguì provocò il ritiro di Faraday dalla ricerca elettromagnetica per alcuni anni.
A questo punto è evidente che Davy stesse tentando di rallentare l'ascesa di Faraday come scienziato. Nel 1825, per esempio, Davy mise a punto i suoi esperimenti con vetri onto-ottici, che portò avanti per sei anni senza grandi risultati. Fino alla morte di Davy, nel 1829, Faraday interruppe questi lavori infruttuosi e scelse sforzi più gratificanti. Due anni dopo, nel 1831, iniziò la sua grande serie di esperimenti in cui scoprì l'induzione elettromagnetica, benché tale scoperta fosse stata anticipata da un'opera di Francesco Zantedeschi. La sua scoperta avvenne quando avvolse due rotoli isolati di filo elettrico attorno a un grande anello di acciaio, fissato a un tavolo, e scoprì che facendo passare corrente attraverso un rotolo, una corrente momentanea era indotta nell'altro rotolo.
Il sistema anello d'acciaio-rotolo è ancora in mostra alla Royal Institution. Negli esperimenti successivi scoprì che, muovendo un magnete attraverso un cappio di filo, nel filo fluiva corrente elettrica. La corrente fluiva anche muovendo il solenoide sopra il magnete fermo.  Le sue dimostrazioni stabilirono che un campo magnetico variabile produce un campo elettrico. Questa relazione è espressa matematicamente mediante la legge di Faraday-Neumann-Lenz, che divenne successivamente una delle quattro equazioni di Maxwell. Queste si sono evolute nella generalizzazione conosciuta come teoria dei campi.
Faraday utilizzò successivamente tale principio per costruire la dinamo, l'antenato dei moderni generatori di corrente.
Nel 1839 terminò una serie di esperimenti finalizzati a investigare la natura fondamentale dell'elettricità. Faraday usò statica, batterie, ed elettricità animale per produrre fenomeni di attrazione elettrostatica, elettrolisi, magnetismo, ecc.; concluse che - contrariamente all'opinione scientifica del tempo - le divisioni tra i vari tipi di elettricità erano illusorie. Faraday invece affermò l'esistenza di un'unica elettricità e che i valori variabili di quantità e intensità (differenza di potenziale e carica) erano responsabili dei diversi gruppi di fenomeni.
Alla fine della sua carriera, Faraday intuì che le forze elettromagnetiche si propagano nel vuoto attorno al conduttore. Quest'idea fu inizialmente rifiutata dalla comunità scientifica, e Faraday non visse abbastanza per vedere le sue intuizioni confermate. Il concetto, elaborato da Faraday, delle linee di flusso che emanano dai corpi carichi e dai magneti fornì un modo di visualizzare i campi elettrici e magnetici. Questo modello fu indispensabile allo sviluppo dei dispositivi elettromeccanici che dominarono l'ingegneria e l'industria per il resto del XIX secolo.
Nel 1845 compì due importanti scoperte: il fenomeno che denominò diamagnetismo e quello che oggi è detto effetto Faraday: il piano di polarizzazione di una luce linearmente polarizzata che si propaga attraverso un mezzo materiale può essere deviato mediante l'applicazione di un campo magnetico esterno allineato alla direzione di propagazione. Scrisse nel suo taccuino, "Alla fine sono riuscito a illuminare una curva magnetica o linea di forza e a magnetizzare un raggio di luce". Grazie a questa scoperta si poté stabilire che forza magnetica e luce erano connesse.
Nella sua ricerca sull'elettricità statica, Faraday dimostrò che la carica risiedeva solamente all'esterno di un conduttore carico, e che la carica esterna non aveva influenza sull'interno del conduttore. Questo perché le cariche esterne si redistribuiscono in modo che i campi interni dovuti a esse si annullino. Questo effetto scudo è sfruttato in quella che oggi è conosciuta come gabbia di Faraday.
A dispetto della sua eccellenza come scienziato sperimentale, la sua abilità matematica non si estendeva oltre la trigonometria e l'algebra più elementare. Tuttavia, le sue scoperte sperimentali furono consolidate da James Clerk Maxwell, il quale sviluppò le equazioni che stanno alla base di tutte le moderne teorie sui fenomeni elettromagnetici. Faraday, comunque, fu abile a comunicare le sue idee in linguaggio chiaro e semplice.
Nel 1848 gli fu assegnata dal principe consorte Alberto di Sassonia-Coburgo-Gotha una casa grace and favour a Hampton Court, Surrey. Questa era stata l'abitazione del capitano Mason e fu in seguito chiamata Faraday House; ora è il No. 37 Hampton Court Road. Nel 1858 si ritirò a vivere lì[6].
Durante la sua vita, Faraday rifiutò il titolo di cavaliere e rifiutò due volte di divenire Presidente della Royal Society. Rifiutò anche di partecipare alla produzione di armi chimiche per la guerra di Crimea, citando ragioni etiche.
Morì nella sua abitazione a Hampton Court il 25 agosto 1867. A Westminster Abbey vicino alla tomba di Isaac Newton si trova una placca in sua memoria. In vita, Faraday rifiutò di essere sepolto lì per cui, alla morte, venne tumulato nel Highgate Cemetery.
Una statua di Faraday campeggia a Savoy Place, Londra, fuori dall'Institution of Electrical Engineers.
Nel 1960 gli è stata dedicata una sala alla Loughborough University. Vicino all'ingresso della sala da pranzo c'è un bronzo che raffigura il simbolo di un trasformatore elettrico, mentre all'interno si può ammirare un ritratto, entrambi in suo onore. Infine, il suo ritratto è stato stampato sulla banconota da 20 sterline dal 1991 fino al 2001.[7]
Nikola Tesla (in serbo: Никола Тесла?; Smiljan, 10 luglio 1856 – New York, 7 gennaio 1943) è stato un inventore, fisico e ingegnere elettrico, nato da famiglia serba[1] nell'attuale territorio della Croazia durante il periodo dell'Impero austriaco, naturalizzato statunitense[2] nel 1891.
Contribuì allo sviluppo di diversi settori delle scienze applicate[3], in particolare nel campo dell'elettromagnetismo, di cui fu un eminente pioniere, tra la fine dell'Ottocento e gli inizi del Novecento. I suoi brevetti e il suo lavoro teorico formano, in particolare, la base del sistema elettrico a corrente alternata, della distribuzione elettrica polifase e dei motori elettrici a corrente alternata, con i quali ha contribuito alla nascita della seconda rivoluzione industriale. A riconoscimento dei suoi contributi fu intitolata a suo nome, durante la Conférence générale des poids et mesures del 1960, l'unità di misura dell'induzione magnetica nel Sistema internazionale di unità di misura.
Negli Stati Uniti d'America fu tra gli scienziati e inventori più famosi, anche nella cultura popolare[4]; dopo la sua dimostrazione di comunicazione senza fili (radio) nel 1893[5], e dopo essere stato il vincitore della cosiddetta "guerra delle correnti" insieme a George Westinghouse contro Thomas Alva Edison, fu riconosciuto come uno dei più grandi ingegneri elettrici statunitensi; molti dei suoi primi studi si rivelarono anticipatori della moderna ingegneria elettrica e diverse sue invenzioni rappresentarono importanti innovazioni tecnologiche.
Fu nominato vicepresidente dell'American Institute of Electrical Engineers (di cui era presidente Alexander Graham Bell) e venne insignito della settima Medaglia Edison nel 1917 dalla stessa AIEE[6], massimo riconoscimento assegnatogli in vita; in un articolo pubblicato sul New York Times[7], Tesla ed Edison furono erroneamente annunciati quali vincitori alla pari del premio Nobel per la fisica 1915, ma in realtà non s'aggiudicarono mai il premio[8].
Depositò nell'arco della sua carriera tra il 1886 e il 1928, un totale di 280 brevetti in 26 paesi[9], di cui 104 negli USA. Non mancarono contestazioni riguardo alla paternità di alcune di queste invenzioni: la scoperta del campo magnetico rotante fu descritta in una nota presentata il 18 marzo 1888 all'Accademia reale svedese delle scienze dallo scienziato italiano Galileo Ferraris, ma Tesla rivendicò la priorità di tale scoperta, che finì nelle aule giudiziarie, dove si stabilì che la paternità dell'invenzione spettava allo scienziato italiano. Nel 1943, pochi mesi dopo la sua morte, una sentenza della Corte suprema degli Stati Uniti d'America[10] attribuì a Tesla la paternità di alcuni brevetti usati per la trasmissione di informazioni via etere, tramite onde radio, precedentemente attribuiti a Guglielmo Marconi.
Negli ultimi anni della sua vita Tesla intervenne spesso su quotidiani e periodici, come il New York Times e l'Electrical Experimenter, riguardo alle sue visionarie opinioni sulla tecnologia o in relazione alla guerra in corso in Europa.[8][11] Morì nel 1943 nell'hotel dove viveva; al suo funerale a New York erano presenti oltre duemila persone, tra cui diversi premi Nobel.[12][13]
Molti dei suoi risultati sono stati usati, spesso polemicamente, per appoggiare diverse pseudoscienze, teorie sugli UFO e occultismo New Age. Ciò è dovuto al fatto che Tesla lasciò scarsa documentazione sui risultati ottenuti, e anche questa spesso sotto forma di appunti, non di lavori organizzati e comprensibili a tutti; pertanto è stato relativamente facile attribuirgli le idee più strampalate, o la paternità di invenzioni mirabolanti non accettate dalla comunità scientifica[14].
Tesla nacque il 10 luglio 1856 come suddito dell'Impero austriaco a Smiljan vicino a Gospić,nella regione della Licca-Corbavia, parte della frontiera militare croata del Regno di Croazia e Slavonia. Il padre, Milutin Tesla, nato nel 1819, era un ministro del culto della Chiesa ortodossa serba e ricordava a memoria passi della Bibbia e poemi epici serbi. La madre, Georgina-Đuka Mandić, nata nel 1822, figlia di un prete ortodosso, pure se analfabeta aveva talento nell'inventare oggetti d'uso casalingo. Nikola ebbe un fratello, che morì a 12 anni cadendo da cavallo, e tre sorelle.
Andò a scuola a Karlovac, quindi studiò ingegneria elettrica all'Università tecnica di Graz (Austria), a quel tempo considerata uno degli istituti migliori al mondo. Durante gli studi si interessò agli impieghi della corrente alternata. Frequentò solo fino al primo semestre del terzo anno, non raggiungendo quindi il conseguimento della laurea. Poi, per un'estate, seguì i corsi dell'Università di Praga, studiando fisica e matematica avanzata. Si dedicò alla lettura di molti lavori, imparando a memoria interi libri grazie alla sua memoria prodigiosa, e leggendo l'intera opera di Voltaire (circa 100 volumi). Tesla affermò, nella sua autobiografia, di avere avuto numerosi momenti di ispirazione.
Nei primi anni di vita egli fu spesso malato: gli apparivano lampi luminosi accecanti, spesso accompagnati da allucinazioni. Molte di queste visioni erano connesse a parole o idee.[15] Tali sintomi oggi segnalerebbero una forma di sinestesia.
Nikola Tesla era alto 188 cm e di corporatura assai magra (sembra che il suo peso tra il 1888 e il 1926 sia rimasto attorno ai 64 kg).[16]
Nel 1881 si spostò a Budapest per lavorare in una compagnia dei telegrafi. Tesla ne divenne il responsabile elettrico e in seguito lavorò come ingegnere per il primo sistema telefonico ungherese. In quegli anni realizzò anche un dispositivo che, secondo alcuni, era un ripetitore o amplificatore telefonico (anche se è molto improbabile che si trattasse di un amplificatore, dal momento che la valvola termoionica, componente indispensabile, non fu inventata prima del 1904), o secondo altri invece potrebbe essere stato il primo altoparlante. Si trasferì quindi a Maribor, in Slovenia, dove lavorò come aiuto ingegnere. In quel periodo soffrì di esaurimento nervoso.
Nel 1882 arrivò a Parigi per lavorare come ingegnere alla Continental Edison Company, progettando migliorie agli apparati elettrici. Tesla affermò, nella sua autobiografia del 1915, di aver concepito in quell'anno l'idea del motore a induzione, cominciando a sviluppare diversi dispositivi capaci di utilizzare il campo magnetico rotante, per i quali ottenne brevetti nel 1888.
Sempre nel 1882 Tesla accorse al capezzale della madre morente, arrivando poche ore prima che ella spirasse. Le sue ultime parole furono "Sei arrivato, Nidžo, mio orgoglio". Dopo la morte della madre, Tesla si ammalò. Rimase in convalescenza due o tre settimane a Gospić e nel paese di Tomingaj vicino a Gračac, dov'era nata la madre.
Nel 1884, al suo arrivo negli Stati Uniti d'America, Tesla aveva in mano poco altro che una lettera credenziale di Charles Batchelor, suo superiore nella precedente attività lavorativa. In questa lettera, indirizzata a Thomas Alva Edison, Batchelor scriveva "Conosco due grandi uomini: uno siete voi, l'altro è questo giovane". Edison assunse Tesla nella sua azienda Edison Machine Works. I compiti di Tesla all'interno dell'azienda furono dapprima semplici, ma ben presto si occupò anche di problemi più complessi; gli fu quindi proposto di riprogettare l'esistente generatore di corrente continua.
Nel 1886 Tesla scrisse che Edison gli aveva offerto, per quel compito, l'esorbitante premio di cinquantamila dollari (equivalenti a circa 1 milione di dollari attuali). Tesla disse di aver lavorato quasi un anno per riprogettare il motore e il generatore. Il suo lavoro fruttò all'azienda di Edison diversi brevetti estremamente redditizi. Quando chiese la riscossione del premio promesso, secondo Tesla, Edison rispose: "Tesla, lei non afferra il senso dell'umorismo americano", e non mantenne la promessa. Tesla si licenziò quando, invece dei 50 000$, gli fu offerto un aumento di stipendio, da 10 dollari a settimana a 18 dollari (va a ogni modo notato come la cifra di cinquantamila dollari corrispondesse all'intero capitale sociale dell'azienda)[senza fonte].
Ironia della sorte, per un certo tempo dovette lavorare come scavatore di fossi, sempre per l'azienda di Edison. Questi, tra l'altro, non volle mai studiare i progetti di Tesla riguardanti la corrente alternata polifase, convinto che il futuro fosse la corrente continua. Tesla continuò a concentrarsi sulla corrente alternata.
Nel 1886 Tesla fondò una propria società, la Tesla Electric Light & Manufacturing. I primi finanziatori non erano d'accordo con Tesla sui suoi progetti per il motore a corrente alternata e alla fine gli tolsero il controllo della società. Tesla lavorò quindi a New York come operaio generico dal 1886 al 1887 per guadagnarsi da vivere. Nel 1887 costruì il primo motore a induzione a corrente alternata senza attrito, di cui fece dimostrazione presso l'American Institute of Electrical Engineers (attualmente parte dell'IEEE) nel 1888, di cui divenne vice presidente[32] e che, dopo la morte intitolò a Tesla un premio[33]. Nello stesso anno, sviluppò i principi della bobina che porta il suo nome e incominciò a lavorare come consulente con George Westinghouse (che lo conobbe proprio a quella dimostrazione) nei laboratori di Pittsburgh della Westinghouse Electric & Manufacturing Company. Westinghouse ascoltò le sue idee per i sistemi polifase che avrebbero permesso la trasmissione di elettricità a corrente alternata lungo grandi distanze.
Nell'aprile del 1887 Tesla incominciò a investigare su quelli che in seguito sarebbero stati chiamati raggi X utilizzando i suoi tubi a vuoto a singolo nodo (analogo al suo brevetto n. 514170). Questo dispositivo differiva dai primi altri tubi a raggi X per il fatto che non aveva elettrodo bersaglio. Il termine moderno per il fenomeno prodotto attraverso questo apparecchio è bremsstrahlung (o radiazione di frenamento). Sappiamo che questo dispositivo operava emettendo elettroni da un singolo elettrodo attraverso una combinazione di emissione di campo ed emissione termoionica. Una volta liberati, gli elettroni sono respinti con forza dall'intenso campo elettrico vicino all'elettrodo durante i picchi a tensione negativa dall'uscita oscillante ad alta tensione della bobina di Tesla, generando raggi X nel momento in cui collidono con l'involucro di vetro. Egli utilizzò anche dei tubi di Geissler. Fin dal 1892 Tesla divenne consapevole di quelli che Wilhelm Röntgen successivamente identificò come effetti dei raggi X.
Tesla commentò i pericoli di lavorare con dispositivi produttori di raggi X a "singolo nodo", attribuendo erroneamente i danni alla pelle all'ozono piuttosto che alla radiazione: «Sulle azioni che feriscono la pelle... noto che esse sono state male interpretate... Esse non sono dovute ai raggi Röntgen, ma semplicemente all'ozono generato in contatto con la pelle. Anche l'acido nitroso potrebbe esserne responsabile, ma per una piccola estensione»
(Tesla, in Electrical Review, 30 novembre 1895)Tesla osservò successivamente un assistente gravemente "bruciato" dai raggi X nel suo laboratorio. Eseguì numerosi esperimenti prima della scoperta di Röntgen (compresa la radiografia delle ossa della propria mano; in seguito spedì tali immagini a Röntgen) ma non rese largamente note le sue scoperte; la maggior parte della sua ricerca è andata perduta nell'incendio del suo laboratorio avvenuto nel marzo del 1895.
Il 30 luglio 1891, a 35 anni, ottenne la naturalizzazione statunitense. Sempre nel 1891 Tesla creò un laboratorio nella Fifth Avenue a Manhattan, a New York. In seguito Tesla stabilì un altro laboratorio in East Houston Street, sempre a New York. Riuscì ad accendere, a distanza e senza fili, dei tubi a vuoto in entrambi i suoi laboratori, fornendo la prova delle potenzialità della trasmissione senza fili di potenza.[34] Alcuni degli amici più stretti di Tesla erano artisti; tra questi il direttore del Century Magazine, Robert Underwood Johnson, che aveva adattato diverse poesie del poeta serbo Jovan Jovanović Zmaj (che Tesla aveva tradotto). Sempre in quegli anni Tesla era influenzato dalla dottrina filosofica vedica di Swami Vivekananda.[35]
All'età di 36 anni Tesla depositò i primi brevetti riguardanti il sistema energetico polifase, in seguito alle sue ricerche sul sistema e sui principi del campo magnetico rotante. Tesla lavorò come vice presidente dell'American Institute of Electrical Engineers (ora parte dell'Institute of Electrical and Electronics Engineers) dal 1892 al 1894. Dal 1893 al 1895 investigò le correnti alternate ad alta frequenza. Generò una tensione alternata di un milione di volt usando una bobina di Tesla conica e investigò l'effetto pelle nei conduttori, progettò circuiti regolatori, inventò una macchina per indurre il sonno[senza fonte], lampade a scarica di gas senza fili e trasmise energia elettromagnetica senza fili, costruendo con successo il primo trasmettitore radio. A St. Louis, Missouri, Tesla diede una dimostrazione relativa alla comunicazione radio nel 1893. Rivolgendosi al Franklin Institute a Filadelfia, Pennsylvania e alla National Electric Light Association, descrisse e dimostrò in dettaglio i suoi principi. Riguardo alle dimostrazioni di Tesla è stato scritto molto su vari media.
All'Esposizione Universale del 1893, la World Columbian Exposition di Chicago, per la prima volta fu dedicato un padiglione all'energia elettrica. Fu un evento storico dal momento che Tesla e George Westinghouse introducevano i visitatori alla potenza della corrente alternata usandola per illuminare l'Esposizione. Furono esposte le lampade luminescenti di Tesla (progenitrici delle lampade neon) e i bulbi a singolo nodo. Inoltre, egli spiegò i principi del campo magnetico rotante e del motore a induzione dimostrando come far stare in equilibrio sulla propria punta un uovo di rame durante la dimostrazione dell'apparecchio da lui costruito, conosciuto come uovo di Colombo.
Alla fine degli anni 1880, Tesla ed Edison divennero avversari, in parte a causa della promozione da parte di Edison della corrente continua (DC) per la distribuzione dell'energia elettrica contro la più efficiente corrente alternata, tanto voluta da Tesla e Westinghouse.
Finché Tesla non inventò il motore a induzione, i vantaggi della corrente alternata per la trasmissione di alte tensioni sulle lunghe distanze furono controbilanciati dall'impossibilità di utilizzare motori con essa. A causa della cosiddetta "guerra delle correnti", Tesla e Westinghouse fecero quasi bancarotta, perciò, nel 1897, Tesla sciolse Westinghouse dal contratto, causandogli la perdita dei diritti d'autore e dei diritti di proprietà industriale sul suo brevetto. Sempre nel 1897, Tesla fece ulteriori ricerche sulle particelle radioattive e sulla radioattività che lo portarono a formulare la teoria di base sui raggi cosmici.[36][37]
A quarantuno anni Tesla registrò il primo brevetto di base della radio.[38] Un anno dopo presentò all'esercito degli Stati Uniti un'imbarcazione radiocontrollata, credendo che almeno i militari avrebbero apprezzato apparecchiature come siluri radiocomandati. Egli sviluppò la "Art of Telautomatics", una forma di primitiva robotica.[39] In seguito, nel 1898, al Madison Square Garden fece una pubblica dimostrazione con una barca radiocomandata, nell'ambito di una mostra sull'elettricità; utilizzò questa volta apparecchi con un innovativo coesore e una serie di porte logiche. Il comando radio a distanza rimase comunque una novità fino agli anni 1960. Nello stesso anno (1898) Tesla inventò anche una "candela elettrica", detta anche candela di accensione, per i motori a combustione interna a benzina. Egli ottenne il brevetto (EN)  US609250, United States Patent and Trademark Office, Stati Uniti d'America. "Electrical Igniter for Gas Engines", per questo sistema di accensione meccanica. Tesla visse al Gerlach Hotel, rinominato, in seguito, "The Radio Wave Building" al 49W della 27th Street (tra Broadway e la Sixth Avenue), nella bassa Manhattan, dove alla fine del secolo condusse esperimenti sulle onde radio. Per onorare e ricordare il suo lavoro, nel 1977 fu posta sull'edificio una targa commemorativa.
Nel 1899 Tesla, per portare avanti le sue ricerche, decise di trasferirsi a Colorado Springs, nel Colorado, dove avrebbe avuto molto spazio per i suoi esperimenti sulle alte tensioni e sulle alte frequenze. Fin dal suo arrivo spiegò ai giornalisti che stava conducendo degli esperimenti sulla telegrafia senza fili. Il suo diario contiene numerose spiegazioni delle sue congetture sulla ionosfera e sugli esperimenti sulle correnti telluriche del suolo, fatte di onde trasversali e onde longitudinali[40]. All'interno del suo laboratorio, Tesla provò che la terra era un buon conduttore, e produsse dei fulmini artificiali (con scariche di milioni di volt, lunghe fino a 40 metri)[41].
Lo scienziato indagò allo stesso tempo sull'elettricità atmosferica, osservando i segnali dei fulmini, catturati con i suoi ricevitori. Le riproduzioni di questi ultimi e dei suoi coesori dimostrano un inatteso livello di complessità (per esempio, modelli a elementi distribuiti, fattore Q, eliche, ritorno della radiofrequenza, schemi di eterodina grezza e circuiti rigenerativi[42]). Tesla dichiarò che a quei tempi stava compiendo le sue osservazioni sulle onde stazionarie[43]. Nel suo laboratorio a Colorado Springs, egli "registrò" alcune tracce di ciò che credeva fossero segnali radio extraterrestri; ciononostante i suoi pubblici annunci e i dati che aveva rilevato furono duramente respinti dalla comunità scientifica. Tesla aveva notato alcune misure di segnali ripetitivi dal suo ricevitore, che erano sostanzialmente differenti da quelli registrati durante i temporali e dal rumore terrestre. Nello specifico, egli ricordò in seguito che i segnali apparivano in gruppi di uno, due, tre e quattro scatti insieme.
Tesla ricercò vari metodi di trasmissione di potenza ed energia senza fili su lunghe distanze (per mezzo di onde trasversali, a meno estese e più immediate onde longitudinali). Egli trasmise nella banda delle frequenze molto basse (ELF) attraverso il terreno tra la superficie della Terra e lo strato di Kennelly-Heaviside. Ricevette poi brevetti su ricetrasmettitori senza fili che sviluppavano onde stazionarie con questo metodo. Compiendo calcoli matematici e computazioni basati sui suoi esperimenti, stimò che la frequenza minima di risonanza della Terra era approssimativamente di 6 hertz[44]. Negli anni sessanta, grazie agli strumenti matematici sviluppati da Winfried Otto Schumann, venne misurata e verificata l'esistenza di quella che in seguito rimase nota come risonanza Schumann e si appurò che questa aveva una frequenza di un ordine di grandezza comparabile con quella stimata da Tesla.
Tesla spese l'ultimo periodo della sua vita tentando di scambiare segnali con il pianeta Marte, ma solo nel 1996 Corum and Corum pubblicò un'analisi dei segnali provenienti dalla magnetosfera di Giove, che indicavano una chiara corrispondenza tra la posizione di Marte a Colorado Springs e la cessazione dei segnali da Giove, nell'estate del 1899, quando lo scienziato era laggiù[45][46].
Tesla lasciò Colorado Springs il 7 gennaio del 1900: il suo laboratorio fu demolito e le sue apparecchiature vendute per pagare i debiti. Gli esperimenti compiuti in Colorado prepararono Tesla per il suo progetto successivo, la costruzione di un'infrastruttura per la trasmissione di potenza senza fili, che sarebbe divenuta meglio nota come Wardenclyffe Tower. Gli fu assegnato il brevetto (EN)  US685012, United States Patent and Trademark Office, Stati Uniti d'America. per i modi di incrementare l'intensità delle oscillazioni elettriche. Il sistema di classificazione dell'ufficio brevetti degli Stati Uniti assegna correntemente questa certificazione alla Primary Class 178/43 ("telegrafia/induzione spaziale"), invece gli altri settori applicabili includono il 505/825 ("apparati relativi alla superconduttività a basse temperature").
Nel 1900, con 150 000 $ (il 51% provenienti da J. Pierpont Morgan), Tesla incominciò a progettare la struttura chiamata "Wardenclyffe Tower". Nel giugno del 1902, le operazioni nel suo laboratorio furono spostate da Houston Street a Wardenclyffe. Alla fine la torre fu smantellata come un rottame durante la prima guerra mondiale. I giornali del tempo etichettarono Wardenclyffe come la "follia di Tesla da un milione di dollari". Nel 1904, poi, l'ufficio brevetti americano cambiò la sua decisione, assegnando a Guglielmo Marconi il brevetto per la radio; fu allora che incominciarono le peripezie di Tesla per riottenere la paternità dell'invenzione. Il giorno del suo cinquantesimo compleanno, nel 1906, egli espose la sua turbina senza pale da 200 hp (150 kW) a 16 000 giri/min.
Tra il 1910 e il 1911 alla Waterside Power Station di New York, alcuni dei suoi motori a turbina furono testati fino a 5 000 hp.
Dal momento che il premio Nobel per la fisica fu consegnato a Marconi per la radio nel 1909, Thomas Edison e Tesla furono menzionati da un dispaccio di agenzia come potenziali candidati per condividere il premio Nobel del 1915, giungendo a uno dei tanti incidenti "diplomatici" del premio Nobel. Alcune fonti affermavano[47] che, a causa dell'animosità reciproca, non fu assegnato loro il premio, nonostante gli enormi contributi scientifici, e che entrambi cercavano di minimizzare i successi dell'altro solamente per aggiudicarsi il titolo. I due scienziati rifiutarono in ogni caso di ricevere il riconoscimento se il collega l'avesse ricevuto per primo e, comunque, nessuno dei due prese in considerazione l'opportunità di condividerlo.
Dopo le polemiche, né Tesla né Edison vinsero il Nobel (anche se Edison ricevette una delle possibili 38 candidature nel 1915 e lo stesso successe per Tesla nel 1937)[48]. Negli anni precedenti, solo Tesla sembrava essere stato candidato per il premio Nobel del 1912, principalmente per i suoi esperimenti sulla messa a punto di circuiti che utilizzavano trasformatori a risonanza ad alta tensione e alta frequenza.
Nel 1915, parallelamente, Tesla intentò una causa contro Marconi tentando, senza successo, di ottenere un processo contro i diritti dell'inventore italiano. Intorno al 1916 Tesla andò in bancarotta, a causa dei suoi debiti arretrati con il fisco; viveva ormai in povertà. Dopo Wardenclyffe, costruì la Telefunken Wireless Station a Sayville, Long Island, ottenendo in parte i successi a cui voleva arrivare a Wardenclyffe. Nel 1917 la struttura fu abbattuta dai Marines, che sospettavano potesse essere utilizzata da spie tedesche.
Precedentemente alla prima guerra mondiale, Tesla incominciò a cercare degli investitori d'oltremare che finanziassero le sue ricerche. All'inizio del conflitto, egli perse anche i contributi che riceveva per i suoi brevetti europei. Terminata la guerra, Tesla, in un articolo del 20 dicembre 1914, fece numerose predizioni sui punti di discussione del primo dopoguerra. Egli credeva che la Società delle Nazioni non fosse un rimedio per i tempi e i problemi di allora. Negli anni successivi, lo scienziato incominciò a mostrare evidenti sintomi di disturbo ossessivo-compulsivo; divenne ossessionato dal numero tre: sovente si sentiva costretto a girare attorno a un palazzo tre volte prima di entrarvi, oppure voleva una pila di dodici o diciotto tovaglioli ben piegati intorno al suo piatto a ogni pasto, o altro ancora. La natura dei suoi disturbi era poco conosciuta a quel tempo e non erano disponibili terapie efficaci, perciò i sintomi vennero considerati come prova di una parziale infermità mentale, danneggiando ciò che ne rimase della propria reputazione.
A quel tempo, egli era alloggiato al Waldorf-Astoria Hotel e affittava una sistemazione a credito, indebitandosi a tal punto che la sua proprietà di Wardenclyffe venne intestata a George Boldt, proprietario del Waldorf-Astoria, per pagare un debito di 20 000 $. Nel 1917, all'incirca nel periodo in cui la Wardenclyffe Tower fu demolita dal nuovo proprietario perché il lotto di terreno acquistasse più valore, Tesla ricevette la più alta onorificenza dell'American Institute of Electrical Engineers (AIEE), la Edison Medal.
In occasione del suo settantacinquesimo compleanno, nel 1931, il Time Magazine gli dedicò l'intera copertina[49][50], ringraziandolo per i suoi contributi nel campo della generazione di energia elettrica. Tesla aveva ricevuto il suo ultimo brevetto nel 1928 per un apparecchio destinato al trasporto aereo, che rappresentava il primo esempio di aeromobile a decollo e atterraggio verticale. Nel 1934 poi scrisse al console del suo paese natale Janković un messaggio di gratitudine nei confronti di Mihajlo Pupin, che aveva dato il via a un programma di donazioni grazie al quale molte compagnie americane potevano supportare le sue ricerche. Tesla aveva però rifiutato i finanziamenti, preferendo vivere della sua modesta pensione iugoslava, continuando così i suoi esperimenti.
Tesla si mostrò scettico relativamente agli sviluppi della teoria dell'elettromagnetismo ottenuti tra la fine dell'Ottocento e gli inizi del Novecento[51], affermando:
«Per oltre diciotto anni ho letto trattati, rapporti scientifici e articoli sulla telegrafia mediante onde Hertziane per tenermi informato, ma mi hanno sempre colpito come lavori di fantasia.[40]»
Egli sostenne di aver provato più volte senza successo a replicare gli esperimenti di Hertz, utilizzando strumentazioni a suo giudizio ben più raffinate. Secondo Tesla, era all'epoca già perfettamente chiaro che circuiti percorsi da correnti alternate producessero delle onde nello spazio circostante, ma non era chiaro quale natura avessero tali onde. Hertz aveva apparentemente mostrato che queste onde erano caratterizzate da vibrazioni trasversali, confermando l'idea che si propagassero in un etere rigido come ipotizzato da Maxwell, e avessero quindi probabilmente la stessa natura della luce. Tesla contestava tali conclusioni sostenendo che i suoi esperimenti sembravano suggerire piuttosto che tali onde fossero del tutto simili alle onde sonore, ovvero onde longitudinali in un etere dalla costituzione più simile a un gas che non a una struttura cristallina[40]
[52]. Secondo sue dichiarazioni, egli si recò nel 1892 a Bonn, in Germania, per discutere con Hertz stesso di questi esperimenti, ma l'incontro fu tanto turbolento da interrompere sul nascere un possibile dialogo tra i due.[40]
All'età di 81 anni, Tesla affermava di aver ultimato una teoria dinamica sulla gravità, commentando che essa "analizzava tutti i dettagli" e che sperava di presentarla al più presto al mondo[53]. All'epoca di questo annuncio, le istituzioni scientifiche lo consideravano fuori di testa; i più credevano che Tesla non avesse mai nemmeno sviluppato la teoria del campo unificato.
Il grosso di questa teoria fu sviluppato tra il 1892 e il 1894, quando conduceva esperimenti elettromagnetici ad alta frequenza e alto potenziale e stava brevettando numerosi apparecchi per l'utilizzo di queste grandi fonti di energia. La teoria fu completata, secondo lo scienziato, entro la fine degli anni trenta.
Ricordando il principio di Mach, nel 1925 Tesla affermava che:
«Non c'è nulla che sia dotato di vita - dall'uomo, che ha reso schiavi gli elementi, alla più agile creatura - in tutto questo pianeta che non oscilli durante una rotazione. Ogni volta che un'azione sia generata da una forza, anche infinitesimale, il bilancio cosmico è alterato e il moto universale ne risente gli effetti.»
Tesla, riguardo alla teoria della relatività di Albert Einstein, osservava che:
«… la teoria della relatività, in ogni caso, è più anziana dei suoi attuali sostenitori. Fu avanzata oltre 200 anni fa dal mio illustre connazionale Ruggero Giuseppe Boscovich, il grande filosofo, che, non sopportando altre e più varie occupazioni, scrisse un migliaio di volumi di eccellente letteratura su una vasta varietà di argomenti. Boscovich si occupò di relatività, includendo il cosiddetto "continuum spaziotemporale"…[54]»
Tesla fu dunque critico sulla relatività di Einstein:
«…[ha] un magnifico abito matematico che affascina, abbaglia e rende la gente cieca di fronte agli errori che vi sono contenuti. La teoria è come un mendicante vestito color porpora che la gente ignorante scambia per un re…, i suoi esponenti sono uomini brillanti, ma sono metafisici, più che fisici… Nemmeno una delle proposizioni della relatività è stata provata.[55]»
Lo scienziato affermò inoltre che:
«Io continuo a ritenere che lo spazio non possa essere curvo, per il semplice fatto che esso non può avere proprietà. Sarebbe come affermare che Dio abbia delle proprietà. Egli ha solo attributi di nostra invenzione. Di proprietà si può parlare solo per la materia che riempie lo spazio. Dire che in presenza di corpi enormi lo spazio diventa curvo, è equivalente ad affermare che qualcosa possa agire sul niente. Io mi rifiuto di sottoscrivere un simile modo di vedere.[56]»
Più tardi Tesla fece alcune affermazioni di rilievo circa un'arma chiamata "teleforce".[57] La stampa la soprannominò "raggio della pace" o "raggio della morte".[58][59]
I componenti erano:[60][61]
Tesla lavorò al progetto di un'arma a energia diretta tra i primi anni del Novecento fino alla sua morte. Nel 1937, egli compose un trattato intitolato "The Art of Projecting Concentrated Non-dispersive Energy through the Natural Media" che riguardava fasci di particelle cariche,[62] che fu pubblicato in seguito per cercare di illustrare una descrizione tecnica di una "super arma che avrebbe messo fine a tutte le guerre nel mondo". Questo documento, che si trova attualmente nell'archivio del Nikola Tesla Museum di Belgrado, descriveva un tubo a vuoto con un'estremità libera e un getto estremamente collimato di gas che permetteva alle particelle di uscire; l'apparato includeva poi la carica di particelle a milioni di volt e un metodo per creare e controllare fasci non dispersivi di particelle con la repulsione elettrostatica.[62]
Dalle memorie dello scienziato si evince che quest'arma era basata su uno stretto raggio di pacchetti atomici di mercurio o tungsteno, accelerati da un'alta differenza di potenziale (in modo analogo al suo "trasmettitore d'amplificazione"). Tesla diede la seguente spiegazione circa le operazioni del particle gun:
«[l'ugello] avrebbe inviato fasci molto concentrati di particelle nell'aria libera, di un'energia così tremenda da abbattere una flotta di 10.000 aeroplani nemici a una distanza di 200 miglia dal confine della nazione attaccata e avrebbe fatto cadere gli eserciti sui loro passi.[63] Tale arma può essere utilizzata contro la fanteria di terra o come contraerea.»
('Death Ray' for Planes, The New York Times, 22 settembre 1940.[64])Dopo aver cercato di attirare l'interesse del Dipartimento della difesa degli Stati Uniti d'America,[65] lo scienziato propose l'apparecchiatura alle nazioni europee;[66] ma nessun governo si mostrò interessato a firmare un contratto di costruzione dell'arma. Poco tempo dopo, Tesla morì nella sua stanza del New Yorker Hotel a 86 anni.[67]
Tesla ipotizzò come le forze elettriche e magnetiche potessero distorcere, o addirittura modificare, il tempo e lo spazio e studiò procedure con le quali controllare tali energie. Verso la fine della vita rimase affascinato dalla teoria secondo cui la luce è formata sia da particelle elementari sia da onde, un postulato fondamentale della fisica quantistica. Queste ricerche lo portarono a ideare un "muro di luce", manipolando le onde elettromagnetiche. Questo misterioso muro di luce avrebbe consentito di alterare lo spazio, la gravità e la materia; da questo nacquero una serie di progetti di Tesla che sembrano usciti direttamente dalla fantascienza, come il teletrasporto, il viaggio nel tempo e la propulsione antigravità[61][68].
La più singolare invenzione che Tesla ipotizzò è probabilmente la "macchina per fotografare il pensiero".[69] Egli pensava che un pensiero formatosi nel cervello creasse una corrispondente immagine nella retina, e che l'impulso elettrico di questa trasmissione neurale potesse essere letto e registrato in un dispositivo. L'informazione immagazzinata, sarebbe stata poi elaborata da un nervo ottico artificiale e visualizzata come immagine su uno schermo.
Un'altra invenzione teorizzata da Tesla è comunemente chiamata “macchina volante di Tesla”[70]. Tesla dichiarò che uno degli scopi della sua vita era quello di creare una macchina volante che potesse funzionare senza l'uso di un motore a combustione interna o ali, alettoni, propellenti o di qualsiasi fonte di combustibile. Inizialmente Tesla pensò a un aereo in grado di volare grazie a un motore elettrico alimentato da un generatore a terra. Con il passare del tempo, ipotizzò che questo aereo potesse muoversi in maniera interamente meccanica. La forma ipotizzata per il velivolo era quella tipica di un sigaro o di una salsiccia.
Tesla è conosciuto anche per l'invenzione di uno speciale trasmettitore chiamato “Teslascopio”, progettato con l'intenzione di inviare segnali e "comunicare" con forme di vita extraterrestri di altri pianeti.
«Era tutto quello che volevo essere. Archimede era il mio ideale.
Ammiravo le opere degli artisti, ma per me erano solo ombre e apparenze.
L'inventore, pensavo, dà al mondo creazioni palpabili, che vivono e funzionano.»
(Nikola Tesla[71])Tesla morì per un attacco cardiaco, solo, nel New Yorker Hotel, tra il 5 e l'8 gennaio del 1943, all'età di 86 anni, in una camera (n. 3327) ancora oggi utilizzata[72]. Nonostante avesse venduto i suoi brevetti sulla corrente alternata, egli era praticamente nullatenente e lasciò consistenti debiti. In seguito, nello stesso anno, la Corte suprema degli Stati Uniti d'America impugnò il suo brevetto numero 645576, riconoscendo lo scienziato come l'inventore della radio.
Al momento della sua morte, l'inventore stava continuando a lavorare sul teleforce, un progetto che aveva proposto senza successo al Dipartimento della Guerra degli USA; sembra che il raggio proposto - che la stampa aveva ribattezzato "raggio della pace" o "raggio della morte" - avesse a che fare con le sue ricerche sul fulmine globulare e sulla fisica del plasma, e che fosse composto di un flusso di particelle. Il governo americano non trovò alcun prototipo dell'apparecchio nella cassaforte, ma i suoi scritti vennero classificati come top secret. Il cosiddetto "raggio della pace" costituisce un elemento di alcune teorie cospirative come mezzo di distruzione. J. Edgar Hoover dichiarò il caso "most secret", vista la natura delle invenzioni di Tesla e dei suoi brevetti.
I documenti sono stati resi disponibili al pubblico a seguito del Freedom of Information Act (FOIA)[73], tuttavia Charlotte Muzar scrisse che c'erano diversi fogli e oggetti "mancanti"[74].
Dopo la sua morte, la famiglia di Tesla e l'ambasciata iugoslava lottarono con le autorità statunitensi per ottenere questi oggetti, per la potenziale importanza di alcune delle sue ricerche. Infine il nipote Sava Kosanoviċ entrò in possesso di alcuni dei suoi effetti personali, ora esposti al museo Nikola Tesla di Belgrado[75]. Le esequie dello scienziato ebbero luogo il 12 gennaio 1943, nella Cattedrale di Saint John the Divine di Manhattan, a New York. Il suo corpo fu cremato e le ceneri trasportate a Belgrado nel 1957. L'urna fu posta nel museo che porta il suo nome, dove si trova tutt'oggi.
Tesla non amava posare per i ritratti; lo fece una sola volta, per la principessa Vilma Lwoff-Parlaghy, ma il ritratto andò perduto. Il suo desiderio era quello di avere una scultura fatta dal suo amico più vicino, lo scultore Ivan Meštrović, che a quel tempo si trovava negli Stati Uniti d'America, ma morì prima di vederlo terminato. Meštrović fece per lui un busto in bronzo (1952), conservato nel museo di Belgrado, e una statua (1955/56), ora presso l'Istituto Ruđer Bošković a Zagabria. Questa scultura fu spostata nel centro di Zagabria, in via Nikola Tesla, in occasione del 150º anniversario della sua nascita, e ne fu consegnato un duplicato all'Istituto. Nel 1976 fu sistemata una statua di bronzo di Tesla nel parco statale di Niagara Falls nello Stato di New York; nel 1986 fu eretta un'opera analoga nella sua città natale Gospić.
Il 2006 fu proclamato dall'UNESCO e dai governi di Serbia e Croazia come anno di Nikola Tesla. In occasione del 150º anniversario della sua nascita, il 10 luglio 2006, il villaggio ricostruito di Smiljan (distrutto durante le guerre degli anni novanta) fu aperto al pubblico assieme alla casa del grande scienziato, allestita come museo alla memoria; fu inoltre dedicato alla vita e al lavoro di Tesla un nuovo centro multimediale. La chiesa parrocchiale di San Pietro e Paolo, dove il padre dell'inventore faceva servizi di manutenzione, fu completamente ristrutturata e sia il museo sia il centro multimediale furono riempiti di repliche delle invenzioni di Tesla. Il museo, in particolare, ha raccolto pressoché ogni documento mai pubblicato da e su Nikola Tesla, la maggior parte dei quali procurati da Ljubo Vojovic, della Tesla Memorial Society di New York.[76] Accanto alla casa dello scienziato è stato eretto un monumento creato dallo scultore Mile Blazevic; nella vicina cittadina di Gospić, nella stessa data, è stata inaugurata una scuola superiore intitolata a Nikola Tesla e presentata una replica della statua dell'inventore, il cui originale è a Belgrado, preparata da Franco Krsinic.
La nascita di Tesla è stata spesso contesa tra le odierne repubbliche di Serbia e di Croazia[77].
Egli era nato a Smiljan, un paese attualmente nel territorio della repubblica croata, ma da famiglia serba, seppur entrambi i genitori vissero sempre nell'attuale territorio della Croazia. Il padre, Milutin era un prete serbo ortodosso e la madre Georgina-Djuka Mandic era figlia anch'essa di un prete serbo ortodosso, Nikola Mandic (1800-1863). Georgina era la quarta di otto figli e si prese cura dei fratelli in seguito alla morte precoce della madre (nonna materna di Nikola Tesla), Sofia Mandic (nata Budisavljevic a Gračac in Lika) ed è per questo motivo che non ebbe l'opportunità di istruirsi. Va tenuto infine presente che all'epoca il Regno di Croazia era unificato alla corona del Regno di Ungheria, e nel 1867 divenne parte dell'Impero austro-ungarico in cui lui è cresciuto.
Tesla assunse infine la cittadinanza statunitense nel 1891.
Negli anni centrali della sua vita, Tesla strinse una forte amicizia con Mark Twain, il quale trascorreva molto tempo insieme a lui, anche nel suo laboratorio. Tesla era rimasto molto amareggiato dalle ripercussioni del suo battibecco con Edison; tanto che, il giorno dopo la morte di quest'ultimo, il New York Times conteneva numerosi encomi della vita del ricercatore, con un'unica opinione negativa scritta da Tesla:
«… Non aveva hobby, non apprezzava alcun divertimento di qualunque tipo e viveva trascurando completamente le più elementari regole d'igiene. … Il suo metodo era estremamente inefficiente, a tal punto che egli dovette coprire un immenso campo di ricerche per giungere assolutamente a nulla, finché la cieca fortuna intervenne e, dapprima, io fui quasi uno spettatore dispiaciuto per ciò che lui faceva, sapendo che appena un po' di teoria e calcoli gli avrebbero evitato il 90% della fatica. Ma egli nutriva un autentico disprezzo per la cultura dei libri e la conoscenza matematica, fidandosi interamente del suo istinto di inventore e del suo senso pratico da americano.»
Quando Edison era già molto vecchio, giunse al punto di dire che, guardandosi indietro, il più grande errore che avesse mai commesso era quello di non aver mai rispettato Tesla o il suo lavoro. Questo giovò davvero poco ai loro rapporti pressoché inesistenti.
Tesla conosceva bene anche Robert Underwood Johnson. Aveva rapporti di amicizia con Francis Marion Crawford, Stanford White, Fritz Lowenstein, George Scherff e Kenneth Swezey. Ciononostante, era considerato dai più un cinico.
Tesla non fu mai sposato. Era celibe e sostenne, come Newton, che la sua castità era molto utile alle sue doti scientifiche[5][78]. Alla domanda se credesse nel matrimonio rispose: «Per un artista, sì; per un musicista, sì; per uno scrittore, sì; ma per un inventore no. I primi tre possono prendere ispirazione dalla presenza femminile ed essere condotti dal loro amore verso risultati migliori. Un inventore possiede una natura così intensa, ricca di caratteristiche così selvagge e passionali che, nel dare sé stesso a una donna che potrebbe amare, perderebbe tutte le sue qualità. Credo che non siate in grado di citare alcuna grande invenzione fatta da un uomo sposato.»
Eccetto per le cene formali, egli mangiava sempre da solo, e mai, in alcuna circostanza, avrebbe cenato di sua spontanea volontà con una donna. Al Waldorf-Astoria e al famoso ristorante Delmonico's selezionava sempre particolari tavoli in disparte, che erano riservati a lui. Anche se veniva sempre descritto come una persona attraente quando interagiva con gli altri, Tesla spesso fingeva nel suo comportamento. L'unica donna con cui ebbe un rapporto di affetto intenso, seppur platonico, fu Katharine MacMahon Johnson, moglie del suo amico Robert Underwood Johnson.
Negli ultimi anni della sua vita Tesla divenne integralmente vegetariano, nutrendosi solo di latte, pane, miele, frutta e succhi vegetali.[79] Nel 1900 si era così espresso: «Come principio generale, l’allevamento del bestiame come mezzo per fornire cibo è discutibile, perché, nel senso di cui sopra, indubbiamente porta all'aumento di una popolazione di una "velocità inferiore". È certamente preferibile coltivare vegetali, e credo quindi che il vegetarianismo sia un allontanamento raccomandabile dalla radicata barbara abitudine. Che si possa vivere di alimenti vegetali e compiere il proprio lavoro ancora meglio non è una teoria, ma un fatto ben dimostrato. Molte razze che vivono quasi esclusivamente di verdure sono di corporatura e forza superiori. Non c'è dubbio che alcuni alimenti vegetali, come la farina d'avena, sono più economici della carne, e superiori ad essa per prestazioni meccaniche e mentali. Tali cibi superiori, inoltre, gravano decisamente meno sui nostri organi digestivi, e, rendendoci più contenti e socievoli, producono una quantità di bene difficile da stimare. Alla luce di questi fatti tutti gli sforzi dovrebbero essere fatti per fermare lo sfrenato e crudele massacro di animali, che è distruttivo per il nostro morale.[80]»
Era affascinato dagli animali, specialmente dai gatti (fu il gatto di famiglia che gli accese da ragazzo l'interesse verso l'elettricità statica e i fenomeni elettrici, dopo aver visto le scintille che si sprigionavano dal pelo quando veniva accarezzato[81]), e dai piccioni domestici e selvatici.
Come tanti in questo momento storico, Tesla, scapolo a vita, divenne un acceso sostenitore di una versione, autoimposta con la riproduzione selettiva, dell'eugenetica. In un'intervista del 1937, egli affermò:
«[…] il nuovo senso di compassione dell'uomo iniziò ad interferire con lo spietato meccanismo della natura. L'unico metodo compatibile con le nostre nozioni di civilizzazione e di razza è quello di impedire la proliferazione degli esseri non adatti per mezzo della sterilizzazione e della guida consapevole dell'istinto riproduttivo […]. Fra gli eugenisti, è opinione comune che bisognerebbe rendere più difficile il matrimonio. È innegabile che, a chiunque appaia come un genitore poco raccomandabile, dovrebbe essere proibita la generazione di figli. Nel giro di un secolo, il caso di una persona normale che si unisca con una eugeneticamente non adatta, sarà improbabile quanto il caso che la veda sposata ad un criminale incallito[61].»
Sosteneva che in futuro il mondo sarebbe stato dominato dalle donne, governato da "api regine".[82]
Lo scienziato mise da parte il suo primo milione di dollari all'età di 40 anni, ma donò quasi tutti i suoi diritti d'autore e di proprietà industriale sulle invenzioni future. Era poco concentrato nel gestire le sue finanze, completamente incurante della ricchezza materiale. Egli strappò addirittura un contratto con Westinghouse, che lo avrebbe reso il primo miliardario in dollari del mondo, in parte a causa delle implicazioni che questo avrebbe avuto sulla sua visione futura dell'energia libera, e in parte perché avrebbe escluso Westinghouse dal trattare gli affari direttamente, e Tesla non aveva alcuna intenzione di avere rapporti diretti con i clienti e i creditori.
«Diciotto tovaglioli di lino puliti erano come sempre impilati accanto al suo piatto. Nikola Tesla non sapeva spiegare la sua preferenza per i numeri divisibili per tre, più di quanto non riuscisse a spiegare la sua paura morbosa dei germi, né per quale motivo fosse perseguitato da una moltitudine di altre strane ossessioni che gli tormentavano la vita.»
(Margaret Cheney, Tesla. Un uomo fuori dal tempo[83])Tesla, affetto da disturbo ossessivo-compulsivo, aveva numerose quanto inusuali abitudini e idiosincrasie. Era particolarmente fissato con il numero "tre" e i suoi multipli, ed esigeva che la camera d'albergo dove alloggiava avesse un numero divisibile per tre.
Si sa che egli era contrario alla gioielleria, specialmente, per motivi sconosciuti, alle collane di perle: nel 1893 gli fu presentata la sua ammiratrice Anne Morgan, figlia di J.P. Morgan. Tesla affermò poi che avrebbe avuto piacere di parlare con lei, ma quando vide i suoi orecchini di perle ne fu così disgustato che cominciò a digrignare i denti e da allora cercò sempre di evitarla.[84]
Era inoltre infastidito in maniera fobica dalle persone sovrappeso o con obesità; pur essendo solitamente un uomo gentile e affabile, quando una delle sue segretarie, che era sovrappeso, urtò un tavolo facendo cadere a terra un oggetto, Tesla la licenziò in tronco, non cambiando idea nemmeno quando lei lo supplicò di riassumerla.[85]
Soffriva di insonnia, e dormiva al massimo due ore per notte senza che questo gli causasse difficoltà nel lavoro[86], e di sinestesia, un disturbo neurologico per cui in corrispondenza di un'idea vedeva lampi di luce e a volte anche allucinazioni. Nel 1890 ebbe una crisi di amnesia a causa dello stress della guerra delle correnti tra Edison e Westinghouse, nonostante fosse nota la sua memoria eidetica prodigiosa. Mostrava anche, a detta di alcuni, caratteristiche tipiche della sindrome di Asperger, come la sua tendenza all'isolamento, la grande memoria, l'udito sviluppato, i suoi interessi specifici e ripetitivi, e il suo disinteresse per la sessualità.[87][88] Tesla era anche molto severo circa l'igiene e la pulizia, in un periodo in cui un comportamento così estremo era visto come una stranezza. Era altamente meticoloso e organizzato, sovente lasciava note e appunti per gli altri, per evitare di dover riorganizzare i suoi lavori.
Tesla era particolarmente ossessionato dai piccioni: ordinava speciali semi per i volatili che nutriva nel Central Park, portandone alcuni nella sua stanza in hotel; a volte i piccioni entravano dalla finestra aperta. Per sua volontà, visse gli ultimi anni della sua vita in una suite di due stanze al 33º piano del New Yorker Hotel, nella Room 3327, dove avrebbe chiesto di esser visitato quotidianamente da un particolare piccione femmina, una colomba di colore bianco, di cui esiste anche una fotografia. Egli avrebbe affermato che il volatile era molto prezioso per lui. L'aneddoto racconta che un giorno del 1922[89] il piccione si ammalò; Nikola tentò di soccorrerlo per rimetterlo in salute, ma esso morì tra le sue braccia. L'inventore aveva posizioni contrastanti verso la religione; pur ammirando apertamente cristianesimo e buddhismo, credeva infatti che dovesse esserci una spiegazione scientifica per ogni cosa.[90] Ma quando quel piccione bianco morì, Tesla giurava di aver visto una luce molto chiara venir fuori dai suoi occhi, così luminosa che nemmeno lui sarebbe riuscito a crearne una di pari intensità. Questo episodio lo portò a dichiarare, negli ultimi anni di vita, secondo alcuni in uno stato mentale ormai alterato, che il candido uccello fosse in origine qualcosa di spirituale. Tesla dichiarò: «Amavo quel piccione come un uomo ama una donna e anche lei mi amava. Finché è stato con me, la mia vita aveva uno scopo».[91][92] Molti biografi annotano che Tesla considerò la morte del piccione come il "colpo finale" per lui e per il suo lavoro, che considerò ormai come finito.[92]
Lo scienziato credeva che la guerra non potesse essere evitata finché la causa del suo ritorno non fosse stata rimossa, ma si opponeva alle guerre, in generale[93]. Egli cercava di ridurre le distanze, come nella comunicazione per una miglior comprensione, così nei trasporti e nella trasmissione dell'energia, come un modo per stringere amichevoli relazioni internazionali[94].
Egli predisse che:«un giorno l'uomo connetterà il suo apparato con i moti originari dell'universo... e le vere forze che spingono i pianeti sulle loro orbite e li fanno ruotare spingeranno i suoi macchinari.»
Tesla era un poliglotta. Accanto al serbo e al croato, conosceva perfettamente altre sette lingue: il ceco, l'inglese, il francese, il tedesco, l'ungherese, l'italiano e il latino.[95]
Tesla studiò matematica, fisica e ingegneria alla Scuola Politecnica di Graz, in Austria, l'odierna Technische Universität Graz. Due fonti sostengono che egli ricevette la laurea magistrale dall'Università di Graz.[96][97]
L'Ateneo nega di avergli conferito tale titolo e informa che egli non proseguì mai gli studi oltre il primo semestre del suo terzo anno, durante il quale Tesla smise di seguire le lezioni[98]. Altri affermano che l'inventore fu espulso senza aver conseguito la laurea per il mancato pagamento delle tasse universitarie del primo semestre del primo anno da matricola.[99][100] Secondo un suo compagno di stanza nel college, egli non ottenne alcun titolo universitario.[101] Tesla fu persuaso più tardi dal padre a iscriversi all'Università Carolino-Ferdinandea di Praga, che egli frequentò per la sessione estiva del 1880. Dopo la morte del padre, si trasferì a Budapest nel gennaio del 1881, dove trovò un impiego come progettista e disegnatore all'Ufficio telegrafico centrale.[102]
Per il suo lavoro Tesla ricevette numerose lauree honoris causa da molti Atenei, tra i quali: Columbia University, Technische Universität Graz, Università di Zagabria, Istituto Politecnico di Bucarest, Università di Belgrado, Università di Brno, Università di Grenoble, Università di Parigi, Università di Poitiers, Università Carolina di Praga, Università di Sofia, Technische Universität Wien, e Yale University.
[103]
Grande appassionato di letteratura fin da ragazzo, nella sua autobiografia cita in particolare il romanzo Abafi ("Il figlio di Aba") dell'ungherese Miklós Jósika come una delle letture più importanti della sua vita, e che avrebbe comportato una svolta nettissima nella sua esistenza, ispirandogli il suo celebre "autocontrollo".[104][105]
Nel 1943 una sentenza della Corte suprema degli Stati Uniti d'America[10] attribuì a Tesla la paternità di alcuni brevetti precedentemente attribuiti a Guglielmo Marconi, tra cui la radio, successiva comunque al brevetto di Oliver Lodge che lo precedette[106]. La sentenza della Corte Suprema statunitense comunque non è universalmente riconosciuta dai sostenitori di Marconi. Molto tempo prima (1911) l'High Court britannica nella persona di Mr. Justice Parker deliberò su un analogo procedimento[107] la validità dei brevetti di Marconi. La sentenza della Corte Suprema statunitense è rimasta una sentenza discussa anche perché in quel periodo l'esercito statunitense era in causa con la società Marconi per l'utilizzo di brevetti sulla radio che non intendeva pagare, e la comodissima sentenza permise al governo di non pagarli.
In realtà il governo USA pagò la somma di 42 000 dollari alla società di Marconi per un brevetto di Oliver Lodge che la suddetta società aveva comprato da quest'ultimo[10].
In realtà nessuno prima di Tesla aveva effettuato esperimenti di trasmissioni radio come le intendiamo oggi, cioè con un circuito risonante[108].
Tesla incominciò a tenere le prime conferenze pubbliche sulla trasmissione di energia tramite onde radio nel 1891 e nel 1893 pubblicò il primo progetto per trasmettere segnali e anche energia elettrica tramite onde radio.[109] I progetti di Tesla si concentravano sulla trasmissione di onde elettromagnetiche continue (CW)[110] per ottenere trasmissioni di segnali e anche di energia. Quelli successivi di Marconi si basavano sulla trasmissione di segnali Morse tramite onde smorzate (DW) e quindi producevano segnali con interferenze e difficili da sintonizzare. Sono progetti differenti[111] che "si suppone non possono essere opera di semplice copia".[112]
Va tuttavia fatto notare che la generazione di oscillazioni elettromagnetiche continue, non smorzate quindi, non fu possibile prima dell'invenzione delle valvole termoioniche e in particolare del triodo (1916), quindi un eventuale progetto di Tesla non avrebbe mai potuto funzionare nel 1893.
Nel 1893, a St. Louis, Missouri, Tesla diede una pubblica dimostrazione della comunicazione senza fili. L'apparato che Tesla usò conteneva tutti gli elementi che erano incorporati nei sistemi radio prima dello sviluppo della “valvola termoionica”.[113]
Tesla è particolarmente omaggiato in Serbia e Croazia, così come nella Repubblica Ceca e in Romania. È stato insignito del massimo ordine del Leone Bianco in Cecoslovacchia.
Per i suoi meriti scientifici fu dato il suo nome all'unità di misura dell'induzione magnetica, il tesla (simbolo T).
Nel 1912 venne candidato al premio Nobel per la fisica. Egli lo rifiutò, offeso per non averlo ricevuto nel 1909 al posto di Guglielmo Marconi. Nel 1915 un articolo del The New York Times annunciò erroneamente che Tesla e Edison avrebbero condiviso il premio Nobel per la fisica. Tuttavia nessuno dei due lo ricevette.[114]
Il 18 maggio 1917 gli fu conferita la Edison Medal, che egli accettò.[115]
Il 10 luglio, giorno in cui Tesla nacque, è stato proclamato dallo Stato di New York Nikola Tesla Day.
Banconota jugoslava da 50 000 dinari del 1963
Banconota jugoslava da 500 dinari del 1970
Banconota jugoslava da 10 miliardi di dinari del 1993
Banconota da 100 dinari del 1994
Banconota da 5 nuovi dinari jugoslavi del 1994
Seconda versione della banconota da 5 nuovi dinari del 1994
Banconota serba da 100 dinari
Moneta serba da 20 dinari
Numerose opere di genere avventuroso/fantascientifico (ma non solo) fanno riferimento al personaggio dello scienziato o a ipotetiche o immaginarie sue invenzioni. Di seguito sono riportate le opere in cui Tesla ha un ruolo primario.
Jean-Paul-Charles-Aymard Sartre (AFI: [ʒɑ̃.pol ʃaʁl ɛ.maːʁ saʁ.tʁ(ə)]; Parigi, 21 giugno 1905 – Parigi, 15 aprile 1980) è stato un filosofo, scrittore, drammaturgo e critico letterario francese, considerato uno dei più importanti rappresentanti dell'esistenzialismo, che in lui prende la forma di un umanesimo ateo in cui ogni individuo è radicalmente libero e responsabile delle sue scelte, ma in una prospettiva soggettivista e relativista. In seguito Sartre diverrà un sostenitore dell'ideologia marxista, della filosofia della prassi e, pur con dei profondi "distinguo", anche del conseguente materialismo storico.[1] Condivise con Simone de Beauvoir la vita privata e professionale.Nel 1964 fu insignito del Premio Nobel per la letteratura, che però rifiutò, motivando il rifiuto col fatto che solo a posteriori, dopo la morte, fosse possibile esprimere un giudizio sull'effettivo valore di un letterato. Nel 1945 aveva già rifiutato la Legion d'onore e, in seguito, la cattedra al Collège de France.[3]
Sartre fu uno dei più importanti intellettuali del XX secolo, influente, amato e criticato al tempo stesso, e uno studioso le cui idee furono sempre ispirate a un pensiero politico orientato verso la sinistra internazionale (negli anni della guerra fredda sostenne talvolta le ragioni dell'allora Unione Sovietica, pur criticandone anche duramente la politica in diversi suoi scritti). Divise con Simone de Beauvoir - conosciuta nel 1929 all'École Normale Supérieure - la propria vita sentimentale e professionale, pur avendo entrambi altre relazioni contemporanee.[3][4] Ebbe inoltre rapporti di collaborazione culturale con numerosi intellettuali contemporanei, come Albert Camus e Bertrand Russell, con cui fondò l'organizzazione per i diritti umani denominata Tribunale Russell-Sartre.
Secondo Bernard-Henri Lévy,[5] il teatro di Sartre colpisce ancora per i suoi testi, che contengono inquietanti profezie sulla crisi della civiltà occidentale capitalista e consumistica, e per la sua forza.[6] Fu inoltre autore di romanzi e di importanti saggi. Sartre morì nel 1980 al culmine del suo successo di intellettuale "impegnato", quando ormai era diventato icona della gioventù ribelle e anticonformista del dopoguerra, in modo particolare della frazione maoista, di cui era diventato leader insieme a Pierre Victor (pseudonimo di Benny Lévy), passando dalla militanza nel Partito Comunista Francese a una posizione di indipendenza di tipo anarco-comunista, abbandonando sia il marxismo-leninismo sia le sue derivazioni. Si stima che al suo funerale presenziarono cinquantamila persone. È sepolto nel cimitero di Montparnasse a Parigi.[3]
Jean-Paul-Charles-Aymard Sartre nacque il 21 giugno 1905, a Parigi; figlio unico, di famiglia borghese: lo zio si era laureato alla prestigiosa École polytechnique, il padre era un militare di famiglia cattolica, mentre la madre Anne-Marie Schweitzer discendeva da una famiglia di intellettuali e di professori alsaziani e luterani, gli Schweitzer (era cugina di Albert Schweitzer, il celebre missionario e attivista protestante).[3]
Il padre Jean-Baptiste Sartre morì di febbre gialla quando Jean-Paul aveva quindici mesi. A incarnare la figura paterna fu il nonno, Charles Schweitzer, uomo dalla forte personalità, che gli impartì la prima istruzione, prima che Jean-Paul, a dieci anni, iniziasse a frequentare la scuola pubblica. Dal 1907 al 1917 il piccolo «Poulou», come era soprannominato in casa, visse quindi con la madre a casa dei nonni materni. Furono dieci anni felici, in cui fu adorato, coccolato e premiato tutti i giorni, ciò contribuì a far nascere in lui un certo narcisismo. Nella grande biblioteca di casa Schweitzer, egli scoprì molto presto la letteratura. Preferiva leggere piuttosto che frequentare gli altri bambini.[3] Durante tutta la vita Sartre mostrerà sempre tratti di leggero egocentrismo e talvolta asocialità, fatto che ha portato a ipotizzare che avesse la condizione neurologica denominata sindrome di Asperger (lo stesso Sartre parlò di Gustave Flaubert descrivendolo come una persona autistica, e scrisse poi, al proposito, «Flaubert sono io»).[7][8][9][10][11][12]
Fin da piccolo soffriva di strabismo,[13] inoltre quando aveva tre anni, perse quasi del tutto la vista dall'occhio destro, già debole per il difetto congenito, a causa di una malattia infantile.[14] Il periodo dell'infanzia fu narrato da Sartre stesso nella sua autobiografia Le parole.[3]
Nel 1917 la madre si risposò con Joseph Mancy, ingegnere nella Marina, che Sartre, a quel tempo dodicenne, avrebbe sempre odiato. Si trasferirono a La Rochelle, dove Sartre rimase fino ai quindici anni: tre anni di sofferenza per lui, passato da un ambiente familiare felice, al contatto con i liceali che gli sembrarono violenti e crudeli.[3] A causa del suo carattere, del suo aspetto fisico e della sua altezza sotto la media, Sartre divenne infatti vittima dei compagni, dei loro scherzi e atti di bullismo verbale.[15]
Verso l'estate del 1920, malato, Jean-Paul Sartre fu portato d'urgenza a Parigi. Preoccupata per l'influsso sul figlio dei cattivi comportamenti dei liceali di La Rochelle, la madre decise di fargli continuare gli studi a Parigi, al liceo Henri IV, dove aveva studiato prima del trasferimento a La Rochelle. A Parigi ritrovò come compagno di studi Paul Nizan, con cui strinse una solida amicizia durata fino alla morte di Nizan, nel 1940. Dopo il baccalaureato, Sartre preparò l'esame di ammissione alla École Normale Supérieure, studiando al liceo Louis-le-Grand.[3]
Studiò all'École Normale Supérieure di Parigi, dove si laureò nel 1929 in filosofia (ma studiò anche la psicologia, specie la Gestalt[16] e i fondamenti della psicoanalisi freudiana), per insegnarla poi nei licei di Le Havre, di Laon e infine di Parigi. Fu lì che conobbe la futura scrittrice femminista Simone de Beauvoir (da lui soprannominata il Castoro, perché lavoratrice infaticabile;[17] la parola inglese per castoro, beaver, ha inoltre un'assonanza col cognome Beauvoir) con cui condivise vita intima, lavoro e impegno politico, anche se non convivranno mai stabilmente.[3]
Avendo vinto una borsa di studio nel 1933, ebbe l'opportunità di specializzarsi a Berlino, potendo entrare in contatto diretto con la fenomenologia di Edmund Husserl e l'ontologia di Martin Heidegger, e leggendo, tra gli altri, Marx e Rousseau.[3]
Vicino al Partito Comunista Francese, viene comunque arruolato e dopo la capitolazione francese del 21 giugno 1940, avvenuta proprio il giorno del suo compleanno, venne fatto prigioniero dai tedeschi in Lorena con altri militari, e internato in un campo di concentramento per soldati nemici a Treviri; qui, assieme ad altri intellettuali prigionieri di guerra, tra cui due preti cattolici, scrive e mette in scena, per il Natale del 1940, l'opera Bariona o il figlio del tuono. Rifiuta di arruolarsi nell'esercito dei collaborazionisti del Governo di Vichy, e nel marzo 1941, grazie a un medico che fa riferimento alla cecità a un occhio, accompagnato da un documento d'identità contraffatto in cui si fa passare per civile, riesce a farsi liberare, evadendo di fatto dalla prigionia e potendo così partecipare alla resistenza francese nella formazione Combat (la stessa dove militò anche Albert Camus).[3][18] Scrisse anche per l'omonimo quotidiano, organo della formazione, ricoprendo per un periodo, su richiesta di Camus (che ne era redattore capo), l'incarico di inviato negli Stati Uniti d'America.
In seguito alla Liberazione, Sartre conobbe un successo enorme e per oltre un decennio dominò il panorama letterario francese. Promuovendo l'impegno politico-culturale come fine a sé stesso, la diffusione delle sue idee avvenne specialmente attraverso la rivista che egli fondò nel 1945, Les Temps Modernes. Sartre vi condivise la sua "penna" con, tra gli altri, Simone de Beauvoir, Merleau-Ponty e Raymond Aron.[19]
Nel lungo editoriale del primo numero, pose i principi di una responsabilità dell'intellettuale nel suo tempo e di una letteratura impegnata. Per lui, lo scrittore è presente «qualunque cosa faccia, segnato, compromesso fino al suo più lontano ritiro dall'attività [...] Lo scrittore è "in situazione" nella sua epoca.» Questa posizione sartriana dominerà tutti i dibattiti intellettuali della seconda metà del XX secolo. La rivista è sempre considerata come la più prestigiosa tra le riviste francesi a livello internazionale.[3]
Simbolo di questa gloria surreale e dell'egemonia culturale di Saint-Germain-des-Prés sul mondo, la sua celebre conferenza dell'ottobre 1945, dove una folla immensa, tra litigi e svenimenti, cerca di entrare nella piccola sala che era stata riservata. Sartre in quell'occasione presenta una sintesi della sua filosofia, l'esistenzialismo, in questa fase già modificato da influssi del pensiero marxista, che sarà poi trascritta nell'opera L'esistenzialismo è un umanismo. La sua pubblicazione, da parte dell'editore Nagel, è fatta all'insaputa di Sartre che giudica la trascrizione ex abrupto, necessariamente semplificatrice.[3]
Saint-Germain-des-Prés, residenza di Sartre sulla rive gauche, diviene quindi il quartiere parigino dell'esistenzialismo, e allo stesso tempo un luogo di vita culturale e notturna, nel quale si festeggia alla maniera esistenziale. L'esistenzialismo diventa pertanto una vera e propria moda, più o meno fedele alle idee sartriane, e di cui l'autore sembra un po' superato dall'ampiezza che prende quest'ultima.[3]
Sartre divenne però l'intellettuale più ammirato del momento, e scrisse addirittura testi di canzoni (come per Juliette Gréco), entrando nell'immaginario popolare francese e mondiale come il simbolo dell'intellettuale impegnato.[3]
Intanto, Sartre afferma il suo impegno politico chiarendo la sua posizione, attraverso i suoi articoli su Les Temps modernes: Sartre sposa, come molti intellettuali della sua epoca, la causa della rivoluzione marxista, ma, almeno dal 1956 in poi, senza per questo concedere i suoi favori al partito comunista, agli ordini di un'URSS che non può soddisfare l'esigenza di libertà. Sartre e i suoi amici continuano perciò a cercare una terza via, quella del doppio rifiuto del capitalismo e dello stalinismo.[3]
Nel dicembre 1946, la rivista prende posizione contro la guerra d'Indocina. Nel 1947, Sartre nei suoi articoli attacca il gollismo e il RPF, che considera come un movimento fascista.
L'anno seguente, la guerra fredda che avanza conduce Les Temps modernes a combattere l'imperialismo americano, affermando al contempo un pacifismo neutralista; pubblica con Maurice Merleau-Ponty un manifesto a favore di un'Europa socialista e neutrale.[3]
È allora che Sartre decide di tradurre il suo pensiero in espressione politica, fondando con un conoscente un nuovo partito politico, il Rassemblement Démocratique Révolutionnaire, che ambisce a rappresentare la "terza forza" alternativa allo schieramento USA-URSS. Malgrado il successo di qualche manifestazione, il RDR non raggiungerà mai un numero di aderenti tale da diventare un vero partito. Intuendo una deriva pro-americana da parte del suo co-leader, Sartre rassegna le sue dimissioni nell'ottobre 1949. A questo punto il riavvicinamento con i comunisti iniziò a diventare per lui una soluzione.[3]
Sempre nel 1949 divenne membro di un comitato internazionale, assieme a Pablo Picasso, Tristan Tzara, Pablo Neruda e Paul Robeson, per ottenere la liberazione del poeta turco e comunista Nazım Hikmet, incarcerato dal governo del proprio paese, obiettivo raggiunto l'anno seguente.[20] Con lo stesso Picasso, Simone de Beauvoir, Frida Kahlo e altri, indirizzò nel 1953 un appello agli Stati Uniti per i coniugi Rosenberg, simpatizzanti del Partito Comunista degli Stati Uniti d'America, condannati a morte e poi giustiziati per presunto spionaggio a favore dell'URSS.[21]
«Si la classe ouvrière veut se détacher du Parti (PCF), elle ne dispose que d'un moyen: tomber en poussière.»
«Se la classe operaia vuole distaccarsi dal Partito (PCF), essa dispone solo di un mezzo: ridursi in polvere.»
(Les Temps Modernes, 1953)La guerra di Corea, che scoppia nel giugno 1950, accelera questa evoluzione verso il riavvicinamento al Partito Comunista Francese (PCF). Per Sartre, la guerra implica il fatto che ognuno ora debba scegliere il proprio campo. Merleau Ponty, in disaccordo, lascia allora, dopo Raymond Aron, les Temps Modernes, di cui egli era un membro importante.[3]
Il 28 maggio 1952, il PCF organizza una manifestazione contro la visita del generale Ridgway, che finirà nella repressione e nel sangue, con la morte di due militanti e l'arresto di Jacques Duclos, segretario del PCF. L'evento scioccò Sartre a tal punto che egli ne parlerà come di un'autentica «conversione»: egli inizia ormai a sostenere anima e corpo il PCF. Scrive l'articolo I comunisti e la pace: qui egli chiarisce che il proletariato non potrebbe vivere senza il suo partito, il partito comunista, e che bisogna dunque assimilare il partito comunista al proletariato. Il PCF diventa così il solo partito in favore del quale ci si deve impegnare.[3]
Gli anni successivi saranno pieni di attività politica e filosofica per Sartre, accanto alla sinistra marxista e maoista, e poi anarco-comunista.[3]
Dal 1956 al 1962, Sartre e la sua rivista intrapresero una lotta radicale a favore della causa nazionalista anticolonialista algerina. Nel marzo del 1956, quando i comunisti votarono in favore dei pieni poteri a Guy Mollet in Algeria, Sartre e i suoi amici denunciarono il mito di un'Algeria francese parlando della realtà colonialista. Quindi essi si impegnarono a favore dell'indipendenza, manifestando altresì la loro solidarietà con il Front de Libération Nationale. Les temps modernes fece anche apparire nella primavera del 1957 la testimonianza di Robert Bonneau, un soldato richiamato, che raccontò i barbari metodi adottati durante la guerra in Algeria, come torture, massacri e pulizia etnica.[3][22] 
Sostenne la denuncia dell'algerino Henri Alleg, vittima di tortura: «La “tortura” non è nulla di inumano, è soltanto un crimine ignobile e lurido, commesso da uomini contro altri uomini, e che altri uomini ancora possono e debbono reprimere. L'inumano non esiste, se non negli incubi generati dalla paura. Basta il calmo coraggio di una vittima, la sua modestia, la sua lucidità, per liberarci dalla mistificazione. Alleg ha strappato la tortura alla notte che la ricopriva.[22]»
Nel settembre 1960 sostiene il manifesto del diritto alla non sottomissione (chiamato manifesto dei 121) e si dichiara solidale con le richieste di aiuto del FLN. Durante il processo a Francis Jeanson, giornalista di Temps Modernes accusato di essere un «portaborse» del FLN, egli proclama il suo assoluto sostegno all'imputato.[23] Questa dichiarazione provoca uno scandalo e, malgrado le proteste di diverse organizzazioni, Charles de Gaulle non volle persecuzioni contro Sartre.[24] Già nel 1957 aveva sostenuto, con Simone de Beauvoir, ma anche con il giornalista militante Georges Arnaud e l'avvocato Jacques Vergès, la causa dell'attivista algerina (torturata dai militari e poi incarcerata in Francia) Djamila Bouhired, che evitò la pena di morte per terrorismo e venne poi amnistiata.[25] Con Simone de Beauvoir e Louis Aragon sostenne anche un'altra militante algerina, Djamila Boupacha.
Questo suo impegno, non di meno, comporta i suoi rischi: nel gennaio 1962, l'OAS, gruppo nazionalista francese di estrema destra, compie un attentato facendo esplodere una parte del suo domicilio, che Sartre aveva abbandonato proprio per timore di rappresaglie.[24]
In questo periodo scrisse anche la prefazione al celebre testo I dannati della terra di Frantz Fanon (divenuto il manifesto dell'anticolonialismo terzomondista),[23] in cui scrive: «È stato dato l'ordine di abbassare gli abitanti del territorio annesso al livello di scimmia superiore per giustificare il fatto che il colonizzatore li tratti come bestie da soma. La violenza coloniale non si propone soltanto lo scopo di tenere a debita distanza questi uomini ridotti in schiavitù, cerca anche di disumanizzarli. Non si lascerà nulla di intentato per annientare le loro tradizioni, per sostituire le nostre lingue alle loro, per distruggere la loro cultura senza dar loro la nostra; saranno abbrutiti dalla fatica (...) la cosa più urgente, se c'è ancora tempo, consiste nell'umiliare [le vittime], nello sradicare l'orgoglio dal loro cuore, nel ridurli al livello della bestia.»
(J.-P. Sartre, Prefazione a «I dannati della terra»[26])«Per il suo lavoro, che, ricco di idee e pieno di spirito di libertà e ricerca della verità, ha esercitato una profonda influenza sulla nostra epoca.»
(Motivazione del Premio Nobel per la letteratura del 1964, declinato da Sartre)Negli anni 1960 la sua salute peggiora rapidamente. Sartre è prematuramente logorato, per la sua costante iperattività letteraria e politica, oltre che a causa del tabacco, dell'alcool che assume in gran quantità,[27] e delle droghe che lo mantengono in forma e gli permettono di mantenere il suo ritmo di lavoro: stimolanti come anfetamine e corydrane, un farmaco composto da aspirina e anfetamine, in gioventù anche l'allucinogeno mescalina (poi sostituì il corydrane con l'hashish e il semplice caffè, in quanto il farmaco era pericoloso per la sua salute malferma) e ansiolitici.[28][29][30]
Nel frattempo, sul piano teorico, il filosofo Sartre si occupa di produrre la teoria economica e sociale che servirà a conciliare socialismo e libertà. Si lancia in quest'impresa, che rimarrà incompiuta, con la pubblicazione della prima parte della Critica della ragione dialettica nel 1960.[3]
Dopo di che l'esistenzialismo sembra perdere colpi: durante gli anni 1960, l'influenza di Sartre sulla letteratura francese e sulle ideologie intellettuali diminuisce poco a poco, specialmente nel confronto con gli strutturalisti come l'antropologo Lévi-Strauss, il filosofo Foucault o lo psicanalista Lacan. Lo strutturalismo è in qualche modo l'avversario dell'esistenzialismo: in effetti nello strutturalismo non c'è molto spazio per la libertà umana, essendo ogni uomo imbrigliato nelle strutture che lo sovrastano e sulle quali non ha presa. Sartre è altrove, non si cura di discutere di questa nuova corrente: è interamente impegnato in un progetto personale, rappresentato dall'analisi del XIX secolo e della creazione letteraria, e soprattutto dalla critica di un autore di cui non ha mai condiviso lo stile parnassiano, Flaubert, ma verso cui prova comunque ammirazione e interesse.[3]
Negli anni '60 fonda con il matematico e filosofo socialista riformista Bertrand Russell, il Tribunale Russell-Sartre, che deve simbolicamente giudicare i crimini di guerra in Vietnam, e che poi si pronuncerà anche sul golpe cileno del 1973, attuato contro il socialista democratico Salvador Allende e altre violazioni di diritti umani.[3]
Nel 1964, fatto che avrà una grande risonanza mondiale, rifiuta il premio Nobel[31] poiché, a suo avviso, «nessun uomo merita di essere consacrato da vivo». Tra i motivi del Nobel, vi era anche il valore letterario della sua autobiografia Le parole. Aveva già rifiutato la Legione d'onore nel 1945, e ancora una cattedra al Collegio di Francia. Questi onori, secondo lui, avrebbero alienato la sua libertà, facendo dello scrittore un'istituzione. Questi suoi gesti resteranno celebri poiché in grado di illuminare lo spirito e lo stato d'animo dell'intellettuale, che dichiarò, pur essendo simpatizzante del blocco comunista (e affermò che il Nobel era secondo lui, comunque, un riconoscimento troppo filoamericano), che avrebbe rifiutato anche il Premio Lenin per la pace o un'altra onorificenza del mondo comunista, qualora l'URSS o altri paesi glielo avessero concesso. Per sottrarsi all'assedio dei mass media nell'occasione del Nobel rifiutato, si rifugiò nella casa di campagna della sorella di Simone de Beauvoir, Hélène.[32]
Nel 1968 manifesta al maggio francese, e viene arrestato per disobbedienza civile, e poco dopo lasciato andare; evita il processo ottenendo, però, l'immediato perdono presidenziale dal suo principale avversario politico del momento, Charles de Gaulle, che affermò "Non si imprigiona Voltaire", con un paragone tra Sartre e Voltaire, il principale intellettuale dell'Illuminismo.[24]
Negli ultimi anni assume come segretario personale il giovane Pierre Victor, noto anche come Benny Lévy, che lo assistette durante gli ultimi tempi, e adotta, già nel 1964, una giovane ventinovenne di famiglia ebraica, Arlette Elkaïm (poi nota come Arlette Elkaïm-Sartre), che era stata per tempo brevissimo una sua amante, per poi divenirne invece la figlia.[33] Riceve i giornalisti nel suo appartamento, tra i suoi molti volumi posseduti (tra cui molti romanzi d'evasione, specie "gialli")[34] e i suoi gatti.[35]
Nel 1974 visitò nella prigione di Stammheim-Stoccarda, in Germania Ovest, il leader della Rote Armee Fraktion (gruppo tedesco dedito alla lotta armata marxista, in maniera analoga alle Brigate Rosse italiane e noto anche come "gruppo Baader-Meinhof), Andreas Baader, in prigione per terrorismo tramite alcuni attentati esplosivi e rapine di autofinanziamento; Sartre incontrò Baader durante uno sciopero della fame collettivo dei detenuti "politici", e criticò le dure condizioni di prigionia a lui imposte (Baader morirà misteriosamente - come altri membri del gruppo - in prigione nel 1977, suicida o, secondo altri, forse assassinato); benché abbia successivamente detto alla televisione tedesca di non essere d'accordo con le idee e la prassi della RAF, il filosofo affermò di essere andato a visitarlo per ragioni umanitarie, e che Baader veniva torturato, tenendolo in un disumano isolamento contrario alle convenzioni sui diritti umani.[36] Chiese, poi, a Baader, senza successo, di chiudere la stagione del terrorismo, poiché la guerriglia e gli atti violenti potevano funzionare contro le dittature militari del Sudamerica, ma non in Europa.[37] Manifestò più volte la sua solidarietà al movimento del '77, attivo in Italia, ad esempio nel caso del cosiddetto Processo 7 aprile.
Nel 1973 aveva subìto un grave ictus, seguito da un'emorragia retinica all'occhio sinistro, l'unico completamente sano. Anche se mantenne la visione periferica, non fu più in grado di leggere o scrivere nel modo in cui era abituato e fu costretto a dettare gli scritti o a registrarli. Oltre a questi seri problemi di vista, che alla fine degli anni '70 lo porteranno alla cecità quasi completa, soffre di perdita dell'udito dovuta all'invecchiamento e di disturbi respiratori; l'ictus gli lascia inoltre una parziale paralisi al volto e a un braccio, e difficoltà di camminata.[13][14][38] Tuttavia, il rifiuto, la rivolta, l'intransigenza si vedono sempre nelle azioni di Sartre, nonostante l'inizio di questo lungo periodo di decadenza fisica.[14] Nello stesso anno partecipò alla fondazione del quotidiano Libération.
Dopo un lungo declino fisico, Sartre morì di edema polmonare a Parigi, il 15 aprile 1980 alle 21:00 presso l'ospedale di Broussais dove era ricoverato dal 20 marzo a causa di problemi respiratori, seguiti poi da insufficienza renale acuta con uremia, gangrena e coma (il 14 aprile).[39] Il presidente Valery Giscard d'Estaing propose i funerali di Stato e la tumulazione immediata al Pantheon (onore concesso solo - con le eccezioni di capi di Stato deceduti nelle loro funzioni e personalità della Rivoluzione francese come Marat e Mirabeau - a Victor Hugo nel 1885), ma la famiglia rifiutò, non ritenendo ciò in linea con la personalità di Sartre.[40]
Dopo una commemorazione civile alla presenza di un'imponente folla, venne sepolto nel cimitero di Montparnasse.[41] Sartre non venne sepolto al cimitero di Père-Lachaise, nella tomba di famiglia, per sua esplicita richiesta; dopo una sepoltura temporanea, quattro giorni dopo il funerale il corpo venne cremato presso la struttura apposita del Père-Lachaise stesso, ma le ceneri furono inumate nella tomba definitiva a Montparnasse, in cui verrà seppellita anche la compagna Simone de Beauvoir, morta nel 1986; ella descrisse gli ultimi anni con il filosofo nel libro La cerimonia degli addii (1982), scrivendo che «la sua morte ci separa. La mia morte non ci riunirà. È così; è già bello che le nostre vite abbiano potuto essere in sintonia così a lungo».[42][43]
«L'Uomo è condannato ad essere libero: condannato perché non si è creato da se stesso, e pur tuttavia libero, perché, una volta gettato nel mondo, è responsabile di tutto ciò che fa.»
(da L'esistenzialismo è un umanismo)
Il pensiero di Sartre rappresenta il vertice dell'esistenzialismo del Novecento e resta interessante per il suo sforzo di coniugare il marxismo e il comunismo con il rispetto della libertà di tipo umanistico, l'individualismo con il collettivismo e il socialismo, ideali spesso fraintesi con la realtà storica.[44] Oltre ad Husserl e Heidegger, Karl Marx esercita una forte influenza su di lui, soprattutto nella fase successiva al 1950: «Lungi dall'essere esaurito, il marxismo è ancora giovanissimo, quasi nell'infanzia: ha appena cominciato a svilupparsi. Esso rimane dunque la filosofia del nostro tempo: è insuperabile perché le circostanze che l'hanno generato non sono ancora superate.»
(Da Questions de méthode (Questioni di metodo), in Critique de la raisson dialectique, Gallimard, Paris, 1960, traduzione italiana di F. Ferniani, Milano, Il Saggiatore, 1976, pp. 92-96.)«Sartre detestava le routine e le gerarchie, le carriere, i focolari, i diritti e i doveri, tutto il serio della vita. Non si adattava all'idea di fare un mestiere, di avere dei colleghi, dei superiori, delle regole da osservare e da imporre; non sarebbe mai diventato un padre di famiglia e nemmeno un uomo sposato.»
(Simone de Beauvoir[45]) Durante l'ultima fase del suo pensiero, Sartre si confrontò con lo storicismo dialettico e il materialismo storico. Quest'ultimo è condiviso anche dal filosofo francese, seppure con dei "distinguo" molto importanti, in quanto Sartre sostiene la preminenza del libero arbitrio sul determinismo.
Egli rimarrà sempre molto influenzato dal pensiero di Edmund Husserl, anche se poi se ne servirà in modo originale, perché sin dai suoi primi studi vi imprime una forte critica psicologistica, che sarà poi solo soppiantata da quella politica dopo il 1946. Un importante fonte di ispirazione per Sartre, fu la filosofia di Heidegger di Essere e tempo e, seppure nella critica (spesso aspra) e nel superamento il pensiero di Hegel. La prima fase del pensiero di Sartre è segnata dall'opera L'essere e il nulla, pubblicata nel 1943, che rimane l'opera principale a testimonianza del suo esistenzialismo ateo. Il tema principale posto in essa è la fondamentale libertà di realizzarsi di ogni uomo come uomo-dio e l'ineludibilità di rimanere sempre un dio-fallito.[3] Ciò che evidenzia il fallimento è l'angoscia che attanaglia l'uomo nel vivere il suo esistere come una libertà fasulla, basata sul nulla:
«Questa libertà, che si rivela nell'angoscia, può caratterizzarsi con l'esistenza di quel niente che si insinua tra i motivi e l'atto. Non già perché sono libero, il mio atto sfugge alla determinazione dei motivi, ma, al contrario, il carattere inefficiente dei motivi è condizione della mia libertà.[46]»
Nelle ultime pagine autobiografiche del volume Le Parole, Sartre descrive il percorso tutt'altro che indolore che lo ha condotto all'ateismo.[3]
«L'enfer, c'est les autres.»
«L'inferno sono gli altri»
(A porte chiuse)Nella fase iniziale, Sartre è ispirato da Heidegger, Nietzsche, Schopenhauer, Jaspers e Kierkegaard; dal punto di vista narrativo, il Sartre romanziere risente dell'influsso di Louis-Ferdinand Céline. La sua concezione è tendente al pessimismo.[47] 
La nausea (1932~1938) è il più celebre romanzo esistenzialista, assieme a Lo straniero di Albert Camus, e la prima opera pubblicata da Sartre, nonché la principale del primo esistenzialismo sartriano. Qui la vita è vista come priva di un senso necessario e vi è anche l'estraneità della coscienza nei confronti della natura, vista come brutalità priva di coscienza; è proposto una specie di dualismo tra ciò che è cosciente e ciò che è incosciente: il "Per Sé" (Pour Soi) è la coscienza, che è "nulla" ("neant"), in quanto è mancanza: è infatti pura possibilità. Essa è rivolta, come coscienza intenzionale, all'"essere in sé "(En soi). L'"essere", come "essere in sé" è statico, monolitico e inerte, e costituisce il riferimento dell'intenzionalità della coscienza. Questa nella sua progettualità tende all'"essere in sé", senza mai raggiungerlo. Sartre lamenta il fatto che la realtà non dia significato da sé, ma che è la coscienza dell'uomo a doverglielo dare. Non esiste un essere necessario (cioè "Dio") che possa dare significato dall'esterno a questa condizione esistenziale.[47]
In questo momento la visione sartriana rimane pessimista e nichilista.[47]
In risposta a questo pessimismo, Sartre concepirà la "morale impegnata" (come morale della situazione) nella fase dell'esistenzialismo successivo, espressa in parte già ne L'essere e il nulla, ma soprattutto ne L'esistenzialismo è un umanismo.[3]
Nell'opera L'esistenzialismo è un umanismo, originariamente una conferenza, Sartre presenta il suo esistenzialismo e risponde alle critiche avanzate da più parti. Costituisce un'introduzione "estremamente chiara", benché semplice (ma non semplicistica) all'esistenzialismo. Tuttavia, l'eccessiva fortuna di questo testo ha condotto Sartre quasi a rinnegarlo filosoficamente, affermando che non può costituire altro che un'introduzione al suo pensiero.[48]
Sartre riteneva che la nozione di senso della storia cara a Hegel, contraddistinta dal concetto di necessità e presente anche in Marx (ma in lui mitigata dalla "filosofia della prassi"), non avesse nulla di necessario e ineluttabile: era pertanto fortemente rigettata. Secondo Sartre, la libertà dell'uomo è tale nel suo proprio divenire che nessuno può prevedere, nemmeno a grandi linee, quale direzione la Storia prenderà domani. Questo porta al rifiuto dell'ottimismo acritico di vari marxisti sui "domani che cantano" e che possono senz'altro non arrivare mai, ma anche del pessimismo.[49]
Sartre afferma che «l'esistenza precede l'essenza» e "l'uomo è condannato a essere libero"[49], famose frasi de L'esistenzialismo è un umanismo . L'Esistenza - la forma sensibile, che per Sartre è il risultato pratico dell'azione del pensiero - è ritenuta superiore all'Essenza (il motivo per cui l'essere è così e non altro, come l'Idea platonica) che è identificata tradizionalmente con l'Essere (cioè che è), e che si manifesta invece nel pensiero teorico. Per Sartre è quindi l'esistenza, cioè il fatto compiuto, quello che conta davvero, è l'uomo e la sua attività la cosa più importante, più che la speculazione teorica astratta, se essa resta mero pensiero. Inoltre è l'esistenza nel presente, nell'azione, che conta, non ciò che si è stati in passato.[49]
Se l'esistenza viene prima dell'essenza, occorre partire dalla soggettività. L'uomo è costretto a inventare l'uomo e su di lui cade la responsabilità totale dell'esistenza; deve cercare uno scopo fuori di sé, solo così si realizzerà. Ciò è in linea con L'essere e il nulla, in cui Sartre aveva identificato l'essere (come "esser per sé") col nulla, staccandolo dalla speculazione; dopo aver spodestato completamente l'essere (inteso come "essere in sé"), l'uomo si trova quindi al centro di tutto, come nell'umanesimo del Rinascimento. Alla fine, con l'adesione al marxismo, sarà l'essenza della materia a trascendere tutto all'interno della filosofia sartriana.[50]
Durante la sua prigionia di guerra (1940-1941) Sartre aveva letto Essere e tempo di Martin Heidegger, una ricerca ontologica condotta con la visione e il metodo della fenomenologia di Edmund Husserl (che di Heidegger fu il maestro). L'opera di Heidegger fu in effetti prodromica a L'essere e il nulla, il cui sottotitolo recita "Saggio fenomenologico sull'ontologia".
Il saggio di Sartre è influenzato da Heidegger, sebbene l'autore francese nutrisse profondo scetticismo riguardo a ogni forma in cui l'umanità potesse raggiungere una sorta di stato personale di realizzazione comparabile con l'ipotesi heideggeriana di re-incontro con l'Essere. Nella sua più tetra descrizione de L'essere e il nulla, l'uomo è una creatura ossessionata da una visione di "compiutezza", che Sartre chiama ens causa sui,[Nota 1][51] e che le religioni fanno coincidere con Dio. Venuti al mondo nella realtà materiale del proprio corpo, in un universo disperatamente materiale, ci si sente inseriti nell'essere (con la "e" minuscola). La coscienza è in uno stato di coabitazione con il suo corpo materiale, ma non ha alcuna realtà obiettiva; è nulla (nel senso etimologico di nulla res, 'nessuna cosa'). La coscienza ha l'attitudine di concettualizzare le possibilità, e di farle apparire, o di annichilirle.[51]
Sartre, grande sostenitore della libertà, ci fornisce un'etica della situazione. Il filosofo francese pensa infatti, a differenza di Heidegger (in cui l'etica è considerata inutile al cospetto della ontologia) che sia importante per l'uomo credere a valori. Questi, in ogni modo, sono costruiti dall'uomo medesimo e sono soggettivi. In questo modo egli rifiuta qualsiasi dottrina morale universalistica, criticando ogni etica fondata su principi oggettivi, come quella cristiana (fondata sulla legge morale naturale)  o quella kantiana (fondata sull'imperativo categorico). Se infatti Dio non esiste, e Sartre, essendo ateo nega la sua esistenza, (perché se esistesse, l'uomo non sarebbe libero), non possono esistere norme assolute. Sia la morale cristiana, sia la morale kantiana sono quindi ugualmente criticate. In proposito Sartre prende in particolare l'esempio di un giovane che debba scegliere tra occuparsi di sua madre oppure raggiungere la Resistenza francese a Londra. In entrambi i casi, la massima della sua azione non è morale, poiché deve necessariamente sacrificare un "fine in sé" riducendolo al grado di "mezzo": abbandonare sua madre è il mezzo per arrivare a Londra, abbandonare i combattenti è invece il mezzo per occuparsi di sua madre.[49]
Sartre illustra la "teoria dei vigliacchi e dei mascalzoni": "Quelli che nasconderanno a sé stessi, seriamente o con scuse deterministe, la loro totale libertà, io li chiamerò vigliacchi; gli altri che cercheranno di mostrare che la loro esistenza è necessaria, mentre essa è la contingenza stessa dell'apparizione dell'uomo sulla terra, io li chiamerò mascalzoni".[49]
L'uomo è pienamente responsabile di ogni sua scelta, anche se ci sono comunque delle cause per ogni azione negativa o positiva, che vanno individuate e analizzate; l'essere umano trova la sua massima realizzazione nell'impegno sociale e politico al miglioramento della propria e dell'altrui condizione.[49]
Per Sartre, "non c'è dottrina più ottimista" del suo nuovo esistenzialismo, che rifiuta il pessimismo e il nichilismo in quanto è «morale dell'azione e dell'impegno». La sola scelta umana e anti-trascendente è di per sé "un bene" soggettivo, anche quando non conduce al bene oggettivo. A questo dilemma morale ("se la scelta è bene intrinseco per il soggetto e l'umanità, come giustificare le scelte negative?"; inoltre se l'uomo è responsabile per sé delle sue scelte perché non è un burattino del Fato, ma le sue scelte sono tutte giuste dal suo punto di vista, diventa come se non fosse responsabile davanti agli altri) risponderà con l'adesione al marxismo, ma nel saggio del 1946 scrive:
«Soggettivismo vuol dire, da una parte, scelta del soggetto individuale per se stesso e, dall'altra, impossibilità per l'uomo di oltrepassare la soggettività umana. Questo secondo è il senso profondo dell'esistenzialismo. (...) Quando diciamo che l'uomo si sceglie, intendiamo che ciascuno di noi si sceglie, ma, come questo, vogliamo anche dire che ciascuno di noi, scegliendosi, sceglie per tutti gli uomini. Infatti, non c'è un solo dei nostri atti che, creando l'uomo che vogliamo essere, non crei nello stesso tempo una immagine dell'uomo quale noi giudichiamo debba essere. Scegliere d'essere questo piuttosto che quello è affermare, nello stesso tempo, il valore della nostra scelta, giacché non possiamo mai scegliere il male; ciò che scegliamo è sempre il bene e nulla può essere bene per noi senza esserlo per tutti. Se l'esistenza, d'altra parte, precede l'essenza e noi vogliamo esistere nello stesso tempo in cui formiamo la nostra immagine, questa immagine è valida per tutti e per tutta intera la nostra epoca. Così la nostra responsabilità è più grande di quello che vorremmo supporre perché coinvolge l'umanità intera. Così sono responsabile per me stesso e per tutti e creo una certa immagine dell'uomo che scelgo. Scegliendomi, io scelgo l'uomo.[52]»
 In sostanza, dal punto di vista personale noi scegliamo sempre quello che crediamo essere il bene.
L'esistenzialismo si configura quindi come una dottrina soggettivista e, fino a un certo punto, relativista, anche Sartre sceglierà poi razionalmente di impegnare la propria soggettività nella prospettiva marxista e nel materialismo storico, dove è la necessità a giustificare utilitaristicamente la scelta.[53] In ciò vi è una componente metafisica che alcuni studiosi di Sartre (come Franco Virzo, [54] ) hanno messo in evidenza
Dopo la seconda guerra mondiale, insieme alla cospicua produzione di opere drammaturgiche di alto livello, l'attenzione di Sartre si rivolge all'azione politica, ma si può dire che in esse esistenzialismo e politica trovino la loro sintesi intellettuale. Con l'adesione al comunismo, Sartre si mette in gioco a favore di questo e dà inizio a un suo ruolo di engagé che farà da modello a molti intellettuali di sinistra tra gli anni '50 e '80. Il resto della sua vita è segnato dal tentativo di riconciliare le idee esistenzialistiche con i principi del marxismo, convinto che le forze socio-economiche determinino il corso dell'esistenza umana e che il riscatto economico per la classe operaia possa diventare anche culturale.[3] Come Elio Vittorini, da cui sarà intervistato per Il Politecnico, Sartre auspica una cultura che non si limiti a consolare dal dolore ma che lo elimini e lo combatta, una cultura «capace di lottare contro la fame e le sofferenze».[55]
È in questa prospettiva che nasce il progetto della Critica della ragion dialettica (che uscirà nel 1960), la sua adesione al marxismo a partire da I comunisti e la pace (1951) e contemporaneamente la rottura con altri intellettuali. La Critica, però, non è per niente allineata alla dottrina comunista sovietica, ma propone una visione della società che lascia all'individualità larghi spazi di libertà e di affermazione, anche se in una prospettiva che coesiste anche con il determinismo. Nel perseguimento della "unità dialettica del soggettivo e dell'oggettivo" la soggettività è infatti dipendente dall'oggettività socioambientale come suo "campo delle possibilità".[3]
La libertà condizionata dell'uomo è in rapporto a un ampio sottofondo di necessità. Gli assunti fondamentali di L'essere e il nulla sono perciò nella Critica della ragion dialettica ridimensionati e superati con l'assunzione teorica del materialismo storico marxiano. È infatti il regno del "pratico-inerte" (l'essenza della materia) a imporsi, a dominare, a determinare la necessità e ad imporla anche all'uomo. Sartre viene quindi a scrivere: «Non è né nell'attività dell'organismo isolato e né nella successione dei fatti fisico-chimici che la necessità si manifesta: il regno della necessità è il dominio, reale, ma ancora astratto dalla storia, dove la materialità inorganica si chiude sulla molteplicità degli uomini e trasforma i produttori nei loro prodotti. La necessità, come limite nel seno della libertà, come evidenza accecante e come momento del rovesciamento della praxis in attività pratico-inerte diventa, dopo la caduta dell'uomo nella società seriale, la struttura stessa di tutti i processi di serialità, quindi la modalità della loro assenza nella presenza e di un'evidenza svuotata.[56]»
Sartre accetta il pensiero di Marx, di cui predilige il pensiero giovanile, presente in particolare nei Manoscritti economico-filosofici del 1844, e nelle Tesi su Feuerbach (1845). In quest'ultimo breve scritto compare la "filosofia della prassi", molto apprezzata da Sartre. Il filosofo francese però non accetta gran parte del materialismo dialettico di Engels. In proposito Sartre afferma: "il modo di produzione della vita materiale domina in generale lo sviluppo della vita sociale, politica e intellettuale". Aggiunge anche che "questa dialettica può effettivamente esistere, ma bisogna riconoscere che non ne abbiamo la benché minima prova"; dal determinismo deriva la dottrina della dialettica di Engels, che è, secondo Sartre, definita dai marxisti classici "come un dogma" acritico, per cui il marxismo della sua epoca "non sa più di nulla: i suoi concetti sono diktat; il suo fine non è più di acquistare cognizioni, ma di costituirsi a priori come sapere assoluto", ha disciolto gli uomini "in un bagno di acido solforico", mentre l'esistenzialismo ha potuto invece "rinascere e mantenersi perché affermava la realtà degli uomini".[57]
Sartre afferma poi che periodi rivoluzionari si dividono in tre fasi: 1) la genesi del «gruppo in fusione»; 2) il predominio della «Fraternità-Terrore», che sfocia nell'«istituzionalizzazione del capo»; 3) la ri-formazione delle istituzioni statuali. Prima di «unirsi in interiorità» nel gruppo in fusione, gli individui sono «uniti in esteriorità», dispersi, frammentati, atomizzati, estraniati nei «collettivi seriali», e tali tornano ad essere nella terza fase, la restaurazione politica post-rivoluzionaria. Rispetto alla Rivoluzione francese, modello fondamentale di ogni rivoluzione, le tre fasi sono: la presa della Bastiglia, il Terrore di Robespierre, il Termidoro. A giudizio del filosofo, la storia umana varia continuamente dalla “serie” al “gruppo” e dal “gruppo” alla “serie”.[58]
«In caso di invasione sovietica della Francia non mi sarei potuto aspettare, nel caso migliore, altro che una deportazione; in quell'epoca venivo definito come un essere spregevole dai giornali legati all'URSS.»
(Sartre sul rapporto con la politica sovietica[59])Il rapporto di Sartre con la politica in senso stretto, con il comunismo e i partiti comunisti fu simile a quello di molti altri intellettuali dell'epoca della guerra fredda, oscillante fra adesione e allontanamento, spesso per i problemi derivanti delle scelte dittatoriali dei regimi comunisti legati all'Unione Sovietica. Spesso cercarono alternative anticapitaliste e terzomondiste, rimanendo delusi da nuove esperienze extrasovietiche come il maoismo e il castrismo, e infine rifugiandosi nella socialdemocrazia o nel libertarismo (nel caso di Sartre l'anarco-comunismo) onde conciliare il proprio impegno umanista con l'opposizione al capitalismo e alle destre. Spesso questi intellettuali tentavano una riforma del comunismo dall'interno, sostenendo anche la dissidenza "moderata" dei paesi comunisti.[60]
A partire dal 1952, Sartre si impegnò in un "matrimonio di ragione" con i sovietici: in particolare, partecipa al Congresso nazionale della pace a Vienna nel novembre 1952, organizzato dall'URSS, e la sua presenza conferisce all'avvenimento una considerazione insperata. Sartre arriva fino ad autocensurarsi facendovi impedire la ripresa della sua pièce Le mani sporche, che i comunisti consideravano antibolscevica, in quanto alludeva all'assassinio di Lev Trockij, e che era previsto andasse in scena in quel periodo a Vienna.[3] Sartre resterà iscritto al PCF per 4 anni. Questo allineamento di Sartre ai comunisti separa lo stesso Sartre e Albert Camus (che abbraccia l'anarchismo al posto del marxismo), precedentemente molto vicini. Per Camus l'ideologia marxista non deve prevalere sui crimini staliniani, laddove per Sartre non si devono utilizzare questi fatti come pretesto per abbandonare l'impegno rivoluzionario. Già nel 1950 infatti Sartre e Merleau-Ponty denunciano pubblicamente il sistema dei gulag.[61]
Nel 1954, al ritorno da un viaggio in URSS, Sartre diede invece al quotidiano di sinistra Libération una serie di sei articoli che illustravano la gloria dell'URSS. Ancora nel 1955 scrisse una pièce teatrale (il Nekrassov) che fustigava la stampa anticomunista.[3] Dopo il rapporto Kruscev, Sartre comincerà ad avere dei dubbi sull'URSS, e affermò di trovare "inammissibile l'esistenza dei campi di concentramento sovietici, ma trovo altrettanto inammissibile l'uso giornaliero che ne fa la stampa borghese... Kruscev ha denunciato Stalin senza fornire sufficienti spiegazioni, senza avvalersi di un'analisi storica, senza prudenza", rifiutando di condannare in toto l'esperienza sovietica, perché considerata una fase di passaggio che aveva, perlomeno, un obiettivo ideale ancora da raggiungere. In un articolo sulla tortura nella guerra d'Algeria, commentando il saggio di Henri Alleg, esprimerà però la sua netta condanna delle pratiche staliniane più deteriori, come i gulag, la persecuzione dei dissidenti e la censura, eredità scomode dello zarismo.[22]
Sartre rifletté sul dissidio avuto con Merleau-Ponty sull'URSS:
«L'esistenza dei campi, egli diceva, permetteva di misurare tutta l'illusione dei comunisti di oggi. Ma subito dopo aggiungeva: “È questa illusione che ci impedisce di confondere il comunismo e il fascismo. Se i nostri comunisti accettano i campi e l'oppressione è perché essi sono in attesa di una società senza classi... Mai nazista si è ingombrato la testa di idee quali riconoscimento dell'uomo da parte dell'uomo, internazionalismo, società senza classi. È vero che le idee trovano nel comunismo di oggi soltanto un portatore infedele... resta il fatto che ci rimangono”. (...) Non bisogna avere indulgenza nei confronti del comunismo, ma non si può in nessun caso venire a patti con i suoi avversari. La sola critica sana è quindi quella che prende di mira, nell'URSS e fuori dell'URSS, lo sfruttamento e l'oppressione”.[62]»
e sostenendo poi che vi era una differenza capitale tra i crimini sovietici e i crimini borghesi, anche se i primi parevano odiosi in un regime nato per evitare i secondi, i crimini sovietici erano colpe del momento storico, mentre i crimini borghesi si sarebbero perpetuati per sempre nel sistema capitalista, per cui i campi «“Sono le loro colonie”. Al che Merleau risponde: “Quindi le nostre colonie, mutatis mutandis, sono i nostri campi di lavoro”».[62]
Nel saggio breve Il fantasma di Stalin. Dal rapporto Kruscev alla tragedia ungherese, che comunque segna l'inizio del distacco dai comunisti francesi, aggiunge che lo stalinismo non aveva troppo deviato dal socialismo e che
«Per conservare la speranza, (...) occorre riconoscere, attraverso gli errori, le mostruosità e i crimini, gli evidenti privilegi del campo socialista e condannare, con tanta maggior energia, la politica che mette in pericolo questi privilegi.»
(Il fantasma di Stalin, in Il filosofo e la politica, Roma, 1964, pp. 65, 94, 98)In futuro si allontanerà ancora di più dal socialismo reale e rinnegherà come tanti queste posizioni, spinto dagli avvenimenti contingenti. Il suo sodalizio con il PCF e il sostegno attivo all'URSS già erano terminati all'indomani degli avvenimenti dell'autunno del 1956, quando i carri sovietici soffocarono la rivoluzione ungherese. L'insurrezione fece riflettere molti comunisti sul fatto che esisteva un proletariato al di fuori dal partito comunista con istanze non solo non rappresentate o misconosciute, ma addirittura negate e avversate. Sartre, dopo aver firmato una petizione di intellettuali di sinistra e di comunisti contestatari, il 9 novembre concesse una lunga intervista al settimanale l'Express (giornale mendésista), per smarcarsi platealmente dal partito. Nel 1956 Sartre decise un cambiamento di strategia ma non cambiò le sue opinioni: socialiste, anti-borghesi, anti-americane, anti-capitaliste, e soprattutto anti-imperialiste; la lotta dell'intellettuale impegnato continuò e prese una nuova forma in seguito agli avvenimenti della guerra d'Algeria.[3]
Nel 1968 attaccò Brežnev e supportò la primavera di Praga di Alexander Dubček, stroncata nuovamente dai sovietici. Nel 1977 Sartre presenzia a un raduno di dissidenti sovietici a Parigi.[63]
Riguardo al progresso egli disse che:
«Potrebbe esserci una dittatura mondiale, oggi, ma nessuno storico, o quasi nessuno, affermerebbe oggi che la dittatura sia meglio della democrazia borghese, proprio come quasi nessuno prima affermava che un legislatore divino fosse meglio della monarchia parlamentare. Ogni tappa può essere superata temporaneamente e il mondo può anche regredire temporaneamente, ma una volta fondata nell'ethos umano, la nozione di progresso si propaga tra la gente di tutto il mondo.»
(Citato in Parlando con Sartre di John Gerassi, p. 207)Negli anni '50, nella Parigi degli ambienti terzomondisti, Sartre conobbe anche un giovane cambogiano di nome Saloth Sar, con cui condivideva la militanza nel Partito Comunista Francese, che diverrà poi noto alle cronache molti anni dopo con il nome di battaglia di Pol Pot, capo dei guerriglieri Khmer rossi e feroce presidente della Kampuchea Democratica dal 1975 al 1979. 
Sartre fu accusato anche, da commentatori di area conservatrice e anticomunista, tra cui Paul Johnson, Francesco Alberoni e Vittorio Messori, di aver influenzato indirettamente l'ideologia dei suddetti Khmer Rossi, tramite l'ex allievo Pol Pot che la portò alle estreme conseguenze fondendola con un nazionalismo totalitario esasperato, con ripetute violazioni dei diritti umani come già si erano viste con Stalin e la degenerazione del comunismo sovietico, sebbene secondo la maggioranza dei commentatori l'azione del Partito Comunista di Kampuchea (finanziato e sostenuto anche dall'occidente in quanto anti-sovietico) non è ovviamente da imputare all'ideologia e alla filosofia sartriana.[65]
Egli comunque non seppe mai nulla della dittatura e del genocidio cambogiano (peraltro poco conosciuto in Occidente prima del 1980), essendo morto quando le scarse notizie cominciarono a filtrare; fu criticato per non aver condannato pubblicamente, nel suo ultimo anno di vita (in cui si era comunque ritirato dalla vita pubblica per seri problemi di salute), Pol Pot e gli altri Khmer Rossi, cosa tra l'altro condivisa dalla maggior parte dei mass media e degli intellettuali occidentali di sinistra (tra cui Noam Chomsky), essendo l'opinione pubblica concentrata sul Vietnam e all'oscuro, tranne pochi testimoni, della realtà cambogiana vista invece benevolmente. (Solo negli anni '80 il regime di Pol Pot verrà pienamente compreso nel suo orrore e condannato universalmente.[66]) Per aver guardato con simpatia all'Unione Sovietica di Stalin (almeno prima della destalinizzazione e della denuncia dei crimini del leader bolscevico da parte di Nikita Krusciov), alla rivoluzione di Mao Zedong - per un lungo periodo Sartre sosterrà il maoismo, nella speranza che potesse essere un comunismo non burocratico e popolare, speranza che andrà delusa - e per l'amicizia, poi interrotta, con Fidel Castro, Sartre venne accusato di supportare le dittature, in ossequio all'ideologia.[65] Sono questi i tempi della sua militanza tra i giovani della Gauche prolétarienne.
Sostenitore attivo della rivoluzione cubana dal 1960, amico di Che Guevara e Fidel Castro, egli ruppe poi con il Líder Máximo nel 1971 a causa del cosiddetto affaire Padilla; Sartre firmò con de Beauvoir, Alberto Moravia, Mario Vargas Llosa, Federico Fellini e altri intellettuali (con l'eccezione di Gabriel García Márquez) una lettera di critica al governo cubano, per aver arrestato e poi costretto ad una pubblica autocritica il poeta Heberto Padilla, accusato di avere scritto contro la Rivoluzione e il castrismo. Per Sartre questo atto fu un abuso di potere e un attacco alla libertà d'espressione, non una difesa dai controrivoluzionari.[67] Egli dirà poi di Fidel Castro: "Il m'a plu, c'est assez rare, il m'a beaucoup plu" ('Mi è piaciuto, il che è piuttosto raro, mi è piaciuto molto').[3] Discussa è l'influenza reciproca tra la dottrina politica di Guevara e quella marxista-esistenzialista di Sartre e dei sartriani, anche se di certo entrambi ponevano l'accento sulla questione umanistica (per Marx facente parte della sovrastruttura, quindi "superflua", oppure derivata dalla struttura, ma secondaria) più che su quella economica.[68][69]
Pur stimando Mao Tse-tung e Lenin, Sartre prenderà poi le distanze dai regimi nati dalle loro rivoluzioni, e alcune critiche alla realizzazione del socialismo reale vennero da lui pronunciate; secondo il filosofo la storia procedeva verso il progresso, e gli errori non potevano fermarla. Come il capitalismo, anche il socialismo faceva gravi errori, ma secondo lui sarebbe migliorato col tempo e avrebbe portato al miglioramento della società, mentre il capitalismo avrebbe condotto il mondo al collasso: «Nessuno afferma che le rivoluzioni siano facili. Se definiamo il progresso come l'aumento della gente che partecipa alle decisioni che riguardano la sua vita, non ci possono essere dubbi che, oltre ai massacri, ai genocidi, agli omicidi di massa che hanno abbondantemente segnato la storia dell'umanità, c'è stato un progresso. (...) Guarda la Rivoluzione culturale, per esempio. Sembra che sia terminata in orribili eccessi (dico «sembra che» perché non ho fiducia nella nostra opinione pubblica, cioè negli storici dell'establishment e nei media). Però la caratteristica principale della Rivoluzione culturale è che il popolo stabilisce le politiche e gli amministratori amministrano quella politica.(...) Non c'è stato terrore a Cuba (...) perché, come hai detto, Castro permise ai tribunali popolari di giudicare gli aguzzini di Batista come un modo per far uscire alla luce del giorno l'odio (...) Gli Stati Uniti permisero ai ricchi di emigrare come volevano (...) Fidel li lasciò partire.»
(da Parlando con Sartre, pp. 207 e 256)Egli non riuscì comunque a staccarsi da una visione utopica della rivoluzione culturale, se non dopo il 1975, relegando le violenze delle Guardie Rosse in una degenerazione spontanea, non imputabile a Mao, ma previde l'involuzione burocratica denghista della Cina:
«Fondamentalmente è stata una fantastica rivoluzione popolare sorta dalle radici ad aver detto: «Noi facciamo la politica, i burocrati amministrano la politica». Però Mao si spaventò perché lui avrebbe potuto essere spedito a raccogliere patate in qualche fattoria collettiva. (...) Quel che è certo che tanto i comunisti di Mao quando l'apparato comunista, il suo o quello dell'esercito oppure quello del partito, hanno fondamentalmente bloccato uno spostamento a sinistra, e ciò significa che la rivoluzione originaria (...) è finita. Hanno fallito, e la Cina si sposterà radicalmente a destra. Ne sono assolutamente sicuro. Una rivoluzione che dà per scontato che per sopravvivere deve schiacciare a sinistra e a destra, come fece Robespierre, come fece Stalin, deve per forza fallire.»
(da Parlando con Sartre, p. 258)«Non fu un cambiamento di idee. Da sempre sono stato più anarchico che marxista. (...) Quando i carri armati sovietici entrarono a Praga, (...) allora dovemmo denunciare l'invasione.»
(Sartre sull'invasione sovietica della Cecoslovacchia nel 1968)«Se si leggono i miei libri, si capirà che non sono mai cambiato in profondità, e sono sempre rimasto un anarchico.»
(Sartre sul movimento del Sessantotto)Sartre sostenne con forza il governo socialista democratico di Salvador Allende in Cile. Egli fu in prima linea nel denunciare il golpe cileno del 1973; nel 1978 firmò con altri nomi della cultura (Paco Ibáñez, Georges Moustaki, Yves Montand, Roland Barthes e Louis Aragon) una petizione per il boicottaggio del campionato mondiale di calcio in Argentina, per protesta contro i crimini della giunta militare di Jorge Rafael Videla.[70]
In seguito a fatti come la persecuzione degli omosessuali a Cuba,[Nota 2] negli ultimi anni di vita Sartre si staccò dal comunismo statalista per avvicinarsi a quello anarchico (l'ideale anarchico, anche se in senso più individualistico, lo aveva attratto anche da giovane, portandolo inizialmente a criticare Lenin). Sartre non rinnega Marx, ma lo affianca ai pensatori di questa corrente, come Bakunin e Proudhon: i fallimenti del socialismo reale hanno ormai insegnato che lo Stato "popolare" è un'utopia; non rinnega le premesse ma la realizzazione politica.[71][72][73][74]
Sempre a proposito dell'anarchismo, nel 1978 denunciò per diffamazione l'anarco-insurrezionalista Alfredo Maria Bonanno, per aver diffuso un falso "testamento politico di Sartre", in cui si incitava ad attaccare violentemente la società, tramite attentati e insurrezioni, idea a cui Sartre non volle essere associato.[75] Si può dire che, come molti intellettuali del XX secolo (un percorso da sinistra analogo a quello di Noam Chomsky), sperò di poter conciliare la libertà col comunismo realizzato, ma ne fu deluso. Difatti, è principalmente nella prassi - e non nella teoria - che il pensiero dell'esistenzialismo sartriano incontra il materialismo storico, restando invece un pensiero individualista a livello speculativo, ma essendo egli un autentico "pensatore della modernità", il reale è in qualche modo razionale e deve hegelianamente essere razionalizzato.[76]
Tra le altre critiche fatte a Sartre fu quella di non essersi opposto alla pena di morte per gravi reati politici nei paesi del blocco sovietico (anche se nel 1950 era stato tra gli intellettuali che avevano richiesto la grazia per la giurista dissidente cecoslovacca Milada Horáková, assieme a Einstein, Churchill, Eleanor Roosevelt e altri esistenzialisti francesi[77]), in quanto "estrema sanzione" per elementi controrivoluzionari, da usare in casi-limite e solo per "salvare la rivoluzione" o in tempi di guerra; egli peraltro la riteneva ingiusta per i crimini comuni ed era contrario al suo uso, ma si astenne sempre da esplicite campagne abolizionistiche, al contrario di Camus, cosa che non gli fu perdonata dai detrattori, che lo accusarono di ambiguità.[78] Sartre scrisse talvolta del tema (nelle opere A porte chiuse e Morti senza tomba è evidente la sua opposizione per motivi umanitari) ed espresse poi, riferendosi a un caso in cui fosse necessaria, facendo l'esempio specifico dei torturatori del regime di Batista, giustiziati nel 1960 dai tribunali popolari della Cuba di Castro, il proprio disagio conflittuale interno fra necessità e ideale: "Sono così contrario alla pena di morte che ciò mi crea dei problemi".[79][80]
Sartre e de Beauvoir si esprimeranno anche contro il fondamentalismo islamico della rivoluzione iraniana (1979), pur essendo avversi al precedente regime filoamericano dello scià contro cui sottoscrissero appelli (assieme ad Amnesty International e alla Croce Rossa), e avendo in precedenza visitato l'ayatollah Khomeini nel suo esilio a Parigi;[82] in particolare Simone de Beauvoir organizzerà manifestazioni contro l'imposizione del chador alle donne iraniane ed entrambi sosterranno politicamente il partito comunista iraniano, il Tudeh (in esilio in occidente).[81]
Un'altra accusa fu di aver giustificato in parte l'uso del terrorismo come ultima arma politica contro forze militari nemiche, una «terribile arma, ma i poveri oppressi non ne hanno altre», disse riferendosi al terrorismo dei palestinesi nel conflitto arabo-israeliano.[Nota 3] Sostanzialmente Sartre cercò di porsi sempre come un mediatore tra le parti e definì positiva la costituzione dello Stato d'Israele, "che ci permette di conservare la speranza." Egli sostenne più volte infatti che la sinistra non avrebbe dovuto scegliere tra due cause entrambe morali e che spettava unicamente agli ebrei e agli arabi risolvere il loro conflitto attraverso la discussione e la negoziazione. Egli cercò di creare un dialogo, mettendo in gioco il suo nome e il suo prestigio intellettuale nella promozione di riunioni private e pubbliche tra i rappresentanti delle due parti, come il Comitato israelo-palestinese del 1970. I suoi sforzi si rilevarono tuttavia infruttuosi, soprattutto a fronte del forte aumento degli insediamenti israeliani nei territori palestinesi occupati a partire dal 1977 e l'inasprirsi di conseguenza del conflitto.[83]
Sartre fu accusato di sostenere e voler diffondere un'etica libertina e scandalosa. La vita e il pensiero radicale si fusero insieme: non visse mai stabilmente con Simone de Beauvoir (anche se avrebbe voluto sposarla, a un certo punto) e avranno relazioni contemporanee e perfino dei ménage à trois (cosa che farà nascere il mito sessantottino e rivoluzionario della coppia aperta Sartre-de Beauvoir) tra Jean-Paul, Simone e occasionali amanti di sesso femminile di de Beauvoir, dichiaratamente bisessuale. «Il nostro è un amore necessario, ci conviene conoscere anche degli amori contingenti», affermava sulla relazione con la scrittrice.[45] La difese strenuamente anche quando venne interdetta dall'insegnamento per una relazione lesbica con una studentessa ancora minorenne di 17 anni, nel 1940.[3][84][85] In certi momenti della sua vita, Sartre si descrisse - affermò, criticamente, di essere così verso la fine della sua vita - come eccessivamente attratto dal sesso.[34]
Nel 1947 Jean Kanapa, firma del giornale del Partito comunista francese (con cui più tardi il filosofo tenterà la conciliazione), l'Humanité, attaccò Sartre in un saggio intitolato L'esistenzialismo non è un umanesimo, in cui si afferma che "il significato sociale dell'esistenzialismo è la necessità attuale per la classe sfruttatrice di addormentare i suoi avversari" e che Jean-Paul Sartre era un "pederasta che corrompe la gioventù".[86] Anche nelle pubblicazioni del Partito Comunista Italiano, Sartre venne contestato (salvo poi far marcia indietro nel decennio seguente) nei primi anni '50, accusato di essere un "degenerato" e di "compiacersi della pederastia e dell'onanismo".[87]
In un articolo redazionale pubblicato sul n. 12 della rivista Tout, Sartre scrisse, nel 1969: «Quanto alla famiglia, scomparirà (...) soltanto quando avremo cominciato a sbarazzarci del tabù dell'incesto (tra genitori e figli, tra fratelli e sorelle); la libertà deve essere pagata a questo prezzo».[88]
Fra il 1977 e il 1979 invece, all'epoca in cui nel Parlamento francese era in discussione la riforma del Codice penale, numerosi intellettuali francesi si schierarono a favore dell'abolizione della legge sull'età del consenso; nel 1977, molti filosofi e pensatori tra i quali lo stesso Jean-Paul Sartre, Simone de Beauvoir, Michel Foucault, Jacques Derrida, Françoise Dolto, Louis Althusser, Serge Quadruppani, André Glucksmann, Louis Aragon, Gilles Deleuze, Philippe Sollers e Roland Barthes, sottoscrissero alcune petizioni indirizzate al Parlamento, chiedendo l'abrogazione di numerosi articoli di legge e la depenalizzazione di qualsiasi rapporto consenziente tra adulti e minori di quindici anni (l'età del consenso in Francia) se il minore era considerato capace di dare consenso, nelle cosiddette Pétitions françaises contre la majorité sexuelle.[89]
Queste accuse di immoralità rivolte a Sartre tornano periodicamente, anche dopo la morte del filosofo.[90][91][92]
Nell'esistenzialismo di Sartre si realizza lo stesso paradosso di Heidegger e Jaspers: la trasformazione del concetto di possibilità in impossibilità. Secondo Sartre l'uomo è definito come "l'essere che progetta di essere Dio" (in "L'essere e il nulla"), ma questa attività si risolve in uno scacco: ciò che per Heidegger e Jaspers è nullificato dalla realtà fattuale, in Sartre è nullificato dalla molteplicità delle scelte e dall'impossibilità di discriminarne la fondatezza e validità.[3]
Tra i cardini filosofici di questo esistenzialismo vi sono vari concetti:[3]
L'impegno non è una maniera di rendersi indispensabile e non importa chi è l'impegnato; esso è intercambiabile, quindi:[3]
L'uomo non vive se non in relazione all'altro (pur essendo presenti a volte, in Sartre, un certo elitarismo e misantropia), e l'"IO" sartriano non è più soggettivo ma oggettivo, in quanto è riferito a ogni uomo in chiave universale e, in sintesi, siamo come una stanza con una finestra che si affaccia sul mondo esterno, e sta a noi, e solo a noi, decidere di aprirla.[3]
L'esistenzialismo, quindi, a detta dello stesso Sartre,[44] vuole essere una filosofia della responsabilità: l'uomo non ha scusanti di fronte alla scelta, la sua caratteristica è il libero arbitrio. Nessuno insomma può giustificarsi, e invocare la necessità di una determinata posizione, magari mascherandosi dietro a varie forme di determinismi (la volontà di Dio, oppure le leggi storiche/sociali), semplicemente perché anche la non scelta è una scelta, talvolta più conveniente ma sempre una scelta deliberata. Il sentimento dell'angoscia, quindi, è intimamente connesso alla possibilità dell'uomo che ha di scegliere, che si pone davanti alle diverse possibilità; alla libertà dell'uomo. La libertà è intimamente connessa col nulla, e l'uomo nella sua esistenza convive con il non essere. Questo, come chiarisce Sartre in più punti, non porta a una concezione pessimista, ma è una filosofia non consolatoria e della responsabilità, perché sottolineando l'essere prima dell'essenza, invita l'uomo a "crearsi una propria morale", a scegliere autenticamente, e nel momento in cui opera questa scelta a livello personale, in realtà sta scegliendo per l'umanità. L'uomo è ciò che sceglie, nel senso che non vi è un concetto, un'essenza predefinita dell'uomo prima della sua scelta, ma è esattamente quello che sceglie di diventare.[3]
Il pensiero (già azione in sé) deve essere seguito dall'azione pratica, non conta la potenza ma solo l'atto, respingendo quindi il quietismo, qui inteso come pessimismo rinunciatario (Sartre non intende difatti il quietismo in senso teologico, ma in questo senso particolare): «L'uomo non è niente altro che quello che progetta di essere; egli non esiste che nella misura in cui si pone in atto; non è, dunque, niente altro che la somma dei suoi atti, niente altro che la sua vita. Da questo possiamo comprendere perché la nostra dottrina faccia orrore a un certo numero di persone. Perché, spesso, esse hanno un solo modo di sopportare la loro miseria, ed è di pensare: le circostanze sono state contro di me, io volevo molto di più di quello che sono stato.»
Controverso è il rapporto di Sartre con la religione: Sartre è ateo, ma è ateo perché il "Dio di Sartre" è un "Dio assente", che l'uomo è costretto a sostituire, non avendo la minima possibilità di un'alternativa della fede, che causerebbe l'abbandono della ragione:[93] «L'assenza di Dio non è più la chiusura: è l'apertura dell'infinito. L'assenza di Dio è più grande, è più divina di Dio (io non sono più Me, ma assenza di Me).»
(Quaderni per una morale, usciti postumi nel 1983, p. 40)
Nel 1980, pochi mesi prima di morire, Sartre fu intervistato dal segretario Pierre Victor, noto anche con il suo vero nome, Benny Lévy. Il contenuto delle interviste, incentrato sui temi della speranza, della libertà e del potere, pubblicato da Le Nouvel Observateur, sconcertò i lettori, abituati al suo esistenzialismo ateo, ma il filosofo confermò l'autenticità dei testi (tuttavia resi pubblici solo dopo la morte nella loro interezza), nei quali si legge tra l'altro, una sorta di conversione "deista", ma anche un appoggio al giudaismo, che era più che altro un'idea di Lévy, che era ebreo di famiglia, a differenza di Sartre, nato da una famiglia cattolica e protestante e di cui non risultano conversioni all'ebraismo, al punto da far nascere il sospetto di una manipolazione o un travisamento delle parole di Sartre da parte del convertito Lévy; Sartre si interessò comunque sempre di ebraismo, specie riguardo alla questione dell'antisemitismo, apprezzando profondamente il ruolo degli ebrei laici e approfondendo il rapporto tra il messianismo e l'idea di rivoluzione permanente in Steven Schwarzschild (rabbino e filosofo tedesco-americano, esponente della teologia dell'Olocausto, del socialismo ebraico pacifista, del noachismo, nonché critico del sionismo).[94] Sartre affermò tra l'altro, sulla sua idea personale del "problema di Dio" (sempre riferito all'ossessione dell'uomo come "Dio fallito" e all'assenza e silenzio del Dio della tradizione dall'orizzonte umano moderno e della sua esperienza): «Non sento di essere il prodotto del caso, un granello di polvere nell'universo, ma qualcuno che era aspettato, preparato, prefigurato. In breve, un essere che solo un Creatore potrebbe mettere qui. E questa idea di una mano creatrice si riferisce a Dio.»
(Sartre nel 1980)Questa citazione fu vista come una professione di fede, anche se probabilmente era solo una constatazione dello stato d'animo umano, degli uomini educati alla religione, ma che cadono nel nichilismo una volta constatata la vanità di essa e la mancanza attuale di nuovi valori, legato al pensiero giovanile dell'ateismo scomodo e sofferto, che impediscono di leggere ciò come una "conversione religiosa":
«Tuttavia l'uomo non è diventato ateo. Il problema, oggi come ieri, resta immutato; il silenzio del trascendente, congiunto al perdurare, nell'uomo moderno, dell'esigenza religiosa»
«È molto scomodo che Dio non esista, poiché con Dio svanisce ogni possibilità di ritrovare dei valori in un cielo intelligibile; non può esserci un bene a priori poiché non c'è nessuna coscienza infinita e perfetta per pensarlo»
(L'esistenzialismo è un umanismo, p. 40)D'altronde emergono alcune incongruenze, che fanno pensare a una strumentalizzazione e una forzatura in senso teistico da parte del segretario del filosofo:
«Victor insiste che tutta l'origine della morale è nella Torah! Ma io non credo che sia tutto lì.[95]»
Sartre avrebbe respinto inoltre l'invito dei suoi amici più intimi a non manifestare tali idee, compreso quello della sua compagna, Simone de Beauvoir, che nel 1982 commentò su "National Review" a proposito delle interviste postume di Lévy: «Come si potrebbe spiegare questo senile atto di un voltagabbana? Tutti i miei amici, tutti "le Sartreans", e la redazione di Les Temps Modernes mi hanno sostenuto nella mia costernazione».[96]
Per alcuni studiosi di Sartre è un enigma che deve ancora essere spiegato in modo soddisfacente, anche se una certa tensione verso l'Assoluto e verso argomenti religiosi, in senso lato e in maniera sentimentale, e non razionale se non di trasformazione della Weltanschauung cristiana della sua formazione cattolico-protestante in una visione laica esistenzialista, è reperibile in buona parte della sua opera,[93] e l'esempio più noto è Bariona o il figlio del tuono (1940), opera scritta durante la prigionia, e prima che abbandonasse completamente la fede religiosa; riprendendo Feuerbach e Nietzsche, afferma poi che "Dio esisteva in quanto creazione umana", ergo non esisteva realmente ma era utile a livello pratico in certi momenti umani;[97][98][99] dirà in seguito: «Avevo bisogno di Dio, mi fu dato, lo ricevetti senza capire che lo cercavo. Non potendo attecchire nel mio cuore, egli ha vegetato in me, poi è morto. Oggi, quando mi si parla di Lui, dico con quel tanto di divertito, senza una punta di rimpianto, nel modo in cui un vecchio, vagheggiando, si rivolge a una vecchia fiamma incontrata per caso: "Cinquant'anni fa, senza quel malinteso, senza quell'errore, senza quell'incidente che ci separò, avrebbe potuto esserci qualcosa fra noi". (...) Mia madre mi educava nei sentimenti cattolici, il nonno lo aveva permesso, ma egli si faceva beffe di queste cose – in una maniera d'altronde poco importante, non mi sembrava che egli avesse particolarmente ragione – ma semplicemente il fatto cattolico, quando appariva, era contestato. Allora ho perduto la fede completamente verso gli undici anni, o piuttosto mi sono accorto che l'avevo perduta: ero a La Rochelle, attendevo due amichette con cui prendevo il tram per andare al liceo, e per distrarmi mi sono detto: “Toh, Dio non esiste”. È caduto in questo modo e non è mai ritornato. Ed era nei fatti una presa di coscienza di ciò che avevo concepito prima.»
(Sartre nel 1972[100])I critici osservano inoltre un'analogia con le altre storie di presunte conversioni, spesso falsificate, come ad esempio Voltaire, Camus, Gramsci, Leopardi e altri. L'avvocato e militante femminista Gisèle Halimi, amica del filosofo dal 1957, è tornata nel 2005 sulle osservazioni pubblicate da Lévy affermando: "Questa intervista è incontestabilmente un falso [...] Sartre non era più in possesso delle sue piene facoltà mentali", riferendosi alla perentorietà della frase contestata, completamente negata, e alla documentata perdita di lucidità che afflisse Sartre nell'ultimo mese di vita.[101]
Nella sua opera la fede è vista come una passione, non una costruzione razionale; ma questa passione non è gratuita, in quanto si paga con l'angoscia, lo "scacco", il silenzio e il vuoto, con l'"assenza di Dio", proclamata da Nietzsche e ribadita nel 1974 da Sartre, in un'intervista con Simone de Beauvoir. Essa è dannosa, poiché, per inseguirla, il soggetto rinuncia alla propria capacità essenziale, cioè la costruzione della morale e l'impegno nella storia. Nonostante questo, l'uomo non può fare a meno di assumere per sé il punto di vista di Dio, di pensare “come se Dio esistesse”, perché la natura del Dio creduto è la stessa natura dell'uomo, specificata dalla contingenza e dalla penuria del progetto fallito. Il problema di Sartre non è tanto escatologico, soteriologico e trascendente (problemi che lo occupano poco, agnosticamente), ma immanente: Sartre vuole una morale da seguire, un ideale umano sostitutivo, che prenda il posto del Dio caduto e inaccettabile, in un mondo ormai ateo poiché materialista (e non potrebbe essere altrimenti).[93]
In alcuni di questi interventi, sembrò rinnegare completamente la validità pratica del marxismo-leninismo (come aveva già fatto qualche anno prima, avvicinandosi all'anarco-comunismo e a un marxismo più libertario, ma in maniera ora più netta), rigettando anche parte del pensiero esistenzialista, suo e della de Beauvoir, oltre a criticare l'uso politico della violenza, prima considerata lecita in casi estremi e particolari, dove fosse l'unica opzione rimasta; ribadì inoltre la sfiducia nella "democrazia borghese", dove il voto viene trasformato in un semplice «rito di massa», in cui vede dei limiti insormontabili.[99][102]
Sartre fa inoltre una certa autocritica, oltre che sui temi della violenza rivoluzionaria, giudica anche, come opinabile, la sua adesione al maoismo come forma di critica allo stalinismo, ribadendo la sua scelta anarchica di fondo e chiarendo che la simpatia per la Cina era dovuta ad alcuni aspetti "popolari" della grande rivoluzione culturale (che non vide mai di persona), che già dal 1973 aveva cominciato a sconfessare, quando l'egualitarismo si rivela demagogia e mancanza di libertà.[38]
Egli si dirà anche, negli anni '70, affascinato dall'azione del leader nonviolento radicale italiano Marco Pannella, appartenente all'area della sinistra liberale e anti-sovietico dichiarato.[103][104]
In questa fase, sostiene inoltre che la vita umana si risolve sempre in un fallimento ma che questo non l'ha mai portato alla disperazione, ribadendo che la sua filosofia nasce da un bisogno derivante dalle sue radici filosofiche, Hegel e il cristianesimo senza più fede.[105] Alla fine, Sartre lancia un appello all'umanità perché ritrovi la fratellanza, come in un'unica famiglia, superando la lotta di classe e lo scontro[94]
«SARTRE: Io penso che le persone dovrebbero avere o possono avere o hanno un certo rapporto primario che è il rapporto di fraternità. B. LÉVY: Perché il rapporto di fraternità è il primo? Siamo tutti figli di uno stesso padre? S.: No, ma il rapporto familiare è primo in relazione a ogni altro rapporto. L.: Si forma una sola famiglia? S: In una certa maniera, si forma una sola famiglia.»
(Conversazione Sartre-Lévy, da Le Nouvel Observateur, marzo 1980)
Ronald Aronson ha commentato che le interviste non vanno estrapolate da un certo contesto e non sono attribuibili a tardive conversioni o discorsi di una mente danneggiata dalla malattia (anche se potrebbe aver influito la depressione per l'impossibilità a scrivere di suo pugno, nonché le delusioni politiche subite dalle grandi idee in cui aveva riposto la sua fiducia, ma al contrario rappresentano un'evoluzione del classico pensiero sartriano, da sempre in "divenire", a modo suo coerente, che cerca sempre di evitare di fallire, dramma supremo per l'essere umano[99]:«Passando di fallimento in fallimento, si raggiunge il progresso.[106]»
John Gerassi sostiene che Sartre sapeva quello che diceva e che il suo obiettivo era quello di "creare uno scandalo", considerando che invece le conversazioni registrate con Simone de Beauvoir nello stesso periodo erano di altro tono.[14]
È stato spesso rimproverato a Sartre un certo intellettualismo, poco conciliabile con le sue convinzioni socio-politiche, marxiste e favorevoli alla cultura di massa. Il suo principale saggio filosofico, L'essere e il nulla, appare talvolta giocato su una teorizzazione della coscienza che ricorda troppo da vicino la metafisica colta che vorrebbe combattere.[3]
Oltre alle critiche alla visione politica comunista e marxista,[107] ha ricevuto quelle degli esistenzialisti disimpegnati, come Eugène Ionesco ed Emil Cioran; quest'ultimo, nel Sommario di decomposizione ne traccia un caustico e anonimo ritratto: «impresario di idee», «pensatore senza destino», nel quale «tutto è notevole, salvo l'autenticità», «infinitamente vacuo e meravigliosamente ampio», ma proprio per questo capace, con un'opera che "degrada il nulla" come una merce, di soddisfare «il nichilismo da boulevard e l'amarezza degli sfaccendati».[108]
Tra le critiche meramente filosofiche vi è quella dell'altro grande teorico dell'esistenzialismo, Martin Heidegger, che lo accusa di soffermarsi su tematiche meramente "esistentive", anziché rivolgersi a una visuale davvero esistenziale, che si occupi cioè del rapporto dell'ente (cioè l'Essenza) con l'Essere. Con la sua opera Essere e tempo il pensatore tedesco, spesso accusato di essersi compromesso col nazismo, afferma invece di avere tracciato i veri punti di riferimento del movimento. Per Heidegger l'Essere e l'Essenza sono due cose diverse, ed entrambe precedono gerarchicamente l'Esistenza.[109]
Heidegger risponde a Sartre sul ruolo dell'intellettuale e criticando l'umanesimo: «Il pensiero non è solo l'engagement dans l'action per e mediante l'ente, nel senso del reale della situazione presente. Il pensiero è l'engagement per e attraverso la verità dell'essere [...] quel che conta è l'essere, non l'uomo».[110]
L'essere e il nulla venne attaccato anche dai marxisti non esistenzialisti e dai cattolici. I cattolici vi scorsero una filosofia atea e materialistica, mentre i marxisti lo accusarono di idealismo, individualismo e pessimismo. Nel saggio L'esistenzialismo è un umanismo, Sartre si difese rifiutando queste interpretazioni, sostenendo di aver proposto una filosofia dell'uomo libero, con rapporti e responsabilità verso gli altri esseri umani.[111]
Sartre è stato attaccato anche da Louis-Ferdinand Céline nel pamphlet[in che modo?] À l'agité du bocal, risposta al testo di Sartre Ritratto dell'antisemita, in cui il pensatore attaccava l'antisemitismo e criticava lo scrittore del Viaggio al termine della notte (libro che Sartre aveva grandemente ammirato alla sua uscita nel 1932) di essere finito a scrivere pamphlets antisemiti per ragioni economiche.[112]
Sartre comparve come attore nei panni di sé stesso in tre opere:
«Il y a un pacte vingt fois séculaire entre la grandeur de la France et la liberté du monde.»
«C'è un patto di duemila anni tra la grandezza della Francia e la libertà del mondo.»
(Charles de Gaulle, Frase pronunciata durante il Discorso tenuto alla "Réunion des Français de Grande Bretagne", alla Kingsway Hall a Londra il 1º marzo 1941 e riportata inoltre sulla statua di de Gaulle sull'avenue des Champs-Élysées (place Clemenceau) a Parigi)Charles André Joseph Marie de Gaulle, comunemente chiamato il Generale de Gaulle (audio[?·info]) (Lilla, 22 novembre 1890 – Colombey-les-Deux-Églises, 9 novembre 1970), è stato un generale, politico e scrittore francese.
Fu capo della Francia libera, poi dirigente del Comitato francese di Liberazione nazionale durante la seconda guerra mondiale, presidente del Governo provvisorio della Repubblica francese dal 1944 al 1946, Presidente del Consiglio dei ministri francese dal 1958 al 1959, creatore della V Repubblica fondata nel 1958, Presidente della Repubblica francese dall'8 gennaio 1959 al 28 aprile 1969. È stato il primo Presidente della quinta Repubblica francese e protocanonico d'onore della Basilica di San Giovanni in Laterano. Cresciuto in una cultura di grandezza nazionale, Charles de Gaulle scelse la carriera di ufficiale. Venne fatto prigioniero durante la prima guerra mondiale. Collaborò con l'entourage di Philippe Pétain e insistette per l'uso delle divisioni di blindati nella guerra contemporanea, scrivendo a diverse personalità politiche. Nel maggio 1940 era a capo di una divisione blindata e condusse diversi contrattacchi durante la battaglia di Francia; fu promosso generale di brigata a titolo temporaneo il 25 maggio 1940. Venne nominato Sottosegretario di Stato alla Difesa nazionale e alla Guerra nel governo Reynaud, durante l'esodo del 1940.
Rifiutò l'armistizio chiesto da Pétain alla Germania nazista. Da Londra lanciò, attraverso la BBC, l'appello del 18 giugno al popolo francese alla resistenza e a raggiungerlo nelle Forze francesi libere. Condannato a morte e privato della nazionalità francese dal regime di Vichy, volle incarnare la legittimità della Francia ed essere riconosciuto come tale degli Alleati. Controllando solamente qualche colonia, ma riconosciuto dalla Resistenza francese, egli unì, nel 1943, la Francia libera all'interno del Comitato francese di Liberazione nazionale, del quale prese la direzione, e condusse il paese alla Liberazione. Favorevole a un potere esecutivo forte, si oppose ai progetti parlamentari dei partiti e si dimise nel 1946. Fondò il Rassemblement du peuple français (RPF), ma il suo rifiuto di ogni compromesso con il «regime dei partiti» lo isolò in una «traversata del deserto» lontano da ogni responsabilità.
De Gaulle fu richiamato al potere nella crisi del 13 maggio 1958, durante la guerra d'Algeria. Nominato presidente del Consiglio dei ministri, fece approvare la Quinta Repubblica francese con un referendum. Eletto presidente della Repubblica, egli volle una «politica di grandezza» della Francia. Consolidò le istituzioni, la moneta (nuovo franco) e diede un ruolo di terza via economica a uno Stato pianificatore e modernizzatore dell'industria, avviando i "Trente Glorieuses" anni di boom economico. Rinunciò progressivamente all'Algeria francese, malgrado l'opposizione dei pieds-noirs (cittadini francesi nati in Nordafrica) e dei militari, che avevano favorito il suo ritorno. Decolonizzò anche l'Africa nera, ma vi mantenne l'influenza francese. De Gaulle era per l'«indipendenza nazionale» in rottura con il federalismo europeo e la divisione di Jalta: egli immaginava dunque una «Europa delle Nazioni» basata sulla riconciliazione franco-tedesca che sarebbe andata «dall'Atlantico agli Urali»; realizzò la forza di dissuasione nucleare francese, ritirò la Francia dal comando militare della NATO, pose un veto all'ingresso del Regno Unito nella Comunità Europea, sostenne il «Québec libero», condannò la guerra del Vietnam e riconobbe la Cina comunista.
La sua visione del potere, cioè di un capo approvato direttamente dalla Nazione, lo oppose ai partiti comunisti, socialisti, centristi pro-europei e di estrema destra. Essi criticavano uno stile di governo troppo personale, quasi un «colpo di Stato permanente», secondo la formula di François Mitterrand[4], contro il quale de Gaulle venne rieletto nel 1965 al suffragio universale diretto. Superò la crisi del maggio 1968 dopo aver dato l'impressione di volersi ritirare, sciogliendo l'Assemblée nationale e convocando delle elezioni anticipate; i partiti gollisti e di sostegno a de Gaulle ottennero una maggioranza schiacciante: 394 seggi su 487. Ma nel 1969 egli sottomise il suo mandato al risultato del referendum sulla riforma del Senato e la regionalizzazione e si dimise dopo la vittoria del «no». Si ritirò nella sua proprietà à Colombey-les-Deux-Églises, dove morì 18 mesi più tardi.
Charles de Gaulle, considerato come uno dei politici francesi più influenti del suo secolo, fu anche uno scrittore di talento. In particolare lasciò le sue Mémoires de guerre[5], nelle quali affermò essersi sempre «fatto una certa idea della Francia», giudicando che «la Francia non può essere la Francia senza la grandezza».
Nato a Lilla in una famiglia cattolica e fortemente nazionalista, di origine aristocratica (fondata da Thébault de Gaulle nel XVI secolo), de Gaulle era figlio di un professore di storia e letteratura, Henri de Gaulle (1848-1932), che gli fece scoprire il nazionalismo, e di Jeanne Maillot (1860-1940). Charles de Gaulle era il terzo figlio ed aveva tre fratelli e una sorella:
Terminati gli studi secondari presso un collegio dei gesuiti stabilitosi al Castello di Antoing, nel 1909 entrò alla scuola militare di Saint-Cyr; nell'ottobre 1912 fu promosso sottotenente e assegnato al 33º reggimento di fanteria, allora comandato dal colonnello Philippe Pétain.
Combatté nella prima guerra mondiale con il grado di tenente nella 11ª compagnia del 33º reggimento di fanteria di Arras. Il 15 agosto 1914 fu ferito durante la battaglia di Dinant, il 15 ottobre 1914 ottenne il comando della 8ª compagnia e ad inizio dicembre assunse il comando del 33º reggimento.
Il 18 gennaio 1915 ricevette la Croix de guerre e il 10 febbraio fu promosso capitano (a titolo temporaneo). Il 6 marzo fu ferito superficialmente a un orecchio e il 10 marzo a una mano a Mesnil-les-Hurlus, venne quindi ospedalizzato. All'inizio di agosto prese il comando della 10ª compagnia e il 3 settembre il grado di capitano diventò definitivo.
Il 26 febbraio 1916 il 33º reggimento di fanteria era a Verdun e partecipò alla battaglia. La 10ª compagnia fu circondata dal nemico nei pressi del fort Douaumont, il 2 marzo fu ferito a una coscia e dato per disperso. Fatto prigioniero fu curato all'ospedale di Magonza. Restò prigioniero fino al termine del conflitto.
Durante i due anni di prigionia conobbe un giovane sottotenente russo, il futuro generale sovietico Michail Tuchačevskij e tentò per ben 5 volte di evadere; rientrò in Francia nel dicembre 1918.
Nel 1919 e 1920 partecipò alla campagna di Polonia con il generale Weygand e prese parte alle operazioni militari condotte dal generale polacco Edward Rydz-Śmigły. Questa esperienza gli valse una citazione da parte del Ministero della Guerra francese e la Virtuti militari polacca.
Nel 1921 ottenne l'incarico di professore di storia militare alla scuola militare di Saint-Cyr.
Tra le due guerre la sua carriera militare conobbe alti e bassi, ma si rivelò comunque piuttosto rapida. Divenne famoso (e controverso) per due proposte: la formazione di un esercito professionale, al posto della leva, e la sua passione per il carro armato, arma di cui divenne uno dei maggiori teorici francesi[6].
Il 7 aprile 1921 sposò Yvonne Charlotte Anne Marie Vendroux, da cui ebbe tre figli:
Al momento dello scoppio della seconda guerra mondiale nel 1939, alla vigilia dell'entrata in guerra della Francia, sottolineò l'insufficienza della difesa, ma non venne preso in considerazione. Promosso generale di brigata a titolo provvisorio, il 6 giugno 1940 entrò nel governo di Paul Reynaud come sottosegretario di Stato alla Difesa nazionale. De Gaulle si oppose all'armistizio con i tedeschi e lasciò la Francia per la Gran Bretagna il 15 giugno 1940.
In Inghilterra, Churchill sostenne de Gaulle come voce della Francia anti-nazista, contro il parere del suo governo che avrebbe preferito personaggi più di spicco. Alla fine passò la scelta di de Gaulle, e la BBC trasmise l'appello del 18 giugno ai francesi, da Londra, esortandoli a resistere ai tedeschi e alla richiesta di armistizio avanzata dal governo Pétain: fu il segnale d'inizio della resistenza francese ai nazisti.
Mentre in Francia il Regime di Vichy lo condannava a morte in contumacia per tradimento, in luglio de Gaulle, al sicuro in Gran Bretagna, cominciò a organizzare France libre (Francia libera). All'inizio si trattava di suscitare la resistenza ai tedeschi a partire dai possedimenti coloniali, che la madrepatria aveva più difficoltà a controllare; queste forze vennero poi collegate alle forze di resistenza francesi, e France libre divenne France combattante.
In quegli anni de Gaulle fu imposto come rappresentante della Francia libera di fronte al mondo in generale e all'Inghilterra in particolare, anche grazie alla preziosa collaborazione del Capitano Teyssot, suo "assistente" dal 1942 al 1944. La sua preoccupazione era quella di salvaguardare fin dall'inizio gli interessi e l'immagine della Francia sconfitta durante e dopo il conflitto, a partire dalla garanzia del mantenimento dei possedimenti coloniali, senza perdere di vista un momento l'onore e la grandeur francesi. Per garantire l'indipendenza della propria organizzazione, de Gaulle volle che gli stessi aiuti finanziari che il Regno Unito forniva a France Libre fossero rimborsabili - e furono effettivamente rimborsati molto prima della fine della guerra.
I rapporti di de Gaulle con Churchill erano spesso conflittuali e competitivi, ma sempre sostenuti da un forte rispetto reciproco. Altra era la situazione con Roosevelt: i due, provenienti da due diverse tradizioni politiche, si detestavano, e una battuta di de Gaulle con Churchill spiega in parte l'atteggiamento francese di fronte all'arroganza dell'americano: "Sono troppo povero per inchinarmi".
Malgrado la scarsa collaborazione degli americani, de Gaulle riuscì a sbarcare ad Algeri nel maggio 1943. Lì creò con il generale Henri Giraud il Comitato francese di Liberazione nazionale (CFLN), per unificare la direzione dell'Impero liberato, e ne venne posto presto al comando. Nel giugno 1944 il CFLN prese il nome di "Governo provvisorio della Repubblica francese" (GPRF) e arrivò a Parigi liberata il 25 agosto 1944.
Il 21 aprile 1944, con un'ordinanza del Comitato francese di Liberazione nazionale, de Gaulle accordò il diritto di voto alle donne; questo diritto fu confermato in seguito da un'altra ordinanza del 5 ottobre del Governo provvisorio della Repubblica francese; le donne votarono per la prima volta in occasione delle elezioni municipali il 23 aprile 1945.
Con la Liberazione de Gaulle avviò varie riforme, dalle nazionalizzazioni all'istituzione di un sistema di sicurezza sociale moderno. Dal 3 giugno 1944 al 2 novembre 1945 fu capo del governo provvisorio, e dal 2 novembre 1945 al 20 gennaio 1946 presidente del consiglio. Ma la politica riprese il suo spazio e i suoi tempi, e l'uomo era impaziente e non approvava la costituzione della Quarta repubblica.
Così nel gennaio 1946 de Gaulle si dimise e rifiutò la proposta del capo del governo di elevarlo nell'aprile di quell'anno al rango di maresciallo di Francia.
Nel 1947 fondò il suo movimento politico, il Rassemblement du Peuple Français (RPF), con l'obiettivo di trasformare la politica francese. Esso raccolse grandi consensi elettorali tra il 1947 e il 1948 (35% dei voti alle municipali, 42% tra i senatori eletti), tuttavia rigettando in blocco il sistema della Quarta Repubblica. 
Nel 1951 l'RPF ottenne il 22,3 % dei suffragi e 117 deputati, ma già l'anno successivo ne perse prima 27, e poi 55, che aderirono ad altri partiti.
Progressivamente perse quindi importanza, e alle elezioni municipali del 1953 l'RPF perse metà dei propri voti.
Scontento dei risultati, de Gaulle si ritirò dalla vita politica nel 1953 rimanendo appartato a Colombey-les-deux-Eglises, mentre di fatto il partito venne messo "in sonno" nel 1955. Gli restarono accanto i sostenitori più fedeli come Jacques Chaban-Delmas, Michel Debré, Jacques Foccart[16], Roger Frey, Olivier Guichard e André Malraux, i cosiddetti "baroni del gollismo" che avranno un ruolo eminente negli anni successivi.
Rientrò in scena allorché la crisi delle dominazioni coloniali successiva alla fine della guerra bussò anche alle porte della Francia. I fallimenti in Indocina e in Algeria travolsero la Quarta Repubblica, in particolare la vicenda algerina, gestita in modo maldestro dai governi di coalizione e causa principale della crisi costituzionale del maggio 1958. 
Infatti il governo di Pierre Pflimlin, che si era installato il 14 maggio, si dimise il 28 maggio. Nel frattempo de Gaulle, con la dichiarazione del 15 maggio, si dichiarò pronto ad assumere i poteri della Repubblica e, nella conferenza stampa del 19 maggio, confermò la sua volontà di rendersi utile per il Paese ma in un quadro strettamente legale e nel rispetto delle libertà pubbliche. Il 29 maggio il presidente René Coty fece appello "al più illustre dei francesi". De Gaulle accettò e il 1º giugno 1958 formò il governo e il giorno dopo ottenne i pieni poteri dall'Assemblea nazionale francese e divenne Presidente del Consiglio, con poteri quasi equivalenti a quelli della prima Costituente.
Come aveva annunciato, utilizzò questo potere per far redigere una nuova Costituzione sulla base delle idee enunciate nel discorso di Bayeux. Questa Costituzione mirava a esautorare la dialettica parlamentare, che egli stesso definiva la "dittatura parlamentare" (cioè quell'assetto istituzionale per il quale il potere di veto delle minoranze parlamentari, in un'Assemblea estremamente frazionata e rissosa, finisce per paralizzare le possibilità di azione dell'esecutivo, condanna i governi all'instabilità e genera una politica caotica), prevedendo una notevole concentrazione di poteri nelle mani dell'esecutivo (Presidente della Repubblica e governo da lui nominato) a discapito del Parlamento. Il presidente della Repubblica, in base agli articoli 6 e 7 della Costituzione, è eletto da un collegio di grandi elettori.
La nuova Costituzione, approvata con il 79,25% di voti favorevoli nella Francia metropolitana al referendum del 28 settembre, segnò il passaggio della Francia alla Quinta Repubblica con i poteri dell'esecutivo fortemente rafforzati. Le elezioni dell'Assemblea nazionale del 23 e 30 novembre (rispettivamente, primo e secondo turno elettorale) accordarono una larga maggioranza ai partiti gollisti.
Il 21 dicembre de Gaulle fu eletto Presidente della Repubblica con oltre il 78% dei voti dei grandi elettori. L'8 gennaio 1959 all'Eliseo avvenne il passaggio delle consegne con René Coty, l'ultimo presidente della Quarta Repubblica.
Nel 1958 de Gaulle fu nominato Persona dell'anno dalla rivista statunitense Time, secondo e sinora ultimo francese a essere nominato dalla rivista.
Assunta la presidenza, de Gaulle perseguì quelli che considerava gli obiettivi strategici della Francia:
Nel 1962 de Gaulle propose un emendamento agli articoli 6 e 7 della Costituzione per consentire l'elezione diretta del Presidente della Repubblica, nonostante la forte opposizione di quasi tutte le forze politiche rappresentate all'Assemblea nazionale. Di fronte a ciò, la procedura di riforma costituzionale (che, regolata dall'articolo 89 della Costituzione, richiedeva - e tuttora richiede - almeno un'approvazione a maggioranza di entrambe le camere) si rivelò irta di ostacoli. Charles de Gaulle decise allora di ricorrere al potere presidenziale - previsto dall'articolo 11 della Costituzione - di indire un referendum popolare su proposta del governo concernente, tra l'altro, un progetto di legge riguardante l'organizzazione dei pubblici poteri.
L'Assemblea nazionale, per reazione al "colpo di mano" del presidente, sfiduciò il governo di Georges Pompidou (5 ottobre) e de Gaulle decise d'indire nuove elezioni. Anche se la forzatura della norma costituzionale era abbastanza evidente (l'articolo 11 si riferisce a leggi ordinarie, mentre le riforme della costituzione richiedono la procedura "rinforzata" di cui all'articolo 89), il 28 ottobre l'emendamento venne approvato dal corpo elettorale, con il 62,25% dei voti. Le successive elezioni politiche del 18 e 25 novembre videro una notevole affermazione gollista.
Adito dal Presidente del Senato il Conseil Constitutionnel (6 novembre 1962) contro tale "forzatura" costituzionale, questo rispose di non essere competente a giudicare questa questione perché il suo compito di giudicare in conformità della Costituzione le leggi organiche e le leggi ordinarie si "ferma" davanti alle leggi adottate dal popolo mediante Referendum. Ciò risultava dallo spirito della Costituzione che aveva fatto del Conseil Constitutionnel un organo regolatore dei pubblici poteri che visiona unicamente le leggi votate dal Parlamento e non anche quelle adottate dal popolo con Referendum, le quali costituiscono l'espressione diretta della sovranità nazionale.[20]
Nel 1963 fu uno dei candidati per il Premio Nobel per la letteratura[21].
Nel 1965 si concluse il primo mandato presidenziale di de Gaulle e si svolsero le prime elezioni presidenziali a suffragio universale diretto. Al primo turno de Gaulle si fermò al 44,65% dei voti e fu costretto al turno di ballottaggio da François Mitterrand, secondo con il 31,72% dei voti, anche a causa della candidatura del centrista Jean Lecanuet, terzo con il 15,57% dei voti. Al secondo turno de Gaulle ottenne un nuovo mandato settennale, con il 55,20% dei voti.
De Gaulle continuò a promuovere energicamente l'indipendenza e un forte ruolo della Francia in politica estera:
La fase di forte inquietudine sociale culminata nel Maggio francese parve riportare de Gaulle ai tempi dell'appello del 18 giugno o della guerra d'Algeria; inizialmente scelse di allontanarsi da Parigi per incontrare a Baden Baden il generale Jacques Massu, comandante delle forze francesi in Germania. In sua assenza, il primo ministro Georges Pompidou riuscì a padroneggiare la situazione e al rientro di de Gaulle, un milione di sostenitori del gollismo sfilò per Parigi. Il Presidente sciolse l'Assemblea nazionale[24] e stravinse le elezioni del giugno 1968, con il partito gollista che ottenne 294 seggi su 487 e una maggioranza presidenziale di 394 deputati.
Ma l'anno dopo il Presidente perse, e con uno scarto minimo, il referendum sulla riforma del Senato e la regionalizzazione, che prevedeva la "costituzionalizzazione delle Regioni come collettività territoriali"[25] e la "riforma del Senato"[26]. Ma dissentirono da lui perfino alcuni autorevoli ex membri del governo come Valéry Giscard d'Estaing, e nell'indire il referendum, de Gaulle preannunciò che, in caso di esito negativo, ne avrebbe tratto tutte le conseguenze del caso.[27]
Preso atto dei risultati del referendum, il 28 aprile 1969 annunciò le proprie dimissioni con effetto immediato da mezzogiorno.
Per evitare di essere implicato nella campagna elettorale per la sua successione, partì per un soggiorno di un mese (dal 10 maggio al 19 giugno, da dove votò per procura per il nuovo Presidente) in Irlanda, a Sneem (dal 10 al 23 maggio), a Cashel (dal 24 al 3 giugno), a Killarney (dal 4 al 17) e infine a Dublino (17-19 giugno), dove fu ricevuto il 17 giugno dal Presidente della Repubblica d'Irlanda Éamon de Valera all'Áras an Uachtaráin.
L'anno successivo, dal 3 al 27 giugno 1970, effettuò un viaggio privato in Spagna, e fu ricevuto dal generale Franco, l'8 giugno a Madrid. De Gaulle in seguito passò la maggior parte del tempo nella sua residenza de La Boisserie a Colombey-les-Deux-Églises, dove lavorò al seguito delle sue Mémoires de guerre, il 18 settembre fu pubblicato il 5° (e ultimo) volume di Discours et messages e il 12 ottobre il 1° volume di Mémoires d'espoir: la morte gli impedirà di completare il 2° volume (solo i primi due capitoli erano pronti per la stampa) e di redigerne il 3°.
Il 9 novembre 1970, com'era sua abitudine, il Generale cominciò un solitario nella biblioteca della sua abitazione a Colombey; verso le 19:00 ebbe un malore causato dalla rottura di un aneurisma e morì alle 19:30. Nell'annunciare la sua morte in televisione, il nuovo presidente della Repubblica Georges Pompidou pronunciò la frase: «Françaises, Français, le général de Gaulle est mort. La France est veuve» ("Francesi, Francesi, il generale de Gaulle è morto. La Francia è vedova")[28][29].
I funerali furono celebrati il 12 novembre 1970 in forma privata a Colombey-les-Deux-Églises, il feretro fu trasportato su un engin blindé de reconnaissance dalla Boisserie verso la chiesa del villaggio, in presenza di una grande folla, di una delegazione dell'Armée française e dei compagni dell'Ordine della Liberazione. Una messa in memoria, in presenza di numerosi capi di Stato stranieri (tra cui Gustav Heinemann, Richard Nixon, Baldovino del Belgio, Carlo, principe di Galles, Giuseppe Saragat e Nikolaj Viktorovič Podgornyj)[30], si tenne nella cattedrale di Notre-Dame.
De Gaulle è sepolto nel cimitero di Colombey-les-Deux-Églises, accanto alla figlia Anne e insieme alla moglie Yvonne (morta 9 anni dopo); a qualche metro riposano il genero Alain de Boissieu (1914-2006), la figlia Elisabeth (1924-2013) e la nuora Henriette (1929-2014)[31].
Alcune settimane dopo la morte di de Gaulle, il 23 dicembre 1970, fu adottata la legge nº 70-1206 sull'«esonero dei diritti di mutazione sulla successione del generale de Gaulle» per «servizi eccezionali resi alla Nazione». La legge fu presentata al Parlamento dal segretario di Stato all'Economia e alle Finanze, Jacques Chirac.
Nel 1972, è stato inaugurato sulle colline di Colombey-les-Deux-Églises, il mémorial Général de Gaulle, segnalato da una grande croce di Lorena in granito. Il nuovo mémorial Général de Gaulle fu inaugurato l'11 ottobre 2008 dal Presidente francese Nicolas Sarkozy e dalla Cancelliera tedesca Angela Merkel.
Inaugurato nel febbraio 2008 nel sottosuolo dell'Hôtel des Invalides, l'historial Charles de Gaulle è una della componenti del Musée de l'Armée.
Il nome di Charles de Gaulle è stato dato a numerose arterie, ponti o immobili importanti dei comuni francesi: nel 2007, la Fondation Charles-de-Gaulle contava 3 634 comuni che avevano una o più vie «de Gaulle»[32], le municipalità di destra o di centro sceglievano generalmente la forma militare «Général-de-Gaulle», mentre quelle di sinistra più generalmente la forma civile «Charles-de-Gaulle». Si possono citare in particolare la place Charles-de-Gaulle (ex place de l'Étoile) e il pont Charles-de-Gaulle a Parigi o l'Aéroport Charles-de-Gaulle (ex Aéroport de Roissy).
Il 4 aprile 2005, durante una trasmissione di France 2 diffusa in diretta dal Sénat, egli è stato designato dai telespettatori come «il più grande francese di tutti i tempi», superando anche Louis Pasteur, l'Abbé Pierre, Marie Curie, Coluche, Victor Hugo. Una parte dei centristi, ma anche della sinistra, come Régis Debray, ha dichiarato di trovare in lui una fonte d'ispirazione.
Secondo un sondaggio effettuato nel 2005, nel contesto del 10º anniversario della morte di François Mitterrand, quest'ultimo, all'epoca solo presidente di sinistra della V Repubblica, è considerato come il miglior presidente dal 35%, seguito da Charles de Gaulle (30%) e Jacques Chirac (12%), che si rivendica gollista.
Un altro sondaggio realizzato da BVA nel 2009 indica che l'87% dei francesi giudicano positivamente la presidenza di de Gaulle, classificandolo così in prima posizione tra i presidenti della V Repubblica. Un altro sondaggio di BVA nel 2013 va nella stessa direzione: con 89% di opinioni positive de Gaulle appare come il presidente preferito dei francesi, mentre Mitterrand non è che in quinta posizione con 55%, dietro Pompidou (83%), Chirac (58%) e Giscard d'Estaing (57%).
Nel novembre 2010, in occasione del 40º anniversario della sua scomparsa, un sondaggio di TNS Sofres qualifica de Gaulle come «personaggio il più importante della storia di Francia» per il 44%, davanti a Napoleone (14%), Carlo Magno (14%), Jean Jaurès (12%), Luis XIV (7%) e Léon Blum (4%). Un'inchiesta realizzata dall'Ifop nell'aprile 2011 indica che il 45% dei francesi considerano il generale de Gaulle come colui che ha maggiormente cambiato la Francia, superando tutti gli altri presidenti della V Repubblica [Mitterrand (29%), Sarkozy (11%), Chirac (8%), Giscard d'Estaing (3%) e Pompidou (3%)].
Delle statue sono state erette in sua memoria anche all'estero: a Québec, Londra, Varsavia o Mosca. La Repubblica Popolare Cinese gli è pubblicamente molto riconoscente perché de Gaulle l'aveva riconosciuta diplomaticamente nel 1964. Israele invece riteneva più duramente le sue dichiarazioni sensazionali del 1967 che il culto popolare che era voluto all'«uomo del 18 giugno», che si poteva confrontare fino a quel momento, come ricordato da Éric Roussel, a quello di «Padre della Nazione» di David Ben Gurion. Il mondo arabo si ricorda di lui per le sue critiche contro l'occupazione di Gaza e della Cisgiordania. Ben Bella rese omaggio a de Gaulle come al più valoroso degli avversari del FLN: «Capo militare, è lui che ha portato contro di noi i colpi più duri», ma che finì per accettare l'indipendenza algerina; in effetti, per Ben Bella: «De Gaulle guardava più lontano» e «De Gaulle non era un politicante. Aveva quella dimensione internazionale che manca troppo spesso ai dirigenti attuali». A coloro che gli rimproveravano di essere rimasto un "cliente della Francia gollista" (Françafrique) Léopold Sédar Senghor replicava che pochi capi di Stato occidentali potevano vantarsi di aver rischiato personalmente la propria vita per realizzare l'indipendenza delle colonie. Il Líder Máximo Fidel Castro aveva dichiarato davanti a delle telecamere di aver trovato in de Gaulle un modello dopo la lettura delle sue Mémoires de guerre. L'America Latina o il Vietnam apprezzano l'uomo che si opponeva alla dominazione statunitense, il Québec colui che rifiutava la predominanza anglofona.
La Costituzione francese del 1958 dura ormai da più di mezzo secolo, con alcune modifiche. «L'uomo di Londra» (o «L'uomo del 18 giugno») è entrato in un passato mitico nel quale, per i francesi, lui incarna, e lui solo, l'opposizione al Governo di Vichy.
Gli anni che l'economista Jean Fourastié ha chiamato i "Trenta Gloriosi" (1945-1975)[35] hanno lasciato ai francesi il ricordo di un'epoca, seppur non facile (due guerre coloniali), almeno di crescita e prosperità. «Noi non siamo i più ricchi, noi non siamo i più potenti, ma io vi garantisco che noi siamo fra i più felici», affermava Georges Pompidou durante i consueti auguri di fine anno ai francesi. Ora, la fine di questo periodo felice corrisponde approssimativamente a quello di de Gaulle: difficile quindi in queste condizioni separare oggettivamente quello che è dovuto all'uomo e al suo delfino designato (Georges Pompidou) da quello che è dovuto al contesto economico.
Dal punto di vista politico il partito da lui fondato nel 1968, l'Unione dei Democratici per la Repubblica (nel 1976 divenne Raggruppamento per la Repubblica) inaugurò di fatto un movimento politico definito "neogollismo", che con Pompidou, Chirac e Sarkozy governerà la Francia a più riprese.
Il primo presidente della quinta Repubblica francese appare oggi come uno degli ultimi grandi uomini capaci di fare la storia, lui che ha saputo spesso muovere gli eventi invece di lasciarsi muovere da essi; "protagonista della storia politica europea del Novecento, Charles de Gaulle è stato anche un pioniere nel ricorso ai mass media[36]. In maniera più aneddotica, molti tratti della sua personalità avevano generato una simpatia dei francesi verso la sua persona: innanzitutto il suo vocabolario non convenzionale per un uomo politico della sua epoca e della sua età («culbute», «chienlit»), le sue battute spiritose, o il suo senso della replica (durante una conferenza stampa, egli rispose a un giornalista la cui domanda era semplicemente «Come state?» con «Non sto male, ma rassicuratevi: un giorno non mancherò di morire»[37]); a Louis Vallon che avrebbe urlato «Morte agli stupidi!» durante una riunione, ai tempi del RPF, de Gaulle rispose: «Vasto programma!»[38]. Noti sono anche il suo disprezzo esibito per i partiti politici e, infine, la sua sfiducia verso una destra che non lo amava (e che glielo fece vedere nel 1969), così come verso una sinistra che non aveva mai veramente sostenuto il progetto di partecipazione dei salariati ai benefici della loro impresa, che gli era caro (conformemente alla sua politica direttamente ispirata dal cattolicesimo sociale[39]). De Gaulle era, in uno spirito molto «Asterix», uno di quei «piccoli che non si lasciano sopraffare dai grandi».[40] Non ci si sorprende quindi della sua dichiarazione secondo la quale il suo libro preferito sarebbe Cyrano de Bergerac. Egli fece un giorno questa constatazione ironica: «In fondo, voi sapete, il mio solo rivale internazionale è Tintin».
Il generale de Gaulle ha pianificato e modernizzato la ricerca e l'industria con l'impulso dello Stato. È durante il suo periodo che datano gli inizi dei grandi programmi che hanno fatto la forza dell'industria francese e che trovano il loro risultato oggi nelle grandi imprese francesi o europee:
Charles de Gaulle ha ricevuto almeno 80 tra onorificenze, distinzioni e decorazioni:[48][49]
Quale Presidente della Repubblica:
Solimano I, detto "il Magnifico" (tra gli occidentali) o Kanuni (tra i turchi), ovvero il Legislatore[1] (in turco moderno: I. Süleyman; in turco ottomano: سليمان, Sulaymān; Trebisonda, 6 novembre 1494 – Szigetvár, 6 settembre 1566), fu sultano e padiscià dell'Impero ottomano dal 1520 alla sua morte, e uno dei monarchi più importanti dell'Europa del XVI secolo. Portò l'Impero ottomano ai massimi fulgori. Sotto la sua amministrazione lo Stato ottomano governava almeno 20-25 milioni di persone[1].
Succedette al padre, il sultano Selim I, nel settembre 1520 e iniziò il suo regno intraprendendo campagne militari contro le potenze cristiane nell'Europa centrale e nel Mediterraneo. Belgrado cadde nel 1521; nel 1522-1523 toccò a Rodi, strappata al lungo dominio dei Cavalieri di San Giovanni. Nella battaglia di Mohács, combattuta nell'agosto del 1526, Solimano distrusse la forza militare dell'Ungheria e lo stesso re ungherese Luigi II perse la vita. In occasione del conflitto con i Safavidi, riuscì ad annettere anche gran parte del Vicino Oriente, Baghdad compresa, e vaste aree del Nord Africa, fino ad arrivare all'ovest dell'Algeria. Sotto il suo dominio, la flotta ottomana dominò i mari, dal Mediterraneo al Mar Rosso, attraversando il Golfo Persico.
Alla guida di un impero in espansione, Solimano promosse importanti modifiche legislative in materia di società, istruzione, fiscalità e diritto penale. Le sue riforme, realizzate in collaborazione con il principale funzionario giudiziario dell'impero, Ebussuud Efendi, armonizzarono il rapporto tra le due forme del diritto ottomano: quello statale (Kanun) e quello religioso (Shari'ah). Solimano fu anche un pregevole poeta e orafo, oltre che un grande mecenate della cultura. Sovrintese alla cosiddetta "età dell'oro" dell'Impero ottomano, favorendo il suo sviluppo artistico, letterario e architettonico.
Infrangendo la tradizione ottomana, Solimano sposò Hürrem Sultan, una donna del suo harem, una cristiana di origini rutene che si convertì all'Islam e che divenne famosa in Occidente con il nome di Roxelana, presumibilmente per via dei suoi capelli rossi.[2] Il loro figlio, Selim II, succedette al padre nel 1566, alla morte di questi, occorsa dopo quasi 46 anni di regno. Gli altri potenziali eredi (Şehzade Mehmed e Şehzade Mustafa) erano già morti, il primo di vaiolo e il secondo strangolato. Un altro figlio, Şehzade Bayezid, venne giustiziato, insieme con i suoi quattro figli, nel 1561, per ordine dello stesso sultano, dopo una ribellione da lui organizzata. Per lungo tempo si è ritenuto che alla morte di Solimano sia seguito un periodo di declino dell'impero. Questa visione è stata poi abbandonata, ma la fine del regno di Solimano è ancora frequentemente indicata come uno spartiacque nella storia ottomana. Nei decenni successivi alla sua morte, infatti, l'impero iniziò a subire significativi cambiamenti politici, istituzionali ed economici, un fenomeno spesso definito come la "trasformazione dell'Impero ottomano".
Poco o nulla si conosce dei primi anni di vita di Solimano; poiché in quell'epoca non vi erano concreti motivi che facessero supporre una sua futura ascesa a sultano, i cronisti non si preoccuparono di registrare particolari fatti della sua infanzia. Si suppone che possa essere nato il 6 novembre 1494 a Trebisonda, nell'attuale Turchia, nel periodo in cui il padre Selim governava tale provincia.[3] Sua madre era la concubina Hafsa Hatun, un tempo ritenuta una principessa dei Giray del Khanato di Crimea, ma l'informazione fu sfatata come leggenda ed è ora confermata come una schiava di origini. cristiane.[4][5] È probabile che la sua educazione dovette iniziare all'età di sette anni; studiò il Corano, l'aritmetica, la musica, la scrittura, il tiro con l'arco e, quasi certamente, imparò la lingua persiana e quella araba. Come usanza per i figli degli alti dignitari, intorno agli undici anni venne circonciso, lasciò la madre e andò ad abitare in una propria residenza.[6] All'età di quindici anni il sultano suo nonno, Bayezid II, gli affidò la funzione di sanjak-bey di Karahisar-i Sahib (l'attuale Afyonkarahisar) e due anni dopo quella di Caffa (l'attuale Feodosia), già colonia genovese e crocevia degli scambi commerciali tra Iran, India e Europa. Il 6 agosto 1509 Solimano partì per raggiungere la città e assumere la carica.[7][8]
Nel 1512, Selim costrinse il padre sultano ad abdicare e nel contempo sterminò i fratelli e gli altri possibili successori, una pratica consuetudinaria nella casa reale ottomana, ponendo così fine alla guerra civile e diventando il nuovo sultano legittimo.[9] In quel momento Solimano aveva 17 anni e, oltre a governare Caffa, svolgeva altre attività amministrative per conto del padre; partecipò a una campagna militare in Iran, governò Edirne e combatté i banditi a Magnesia dove poi si fermerà dal 1512 per assumerne le redini.[7][10][11] Proprio a Magnesia intraprese una stretta amicizia con Pargali Ibrahim Pascià, uno schiavo che successivamente sarebbe diventato uno dei suoi più stretti consiglieri. Nel frattempo l'Impero ottomano, sotto la guida di Selim, continuava la sua espansione, sconfiggendo il rivale sultanato egiziano dei Mamelucchi circassi della dinastia burjī. Questo portò i turchi ad annettere la Siria, l'Egitto, la Palestina e l'Arabia, assumendo il controllo delle tre città sante di La Mecca, Medina e Gerusalemme.[11][12]
Mentre il futuro sultano era occupato a fare pratica amministrativa nell'impero, il padre Selim, durante un viaggio da Costantinopoli a Edirne, morì. Immediatamente si preferì mantenere segreta tale notizia, in attesa dell'arrivo sul posto del figlio, onde prevenire possibili rivolte tra le file dell'esercito. Tuttavia, una volta che Solimano giunse al feretro del padre, i giannizzeri, le truppe di fanteria scelte dell'esercito, accolsero positivamente la successione e gettarono i berretti in segno di lutto senza che vi fossero tumulti,[11] anche grazie al donativo di 5 000 aspri a testa conferitogli dal neo sultano per garantirsi la loro fedeltà.[13] Tornato a Costantinopoli alla testa del corteo funebre, il 1º novembre Solimano poté ricevere nella sala del divan gli omaggi degli alti dignitari, degli ulema e del Gran Mufti, salendo ufficialmente al trono come decimo sultano ottomano. Tra i primi suoi atti ufficiali, vi fu l'ordine di costruire una moschea dedicata al padre e di compiere le consuete elargizioni di regalie ai membri dell'esercito. Inoltre, decise di abrogare alcune dure disposizioni emanate precedentemente da Selim e liberò seicento notabili egiziani al fine di tracciare una linea di demarcazione con lo spietato regime imposto dal padre negli ultimi anni di vita.[14]
La prima preoccupazione di ordine pubblico, invece, gli arrivò dalla Siria dove era in corso una rivolta fomentata da un alto dignitario che aveva conquistato Damasco, Beirut e Tripoli. Solimano rispose prontamente, inviando un contingente agli ordini di Ferhad Pascià che ebbe la meglio sui ribelli soffocando la sommossa.[10][15] Aveva, così, dato prova di risolutezza e capacità amministrativa, caratteristiche che lo resero agli occhi dei sudditi degno di regnare su un impero già all'epoca vastissimo, predominante su tutto il mondo musulmano, e che egli continuerà a espandere per tutta la vita.[16][17]
Imposta la sua autorità all'interno dei confini ottomani, Solimano poté occuparsi della politica estera. In quel periodo, l'Europa viveva un periodo di difficoltà causata dai continui conflitti e dalle violente divisioni interne tra cattolici e protestanti. A difendere i confini del Sacro Romano Impero a est vi era Ferdinando d'Asburgo, fratello dell'imperatore Carlo V.[18]
La pace del 1503, siglata al termine della guerra turco-veneziana, aveva previsto il pagamento di un tributo annuo a favore degli ottomani. L'assassinio dell'inviato venuto a riscuotere il denaro da parte degli ungheresi fu il casus belli per Solimano per attaccare i cristiani del Danubio con l'obiettivo di conquistare Belgrado, una città strategica da dove, successivamente, avrebbe potuto muovere verso Vienna e Budapest. Per tutto l'inverno del 1520 l'impero fu occupato a preparare la spedizione, la prima di Solimano.[19] Il 6 febbraio dell'anno seguente, l'esercito con in testa il sultano, lasciò Costantinopoli tra sontuosi festeggiamenti.[20]
Dopo aver viaggiato per alcuni mesi divise su tre colonne, le truppe si ricongiunsero sotto le porte di Belgrado, dando inizio il 25 giugno all'assedio della città; nella direzione delle operazioni il sultano era affiancato dai suoi più alti dignitari, tra cui il pascià Pargali Ibrahim, il gran visir Piri Mehmed e da Mehmet Beg Mihaloglu successivamente governatore de facto della Valacchia. Inizialmente la difesa della città si rivelò efficace, ma quando le divisioni di fede religiosa tra gli assediati, cattolici e ortodossi, si fecero sentire, queste spianarono la strada agli ottomani. Così, dopo un lungo bombardamento, il 29 agosto Solimano poté fare il suo ingresso in città dove recitò personalmente la preghiera del venerdì.[21][22][23]
Galvanizzato dal successo di Belgrado, Solimano riprese in mano il progetto elaborato dal padre Selim di assalire la fortezza cristiana di Rodi, impresa peraltro già tentata tentata senza successo nel 1480 da Maometto II. L'isola di Rodi, a quel tempo in mano ai Cavalieri di San Giovanni, rappresentava un vero pericolo per gli ottomani, in quanto base di corsari cristiani che da tempo attaccavano i pellegrini musulmani in viaggio verso la Mecca e depredavano la navi mercantili. Conscio che gli europei non sarebbero intervenuti poiché occupati in conflitti interni, il sultano era risoluto a mettere fine a tutto questo.[22][24]
Dopo aver fatto recapitare, il 1º giugno 1522, al gran Maestro dei cavalieri Philippe de Villiers de L'Isle-Adam una lettera in cui si chiedeva la resa dell'isola, Solimano ordinò al capo della spedizione Lala Kara Mustafa Pascià che la marina ottomana lasciasse il porto di Costantinopoli e dirigesse le sue circa trecento navi verso Rodi. Pochi giorni dopo, il 18 giugno, lo stesso sultano partì via terra con un seguito di centomila uomini da Üsküdar per portare guerra ai cavalieri. Arrivato il 2 luglio a Kütahya, si unì alle altre forze messe a disposizione dai beilerbei (governatori) di Rumelia e Anatolia. L'esercito ottomano giunse, dunque, a Marmaris il 28 luglio. Salutato dallo sparo di oltre cento bocche da fuoco, il sultano dette inizio all'assedio di Rodi.[25][26]
L'Isle-Adam benché potesse contare su un'esigua forza a difesa della città, composta da circa 7 000 soldati e 700 cavalieri, questa risultava ben motivata. Al Gran Maestro fu però chiaro che l'unica strategia possibile per fermare i 200 000 ottomani era quella di prendere tempo e sperare in un intervento rapido da parte delle altre forze cristiane europee. Preoccupato dal protrarsi dell'assedio, il 23 settembre Solimano ordinò un assalto alle mura di Rodi che tuttavia fallì per la strenua difesa dei Cavalieri e che costò gravissime perdite a entrambe le parti.[27] Anche un nuovo assalto tentato il 12 del mese seguente si concluse in un insuccesso dopo il ferimento dell'ağa (comandante) dei giannizzeri. Il 10 dicembre, dopo avere perso oltre 3 000 soldati in un solo attacco qualche giorno prima, Solimano propose ai cristiani di negoziare una resa. Dopo aver preso ulteriore tempo, L'Isle-Adam si rese definitivamente conto che non avrebbe mai ricevuto l'assistenza sperata dai cristiani di occidente e che non avrebbe potuto reggere l'assedio ancora per molto.[28] Così venne stipulato un accordo di resa che consentisse ai cavalieri di lasciare l'isola in sicurezza e agli abitanti rimasti di essere esentati per cinque anni dalle imposte e dal devscirme; nonostante ciò, i comandanti non riuscirono a fermare i giannizzeri che si dettero al saccheggio della città e alla profanazione dei luoghi sacri.[29][30]
Solimano ricevette personalmente il Gran Maestro prima che lasciasse la città, accogliendolo amichevolmente e consolandolo; sembra che il sultano abbia confidato al gran visir di essere «davvero addolorato di aver cacciato quel vecchio dal suo palazzo». Il 1º gennaio 1523 i Cavalieri sopravvissuti lasciarono l'isola per dirigersi in esilio a Messina (da dove poi, qualche anno più tardi, si sarebbero stabiliti a Malta); Solimano aveva, non senza difficoltà, trionfato ancora una volta, gettando il terrore nella popolazione cristiana d'Europa.[23][29][31]
Tornato a Costantinopoli, Solimano nominò il suo amico di vecchia data Pargali Ibrahim Pascià gran visir dell'impero ottomano e comandante di tutto l'esercito con l'eccezione dei giannizzeri, come era d'uso. Il rapporto di grande amicizia e fiducia tra il sultano e Ibrahim ha da sempre interessato molto gli storici e scandalizzato i contemporanei; nato cristiano nel 1494 probabilmente a Parga, antico possedimento veneziano in Epiro, Ibrahim venne fatto prigioniero e successivamente offerto a Solimano. Fin da subito si mise in luce per la sua intelligenza e per la capacità di apprendimento, così venne deciso di istruirlo a dovere. Quando Solimano divenne sultano, Ibrahim ebbe l'occasione di scalare velocemente la gerarchia dell'impero, arrivando in poco tempo al vertice grazie alla nomina a gran visir nel giugno del 1523. Sembra, tuttavia, che lo stesso Ibrahim, preoccupato per la sua incolumità, avesse chiesto all'amico sultano di non essere preso in considerazione per un incarico così prestigioso, e allo stesso tempo rischioso, ma che Solimano avesse rifiutato di esaudire la sua supplica, assicurandogli tuttavia la sua protezione incondizionata.[32][33]
Il 18 maggio 1524 la haseki (concubina favorita) e moglie di Solimano, Hürrem Sultan (1502–1558), diede alla luce il figlio Selim. Poco si conosce delle origini di Hürrem, conosciuta in occidente come Roxelana, probabilmente fu una schiava tartara ceduta per l'harem imperiale. In ogni caso divenne ben presto la favorita di Solimano, che per lei abbandonò la prima ''haseki'' Mahidevran che gli aveva dato il primogenito Şehzade Mustafa nel 1515, quando ancora era governatore di Magnesia. Prima di Selim, Hürrem aveva avuto dal sultano altri due figli, Şehzade Mehmed nato nel 1521 e Şehzade Abdullah nato nel 1522 e morto solo tre anni più tardi. Molto si è discusso della figura di Roxelana; in grado di passare in poco tempo da schiava dell'harem a concubina e infine a moglie legale, contravvenendo alle consuetudini ottomane, ebbe una grandissima influenza sul sultano, tanto che alcuni storici vedono in lei la tessitrice di trame che finirono per condizionare l'intera politica dell'impero e in particolare della successione al sultanato, vedendo in lei l'iniziatrice del cosiddetto "sultanato delle donne".[34][35]
Nonostante la fermezza con cui veniva governato l'impero, le ribellioni erano abbastanza frequenti. Probabilmente a causa del malcontento per la nomina di Ibrahim Pascià a gran visir, il suo concorrente Ahmed Pascià, appena nominato governatore dell'Egitto, mise in atto un'insurrezione, riuscendo in un primo momento a ottenere il sostegno dei dignitari mamelucchi, del maestro dei Cavalieri Ospitalieri di Gerusalemme, dello Scià Isma'il I di Persia e, perfino, del papa. Tuttavia quando i mamelucchi lo abbandonarono, venne presto assassinato e la rivolta sedata.[36] Conscio del fatto che l'Egitto rappresentava un terreno fertile per le insurrezioni, Solimano decise di mandare in missione Ibrahim, l'unica persona di cui si poteva fidare totalmente.[37] In un anno, il fedele gran visir, riuscì a sottomettere i ribelli, promulgò leggi, riorganizzò la gestione del potere; il suo successo fu talmente ampio che non vi furono più rivolte in zona per oltre tre secoli.[38]
Dopo le vittorie sul Danubio e Rodi, l'impero stava trascorrendo un periodo di pace, ma questa non era una situazione ben vista da tutti, in quanto la tradizione guerriera ottomana voleva che il sultano fosse impegnato costantemente a combattere per ampliare i confini imperiali e diffondere l'Islam in tutto il mondo. Quando i giannizzeri capirono che non vi erano piani per nuove campagne militari, approfittando dell'assenza del sultano che si era recato a Edirne per la caccia, dettero vita ad alcuni tumulti nella capitale, costringendo il sultano a fare immediato ritorno. Ripreso immediatamente il controllo, sia giustiziando di propria mano alcuni rivoltosi, sia distribuendo denaro ai soldati affinché si quietassero, a Solimano era chiaro che fosse necessario pianificare una spedizione militare al più presto.[39]
Così, agli inizi dell'inverno del 1525, il sultano ordinò di intraprendere i preparativi per una campagna militare pur senza averne deciso l'obiettivo. Fu solo nei primi mesi del 1526, su invito anche di Francesco I di Francia con cui l'impero aveva iniziato a tessere i primi contatti (che sfoceranno presto in un'alleanza in chiave anti asburgica),[40][41] che scelse di attaccare nuovamente i confini cristiani; la spedizione si sarebbe dunque mossa alla volta dell'Ungheria.[42] La preparazione diplomatica fu febbrile: ci si assicurò la neutralità della Repubblica di Venezia grazie alla concessione di alcuni privilegi, mentre era chiaro che l'imperatore Carlo V non sarebbe intervenuto perché occupato nella guerra della Lega di Cognac contro Francesco I. Inoltre, Solimano, considerava i confini orientali con la Persia dello Scià Tahmasp I sicuri e che un suo intervento là poteva essere rimandato.[43]
Così, il 21 aprile 1526 Solimano lasciò la capitale alla guida di un esercito forte di 100 000 uomini e trecento cannoni. Insieme a lui marciava il gran visir Ibrahim, alcuni visir, il dragomanno della porta e altri dignitari.[43] La spedizione giunse, non senza difficoltà, a Sofia dove si divise: il sultano si diresse verso Belgrado da dove avrebbe proseguito per Buda (l'attuale Budapest) mentre il gran visir ebbe come meta Petrovaradin che prese dopo un breve assedio che gli costò solamente 25 uomini.[44] Durante la marcia vennero sottomesse le cittadine di Ilok e Osijek e venne fatto costruire in soli cinque giorni un ponte sulla Drava di ben 332 metri di lunghezza, fatto immediatamente distruggere una volta che l'esercito lo aveva oltrepassato, per eliminare ogni possibilità di ritiro. L'esercito arrivò, dunque, nella pianura di Mohács dove lo attendeva il re Luigi II d'Ungheria e Boemia (Lajos II / Ludvik Jagellonsky) per impedirgli di proseguire verso Buda.[44]
La battaglia di Mohács ebbe luogo il 29 agosto e incominciò favorevolmente alle truppe cristiane, nonostante la loro inferiorità numerica dovuta anche al fatto che le richieste di aiuto di Luigi all'occidente erano andate deluse. Il grande valore della cavalleria ungherese si mise in luce, tanto che 32 cavalieri arrivarono fino a mettere a serio repentaglio la vita dello stesso Solimano, che venne salvato dalla sua corazza e dal sacrificio delle proprie guardie del corpo e dai giannizzeri che si chiusero in sua difesa.[45] Tuttavia, la netta superiorità dell'artiglieria ottomana fece la differenza e verso sera l'esercito cristiano era in rotta; nella ritirata re Luigi trovò la morte cadendo in un fiume, andando ad aggiungersi ai trentamila morti tra le file cristiane. Solimano aveva trionfato ancora una volta, la strada per un ingresso trionfale a Buda era aperta.[40][46][47][48]
Rientrato alla fine della campagna a Costantinopoli, il sultano poteva considerarsi padrone delle sorti dell'Ungheria. La morte del re Luigi fece collassare l'autorità centrale magiara e si scatenò una lotta per il potere. Alcuni nobili offrirono la corona d'Ungheria all'arciduca d'Austria Ferdinando I d'Asburgo, legato con parentela alla famiglia reale ungherese. Altri nobili, però, si volsero a Giovanni Zápolya, che era supportato da Solimano ma che non fu riconosciuto dalle potenze dell'Europa cristiana.[49]
L'Ungheria venne spartita in tre tronconi: la maggior parte dell'odierna Ungheria fu rivendicata da Solimano, fu creato lo Stato vassallo di Transilvania che venne affidato alla famiglia Zápolya, mentre Ferdinando I ottenne l'Ungheria Reale. Si fissò così, temporaneamente, il confine fra l'Impero ottomano e il Sacro Romano Impero.[50][51]
Sottomessa ora l'Ungheria, Solimano poteva puntare verso una delle sue più grandi ambizioni: Vienna. Così, il 10 maggio 1529, con le consuete cerimonie in pompa magna lasciò la capitale per fare ritorno a Mohács dove incontrò Zápolya che fu, nel corso di una solenne udienza, riconosciuto come re d'Ungheria e di conseguenza come un vassallo dell'Impero ottomano. Una miniatura conservata nel palazzo di Topkapi ricorda l'evento, mostrando il momento in cui il sultano consegna a Zápolya, vestito di un caffettano d'onore, la corona. Lasciato il luogo di quella che era stata una delle sue vittorie più importanti, Solimano raggiunse in soli tre giorni Buda, nuovamente occupata da truppe cristiane.[52] Dopo un breve assedio, la città venne presa e gli abitanti ridotti in schiavitù ma, a differenza della volta precedente, ai giannizzeri venne proibito il saccheggio. Pochi giorni dopo, Zápolya venne ufficialmente incoronato re; alla cerimonia non partecipò Solimano, probabilmente per non dare troppa importanza a colui che considerava solo un vassallo di scarso rilievo; inoltre, l'autunno si avvicinava e pertanto era necessario muovere verso Vienna il prima possibile.[53]
L'assedio di Vienna ebbe inizio il 27 settembre 1529 e vide il confronto tra l'esercito ottomano di Solimano, forte di 120 000 uomini, 28 000 cammelli e 300 pezzi di artiglieria, e i difensori cristiani che contavano circa 20 000 combattenti e 72 cannoni agli ordini di Filippo del Palatinato-Neuburg.[54]
Le operazioni si rivelarono più difficili del previsto per gli ottomani, nonostante l'incessante tiro dell'artiglieria fosse riuscito ad aprire una breccia nelle mura della città, gli attaccanti non approfittarono inspiegabilmente di ciò per tentare una sortita all'interno.[55][56] La frustrazione per il protrarsi dell'assedio oltre alle aspettative e la preoccupazione per l'inverno che si avvicinava, indussero Solimano a ordinare un assalto alla porta di Carinzia per il 14 ottobre. Il risultato però dell'azione fu inconcludente e al grande sultano non rimase altro che rinunciare all'impresa e fare ritorno a Costantinopoli, ma non prima di aver comunque festeggiato la campagna militare come fosse stata un successo e negando che l'obiettivo fosse quello di conquistare Vienna. Il viaggio di ritorno durò circa due mesi, durante i quali l'esercito ottomano perse moltissimi uomini a causa di malattie e del maltempo.[57][58][59]
Nonostante le sue schiaccianti vittorie in Ungheria, Solimano non aveva ancora del tutto affermato la sua autorità nella regione. Così, il 22 aprile del 1532, lasciò ancora una volta la capitale alla testa di oltre 100 000 uomini[60] tra le cui fila si contavano 12 000 giannizzeri, 30 000 soldati provenienti dall'Anatolia, 16 000 dalla Rumelia, 20 000 spahi a cui si aggiungeva un'artiglieria forte di 300 cannoni.[61]
Arrivato a Belgrado ricevette ulteriori rinforzi dai tartari di Sahib I Giray, Solimano era pronto per affrontare una volta per tutte l'imperatore Carlo V. Tuttavia, la sua ambizione non poté essere esaudita: i cristiani non si sentivano affatto preparati ad affrontare un nemico così determinato e numeroso e, pertanto, Ferdinando d'Asburgo preferì inviare al sultano due ambasciatori per offrirgli un tributo di 100 000 ducati in cambio della pace e del suo riconoscimento a re d'Ungheria. Nel frattempo Solimano ricevette un'ulteriore proposta diplomatica: il re di Francia gli proponeva di invadere l'Italia per scontrarsi là con Carlo. Solimano declinò entrambe le offerte, ma per quanto riguarda la seconda, promise che avrebbe aiutato i francesi nella conquista di Genova e Milano, uno dei primi atti sostanziali dell'alleanza franco-ottomana.[61]
Fallito il tentativo diplomatico di arginare l'avanzata ottomana, i cristiani dovettero mettersi sulla difensiva. L'esercito di Solimano, dopo numerosi successi,[62] trovò una battuta di arresto durante l'assedio di Güns, una cittadina a soli 100 chilometri da Vienna e difesa da solo 800 uomini comandati da Nikola Jurišić, che si protrasse per tutto il mese di agosto, facendo perdere agli ottomani tempo prezioso.[63][64] Dopo aver conquistato faticosamente la cittadina, Solimano preferì dirigersi verso l'ovest, in Stiria, invece che puntare direttamente su Vienna, probabilmente perché contava di far uscire Carlo V dalla città e quindi confrontarsi in campo aperto, ma l'imperatore asburgico preferì evitare il contatto e rimase dentro le mura.[65]
In Stiria, Solimano, conquistò diverse città ma dovette rinunciare alla presa di Graz e Maribor che non cedettero alla forza ottomana. Il tempo perso a Güns non gli permise di continuare a lungo con le operazioni e, il 18 novembre 1532, fece ritorno a Costantinopoli. Anche l'esito di questa campagna fu festeggiato solennemente: si racconta che nella capitale vi furono ben cinque giorni di cerimonie, tuttavia il sultano non poteva considerarsi pienamente soddisfatto.[66] A conclusione degli eventi, tra gli ottomani e i cristiani venne siglata una tregua, sfociata poi nel trattato di Costantinopoli del 1533; con questa Zápolya manteneva il regno d'Ungheria, Carlo V salvava i confini e poteva concentrare le sue forze per contrastare la lega di Smalcalda. Solimano, invece, poteva ora volgere il suo sguardo verso la Persia, conscio dell'opportunità di rompere la tregua con i cristiani quando voleva.[67]
Da secoli, nel mondo musulmano, vi erano contrasti tra gli ottomani e l'impero Safavide con quest'ultimo che governava la Persia e l'odierno Iraq, divisi dalla fede religiosa: sunniti i primi, sciiti i secondi.[68][69] I discepoli sciiti, o kizilbash, perseguitavano i sunniti nella Mesopotamia, convertivano le moschee e, nel 1508, si erano resi colpevoli della distruzione della tomba di Abū Ḥanīfa al-Nuʿmān, uno dei più importanti teologi sunniti della storia. Erano soliti, inoltre, impedire i collegamenti tra gli ottomani e i loro alleati Uzbeki. Tale situazione imponeva agli ottomani di intervenire al più presto. Appena al sultano arrivò il pretesto per reclamare il possesso di Baghdad decise di attaccare l'impero rivale e a Ibrahim, nell'autunno del 1533, arrivò l'ordine di mettersi a capo dell'esercito per dirigersi verso l'Azerbaigian persiano dove, il 16 luglio dell'anno seguente, conquistò Tabriz. Era incominciata quella che verrà conosciuta come "campagna dei due Iraq".[40][70][71]
Due mesi più tardi, dopo un viaggio che lo vide attraversare da trionfatore le varie città, Solimano raggiunse il suo gran visir e insieme a lui mosse verso la capitale della Persia, quella Baghdad che a lungo fu uno dei centri più importanti dell'Islam e sede del califfato ma che a quell'epoca già da tempo in decadenza. L'esercito che prese parte a tale spedizione era enorme: si racconta che fosse composto da circa 200 000 uomini, comportando non poche difficoltà logistiche e di approvvigionamento, difficoltà accentuate dall'incombere della cattiva stagione.[72][73]
All'avvicinarsi dell'esercito ottomano, lo scià rifiutò lo scontro diretto ed evacuò la città; il 4 dicembre 1543, Solimano poté così entrare senza combattere[74] e considerarsi quindi legittimo successore dei califfi e un campione del sunnismo.[75][76] Con l'annessione di Baghdad all'impero ottomano, la città conoscerà una nuova stagione di crescita e prosperità. Trascorso l'inverno a Baghdad, il 2 aprile del 1545 Solimano con il suo esercito intraprese un difficile viaggio che in tre mesi lo condusse nuovamente a Tabriz dove si insediò nel palazzo dello scià.[77] Come era accaduto nella passata campagna di Ungheria, quando Solimano aveva cercato lo scontro diretto con Carlo V, nello stesso modo confidava nel poter confrontarsi con lo scià; ma anche lui, come aveva fatto Carlo, si era sottratto da un impatto contro un esercito così forte, preferendo una strategia più attendista. Così le ben note difficoltà logistiche dell'esercito ottomano, che si trovava ben distante dalle proprie basi di rifornimento, lo costrinsero ad abbandonare l'idea di inseguire l'esercito dello scià, ben più mobile e a suo agio nella regione, e di conquistare le città sante di Qom e di Kashan.[78] Solimano dette allora l'ordine di rientrare a Costantinopoli, dove giunse nei primi giorni di gennaio 1536. La campagna aveva visto la perdita di oltre 30 000 uomini, soprattutto per fame e malattie, ma aveva consacrato il sultano agli occhi dei suoi contemporanei correligionari come un grandissimo conquistatore che aveva fatto trionfare il sunnismo sull'eresia scita; l'impero ora si estendeva dalle porte di Vienna a Baghdad.[58][79][80]
Pochi giorni dopo il termine della spedizione accadde un fatto su cui gli storici si interrogano ancora oggi. Il 15 marzo 1536 il gran visir Pargali Ibrahim Pascià venne trovato morto assassinato nella sua stanza da letto al palazzo di Topkapi. Fu certamente lo stesso Solimano a ordinare la sua esecuzione; i motivi che spinsero il sultano a tale scelta sono sconosciuti e sono state formulate solamente delle teorie: il sospetto che fosse artefice di una congiura o il risultato di una richiesta di Roxelana che vedeva in Ibrahim un rivale di potere, sono le ipotesi più accreditate. Sta di fatto che Solimano si dovette pentire di aver fatto uccidere il suo miglior amico, compagno di successi e ottimo stratega.[81][82][83][84][85]
Dopo le campagne danubiane e persiane, Solimano incominciò a guardare al Mediterraneo, all'epoca sotto controllo delle marine della Repubblica di Venezia e di Ragusa.[86] Nonostante alcuni successi come quelli colti a Rodi o in Egitto, la flotta ottomana non era temibile come lo erano le sue forze terrestri, tuttavia la disponibilità di porti in posizioni strategiche e di efficienti arsenali fornivano agli ottomani le potenzialità di imprimere l'autorità anche sul mare.[87] Il personaggio chiave della riorganizzazione della marina ottomana fu, come lo fu il coevo Andrea Doria per gli spagnoli, il corsaro Khayr al-Dīn, conosciuto in Europa come "il Barbarossa". Figlio di un vasaio greco di Mitilene,[88] grazie alle sue scorrerie nel Mediterraneo acquistò ben presto una grande fama che lo porta alla fine del 1533 a fare il suo ingresso trionfale a Costantinopoli dove viene nominato kapudanpaşa (equivalente di grande ammiraglio) della flotta ottomana e governatore (Bey) delle isole. Forte del prestigioso titolo, in pochi mesi organizza la flotta di Solimano, mentre questi era occupato in Persia, pronto a dare battaglia alle potenze navali cristiane.[89][90]
Come prima azione, Barbarossa conquistò Tunisi, in quel momento in mano alla dinastia hafside.[91] Tuttavia, nel luglio 1535 la città verrà a sua volta conquistata da Carlo V che, preoccupato dell'espansione ottomana nel Mediterraneo, aveva personalmente preso il comando in una controffensiva considerata dai contemporanei una crociata insieme a Doria.[92][93] Nonostante la grande vittoria dei cristiani, la flotta del Barbarossa subì solo marginali perdite e fu in grado, pochi mesi più tardi, di attaccare le Baleari e Valencia, saccheggiandole. Convinto delle possibilità di successo sul mare lo stesso sultano sovrintese i lavori di armamento di una nuova flotta che si protrassero per tutto il 1536 nei cantieri del corno d'oro.[94][95]
Il 17 maggio 1537 Solimano, accompagnato dai figli Selim e Mehmed, giunse a Valona, nell'attuale Albania, con il progetto di attaccare Brindisi, mentre l'alleato Francesco I di Francia muoveva alla conquista di Genova e Milano. Alla spedizione avrebbero partecipato, come comandanti della flotta, Lütfi Pasha e Barbarossa. Il piano però non ebbe attuazione, in quanto il re di Francia infranse gli accordi e attaccò nelle Fiandre e in Piccardia. Nel frattempo, un attacco da parte di alcune galee veneziane a una delegazione diplomatica ottomana in viaggio, dette a Solimano il pretesto per cambiare obiettivo e dirigersi verso Corfù, importante base della Serenissima.[96]
Le operazioni per l'assedio della città ebbero inizio ad agosto dello stesso anno e fu il primo atto di quella che viene definita come terza guerra turco-veneziana facente parte del più ampio scenario delle guerre turco-veneziane. Nonostante Solimano potesse contare sulla forza di 25 000 uomini e 320 navi, la resistenza dei veneziani si dimostrò alquanto tenace, in particolare l'artiglieria dei difensori fu determinante per far decidere al sultano di ritirarsi. La tradizione vuole che Solimano, dopo aver constatato la perdita di due galee, avesse dichiarato che «la vita di un solo musulmano non può essere pagata con la conquista di mille fortezze».[97][98]
Tornato a Costantinopoli, il sultano affidò a Barbarossa la missione di combattere contro i veneziani stanziati nelle isole del mar Egeo al fine di scacciarli. Durante le due campagne militari che seguirono, il kapudanpaşa conseguì un successo dopo l'altro, annoverando tra le varie conquiste, le isole di Siro, Patmo, Egina, Paro, Andro, Skiathos, Sciro, Serifo. Il 28 settembre 1538 Barbarossa sconfisse la Lega Santa promossa da papa Paolo III nella battaglia di Prevesa.[99] Alla fine delle operazioni, 25 isole veneziane caddero o vennero saccheggiate mentre migliaia di cristiani erano stati fatti prigionieri.[100] Il 20 ottobre 1540 venne siglata una pace in cui gli ambasciatori di Venezia si accordarono con Solimano per pagare 300 000 ducati come indennità di guerra e abbandonare definitivamente le isole conquistate dal Barbarossa, a cui si aggiunsero Nauplia e Malvasia.[101]
Nell'ottobre dell'anno successivo Carlo V tentò di arginare i successi ottomani guidando una spedizione verso Algeri che tuttavia si rivelò disastrosa per i cristiani.[102][103] Solimano si trovava così a essere signore assoluto del Mediterraneo, primato che gli ottomani mantennero per oltre trent'anni.[104]
Nel 1539 era morto di peste il gran visir Ayas Mehmed Pasha, succeduto alla più alta carica della Sublime Porta dopo l'assassinio di Ibrahim Pascià, e il sultano decise di nominare al suo posto Lütfi Pasha, suo cognato e generale dell'esercito ottomano che annoverava origini albanesi.[105]
Il sultano non aveva fatto in tempo a siglare la pace con Venezia che già doveva tornare a volgere la sua attenzione verso l'Ungheria da dove arrivavano notizie preoccupanti. A luglio 1540 Zápolya era morto quindici giorni dopo aver avuto un figlio da Isabella Jagiełło, figlia di re Sigismondo I di Polonia. Nonostante Solimano ritenesse che il bambino fosse il legittimo successore, venne alla luce un accordo segreto che Zápolya aveva stipulato nel 1538 in cui dichiarava che alla sua morte l'Ungheria sarebbe tornata a Ferdinando d'Asburgo in cambio del suo riconoscimento al trono fintantoché fosse stato in vita. Per Solimano questo accordo era inaccettabile poiché stipulato prima della nascita del figlio, mentre Ferdinando asseriva che il bambino non fosse il figlio di Isabella e quindi invase l'Ungheria.[106]
Così, Isabella e il figlio Giovanni abbandonarono Buda per chiedere aiuto a Solimano che dovette, pertanto, mettersi nuovamente in strada in direzione dell'Ungheria. Questa volta l'esercito ottomano incontrò una flebile resistenza sul suo cammino e, rafforzato dalle truppe messe in campo da Isabella, assediò Buda sconfiggendo le difese guidate da Wilhelm von Roggendorf scacciando gli imperiali che lasciarono sul campo 16 000 uomini.[107] Il 2 settembre 1541, il sultano accompagnato dal figlio Şehzade Bayezid e dal gran visir Hadım Suleiman Pasha (da pochi mesi subentrato a Lütfi Pasha) entrò con grandi onori in città e, come era sua consuetudine, si recò in una chiesa nel frattempo trasformata in moschea a pregare. Come prima cosa dette la sua parola a Isabella che il giovane figlio Giovanni avrebbe regnato sull'Ungheria non appena raggiunta l'età necessaria, quindi fece ritorno a Costantinopoli.[108][109]
Ma non passarono nemmeno due anni che dovette partire nuovamente per la sua ottava campagna in Ungheria. Infatti Ferdinando, forte di un momento di tranquillità sul fronte interno con i protestanti, aveva nuovamente mosso pretese verso il trono di Ungheria proponendo a Solimano di essere riconosciuto re in cambio di un tributo annuale di 100 000 ducati. Al sultano, che non intendeva assolutamente accettare l'offerta, non rimase altro che lasciare la capitale, il 23 aprile 1543, per dare guerra all'Asburgo.[110] Anche questa volta la campagna ebbe inizio nel modo migliore per gli ottomani che presero una dietro l'altra le fortezze della Slavonia e dell'Ungheria fedeli a Ferdinando.[110] Dopo essere entrato nuovamente a Buda, l'esercito ottomano si diresse subito a nord per assediare Esztergom che cadde dopo circa due settimane anche grazie all'aiuto dell'artiglieria francese offerta dal re Francesco I.[111]
Il nuovo successo colto contro i cristiani metteva fine alle ambizioni di Ferdinando sull'Ungheria che rimarrà nelle mani degli ottomani fino al 1686. A questo successo fecero seguito lunghe trattative che sfociarono in una pace stipulata il 13 giugno del 1547 tra gli ottomani e il Sacro Romano Impero. Solimano non poteva comunque ritenersi del tutto soddisfatto, poiché non era riuscito ancora a scontrarsi in campo aperto contro l'imperatore Carlo V e la morte di Francesco I, avvenuta il 31 marzo 1547, rendeva questo obiettivo improbabile nel futuro, essendogli mancato un fondamentale alleato sullo scacchiere europeo. Per lui era ora di guardare nuovamente alla Persia.[112]
Agli inizi del 1548 Solimano lasciò ancora una volta Costantinopoli per mettersi in marcia con il suo esercito per raggiungere la Persia. Nonostante il successo colto nella sua prima spedizione, la sua autorità era in pericolo: diversi vassalli si erano dimostrati infedeli e la propaganda dei safavidi a favore dello sciismo continuava a fare proseliti in Anatolia.[113]
La prima azione, una volta giunto sul teatro delle operazioni, fu assediare Van, da poco tornata nelle mani dello Scià Tahmasp I dopo averla persa nel 1534. Presa Van intorno alla fine di agosto, il sultano decise di riparare ad Aleppo per svernare. Nello stesso momento, l'esercito ottomano occupò altre fortezze del luogo mentre il figlio dello scià Suleiman Mirza, passato tra le file degli ottomani, devastò l'Iran occidentale fino a quando venne catturato e successivamente ucciso.[114] Trascorso l'inverno, l'esercito turco spostò verso Erzurum mentre il gran visir Rüstem Pascià continuò a sottomettere fortezze safavidi tra Kars e Artvin.[114]
La campagna fu un successo che ribadì l'autorità ottomana sulla Persia, ma Solimano non era riuscito nemmeno questa volta a chiudere i conti definitivamente con la dinastia Safavide, obbligandolo pochi anni più tardi a prendere nuovamente la via della Persia per una terza campagna.[115]
Solimano ebbe dalle sue due consorti, Mahidevran e Hürrem, sei figli maschi, quattro dei quali sopravvissero oltre il 1550: il più vecchio Şehzade Mustafa era figlio di Mahidevran, mentre i più giovani Selim, Bayezid e Cihangir li aveva avuti da Hürrem. Hürrem era consapevole che se Mustafa fosse diventato sultano, i suoi stessi figli sarebbero stati uccisi per strangolamento, una consuetudine nella dinastia ottomana. Infatti, almeno fino al regno di Ahmed I, all'impero mancava qualsiasi mezzo formale per regolare le successioni e pertanto spesso ci si affidava alla crudele pratica di mettere a morte i principi in competizione al fine di evitare disordini e ribellioni. Inoltre, il figlio di Mahidevran era riconosciuto unanimemente come il più talentuoso di tutti i fratelli e godeva dell'appoggio del potente Pargalı İbrahim Pasha, a quel tempo gran visir dell'impero, nonché dell'esercito e in particolare dei giannizzeri. L'ambasciatore austriaco Ogier Ghiselin de Busbecq notò che «Solimano ha tra i suoi figli un figlio chiamato Mustafa, meravigliosamente ben educato e prudente e di un'età da governare, dato che ha 24 o 25 anni; che Dio non permetta mai a un saraceno di tale forza di avvicinarsi a noi», inoltre continuò a parlare dei "notevoli doni naturali" di Mustafa. Si ritiene che Hürrem, almeno in parte, sia responsabile degli intrighi intercorsi per la nomina del successore al sultanato; sebbene fosse la moglie del sultano, ella non aveva alcun ruolo pubblico ufficiale ma ciò non le impedì di esercitare una forte influenza politica. Nel tentativo di evitare l'esecuzione dei suoi figli, Hürrem molto probabilmente utilizzò il suo ascendente sul marito per eliminare coloro che sostenevano l'ascesa di Mustafa.[116][117][118]
Così, nelle lotte per il potere apparentemente istigate da Hürrem, Solimano fece assassinare Ibrahim e lo sostituì con il genero, Rüstem Pasha. Nel 1552, quando incominciò la terza campagna contro la Persia e Rüstem venne nominato comandante in capo della spedizione, ebbero inizio gli intrighi contro Mustafa. Rüstem mandò uno degli uomini più fidati del sultano a riferire che i soldati ritenevano che fosse giunto il momento di mettere un principe più giovane sul trono, poiché il sultano non aveva condotto l'esercito personalmente; allo stesso tempo vennero diffuse voci secondo le quali Mustafa si era dimostrato favorevole all'idea. Irritato da ciò e ritenendo che Mustafa ordisse contro di lui per ottenere il trono, nell'estate seguente durante il ritorno dalla sua campagna in Persia, Solimano convocò il figlio nella sua tenda presso la valle di Ereğli affermando che avrebbe «potuto liberarsi dei crimini di cui è stato accusato e non avrebbe avuto nulla da temere se fosse venuto».[119]
Mustafa si trovò di fronte a una scelta: o comparire davanti a suo padre con il rischio di essere ucciso o, se si fosse rifiutato, di essere accusato di tradimento. Alla fine, Mustafa scelse di entrare nella tenda di suo padre, fiducioso che il sostegno dell'esercito lo avrebbe protetto. Busbecq, che afferma di aver ricevuto un resoconto da un testimone oculare, descrisse gli ultimi momenti di Mustafa. Mentre Mustafa entrava nella tenda di suo padre, gli eunuchi lo attaccarono mentre si difendeva coraggiosamente. Il padre, separato dalla lotta solo dai tendaggi di lino della tenda, scrutò attraverso la sua tenda e «rivolse sguardi feroci e minacciosi ai muti, e con gesti minacciosi rimproverò severamente la loro esitazione. Quindi, i muti nel loro allarme, raddoppiando i loro sforzi, scagliarono Mustafa a terra e, gettandogli la corda attorno al collo, lo strangolarono».[120][121] Il popolo ottomano accolse negativamente la notizia dell'assassinio di Mustafa, i giannizzeri accusarono Solimano di aver «spento il sole più luminoso»; poeti e scrittori celebrarono il giovane principe a cui dedicarono elegie e opere.[122][123][124]
Si dice che Cihangir sia morto di dolore pochi mesi dopo la notizia dell'omicidio del suo fratellastro.[125] Ai due fratelli sopravvissuti, Selim e Bayezid, fu dato il comando in diverse parti dell'impero. Nel giro di pochi anni, tuttavia, scoppiò tra di loro una guerra civile, ciascuno di essi supportato dalle forze leali. Con l'aiuto dell'esercito del padre, Selim sconfisse Bayezid a Konya nel 1559, portando quest'ultimo a cercare rifugio presso i safavidi insieme ai suoi quattro figli.[126] A seguito di scambi diplomatici, il sultano chiese allo Scià Tahmasp I che Bayezid fosse estradato o giustiziato. Nel 1561, in cambio di grandi quantità di oro, lo scià permise a un sicario turco di strangolare Bayezid insieme a tutti i suoi figli, aprendo di fatto la strada per la successione di Selim al trono che avverrà cinque anni più tardi.[127][128]
I tragici fatti legati alla successione si svolsero, come detto, sullo sfondo di quella che verrà conosciuta come la terza campagna di Persia, l'ultima combattuta da Solimano. Le operazioni erano incominciate nel 1552 quando il gran visir Rustem Pasha, al comando dell'esercito, si diresse verso l'Anatolia raggiungendo Carmania dove si fermò per passare la cattiva stagione. Fu in questa occasione che Rustem incominciò la sua trama contro il principe Mustafa, di cui si è già detto, facendo in mondo che l'estate seguente Solimano, per dimostrare di essere ancora lui a capo dell'Impero, si mettesse anch'egli alla testa di un esercito per raggiungere il gran visir e partecipare alla campagna.[119]
Compiuta l'esecuzione del figlio Mustafa, il sultano si diresse verso Aleppo per acquartierarsi. L'entrata nella città, attualmente parte della Siria, fu trionfale e fastosa. L'esploratore inglese Anthony Jenkinson raccontò con dovizia di particolari che il corteo fu aperto da 6 000 cavalieri leggeri Sipahi, vestiti di rosso scarlatto seguiti da 10 000 tributari, in abiti di velluto giallo, a loro volta seguiti da 4 capitani, ciascuno alla testa di 12 000 armati; poi 16 000 giannizzeri vestiti di viola, mille paggi d'onore e tre uomini su cavalli bianchi; quindi il sultano «nella sua sfolgorante maestà» seguito dai grandi dignitari e 4 000 cavalieri armati che chiudevano il corteo.[129]
In primavera, dopo aver spedito allo Scià Tahmasp I un ultimatum in cui gli chiedeva di rientrare nel sunnismo a cui seguì una scontata risposta negativa, Solimano dette inizio alle operazioni militari che comportarono devastazioni in tutta la regione di Erevan.[130] La violenta offensiva ottomana spinse lo scià a chiedere la fine delle ostilità; il sultano accettò l'offerta e da ciò scaturì la pace di Amasya,[131] stipulata il 29 maggio 1555, in cui si ridisegnavano i confini tra i due imperi con lo scià che riconosceva la conquiste ottomane ma in cui Solimano consentiva ai pellegrini sciiti di raggiungere in sicurezza i luoghi santi dell'Islam sotto il suo controllo.[132] Inoltre, lo scià prometteva che avrebbe fatto cessare le razzie e la propaganda sciita in Anatolia.[133] A seguito di questi accordi, per oltre vent'anni non vi furono più scontri sul fronte persiano.[80]
Contemporaneamente Solimano dovette occuparsi anche di far soffocare una nuova ribellione, una delle più gravi, all'interno del suo impero. Un suddito asserì di essere il principe Mustafa scampato all'omicidio e mise in piedi un nuovo governo illegittimo nell'Anatolia del nord reclutando molti ribelli. Gli insorti vennero fermati dal deciso intervento del principe Bayezid, ma fu chiaro che questi disordini erano un segnale delle cattive condizioni della popolazione contadina, schiacciata dall'inflazione e dalle gravose imposte a cui erano sottoposti.[134] Nell'impero si stava assistendo a una severa crisi monetaria causata dall'arrivo dall'Europa di denaro a basso costo, spesso contraffatto.[135]
Nel 1530 l'imperatore Carlo V aveva donato ai Cavalieri Ospitalieri, scacciati alcuni anni prima da Rodi per opera di Solimano, l'isola di Malta dove, stabilitisi, ebbero l'occasione di ricostituirsi.[136] Il divan ottomano, preoccupato per le incursioni dei cristiani contro la loro marina, decise di preparare una spedizione per attaccarli nella loro nuova base. La pianificazione della nuova campagna, che coinvolse tutti i cantieri navali del Corno d'Oro, fu lunga e durò fino agli inizi del 1565. Una volta pronta, la flotta che contava oltre duecento navi, tra cui 150 galee in assetto da combattimento, prese il mare ai comandi di Lala Kara Mustafa Pascià. I grandi preparativi però non poterono essere tenuti nascosti e avevano, quindi, messo in allarme i Cavalieri che ebbero il tempo per preparare le difese; la resistenza dell'sola, guidata dal Gran Maestro Jean de la Valette, poteva contare su 8 500 difensori di cui settecento cavalieri.[137]
Il Grande Assedio di Malta ebbe inizio il 18 maggio e ben presto l'isola fu occupata dagli ottomani che però non riuscirono a prendere le strategiche fortezze di Sant'Elmo e Sant'Angelo.[138] Nonostante un incessante bombardamento, gli ottomani non poterono avere la meglio e il 12 settembre si decise di far ripiegare la flotta verso la capitale. La sconfitta, la prima ai tempi di Solimano, costò ai turchi dai 20 000 ai 35 000 uomini, a seconda delle fonti.[139][140][141]
Nel 1566 Solimano aveva 72 anni, di cui 46 trascorsi al governo dell'impero; l'anziano sultano soffriva di gotta che lo costringeva a muoversi su una carrozzella. Massimiliano II d'Asburgo era succeduto al padre Ferdinando I sul trono del Sacro Romano Impero e aveva portato nuova linfa alle pretese asburgiche sui paesi danubiani, riaprendo la questione sulla Transilvania accantonata da alcuni anni a seguito delle vittorie ottomane.[142]
Il 1º maggio 1566 il sultano lasciò Costantinopoli a capo di una delle più grandi armate che avesse mai comandato, si parla di 300 000 soldati dotati di un'imponente artiglieria, per la sua tredicesima campagna militare. Erano oltre dieci anni che non prendeva personalmente parte a una spedizione e per questo era criticato, sia dai visir sia dalla gente comune, in quanto si riteneva che per il capo degli ottomani fosse un dovere combattere continuamente per espandere i confini dell'Islam ai danni degli infedeli. Secondo le informazioni, la campagna sarebbe stata semplice, senza che probabilmente vi fosse nemmeno la necessità di scontrarsi o quasi.[143]
Tuttavia, la malattia lo aveva profondamente debilitato, non riusciva più a salire a cavallo ed era costretto a seguire le truppe solo grazie a una vettura. Dopo una marcia rallentata da cause naturali, durata 49 giorni, Solimano fece il suo arrivo a Belgrado per poi proseguire per Zemun dove venne accolto da Giovanni Sigismondo con grande fasto.[144][145]
Dopo avergli conferito il potere sui territori posti tra Tibisco e la Transilvania, il sultano si diresse verso Szigetvár, che mise sotto assedio a partire dal 6 agosto. I combattimenti continueranno fino all'8 settembre, ma Solimano non poté vederne la fine: morì infatti nella sua tenda nella notte tra il 5 e il 6 settembre. Per evitare disordini nell'esercito, ancora impegnato nella campagna, il gran visir Sokollu decise di mantenere segreta la notizia della scomparsa del sovrano, almeno fino a quando il successore Selim non fosse giunto davanti al feretro del padre. In quel momento, l'unico principe rimasto si trovava a Kütahya dove era governatore e, appena messo al corrente partì per raggiungere Sokollu. Nell'attesa il gran visir impedì a tutti di entrare nella tenda ove si trovava il corpo di Solimano e dava alle truppe ordini come se provenissero dallo stesso sultano oramai defunto.[146] Il riserbo venne mantenuto anche quando l'esercito si mise in marcia per il ritorno a Costantinopoli a seguito della fine delle operazioni nella regione transdanubiana. Solo quando il corteo si trovò nei pressi di Belgrado giunse Selim e allora la notizia poté essere diffusa.[147][148]
Il corpo imbalsamato del sultano venne riportato a Costantinopoli per essere sepolto a fianco di Roxelana nel mausoleo sorto vicino alla moschea Süleymaniye, mentre il suo cuore, il fegato e alcuni altri organi vennero sepolti a Turbék, fuori Szigetvár, dove venne eretto un cenotafio che divenne un luogo sacro e meta di pellegrinaggi. Nel giro di un decennio vennero realizzate una moschea e un ospizio sufi vicino e diverse decine di soldati vennero messi a presidiare il luogo. Della cerimonia funebre del grande sultano nessuno storico ne tramandò un ricordo; dovette essere molto semplice, come era di consuetudine nell'Islam.[149]
Il diplomatico veneziano Bartolomeo Contarini ci ha lasciato una delle prime descrizioni dell'aspetto di Solimano, nell'epoca in cui divenne sultano: «ha solo venticinque anni [in realtà 26], alto e magro ma duro, con una faccia sottile e ossuta. I peli sul viso sono evidenti, ma solo a malapena. Il sultano appare amichevole e di buon umore. Si dice che Solimano abbia un nome appropriato, che si diverta a leggere, che sia ben informato e che abbia un buon senso».[150][151] Una prima immagine disegnata è invece opera di Albrecht Dürer del 1526 il quale, tuttavia, non incontrò mai il sultano ottomano ma si basò sulle descrizioni di mercanti veneziani che erano stati a Costantinopoli. La bontà della rappresentazione di Dürer è comunque confermata dalle similitudini con il disegno fatto da Hieronymus Hopfer; in entrambi i casi il grande sultano appare con un collo allungato, naso arcuato e orecchie piccole; tratti somatici che ricordano fortemente l'aspetto del bisnonno Maometto II come tramandato dal celebre ritratto di Gentile Bellini.[150] Una descrizione più tarda, risalente agli anni della maturità, lo descrive come un "uomo giovanile, esile e assai fragile, ma la sua mano è molto forte e lo si dice capace di tirare con l'arco meglio di tutti".[147]
Ogier Ghislain de Busbecq ci fornisce invece la descrizione di un Solimano ormai vecchio, risalente agli anni dell'entrata ad Amasya (1555): «Benché il volto fosse triste, la sua espressione continuava a ispirare un senso di grande maestà. La sua salute è buona se non fosse per il brutto colorito, indizio di qualche segreta malattia. Ma, al pari delle donne, sa affrontare bene le offese del tempo. Si mette il belletto, soprattutto nei giorni in cui congeda qualche ambasciatore».[133]
Il carattere del magnifico sultano è descritto dai più calmo e ponderato, ben distante da quello irascibile del padre Selim I,[150] mentre un diplomatico veneziano alla corte ottomana intorno al 1530 afferma che «il suo carattere è collerico e melanconico e che non è molto portato per il lavoro perché ha abbandonato l'impero al gran visir senza il parere del quale né lui né altri membri della corte prendono decisioni, mentre Ibrahim agisce senza mai consultare il Gran Signore né nessun altro».[147] Infatti, sebbene i suoi contemporanei europei lo considerassero un sovrano di indubbia grandezza, non mancarono di riconoscere una sua, forse eccessiva, dipendenza dalla moglie Roxelana e da Ibrāhīm Pascià, nonché di accusarlo della morte dei propri figli.[152]
In ogni caso, tutti i commentatori concordano sul descriverlo come un «pio musulmano, immune da ogni fanatismo, tollerante verso i cristiani» garantendo i diritti degli infedeli (Dhimmi) ma è anche implacabile contro quella che considerava l'eresia sciita.[16] Fermamente convinto di essere nel favore di Dio, prima di ogni importante battaglia recitava fervide preghiere e appena conquistata una città si recava in una moschea per ringraziare della vittoria. Quando non era impegnato ad amministrare prendeva parte a discussioni teologiche con i dotti della corte, studiava la filosofia e i libri sacri, tanto che sono giunti fino a noi otto esemplari del Corano copiati personalmente da Solimano.[147]
Da buon musulmano, dimostrò anche uno stile di vita improntato alla sobrietà sebbene non parificabile a quella dei primi sultani. I commentatori raccontano dettagliatamente che alla sua tavola i piatti erano rigorosamente in porcellana, solo una volta utilizzò vasellame prezioso ma i giuristi lo rimproverarono. In vecchiaia fu ancora più attento, tanto che si servì solo di stoviglie in terracotta. Anche le bevande alcoliche, che in gioventù aveva tollerato, divennero proibite in tarda età.[152][153] Tuttavia, la sua immagine pubblica fu sempre contornata da un alone di sfarzosità. Alla sua corte si rispettava un corposo cerimoniale da lui stesso elaborato e gli ambasciatori da lui ricevuti raccontarono la loro meraviglia davanti a tanta ricchezza. Ogni qualvolta che Solimano lasciava la capitale al comando dell'esercito per intraprendere una delle tante campagne che hanno segnato la sua vita, si tenevano sontuosi festeggiamenti. In tali occasioni, il sultano amava vestirsi con stoffe preziose e indossava bellissimi gioielli.[154]
In età avanzata Solimano, stanco a causa della malattia e delle continue campagne militari, perse un po' dell'indole guerriera che lo aveva contraddistinto in gioventù; il nobile Antonio Barbarigo ci fornisce un affresco del sultano nel 1558: «È questo Signore di età 66, e sono 32 anni che regna felicissimamente; di statura mediocre, più tosto che altrimenti, pallido, ha gli occhi neri e grossi, con il naso aquilino; è signor giusto, benigno e religiosissimo nella sua legge sebbene essendo giovane fu bellicoso ed amator di guerra si comprende però che ora, che è vecchio desidera la pace con ogni principe, né mai porterà guerra ad alcuno se non sforzato da quelli con chi guerreggia o da false persuasioni de' suoi ministri [...] Conosce esser signore di molti paesi e regni, e desidera godere in pace quelli che ha. Gli è sommamente grata l'istoria, e continuamente legge le istorie di Alessandro Magno e quelle de' persiani. È questo Signor travagliato molto dalla gotta e per tal causa, per consiglio de' medici per mutazioni d'aria va ogni anno a far l'invernata in Adrianopoli...».[155]
Solimano ebbe due concubine note:[156][157]
Inoltre, Solimano aveva altre tre concubine non identificate, madri dei suoi tre figli nati e morti nell'infanzia, prima della sua salita al trono:
Solimano ebbe otto figli maschi:[156][157]
Solimano ebbe anche due figlie femmine:[156][157]
Sebbene Solimano fosse conosciuto come "il Magnifico" in Occidente, per gli ottomani era Kanuni Suleiman o "Il Legislatore" (قانونی).[167][168] All'epoca la Shari'ah, o Legge Sacra, era la legge principale nell'impero e, essendo considerata divina dall'Islam, nemmeno il sultano aveva il potere di cambiarla.[169] Tuttavia un'area legislativa distinta, nota come Kanun (قانون, legislazione canonica), dipendeva esclusivamente dalla volontà di Solimano e copriva settori fondamentali come il diritto penale, il possesso fondiario e l'imposizione fiscale. Egli fece raccogliere tutti i vari giudizi emessi dai nove sultani ottomani che lo avevano preceduto e, dopo aver eliminato le duplicazioni e risolto le dichiarazioni contraddittorie, emise un unico codice legale, prestando comunque attenzione a non violare le leggi fondamentali dell'Islam. Fu in questo contesto che il sultano, sostenuto dal suo Gran Mufti Ebussuud Efendi, cercò di riformare la legislazione per adattarsi a un impero in rapido cambiamento. Quando le leggi Kanun raggiunsero la loro forma finale, il codice delle leggi divenne noto come kanun-i Osmani (قانون عثمانی), o "leggi ottomane". Il codice legale di Solimano durò oltre trecento anni.[170][171][172]
Egli prestò particolare attenzione alla difficile situazione dei Rayah, soggetti cristiani che lavoravano la terra dei Spahi. Il suo Kanune Raya, o "Codice dei Rayas", riformò la legge che regolava i prelievi e le tasse a cui i rayas erano obbligati, elevando il loro status al di sopra dei servi tanto che molti servi cristiani emigrarono nei territori turchi per beneficiare di tale riforma. Il sultano si occupò anche di fornire una protezione agli ebrei residenti nel suo impero per i secoli a venire: alla fine del 1553 o del 1554, su suggerimento del suo medico e dentista preferito, l'ebreo spagnolo Moses Hamon, il sultano emise un firmano (فرمان) che denunciava formalmente le diffamazioni contro di essi. Inoltre emanò nuove leggi penali e di polizia, prescrivendo una serie di sanzioni pecuniarie per reati specifici, nonché riducendo i casi che comportavano un'esecuzione capitale o delle mutilazioni. Nel settore fiscale, vennero applicate imposte, seppur giudicate lievi, su vari beni e prodotti, inclusi animali, miniere, profitti commerciali e dazi sull'importazione e sull'esportazione.[173]
Durante il suo regno, Solimano si è sempre occupato di delineare personalmente una strategia generale che l'impero avrebbe dovuto seguire ma l'esecuzione di tali direttive e per la cura dei dettagli si avvaleva dei visir (letteralmente "colui che decide"), ovvero alti dignitari che svolgevano la funzione di consiglieri e ministri.[175] Questi consiglieri componevano il diwan (o dīvān), l'organo supremo di amministrazione dell'impero con competenze praticamente illimitate. Solitamente vi sedevano tre visir che amministravano congiuntamente la politica interna e quella estera oltre all'ordine pubblico, mentre due defterdar sovrintendevano a un'articolata organizzazione di uffici a cui veniva demandata la gestione delle finanze. Un'altra importante carica era il nişancı, il calligrafo di corte, a cui era demandata l'autenticazione dei documenti apponendo la tughra del sultano e il controllo delle leggi promulgate; due kazasker amministravano l'intero sistema giudiziario. Se le circostanze lo richiedevano, potevano partecipare anche altri dignitari. Il diwan era presieduto dal gran visir, l'uomo di fiducia del sultano. Durante il suo lungo regno, si alternarono ben dieci persone per questa carica, nell'ordine: Piri Mehmed Pascià (1518-1523), Pargali İbrahim Pascià (1523-1536), Ayas Mehmed Pascià (1536-1539), Çelebi Lütfi Pascià (1539-1541), Hadım Suleiman Pasha (1541-1544), Rüstem Pascià (1544-1553) Kara Ahmed Pascià (1553-1555), Rustem Pascià (1555-1561), Semiz Ali Pascià (1561-1565), Sokollu Mehmed Pascià (1565-1579). Solimano, come del resto tutti i sultani dopo Maometto II, non presenziava direttamente nella stanza dove avvenivano le riunioni, tuttavia vi era comunque la possibilità per lui di assistere di nascosto. Presso il Diwan il Magnifico usava anche ricevere gli ambasciatori con cerimonie di grandissimi sfarzo.[176][177]
Per imporre i propri diritti, egli dovette combattere contro un'infinita serie di avversari. La forza del suo sultanato era basata sulla funzione cruciale del corpo di fanteria dei giannizzeri (dal turco yeni çeri, "Nuova truppa"). Questi venivano reclutati forzatamente fra i giovani cristiani, obbligati nei primi secoli del sultanato al celibato, affratellati dalla tradizionale aderenza a una stessa confraternita religiosa che era la Bektashiyya. I giannizzeri, considerati l'élite dell'esercito ottomano (nella prima metà del XVI secolo erano circa 12 000[178]), non potevano avere altra occupazione o fonte di reddito che non fossero quelle derivanti dal mestiere delle armi e la loro inattività in tempo di pace faceva aumentare i rischi di disordini. La necessità di tenerli occupati può aiutare a comprendere il perché della frequenza delle campagne militari ottomane e per questo il primo decennio del suo regno vi fu di conseguenza un periodo di intensa attività bellica.[179]
Solimano dette un forte impulso anche al potenziamento della flotta militare ottomana, prima non particolarmente sviluppata. La disponibilità di risorse praticamente illimitate, di porti sicuri in posizioni strategiche, di arsenali efficienti, permisero di raggiungere molto velocemente risultati impensabili, tanto che gli ottomani arrivarono ad avere ben presto il controllo del Mediterraneo. A Galata, sul Corno d'Oro vi era il maggior centro di produzione della flotta con i suoi oltre 120 ripari coperti in grado di ospitare ciascuno due galee disponibili nel 1550,[180] mentre dieci anni più tardi si contavano 15 000 lavoratori nel porto.[181] Lo sviluppo della flotta fu tanto rapido che per l'assedio di Rodi gli ottomani potevano contare su 100 vascelli, mentre per quella di Malta nel 1566 ne erano a disposizione il doppio.[182]
I primi decenni del suo sultanato coincisero con un periodo molto favorevole per l'economia dei suoi sudditi. Il modello economico adottato a quel tempo tra gli ottomani era molto diverso da quello occidentale, con quest'ultimo che andava ad avvicinarsi al capitalismo. Nell'impero ottomano era in vigore, e lo rimase fino alla fine del XIX secolo, una gestione dell'economia molto più rigida e improntata più al soddisfare le necessità dello Stato e della popolazione piuttosto che sul perseguimento dell'arricchimento personale. Per fare ciò, il governo centrale controllava con inflessibile autorità, grazie a numerosi funzionari, le attività produttive e distributive, fissandone i prezzi a protezione del consumatore.[183]
Qualsiasi lavoratore dell'impero era inquadrato in esnaf (simili alle corporazioni occidentali) tanto che nel XVI secolo se ne contavano fino a un migliaio nella sola Costantinopoli. Queste, raggruppate a loro volta in gruppi, erano guidate da un capo e da un comitato, tutti eletti dagli appartenenti e sovrintendevano al controllo dei prezzi, regolavano l'accesso alla professione e controllavano la ripartizione delle materie prime. Tali istituzioni si ispiravano alle consuetudini della futuwwa (fratellanza religiosa) risalenti al tempo degli abbassidi e sviluppatisi sotto i Selgiuchidi di Rum e tra i principati dell'Anatolia.[184][185]
I commerci erano molto sviluppati e le vie di approvvigionamento si estendevano per tutto l'impero e oltre. Alla capitale arrivavano carne, cereali, legna, miele, metalli dalla Bulgaria e dalla Romania; l'Anatolia forniva cereali, frutta e cavalli mentre dall'Egitto giungevano riso, zucchero, cotone e ingenti forniture di grano. Da altri Paesi arabi dell'est veniva importato caffè, spezie e cavalli, dalla Persia provenivano sete e tappeti, dall'estremo oriente le pietre preziose. L'Europa, e in particolare la Repubblica di Venezia, esportavano nell'Impero ottomano prodotti manifatturieri, tecnologici e beni di lusso.[186][187] L'impero, invece, esportava materie prime e spezie soprattutto in Europa.[188]
Per favorire i traffici, Solimano fece costruire strade e ponti, alcuni di essi ancora in funzione alla fine del XX secolo, favorì la ristrutturazione e ampliamento di caravanserragli già costruiti dai Selgiuchidi.[189] Le campagne militari intraprese ebbero uno scopo anche commerciale; in particolare le spedizioni in Persia che consentirono di aprire nuove vie commerciali verso l'Asia e di rafforzare gli scambi con gli alleati Uzbechi.[190]
L'istruzione fu un altro settore giudicato molto importante per il sultano. Le scuole collegate alle moschee e finanziate da fondazioni religiose offrirono lezioni in gran parte gratuite ai ragazzi musulmani prima che ciò avvenisse nei paesi cristiani dell'epoca. Nella capitale dell'impero, Solimano aumentò il numero di mektebs (مكتب, scuole elementari) portandolo a quattordici, insegnando ai ragazzi a leggere e scrivere, nonché i principi dell'Islam. I giovani che desideravano un'istruzione superiore potevano poi accedere a una delle otto madrase (مدرسه) il cui programma di studi includeva la grammatica, la metafisica, la filosofia, l'astronomia e l'astrologia. I corsi di perfezionamento consentivano di ottenere un'istruzione di livello universitario, i cui laureati divenivano imam (امام) o insegnanti. I centri educativi erano spesso uno dei tanti edifici che circondavano i cortili delle moschee, gli altri potevano essere biblioteche, bagni, cucine, abitazioni e ospedali a beneficio del popolo. La frequentazione di un corso di studi era un presupposto essenziale per poter ambire a un qualsiasi incarico di prestigio nell'impero. Da queste istituzioni culturali uscirono uomini di scienza di grandissimo valore che segnarono la vita scientifica dell'impero per tutto il secolo, come il matematico e astronomo Taqī al-Dīn Muḥammad ibn Maʿrūf che nel 1577 realizzò l'Osservatorio di Costantinopoli grazie al quale poté aggiornare le tavole di Uluğ Bek risalenti al secolo precedente, e lo studioso di geometria Alì Ib Veli che anticipò di molto gli europei sullo studio dei logaritmi.[191][192]
Se alla fine del XVI secolo l'ambiente culturale ottomano appariva variegato e stimolante, e nella sola capitale si contavano oltre 100 madrase, tale favorevole situazione andò a scemare negli anni seguenti quando gli ulema incominciarono a interferire vietando lo studio delle scienze preferendo l'insegnamento di una rigida visione religiosa al limite del fanatismo.[193]
Sotto il patrocinio di Solimano, l'Impero ottomano entrò nel massimo del suo sviluppo culturale. La sede imperiale sovrintese a centinaia di società artistiche (chiamate اهل حرف Ehl-i Hiref, "Comunità degli artigiani") che ebbero sede presso il Palazzo di Topkapı. Dopo un periodo di apprendistato, gli artisti e gli artigiani potevano avanzare di rango nel loro campo e venivano pagati con salari commisurati in rate annuali o trimestrali. I registri delle buste paga, sopravvissuti fino a oggi, testimoniano l'ampiezza del mecenatismo artistico di Solimano;[194] ad esempio, il primo dei documenti risalenti al 1526 elenca 40 società con oltre 600 membri. L'Ehl-i Hiref fece affluire gli artigiani più talentuosi dell'impero verso la corte del sultano, sia quelli provenienti dal mondo islamico sia quelli originari dei territori recentemente conquistati in Europa, andando a formare una miscela di culture arabe, turche ed europee.[195] Gli artigiani al servizio della corte includevano pittori, rilegatori di libri, pellicciai, gioiellieri e orafi. Mentre i precedenti sovrani erano stati influenzati dalla cultura persiana (Selim I, ad esempio, scrisse poesie in persiano), durante il periodo di Solimano si vide affermare l'identità artistica dell'impero ottomano.[196]
Il suo regno è considerato un'epoca d'ora per la letteratura turca;[197] egli stesso fu un poeta che scrisse in persiano e in turco sotto il takhallus (nome di penna o pseudonimo) Habibi (محبی, "l'Amante" o "l'innamorato").[198] Alcuni versi di Solimano divennero proverbi turchi, come il celebre «Tutti puntano sullo stesso significato, ma molte sono le versioni della storia». Un ambasciatore veneziano osservò che il sultano: «si diletta di componer in laude di Dio, facendosi umile e dicendo sempre egli esser niente; ma per lasciar memoria della sua grandezza, fa fare una cronica di tutto quello che ha operato».[199] Quando il suo giovane figlio Mehmed morì nel 1543, compose un commovente cronogramma per commemorare l'anno: «impareggiabile tra principi, il mio Sultano Mehmed». Oltre all'opera del sultano, molti grandi talenti animarono il mondo letterario durante il suo regno, tra cui Fuzûlî e Bâkî.[200] Lo storico letterario Elias John Wilkinson Gibb osservò che «in nessun momento, anche in Turchia, fu dato maggiore incoraggiamento alla poesia che durante il regno di questo Sultano».[201]
Solimano è famoso anche per aver finanziato la costruzione di numerosi monumenti e aver favorito lo sviluppo architettonico all'interno del suo impero. Grazie a una serie di progetti, il sultano cercò di trasformare Costantinopoli nel centro della civiltà islamica, facendo realizzare ponti, moschee, palazzi e diversi istituti di beneficenza e sociali. Il più grande di questi venne costruito da Mimar Sinan, il principale architetto del sultano, grazie al quale l'architettura ottomana raggiunse il suo apice.[202] Sinan divenne responsabile dell'edificazione di oltre trecento monumenti sparsi in tutto l'impero, inclusi i suoi due capolavori, la moschea Suleymaniye e la moschea Selimiye, quest'ultima costruita ad Adrianopoli (ora Edirne) durante il regno di suo figlio Selim II. Solimano fece restaurare anche la Cupola della Roccia a Gerusalemme e le mura cittadine (le attuali mura della Città Vecchia di Gerusalemme), rinnovò la Caaba alla Mecca e costruì un complesso a Damasco.[203][204]
Alla morte di Solimano, l'Impero ottomano rappresentava una delle maggiori potenze del mondo.[205] Le conquiste del Magnifico avevano potuto espanderne il confini fino a includere Baghdad, molti territori balcanici comprese le attuali Croazia e Ungheria e la maggior parte del Nord Africa. L'allargamento dell'impero fino in Europa aveva dato agli ottomani la possibilità di influire direttamente negli equilibri dell'occidente cristiano, tanto che l'ambasciatore austriaco Ogier Ghislain de Busbecq avvertì dell'imminente conquista dell'Europa: «Dalla parte [dei turchi] ci sono le risorse di un potente impero, la forza intatta, l'abitudine alla vittoria, la resistenza di fatica, unità, disciplina, frugalità e vigilanza [...] Possiamo dubitare di quale sarà il risultato? ... Quando i turchi si stabiliranno con la Persia, voleranno alla nostra gola sostenuti dalla potenza di tutto l'Oriente; quanto noi siamo impreparati non oso dirlo».[206]
La sua eredità, tuttavia, non ha riguardato solamente l'aspetto militare; un secolo dopo il viaggiatore francese Jean de Thévenot parlò di una «forte base agricola del paese, del benessere dei contadini, dell'abbondanza di alimenti di base e della preminenza dell'organizzazione nel governo di Solimano».[207] Trent'anni dopo la sua morte, il celebre drammaturgo inglese William Shakespeare lo cita come un prodigio militare in Il mercante di Venezia, dove il Principe del Marocco si vanta della sua abilità dicendo che sconfisse Solimano in tre battaglie.
Tuttavia, le valutazioni dell'operato del "magnifico" sultano, dei suoi successi in campo amministrativo culturale e militare, devono considerare anche il fondamentale apporto delle molte figure di talento che lo servirono, come i grandi visir Ibrahim Pasha e Rüstem Pasha, il Gran Mufti Ebussuud Efendi, che svolse un importante ruolo nella riforma legale, e il cancelliere e cronista Celâlzâde Mustafa Çelebi, fondamentale nello sviluppo della burocrazia e nell'affermazione del mito del Magnifico.[208]
Altri progettiSegnalazioni  ·  Criteri di ammissione  ·  Voci di qualità in altre lingue
Il libero arbitrio è un concetto filosofico e teologico secondo il quale ogni persona ha il potere di decidere gli scopi del proprio agire e pensare, tipicamente perseguiti tramite volontà, nel senso che la sua possibilità di scelta ha origine nella persona stessa e non in forze esterne.
Ciò si contrappone alle varie concezioni secondo cui questa possibilità sarebbe in qualche modo predeterminata da fattori sovrannaturali (destino), o naturali (determinismo), per via dei quali il volere degli individui sarebbe prestabilito prima della loro nascita: si parla allora a seconda dei casi di predestinazione, servo arbitrio o fatalismo.
Il concetto di libero arbitrio ha implicazioni in campo religioso, etico e scientifico, dove pone diversi problemi:
La questione ha ripercussioni anche nel diritto, dove il concetto di libero arbitrio e di responsabilità individuale sta alla base del codice di procedura civile e penale.
Il tentativo di conciliare il libero arbitrio dell'uomo con l'onniscienza e onnipotenza divine è stato uno dei maggiori problemi con cui è misurata la teologia cristiana.
Per risolverlo, Agostino d'Ippona distinse la libertà propriamente detta, ossia la capacità di dare realizzazione ai nostri propositi, dal libero arbitrio, inteso invece come la facoltà di scegliere, in linea teorica, tra opzioni contrapposte, ossia tra il bene e il male.[2] Mentre cioè il libero arbitrio entrerebbe in gioco solo nel momento della scelta, rivolgendosi ad esempio al bene, la libertà sarebbe incapace di realizzarla.
In polemica contro Pelagio, Agostino poteva così sostenere che la volontà umana è stata irrimediabilmente corrotta dal peccato originale, che ha inficiato per sempre la nostra capacità di realizzare le nostre scelte, e quindi la nostra stessa libertà. A causa della corruzione, dunque, nessun uomo sarebbe degno della salvezza, ma Dio può scegliere gratuitamente chi salvare, elargendo la Sua grazia con cui gli infonde la volontà effettiva di perseguire la scelta del bene, volontà che altrimenti sarebbe facile preda delle tentazioni malvagie.
Agostino si rifaceva in proposito alle parole di Paolo di Tarso: «C'è in me il desiderio del bene, ma non la capacità di attuarlo; io infatti non compio il bene che voglio, ma il male che non voglio. Ora, se faccio quello che non voglio, non sono più io a farlo, ma il peccato che abita in me».[3]
Nel De diversis quaestionibus ad Simplicianum Agostino approfondì la propria concezione filosofica, sostenendo che la grazia di Dio è necessaria non solo nel momento realizzativo, ma anche per illuminare l'uomo su cosa è il bene. Egli riportava così il problema di chi Dio scelga di salvare, e perché, all'originale teologia della giustificazione di Paolo di Tarso.
Del problema si occupò successivamente la scolastica cristiana. Secondo Tommaso d'Aquino, il libero arbitrio non è in contraddizione con la predestinazione alla salvezza, poiché la libertà umana e l'azione divina della Grazia tendono ad unico fine, ed hanno una medesima causa, cioè Dio. La volontà libera si distingue da quella non libera perché a differenza di quest'ultima si sottomette ai criteri della ragione, «essendo proprio della medesima potenza il volere e lo scegliere».[4] Tommaso, come Bonaventura da Bagnoregio, sostenne inoltre che l'uomo ha sinderesi, ovvero la naturale disposizione e tendenza al bene e alla conoscenza di tale bene. Per Bonaventura tuttavia la volontà ha il primato sull'intelletto.
All'interno della scuola francescana di cui Bonaventura era stato il capostipite, Duns Scoto si spinse più in là, slegando il libero arbitrio da motivazioni razionali, ammettendo la possibilità che esso si determini sia in una direzione che in quella opposta. Il francescano Guglielmo di Ockham, infine, esponente della corrente nominalista, radicalizzò la teologia di Scoto affermando che l'essere umano è del tutto libero, e solo questa libertà può fondare la moralità dell'uomo, la cui salvezza però non è frutto della predestinazione, né delle sue opere. È soltanto la volontà di Dio che determina, in modo del tutto inconoscibile, il destino del singolo essere umano. Egli cioè concepì il libero arbitrio come «arbitrio dell'indifferenza» (arbitrium indifferentiae), ossia come puro arbitrio, indipendente da ogni motivazione passionale o razionale.
Il suo allievo Giovanni Buridano avrebbe illustrato questa posizione estrema con il celebre paradosso dell'asino a lui attribuito.[5]
Con l'avvento della Riforma, Martin Lutero fece propria la teoria della predestinazione negando alla radice l'esistenza del libero arbitrio: non è la buona volontà che consente all'uomo di salvarsi, ma solo la fede, infusa dalla grazia divina. È solo Dio, quello absconditus della tradizione occamista, a spingerlo in direzione della dannazione o della salvezza.[6] 
«La volontà umana è posta tra i due [Dio e Satana ] come un giumento, il quale, se sul dorso abbia Dio, vuole andare e va dove vuole Dio, [...] se invece sul suo dorso si sia assiso Satana, allora vuole andare e va dove vuole Satana, e non è sua facoltà di correre e cercare l'uno o l'altro cavalcatore, ma i due cavalcatori contendono fra loro per averlo e possederlo.»
(Lutero, De servo arbitrio[7])Alla dottrina del servo arbitrio Erasmo da Rotterdam replicò che il libero arbitrio è stato sì viziato ma non distrutto completamente dal peccato originale, e che senza un minimo di libertà da parte dell'uomo la giustizia e la misericordia divina diventano prive di significato.[8] Se infatti l'essere umano non avesse la facoltà di accettare o rifiutare liberamente la grazia divina che gli viene offerta, perché nelle Scritture sono presenti ammonimenti e biasimi, minacce di castighi ed elogi dell'obbedienza? Se inoltre, come predicava Lutero, l'uomo non ha bisogno di chiese e organi intermediari tra sé e Dio, ma è l'unico sacerdote di se stesso, come si concilia questa supposta autonomia con la sua assoluta impossibilità di scelta in ambito morale?
Particolarmente incisivo è l'esempio che Erasmo presenta per supportare la sua soluzione, quello di un padre e del suo figliolo che vuole cogliere un frutto: il padre alza nelle sue braccia il figlio che ancora non sa camminare, che cade e che fa degli sforzi disordinati; gli mostra un frutto posato davanti a lui; il bambino vuole correre a prenderlo, ma la sua debolezza è tale che cadrebbe se il padre non lo sostenesse e guidasse. È quindi solo grazie alla conduzione del padre (la Grazia di Dio) che il bambino arriva al frutto che sempre suo padre gli offre; ma il bambino non sarebbe riuscito ad alzarsi se il padre non l'avesse sostenuto, non avrebbe visto il frutto se il padre non glielo avesse mostrato, non sarebbe potuto avanzare senza la guida del padre, non avrebbe potuto prendere il frutto se il padre non glielo avesse concesso. Cosa potrà arrogarsi il bambino come sua autonoma azione? Anche se non avrebbe potuto compiere nulla con le sue forze senza la Grazia, ha purtuttavia fatto qualcosa.
Ad una concezione estremamente volontaristica del libero arbitrio aderì Giovanni Calvino, che radicalizzò il concetto di predestinazione fino a interpretarlo in un senso rigorosamente determinista. È la Provvidenza a guidare gli uomini, indipendentemente dai loro meriti, sulla base della prescienza e onnipotenza divine. L'uomo tuttavia può ricevere alcuni "segni" del proprio destino ultraterreno in base al successo o meno ottenuto nella propria vita politica ed economica.
Anche all'interno della Chiesa cattolica, che pure si era schierata contro le tesi di Lutero e Calvino, iniziarono una serie di dispute sul concetto di libero arbitrio. Secondo Luis de Molina la salvezza era sempre possibile per l'uomo dotato di buona volontà. Egli sostenne che:
A lui si contrappose Giansenio, fautore di un ritorno ad Agostino: secondo Giansenio l'uomo è corrotto dalla concupiscenza, per cui senza la grazia è destinato a peccare e compiere il male; questa corruzione viene trasmessa ereditariamente. Il punto centrale del sistema di Agostino risiedeva per i giansenisti nella differenza essenziale tra il governo divino della grazia prima e dopo la caduta di Adamo. All'atto della creazione Dio avrebbe dotato l'uomo di piena libertà e della «grazia sufficiente», ma questi l'aveva persa con il peccato originale. Allora Dio avrebbe deciso di donare, attraverso la morte e resurrezione di Cristo, una «grazia efficace» agli uomini da lui predestinati, resi giusti dalla fede e dalle opere.
Il pensiero moderno ha assunto una visione razionalista con Cartesio, che definiva la libertà non come un puro e semplice «libero arbitrio d'indifferenza»[9] ma come impegnativa scelta concreta di cercare la verità tramite il dubbio.[10]
Mentre però Cartesio si arenò nella duplice accezione di res cogitans e res extensa, attribuendo assoluta libertà alla prima e passività meccanica alla seconda, Spinoza cercò di conciliarle riprendendo il tema stoico di un Dio immanente alla Natura, dove tutto avviene secondo necessità. La libera volontà dell'uomo dunque non è altro che la capacità di accettare la legge universale ineluttabile che domina l'universo. La libertà non sta nell'arbitrio, ma nell'assenza di costrizioni che consente ad esempio a una pianta di svilupparsi secondo le sue leggi: «Tale è questa libertà umana, che tutti si vantano di possedere, che in effetti consiste soltanto in questo: che gli uomini sono coscienti delle loro passioni e appetiti e invece non conoscono le cause che li determinano».[11]
Leibniz cercò di darne una connotazione positiva dopo quanto espresso su questo tema da Spinoza, osservando che «quando si discute intorno alla libertà del volere o del libero arbitrio, non si domanda se l'uomo possa far ciò che vuole, bensì se nella sua volontà vi sia sufficiente indipendenza».[12] Pur accettando l'idea della libertà come semplice autonomia dell'uomo, accettazione di una legge che egli stesso riconosce come tale, Leibniz voleva nel contempo mantenere la concezione cristiana della libertà individuale e della conseguente responsabilità. Per questo scopo egli concepiva la libertà fondata metafisicamente sulla "monade": nel senso che ogni individualità, pur essendo un'"isola" completamente separata dalle altre, compirebbe "liberamente" atti che si incastrano come pezzi di un mosaico negli atti corrispondenti delle altre monadi, in un tutto che è l'"armonia prestabilita" da Dio. Il libero arbitrio non è indifferenza per Leibniz, ma «determinazione secondo quanto la ragione considera il meglio».[13]
Dalla fine del Settecento, e sempre più con l'affermarsi del positivismo, la nascente comunità scientifica iniziò a sviluppare la credenza in un universo deterministico, nel quale cioè, date le condizioni iniziali di un processo fisico, o del quale siano note un certo numero di informazioni sufficienti, si fosse in grado di conoscerne l'esito e lo sviluppo con accuratezza assoluta, ovvero con certezza.
Già l'empirista anglosassone David Hume, nel Trattato sulla natura umana, si era proposto di conoscere scientificamente il «meccanismo regolare» delle passioni umane, «non meno delle leggi del moto, dell'ottica, dell'idrostatica o di qualsiasi branca della filosofia naturale».[14] Hume riteneva che l'uomo fosse preda delle passioni al punto da rendere la stessa ragione umana incapace di raffigurarsi obiettivamente il mondo, e che pertanto qualunque verità razionale, compresa l'autocoscienza del libero arbitrio, non avesse alcun valore oggettivo, ma risiedesse soltanto nella soggettività arbitraria del sentimento.[14]
Con lo sviluppo della biologia, conseguente soprattutto alla scoperta del microscopio, l'essere umano iniziò ad essere concepito come un complesso sistema fisico composto da particelle, e successivamente molecole, che fanno uso di reazioni chimiche, fisiche, proprio come ogni altro sistema fisico nell'universo, e dunque ritenuto soggetto alle stesse leggi della fisica che conosciamo; sorse allora il problema di stabilire se tali reazioni materiali fossero l'effetto o piuttosto la causa della sua volontà.
Si venne in particolare scoprendo che il cervello umano sfrutta una serie di reazioni chimiche e chimico-fisiche che generano i campi elettrici e magnetici, tramite i quali avviene la comunicazione dei neuroni, quindi la decisione volontaria di un individuo potrebbe determinare queste reazioni, regolate a loro volta da leggi fisiche ben precise, oppure esserne determinata.
Il problema fu affrontato tra gli altri da Kant, il quale si fece sostenitore di una duplice visione: da un lato egli riteneva che l'uomo, in quanto appartenente al mondo empirico e sensibile, fosse naturalisticamente condizionato; dall'altro ammetteva la libertà come postulato dell'agire morale, a cui approssimare la propria condotta.[15] Libertà e necessità, termini apparentemente inconciliabili, possono per Kant coesistere nel concetto di autonomia, quando l'uomo cerchi di obbedire ad una legge che egli stesso liberamente si è dato.[16]
Una soluzione più pessimista fu formulata da Schopenhauer, il quale riteneva che l'agire umano fosse sottomesso ad una volontà cieca e imperscrutabile. La libertà dell'uomo è per lui illusoria, in quanto determinata di volta in volta da uno scopo stabilito a priori: «Si può fare ciò che si vuole, ma in ogni momento della vita si può volere solo una cosa precisa e assolutamente nient'altro che quella».[17]
Nell'ottica del positivismo ottocentesco, il libero arbitrio verrebbe a scontrarsi con il determinismo, ossia l'idea che tutte le situazioni che accadono nel presente e nel futuro siano una conseguenza necessaria causata dagli eventi precedenti.
Il compatibilismo (anche detto determinismo morbido) ammette tuttavia che l'esistenza del libero arbitrio sia compatibile con un universo deterministico, mentre all'opposto l'incompatibilismo nega questa possibilità. Il determinismo forte è una versione dell'incompatibilismo che accetta che tutto sia determinato, anche le azioni e la volontà umane.
Il libertarismo (in inglese, Libertarianism) si accorda con il determinismo forte solo nel rifiutare il compatibilismo; ma i libertari accettano l'esistenza di un certo libero arbitrio insieme con l'idea che esistano alcuni ambiti indeterminati della realtà.
Con l'avvento delle prime conoscenze in campo atomico, e soprattutto in seguito alla formulazione del principio di indeterminazione di Heisenberg, alla concezione deterministica propria della meccanica classica si è affiancata una concezione stocastica, basata sulla meccanica quantistica in grado di predire eventi solo in termini di probabilità, che non è più ritenuta il frutto di una conoscenza incompleta del sistema fisico, ma una caratteristica intrinseca del mondo quantistico.
Come il determinismo, tuttavia, anche l'indeterminismo venne utilizzato come argomento contro la possibilità del libero arbitrio. Se infatti il determinismo aveva finito per negare la libertà umana, i sostenitori dell'indeterminismo adesso attribuivano al caso la genesi delle nostre azioni, giungendo così ugualmente a negare che la volontà umana fosse libera, in quanto essendo soggetta a parametri irrazionali, risulterebbe incontrollabile.
L'argomento standard contro l'esistenza del libero arbitrio ebbe modo così di basarsi su due differenti opzioni, cioè sulle seguenti concezioni:
Per via di una tale impostazione filosofica veniva a porsi il problema, di natura non solo morale ma anche giuridica, se l'uomo fosse ancora da considerarsi eticamente responsabile delle sue azioni.
Contro questo modo riduzionistico di considerare l'essere umano, tuttavia, ha preso posizione il filosofo della scienza Karl Raimund Popper, che attaccando il cosiddetto determinismo genetico, il neodarwinismo, e la sociobiologia, ha affermato l'autonomia della mente e la sua azione causale nei confronti del cervello e delle sue componenti genetiche. Popper si considera dualista ma non alla maniera di Cartesio, sostenendo che tra i fenomeni mentali e quelli fisici permane una forte dose di incertezza che garantisce l'esistenza del libero arbitrio.[18]
L'epifenomenismo ha rappresentato un ulteriore tentativo di sfiducia nei confronti del libero arbitrio umano. Il biologo e pensatore inglese Thomas Henry Huxley ipotizzò nell'Ottocento che tutti i pensieri coscienti siano un fenomeno secondario, senza alcun potere causale, che accompagnano i processi fondamentali nel sistema nervoso dell'uomo. Il concetto di epifenomeno, appartenente all'ambito del materialismo psicofisico, attribuisce un'origine somatica a tutte le forme di emozione, per cui il sentimento di piacere o dolore sarebbe l'effetto di un cambiamento a livello puramente corporeo o fisiologico.[19]
Il flusso della coscienza, stando a queste argomentazioni, sarebbe un prodotto degli eventi, privo del potere di influire su di essi: a provocare le nostre azioni non sarebbe la coscienza, ritenuta appunto un epifenomeno, ma soltanto i processi fisici del cervello.[20]
Alle concezioni materialiste e fenomeniste della coscienza ha obiettato il filosofo ed esoterista Rudolf Steiner nel suo più completo scritto filosofico, La filosofia della libertà.
Per Steiner, il pensiero non deriva da processi cerebrali, sui quali piuttosto esso si imprime, ma può essere direttamente contemplato come un'entità in sé compiuta, «che si sorregge da sé». Quello che i fisiologi riduzionisti scambiano per il pensiero, in realtà non è che la sua controimmagine, come le orme lasciate da chi cammina su un terreno soffice.[21] Ad esempio, il modo in cui il concetto di lampo viene connesso a quello di tuono non può essere determinato da processi fisiologici del cervello, ma soltanto da una connessione ideale inerente al contenuto stesso di quei concetti, che anzi induce l'attività organica del cervello a ritirarsi, per far posto a quella spirituale del pensiero.
Analogamente, per Steiner, quando l'uomo fa derivare i motivi del suo agire da un'intuizione ideale, allora è libero.
«Se io osservo una volontà che ritrae l'intuizione, anche da questo volere si è ritirata la necessaria attività organica. La volontà è libera. Non può però osservare questa libertà della volontà, chi non è in grado di vedere che la libera volontà consiste in questo, che soltanto dall'elemento intuitivo la necessaria attività dell'organismo umano viene paralizzata, respinta, e sostituita dall'attività spirituale della volontà piena di idee.[...] Chi invece è in grado di osservarlo, si apre un varco alla comprensione del fatto che in tanto l'uomo non è libero, in quanto non è capace di compiere fino in fondo il processo di repressione dell'attività organica; che però questa non-libertà anela alla libertà, la quale non è per nulla un ideale astratto, bensì una forza dirigente che risiede nell'essere umano.»
(R. Steiner, La filosofia della libertà [1894], trad. it., Fratelli Bocca Editori, Milano 1946, pag. 61)Per Steiner non ha senso chiedersi se l'uomo tout court sia libero oppure no, perché egli in realtà è un essere in evoluzione, che «è chiamato allo spirito libero, come ogni germe di rosa è chiamato a divenire rosa». Steiner ha modo di obiettare a Schopenhauer che è assurdo giudicare non libera una volontà che sia determinata nel suo agire da un motivo o uno scopo preciso: la libertà è da intendere semmai come la capacità di determinare da sé, attraverso una propria facoltà chiamata da Steiner «fantasia morale», i motivi del proprio agire, non ricevendoli da altri.
Il buddhismo (in sanscrito: buddha-śasana) o, più comunemente, buddismo[2][3][4][5] è una delle religioni più antiche e diffuse al mondo. Originato dagli insegnamenti dell'asceta itinerante indiano Siddhārtha Gautama (VI, V sec. a.C.), comunemente si riassume nelle dottrine fondate sulle quattro nobili verità (sanscrito: Catvāri-ārya-satyāni). Nel mondo ha tra i 350 e i 550 milioni di fedeli.
Con il termine buddhismo si indica quell'insieme di tradizioni, sistemi di pensiero, pratiche e tecniche spirituali, individuali e devozionali, nate dalle differenti interpretazioni di queste dottrine, che si sono evolute in modo anche molto eterogeneo e diversificato[6][7].
Sorto nel VI-V secolo a.C. come disciplina spirituale assunse nei secoli successivi i caratteri di dottrina filosofica e, secondo alcuni autori, di religione "ateistica"[8], intendendo con quest'ultimo termine non la negazione dell'esistenza degli dei (deva), quanto piuttosto il fatto che la devozione ad essi, fatto comunque considerato positivo, non condurrebbe alla liberazione ultima. Altri considerano i libri sacri buddhisti (Canone pāli, Canone cinese e Canone tibetano) testi che non divinizzano Siddhārtha Gautama Buddha sakyamuni ma Adi-Buddha o Buddha eterno[9], concetti buddhisti equivalenti a Dio; tuttavia non è una concezione affine a quella della divinità in senso occidentale, quanto, nel buddhismo Mahāyāna, il principio della buddhità, raffigurato a volte nelle figure dei Buddha come Vairocana o Amitabha, manifestatosi storicamente come Gautama.[10][11][12] Il Mahāyāna venera anche i bodhisattva, esseri vicini all'illuminazione.
A partire dall'India il buddhismo si diffuse nei secoli successivi soprattutto nel Sud-est asiatico e in Estremo Oriente, giungendo, a partire dal XIX secolo, anche in Occidente.
Di seguito l'elenco dei praticanti Buddhisti per singolo paese:[13]
La parola buddhismo fu introdotta in Europa nel XIX secolo[14] per riferirsi a ciò che è correlabile agli insegnamenti di Siddhārtha Gautama in quanto Buddha. In realtà un'unica parola per esprimere questo concetto non esiste in nessuno dei paesi asiatici originari di tale tradizione religiosa.[15].
La traduzione dei termini originari letteralmente va intesa come "insegnamento del Buddha" (sanscrito buddha-śāsana, pāli buddha-sāsana, cinese 佛教 pinyin fójiào Wade-Giles fo2-chiao4, giapponese bukkyō, tibetano sangs rgyas kyi bka' , coreano 불교 pulgyo, vietnamita phật giáo).
Originariamente "l'insegnamento del Buddha" si denominava come dharma Vinaya (pāli dhamma-vinaya, cinese 法律 fǎlǜ, giapponese hōritsu, tibetano chos 'dul ba, coreano 법률 pŏmnyul, vietnamita phật pháp), ma questa denominazione non ha avuto quella diffusione nelle lingue asiatiche diverse dal sanscrito quanto invece la denominazione buddha-śāsana.
Altri termini sanscriti con cui viene indicato il buddhismo, nella sua accezione di religione esposta dal Buddha Shakyamuni, sono: buddhânuśāsana, jinaśāsana, tathāgataśāsana, dharma, buddhânuśāsti, śāsana, śāstuḥ ma anche buddha-dharma e buddha-vacana.
La storia del buddhismo inizia nel VI-V secolo a.C., con la predicazione di Siddhārtha Gautama. Nel lungo periodo della sua esistenza, la religione si è evoluta adattandosi ai vari Paesi, epoche e culture che ha attraversato, aggiungendo alla sua originale impronta indiana elementi culturali ellenistici, dell'Asia Centrale, dell'Estremo Oriente e del Sud-Est Asiatico; la sua diffusione geografica fu considerevole al punto da aver influenzato in diverse epoche storiche gran parte del continente asiatico. La storia del buddhismo, come quella delle maggiori religioni, è anche caratterizzata da numerose correnti di pensiero e divisioni, con la formazione di varie scuole; tra queste, le più importanti esistenti sono la scuola Theravāda, le scuole del Mahāyāna e le scuole Vajrayāna.
All'origine e a fondamento del buddhismo dei Nikāya e del buddhismo Theravāda troviamo le quattro nobili verità. Si narra che il Buddha, meditando sotto l'albero della Bodhi, le comprese nel momento del proprio risveglio spirituale[16].
Esse sono riportate in vari discorsi del Canone pāli[17], a cominciare dal Dhammacakkappavattana Sutta del Saṃyutta Nikāya, e nel Canone cinese nello Záhánjīng (雜含經, giapp. Zōgon agonkyō, collocato nello Āhánbù, T.D. 99.2.1a-373b), traduzione in cinese del testo sanscrito Saṃyuktāgama al cui interno è collocato il Dharmacakrapravartana Sūtra.[18]
Questo è, sempre secondo la tradizione, il primo discorso del Buddha, tenuto nel parco delle gazzelle nei pressi di Sarnath vicino Varanasi (detta anche Benares) nel 528 a.C. ai suoi primi cinque discepoli, all'età di 35 anni, dopo che nei pressi del villaggio di Bodhgaya, nell'odierno Stato del Bihar, aveva raggiunto il risveglio spirituale.
Questo discorso è quindi anche detto il "Discorso di Benares", fondamentale per il buddhismo, che da esso prende le mosse, tanto da essere considerato l'evento che dà inizio al dharma, ossia la dottrina buddhista. La ricorrenza di questo evento è celebrata nei paesi di tradizione theravāda con la festa di Āsāḷha Pūjā. Da altri è invece considerato il punto d'inizio della prima comunità buddhista, formata proprio da quei cinque asceti che lo avevano abbandonato anni prima sfiduciati, dopo essere stati a lungo suoi discepoli.
In questo discorso si identifica il buddhismo come "la via di mezzo" (sanscrito madhyamā pratipadā, pāli majjhimā pāṭipadā) in cui si riconosce che la retta condotta risiede nella linea mediana di condotta di vita evitando tanto gli eccessi e gli assolutismi, quanto il lassismo e l'individualismo.
Nell'esposizione di questo insegnamento il Buddha enuncia le quattro nobili verità, frutto del proprio risveglio spirituale testé raggiunto, che contemplano l'aspetto pratico della condotta di vita e della pratica spirituale buddhista nel cosiddetto Nobile ottuplice sentiero, che costituisce il secondo cardine dottrinale del buddhismo.
I punti salienti della visione buddhista della "realtà percettiva" indirizzata dall'insegnamento del Buddha, sono:
Tale visione è integrata nella:
Un elemento importante del buddhismo, riportato in tutti i Canoni, è la conferma dell'esistenza delle divinità come già proclamate dalla letteratura religiosa vedica (i deva, tuttavia, nel buddhismo sono sottomessi alla legge del karma e la loro esistenza è condizionata dal saṃsāra). Così nel Majjhima Nikāya 100 II-212[19] dove al brahmano Sangarava che gli chiedeva se esistessero i Deva, il Buddha storico rispose: «I Deva esistono! È questo un fatto che io ho riconosciuto e su cui tutto il mondo è d'accordo». Sempre nei testi che raccolgono i suoi insegnamenti, testi riconosciuti tra i più antichi in assoluto e conservati sia nel Canone pāli che nel Canone cinese e che la storiografia contemporanea inquadra nel termine Āgama-Nikāya, il Buddha storico consiglia a due brāhmaṇa che, dopo aver dato da mangiare a uomini santi, si debba dedicare questa azione alle divinità (deva) locali che restituiranno l'onore concesso loro assicurando il benessere dell'individuo (Digha-nikāya, 2,88-89[20]). È evidente, a partire da questi due antichi brani, la certezza da parte del Buddha storico che le divinità esistessero e andassero onorate. A differenza, tuttavia, delle altre correnti religiose dell'epoca, il Buddha ritiene che le divinità non possano offrire all'uomo la salvezza dal saṃsāra, né un significato ultimo della propria esistenza. Va precisato, peraltro, che non esiste, né è mai esistita alcuna scuola buddhista al mondo che affermi, o abbia affermato, l'inesistenza delle divinità. Tuttavia la totale mancanza di centralità delle divinità nelle pratiche religiose e nelle dottrine buddhiste di tutte le epoche ha fatto considerare, da parte di alcuni studiosi contemporanei, il buddhismo come una religione 'atea'[21].
A questo quadro dottrinario, proprio del buddhismo dei Nikāya e del buddhismo Theravāda, il buddhismo Mahāyāna aggiunge le dottrine esposte nei Prajñāpāramitā sūtra e nel Sutra del loto. All'interno di questi insegnamenti la dottrina della vacuità (sans. śunyātā) acquisisce un ruolo assolutamente centrale in quanto rende correlate, nella Realtà assoluta, tutte le altre realtà e dottrine. Questa unificazione nella vacuità, ovvero di privazione di sostanzialità inerente, fa dichiarare al patriarca del Mahāyāna, Nāgārjuna:
«na saṃsārasya nirvāṇāt kiṃcid asti viśeṣaṇam na nirvāṇasya saṃsārāt kiṃcid asti viśeṣaṇam nirvāṇasya ca yā koṭiḥ koṭiḥ saṃsaraṇasya cana tayor antaraṃ kiṃcit susūkṣmam api vidyate»
«Il saṃsāra è in nulla differente dal nirvāṇa. Il nirvāṇa è in nulla differente dal saṃsāra. I confini del nirvāṇa sono i confini del saṃsāra. Tra questi due non c'è alcuna differenza.»
(Nāgārjuna, Mūla-madhyamaka-kārikā, XXV, 19-20)Per il Sutra del Loto inoltre:
«A beneficio di chi cercava di diventare un ascoltatore della voce, il Buddha rispondeva esponendo la Legge delle Quattro Nobili Verità così che potesse trascendere nascita, vecchiaia, malattia e morte e ottenere il nirvana. A beneficio di chi cercava di diventare pratyekabuddha rispondeva la Legge della dodecupla catena di causalità. A beneficio del bodhisattva rispondeva esponendo le sei pāramitā, facendo ottenere loro l'anuttarā-samyak-saṃbodhi e acquisire la saggezza onnicomprensiva[22].»
Questa presentazione delle quattro nobili verità nella parte più antica del Sutra del Loto indica che, secondo le dottrine esposte in questo Sutra e attribuite da questo testo allo stesso Buddha Śākyamuni, tale dottrina non esaurisce l'insegnamento buddhista il quale deve invece mirare all'anuttara-samyak-sambodhi ovvero all'illuminazione profonda e non limitarsi al nirvāṇa generato dalla comprensione delle quattro nobili verità. Nel suo complesso anche il Sutra del Loto non insiste sulle dottrine del duḥkha (la sofferenza, la prima delle quattro nobili verità) e dell'anitya (impermanenza dei fenomeni) quanto piuttosto su quelle dell'anātman e dello śūnyatā (assenza di sostanzialità inerente a tutti i fenomeni). Il Dharma esposto nei primi 14 capitoli del Sutra del Loto corrisponde alla verità dell'apparire dei fenomeni secondo la causazione che segue le dieci condizioni (o "talità", sanscrito tathata) descritte nel II capitolo del Sutra. Il Dharma profondo è quindi nella comprensione della causa dei fenomeni; la realizzazione spirituale, la bodhi profonda (l'anuttarā-samyak-saṃbodhi), consiste nel comprendere questa "causa" dell'esistere, mentre la verità della sofferenza (duḥkha), come anche la dottrina dell'anitya, implica solo un giudizio. Nel Sutra del Loto non viene quindi enfatizzata la verità della sofferenza contenuta nelle quattro nobili verità. Ecco perché quando il Buddha è sollecitato a insegnare la Legge "profonda" (nel II capitolo) non la esprime con la dottrina delle quattro nobili verità (considerata nel Sutra come dottrina hīnayāna) ma la esprime secondo le dieci talità (o condizioni, sanscrito tathātā, dottrina mahāyāna)[23].
La terza grande corrente del buddhismo esistente in epoca contemporanea, la corrente Vajrayāna (Veicolo del diamante), è essa stessa uno sviluppo del buddhismo Mahāyāna. Alle dottrine proprie del Mahāyāna quali ad esempio la vacuità (śunyātā), karuṇā, la bodhicitta il Vajrayāna aggiunge, allo scopo di poter realizzare "in questo corpo e in questa vita" l'"illuminazione profonda", alcuni insegnamenti "segreti" denominati come tantra e riportati nella propria letteratura religiosa.
Fra i testi più antichi del buddhismo si annoverano i cosiddetti canoni: il Canone pāli (o Pāli Tipitaka), il Canone cinese (in cinese: 大藏經T, Dàzàng jīngP), e il Canone tibetano (composto dal Kangyur e dal Tenjur) così denominati in base alla lingua degli scritti.
Il Canone pāli è proprio del buddhismo Theravāda, e si compone di tre piṭaka, o canestri successivamente raccolti in 57 volumi: il Vinaya Piṭaka, o canestro della disciplina, con le regole di vita dei monaci; il Sutta Piṭaka o canestro della dottrina, con i sermoni del Buddha; infine l'Abhidhamma Piṭaka o canestro della fenomenologia in ambito cosmologico, psicologico e metafisico, che raccoglie gli approfondimenti alla dottrina esposta nel Sutta Piṭaka.
Il Canone cinese si compone di 2.184 testi a cui vanno aggiunti 3.136 supplementi tutti raccolti successivamente in una edizione in 85 volumi.
Il Canone tibetano si suddivide in due raccolte, il Kangyur (composto da 600 testi, in 98 volumi, riporta discorsi attribuiti al Buddha Shakyamuni) e il Tanjur (Raccolta, in 224 volumi, di 3.626 testi tra commentari e insegnamenti).
Parte dei Canoni cinese e tibetano si rifanno ad un precedente Canone tradotto in sanscrito ibrido sotto l'Impero Kushan e poi andato in buona parte perduto. Questi due Canoni furono adottati dalla tradizione Mahāyāna che prevalse sia in Cina che in Tibet. Il Canone sanscrito riportava tutti i testi delle differenti antiche scuole e dei differenti insegnamenti presenti nell'Impero Kushan. La traduzione di tutte queste opere dalle originali lingue pracritiche a quella sanscrita (una sorta di lingua dotta 'internazionale' come lo fu il latino nel Medioevo europeo) fu voluta dagli stessi imperatori kushan. Buona parte di questi testi furono successivamente trasferiti in Tibet e in Cina sia da missionari kushani (ma anche persiani, sogdiani e khotanesi), sia riportati in patria da pellegrini. Da segnalare che le regole monastiche (Vinaya) delle scuole presenti in Tibet e in Cina derivano da due antichissime scuole indiane (vedi buddhismo dei Nikāya), rispettivamente dalla Mūlasarvāstivāda e dalla Dharmaguptaka.
Il buddhismo nacque in India, paese d'origine, approssimativamente attorno al VI secolo a.C. Tuttavia, durante più di 1500 anni di storia il buddhismo indiano ha sviluppato indirizzi e interpretazioni diverse, anche estremamente complesse. Lo sviluppo di tale complessità si rese necessario con il continuo confronto dottrinale sia all'esterno delle Comunità monastiche con le scuole brahmaniche e jaina, sia all'interno delle stesse per svelare progressivamente gli insegnamenti (soprattutto i cosiddetti "inesprimibili", sanscrito avyākṛtavastūni) contenuti negli antichi Āgama-Nikāya. Le scuole nate nel sub-continente indiano nel corso di questi 1500 anni di storia sono suddivisibili in tre gruppi:
Tra le tradizioni che fuori dall'India hanno avuto una lunga storia e un'evoluzione in parte indipendente ricordiamo:
«Dall'Ottocento agli inizi del Novecento uno dei tratti più costanti delle interpretazioni del buddhismo consiste nel non riconoscergli lo statuto di religione. Questo argomento, uno dei temi classici dell'orientalismo erudito ottocentesco, si ripresenta con forza alla fine del Novecento per giustificare il successo del buddhismo nelle società occidentali moderne. La sua trasfigurazione in una "non-religione" si spiega in primo luogo con la conoscenza parziale e selettiva che gli occidentali ne avevano (e ne hanno tuttora) [...].»
(Lionel Obadia. Il buddhismo in Occidente. Bologna, Mulino, 2009, pag.45.)Di seguito una bibliografia ragionata dei testi 'del' e 'sul' buddhismo in lingua italiana.
Sono i testi ritenuti canonici da tutte le scuole buddhiste. Occorre ricordare che la scuola Theravāda considera "canoniche" solo le opere contenute nel Canone pāli.
Sono testi considerati canonici solo dalle scuole del buddhismo Mahāyāna e del buddhismo Vajrayāna. Non sono ritenuti canonici dalla scuola Theravāda e dalle altre scuole del buddhismo dei Nikāya, queste ultime tutte scomparse.
L'uomo è un essere umano adulto di sesso maschile. Si distingue dal maschio prepubere, che può essere chiamato, a seconda dell'età: ragazzo, adolescente, bambino, e dall'altro sesso della specie Homo sapiens.
La parola uomo deriva dal latino hŏmō, legato a hŭmus ‘terra’, avente senso, quindi, di "terrestre"; in francese e spagnolo, rispettivamente homme e hombre hanno la stessa origine, ma dal caso accusativo hŏmine(m). In inglese man ha origine dall'inglese antico nel quale significava "maschio adulto", come l'attuale termine tedesco Mann, che deriva a sua volta dal proto-germanico *mann-z, che significa "persona". Secondo Tacito, il progenitore mitologico delle tribù germaniche si chiamava "Mannus".
Accanto al termine homo, che indica l'essere umano in generale, senza specificazione di genere, il latino possiede anche il termine vir per indicare un essere umano adulto di sesso maschile; questa parola, che non ha discendente diretto in italiano[1], si ritrova in spagnolo come varón, col significato di essere umano di sesso maschile. Vir significa anche marito, maschio ed eroe. Da vir derivano sia gli aggettivi "virile" e "virtuoso", sia il sostantivo "virtù".[2].
Dal greco ἀνήρ, (anḕr), gen. ἀνδρός (andròs), di significato analogo al latino vir, derivano alcuni termini scientifici come "andrologia", "androgino", "andropausa", nonché i nomi propri Andrea o Alessandro. L'equivalente greco di homo è invece ἄνθρωπος (ànthrōpos) da cui derivano altri termini scientifici come "antropologia", "antroposofia", "antropomorfo" e così via.
L'italiano "maschio" deriva dal latino classico mas (gen. maris) attraverso la forma masculus, in origine diminutivo. Anche "marito" deriva da mas.
Con i termini "ragazzo", "adolescente", "bambino" si indica, nella terminologia comune, in relazione alle diverse età dello sviluppo e dell'accrescimento, un giovane uomo, che non ha ancora raggiunto la piena maturità sessuale o l'età considerata adulta.
La pubertà è il periodo di passaggio dall'infanzia all'età virile. In quasi tutte le società, il passaggio più importante nella vita di un individuo è proprio la pubertà e molto spesso questo momento è segnato da un rituale molto elaborato. I riti legati alla pubertà costituiscono un esempio particolarmente significativo di quelli che vengono chiamati riti di passaggio. Questi riti celebrano il cambiamento di status con il quale l'individuo assume nuovi ruoli sociali. Come per la nascita, non è il semplice cambiamento fisico (il raggiungimento della maturità sessuale) che viene celebrato, ma il riconoscimento sociale di quel mutamento. I riti d'iniziazione comportano in molti casi, in alcune culture, un periodo di separazione dal resto del mondo, durante il quale gli iniziati ricevono degli insegnamenti particolari.
Un esempio che può essere citato è il Bar mitzvah della religione ebraica che si svolge quando un ragazzo ha 13 anni.
È importante notare, che questi riti di iniziazione non sono realmente finalizzati a fornire conoscenze e capacità tecniche, che i giovani normalmente apprendono nella vita di ogni giorno, ma tendono a sottolineare piuttosto i doveri morali e le responsabilità sociali degli adulti. L'iniziazione puberale o semplicemente l'inizio della pubertà spesso segnano l'inizio della vita sessuale attiva di un individuo.
L'uomo possiede, a livello fisico e biologico, svariate caratteristiche che lo differenziano dalla donna (caratteri sessuali primari e secondari).
Gli esseri umani, infatti, presentano dimorfismo sessuale, anche se la maggior parte di tali caratteristiche non hanno alcun legame diretto con la capacità riproduttiva, hanno un ruolo nell'attrazione sessuale, e possono, in alcune culture, essere coinvolti nel/nei rituali di corteggiamento in funzione dell'accoppiamento.
I caratteri sessuali primari si riferiscono più propriamente all'aspetto degli organi genitali e della riproduzione, quelli secondari si sviluppano fondamentalmente nel passaggio da ragazzi all'età adulta e si differenziano da quelli femminili, per le seguenti caratteristiche:
Geneticamente, e dal punto di vista della biologia molecolare, l'uomo, al di là di possibili patologie genetiche, è caratterizzato da cariotipo 46, XY.
Gli organi sessuali di un uomo fanno parte del relativo apparato riproduttivo ed urinario, che si distingue notevolmente da quello femminile.
Gli uomini hanno organi sessuali che sono prevalentemente esterni, anche se alcune parti del sistema riproduttivo maschile sono interne.
La disciplina che studia la riproduzione nell'uomo e gli organi associati, e le conseguenti possibili patologie, è chiamata andrologia.
Per gli uomini durante la pubertà, il testosterone, con gonadotropine rilasciato dalla ghiandola pituitaria, stimola la spermatogenesi, e la distinzione sessuale completa nei caratteri sessuali secondari dell'individuo maschio dalla femmina, nelle donne, invece le relative trasformazioni e distinzioni sessuali sono attuate dagli estrogeni e dal progesterone.
In generale, gli uomini soffrono delle stesse malattie delle donne: ci sono tuttavia alcune malattie legate ad aspetti genetici, che sono tipiche, o intervengono più frequentemente, negli uomini. Per esempio l'autismo e il daltonismo sono più comuni negli uomini che nelle donne.
Vi sono anche altre malattie che colpiscono esclusivamente gli uomini, e tra queste si evidenziano quelle che colpiscono la prostata, dato che questa è una ghiandola presente solo nell'apparato genitale maschile. Le malattie che colpiscono questa ghiandola hanno particolare rilievo, in quanto sono tra le patologie che si presentano con più elevata incidenza, per gli uomini di età superiore ai 60 anni.
La più grave è il cancro o carcinoma della prostata che colpisce secondo le attuali recenti statistiche, mediamente tra i paesi occidentali, fino al 15% degli uomini di età compresa tra i 61 ed i 95 anni, (uno su sette), e che si conferma essere anche una delle più gravi forme tumorali nel sesso maschile[3].
Meno grave, ma con una incidenza maggiore, è l'iperplasia prostatica benigna conosciuta anche come adenoma prostatico che colpisce il 5-10% degli uomini di 40 anni di età, e fino all'80% degli uomini tra 70 e 80 anni.
Fattori biologici (tra cui patologie e difformità genetiche), disturbi insorti nella fase dello sviluppo, della differenziazione cromosomica o ormonale, fattori culturali e altri fattori ancora oggetto di studio, possono influire sull'identità di genere in cui si identifica un individuo (sia di sesso maschile sia femminile). Tra le patologie che possono essere legate a questo aspetto, esiste la cosiddetta sindrome di Morris.
Enormi dibattiti, nelle società occidentali, si sono concentrati sulla percezione delle differenze sociali, intellettuali, emotive tra uomini e donne. Queste differenze sono molto difficili da quantificare, per ragioni sia scientifiche che politiche, anche se normalmente gli individui, attribuiscono loro, una considerevole importanza.
La mascolinità trae le sue radici nella genetica (vedi anche sesso)[4], pertanto mentre essa si presenta con forme, usanze diverse in culture differenti, vi sono aspetti comuni nella sua definizione attraverso le stesse[5].
A volte gli studiosi di genere usano la frase "mascolinità egemone" per distinguere la forma più dominante di mascolinità, dalle altre varianti. Nella metà del XX secolo negli Stati Uniti, per esempio, John Wayne potrebbe incarnare una forma di "mascolinità egemone", mentre Albert Einstein potrebbe essere comunque considerato mascolino, ma non nella stessa forma egemone (tali considerazioni ovviamente, non rappresentano degli assiomi ma rientrano, per loro natura nella categoria degli stereotipi di genere).
L'antropologia ha dimostrato come in molte culture la mascolinità in sé stessa, sia uno status sociale, così come la ricchezza, la razza e la classe sociale. Nella cultura occidentale, per esempio, tradizionalmente una maggiore mascolinità, nel confronto tra uomo e uomo, ed a parità di altre condizioni, favorisce di solito un maggiore status sociale. Molte parole, come virtù e virile (dal latino e ancor più dalla radice sanscrita vir che significa uomo) rispecchiano questa situazione. Da ciò ne è derivata, nel pensare comune, una implicita associazione con forza o valore fisico e morale. La mascolinità è associata più frequentemente alla condizione di uomo adulto che di ragazzo.
In alcune culture, non presentare caratteristiche tipiche e consone al proprio genere può diventare un problema sociale per l'individuo. Tra gli uomini, alcuni comportamenti differenti dallo standard, o atteggiamenti non virili, possono indurre ed essere considerati un segno di omosessualità, mentre tra le ragazze chi mostra un comportamento maschile è spesso apostrofata come un "maschiaccio".
All'interno della sociologia tali etichettature, condizionamenti a volte fortemente discriminatorie sono definite, nei casi più gravi, con i termini xenofobia ed omofobia ed un compito delle scienze sociali è appunto quello di migliorare l'accettazione degli individui che hanno preferenze o stili di vita "non standard" o meglio, che non interpretano i comportamenti "della maggioranza degli individui", attraverso una migliore apertura culturale. Il comportamento corrispondente ad un atteggiamento culturale e sociale, basato solo o principalmente, sull'affermazione delle virtù e delle qualità legate alla mascolinità è definita machismo o maschilismo.
L'importanza relativa dei ruoli di socializzazione e della genetica, nello sviluppo della mascolinità, continua ad essere dibattuta. Il condizionamento sociale e l'educazione, soprattutto nell'età dello sviluppo, gioca ovviamente un ruolo, va sottolineato comunque, come rilevanza statistica, che alcuni aspetti della identità maschile, esistono in quasi tutte le culture umane.
Lo sviluppo storico del ruolo di genere è affrontato da settori quali la genetica del comportamento, la psicologia evolutiva, l'ecologia umana, e la sociobiologia. Tutte le culture umane sembrano incoraggiare lo sviluppo dei ruoli di genere, attraverso la letteratura, il costume ed anche il canto. Alcuni esempi di questo aspetto si trovano in grandi opere del passato quali l'epica di Omero, i racconti di Re Artù (Ciclo Bretone), le citazioni filosofiche di Confucio o gli studi biografici del profeta Maometto.
Trattazioni più specializzate dell'aspetto della mascolinità possono essere trovate in opere come la Bhagavad Gita.
In termini di apparenza estetica, pochi uomini occidentali indossano gioielli o fanno uso di cosmetici, in quanto pratiche considerate più propriamente femminili. La moda tuttavia, sebbene in occidente sia diversificata in moda maschile e moda femminile è in continua trasformazione, indossare gioielli (per esempio indossare orecchini) è oggi, in alcuni ambiti culturali, diffuso anche tra gli uomini[senza fonte].
In termini di genere, secondo diverse ricerche condotte negli ultimi anni, esistono differenze cerebrali tra uomini e donne, nel modo di pensare e di comportarsi, che sembrano andare oltre gli effetti dei condizionamenti culturali e dell'educazione. Le prime differenze iniziano addirittura a livello fetale: nei nove mesi di gravidanza gli ormoni sessuali, estrogeni e androgeni, oltre ad indirizzare lo sviluppo fisico del futuro bambino sono in grado di modificare l'organizzazione cerebrale in un senso o nell'altro[6].
In pratica, il bagno ormonale in cui siamo immersi prima della nascita, condiziona la formazione delle sinapsi, cioè i collegamenti tra neuroni. E crea le prime importanti differenze tra il cervello maschile e quello femminile.
Si possono delineare alcune caratteristiche generalmente associate agli uomini, per quanto sia importante ricordare come tali generalizzazioni debbano essere considerate solo come una tendenza generale dei risultati delle ricerche e non in senso assoluto, dato che possono variare da individuo ad individuo:
Esistono alcune posizioni e titoli riservati ai soli uomini, ad esempio ruoli religiosi come il sacerdozio nella Chiesa cattolica e nelle Chiese ortodosse, il ruolo di imam nella maggior parte delle correnti dell'Islam, il ruolo di rabbino nella religione ebraica ortodossa.
Nelle monarchie, il diritto dinastico di erede al trono nella linea di successione al monarca regnante spetta più frequentemente agli uomini (legge salica). Le monarchie dell'Europa settentrionale hanno progressivamente abolito tra la fine del XX e l'inizio del XXI secolo la legge salica o semisalica, e la linea di successione spetta al primogenito a prescindere dal genere di appartenenza.
«Il socialismo è portare avanti tutti quelli che sono nati indietro.»
(Pietro Nenni)Il socialismo è un complesso di ideologie, movimenti e dottrine legato a orientamenti politici di sinistra tendente a una trasformazione della società finalizzata a ridurre le disuguaglianze fra i cittadini sul piano sociale, economico e giuridico.
Originariamente tutte le dottrine e movimenti di matrice socialista miravano a perseguire i propri obiettivi attraverso l'abolizione delle classi sociali e la soppressione totale della proprietà privata dei mezzi di produzione e di scambio. Fino al 1848, i termini socialismo e comunismo erano considerati intercambiabili. In quell'anno, nel Manifesto del Partito Comunista di Marx ed Engels, si opera la distinzione tra "socialismo utopico" e "socialismo scientifico", il solo, quest'ultimo, che può garantire la transizione verso una fase successiva, il "comunismo", per evidenziarne polemicamente le differenze con il primo.
Tuttavia, quello a cui fanno riferimento i due filosofi tedeschi è appunto un "comunismo" filosofico, ben diverso dal quello che nascerà con Lenin e da cui si terranno lontani i partiti di origine marxista dell'Europa occidentale. Movimenti come quello fascista e nazionalsocialista, agli inizi, erano soliti definirsi "socialisti" per cercare di prendere più consenso possibile dalla popolazione, anche se erano, in realtà, in contrasto con le idee socialiste, eccezion fatta per alcune caratteristiche come l'anticapitalismo.
Per socialismo si intende uguaglianza formale con l'obiettivo di raggiungere anche quella sostanziale.
Nel pensiero marxista, il socialismo e il comunismo divennero due fasi della rivoluzione: la fase socialista, cioè quella delle statalizzazioni, che facevano parte della dittatura del proletariato, che si realizzava in un nuovo concetto di Stato, diverso da quello borghese; poi la fase comunista, che prevedeva l'abolizione delle classi, intesa come libera associazione di tutti. Contrariamente all'anarchismo, che fin dall'inizio prevedeva una abolizione di qualsiasi organizzazione statale, questa concezione di Karl Marx prevedeva quindi due fasi: la dittatura del proletariato e la società senza classi. La seconda fase fu abbandonata quasi subito dai regimi del socialismo reale.
Originariamente infatti nella fase comunista si prevedeva la dissoluzione dello Stato, perché considerato a quel punto inutile: i beni e i mezzi di produzione erano tornati alla collettività. Oggi, data l'evoluzione dei tempi, le due fasi vanno a coincidere: dunque si può parlare di una sostanziale coincidenza dei due termini, socialismo e comunismo. Questi molto spesso sono usati come sinonimi, ma il termine socialismo sembra possedere  un'accezione più ampia.
Contemporaneamente si sviluppava un'altra forma di dottrina di analoga matrice socialista: l'anarchismo, un'ipotesi di organizzazione i cui obiettivi egualitari in termini economici sociali e civili venissero fondati sull'autonomia e la libertà degli individui, contrapponendosi ad ogni forma di potere costituito compreso quello statale. Tale dottrina, prendendo le mosse dal pensiero dell'illuminista William Godwin, si concretizzava nelle teorie di Pierre-Joseph Proudhon, fin dagli esordi in polemica con Marx. Lo scontro divampò progressivamente nel corso del secolo, e ulteriormente all'interno dell'Associazione internazionale dei lavoratori (Prima Internazionale), portando tra il 1871 e il 1872 ad una prima scissione, concretizzata nel 1896. Nel XX secolo marxisti e anarchici si troveranno spesso a condividere e combattere insieme nelle fasi iniziali dei moti rivoluzionari di ispirazione socialista come la guerra civile spagnola o la rivoluzione d'ottobre russa, giungendo in fasi successive a scontri e repressioni da parte delle fazioni marxiste verso i socialisti libertari (rivoluzione anarchica spagnola, rivolta di Kronštadt, insurrezione rivoluzionaria d'Ucraina, eccetera). Il filone, nel tempo, si è suddiviso in aree con diverse connotazioni, fondendo temi propri di varie ispirazioni, originando socialismo libertario, anarco-comunismo, anarco-sindacalismo, eccetera.
In ogni modo, il termine comunismo continuò a essere un sinonimo di socialismo per tutto l'Ottocento: i partiti che prendevano parte alla Seconda Internazionale, tutti definitivamente di ispirazione marxista dopo il IV congresso di Londra del 1896, venivano denominati socialisti o socialdemocratici.
La separazione dei termini comunismo e socialismo, in area marxista, avvenne per iniziativa di Lenin: con la rivoluzione bolscevica (1917) e la costituzione dell'Internazionale Comunista o Terza internazionale (1919) l'ala rivoluzionaria del socialismo si distaccò organizzandosi nei partiti comunisti, mentre i partiti socialisti, ormai orientati in senso riformista e inseriti nei sistemi democratico-borghesi dei diversi paesi, per lo più presero gradualmente le distanze dal marxismo, e in ogni caso dal leninismo (anti-leninisti) e recuperarono le istanze liberali dell'utopismo socialista pre-marxista, dando vita al socialismo democratico, alla socialdemocrazia e al socialismo liberale. In seguito, entro la fine del XX secolo, anche i più grandi partiti comunisti, spesso altrettanto orientati in senso riformista e altrettanto inseriti nei sistemi democratico-borghesi, in particolare nei paesi europei o comunque occidentali, per lo più presero gradualmente le distanze dal marxismo inteso nell'originale senso rivoluzionario, senza che venissero meno idee come il socialismo rivoluzionario e il massimalismo.
Il socialismo, nel tempo, si è diviso ed ha fuso il pensiero socialista con altre connotazioni politiche. I principali esempi di queste sintetizzazioni sono il socialismo cristiano, l'ecosocialismo, il socialismo nazionale, il socialismo libertario, il socialismo liberale, il socialismo democratico ed il socialismo del XXI secolo.
Il socialismo è una corrente di pensiero legata ai movimenti politici che, a partire dal XIX secolo, lottarono per modificare la vita sociale ed economica delle classi meno abbienti e in particolare del proletariato.
Il movimento operaio da cui scaturì il socialismo pose per la prima volta il problema della giustizia sociale. In una prospettiva di analisi teorica storica, quindi, mentre si vede il periodo feudale come caratterizzato dal predominio dell'aristocrazia e del clero, e il periodo post-rivoluzioni francese ed americana come caratterizzato dall'ascesa al potere sociale della borghesia (e quindi del liberalismo e del capitalismo), il socialismo dovrebbe essere lo stadio successivo, caratterizzato dal predominio delle classi popolari che detengono il potere economico e asserviscono, o addirittura annullano, lo Stato.
Il socialismo si oppone inizialmente al liberalismo classico, che postula il liberismo in economia, chiedendo invece la nazionalizzazione o la socializzazione di tutte o parte delle attività economiche e dei mezzi di produzione. Il criterio economico socialista di gestione delle risorse e di produzione non è quello del profitto individuale ma quello della ricerca del bene comune collettivo. Il socialismo contesta inoltre l'idea delle neutralità delle istituzioni statali rispetto alla lotta di classe e si batte per un mutamento del ruolo dello Stato o, addirittura, nella versione avanzata dall'anarchismo, per la sua eliminazione.
Sul piano internazionale il movimento socialista nasce come un movimento favorevole all'autodeterminazione dei popoli, contrapponendosi al nazionalismo e all'imperialismo occidentali. Nell'ala riformista e della socialdemocrazia la linea politica è spesso pacifista, mentre storicamente i socialisti rivoluzionari hanno auspicato una rivoluzione violenta.
Nella prassi tuttavia, soprattutto durante il periodo della prima guerra mondiale, molti partiti socialisti o correnti di essi finiscono per abbandonare il pacifismo e l'internazionalismo, appoggiando le imprese belliche dei loro paesi con motivazioni patriottiche. Un esempio è il nazionalismo dell'Unione Sovietica che scaturì dalla politica di Stalin del socialismo in un solo paese prima e dalla "grande guerra patriottica" poi (anche se per i più ortodossi ciò che si instaurò nella Russia post-rivoluzionaria non si può definire esattamente "socialismo").
Partiti e movimenti estremamente diversi fra loro si sono definiti socialisti: molti di essi sopravvivono ancora oggi e formano una delle più importanti correnti politiche in Europa, nonché la principale componente della sinistra europea, con la definizione di socialdemocrazia. Il movimento socialista conosce numerosissime scissioni, accuse reciproche di aver tradito gli ideali originari asservendosi allo Stato liberale, ecc. La scissione più importante è probabilmente quella verificatasi all'indomani della rivoluzione d'ottobre, che vede una larga fetta della sinistra dei partiti socialisti staccarsi e scegliere la denominazione comunista, già utilizzata in passato da alcuni teorici socialisti come Karl Marx. Per informazioni sul comunismo e su altre particolari correnti del socialismo si rimanda alle pagine relative, così come per l'illustrazione dettagliata delle dottrine dei vari pensatori socialisti.
I movimenti ottocenteschi derivano dalle lotte rivoluzionarie repubblicane, in particolare dall'esperienza della Rivoluzione francese con il movimento dei Montagnardi e dei Sanculotti, e dalle rivolte contadine che dal Medioevo si ripetevano ciclicamente contro l'aristocrazia terriera; talvolta queste rivolte assumevano connotati religiosi che sfociavano nell'egualitarismo e nella comunione dei beni di produzione.
Nel XIX secolo si ebbe il socialismo di Robert Owen in Inghilterra, mentre in Francia un'influenza sui primi movimenti l'ebbe anche il sansimonismo, una corrente politico-religiosa che divulgava il pacifismo e la comunione dei beni in una società che avrebbe dato a ogni individuo il ruolo a lui più congeniale. Nello stesso filone "utopico" si inserì Auguste Blanqui, e successivamente Pierre-Joseph Proudhon, il teorico dell'anarchia e del socialismo libertario, che Karl Marx definì socialista conservatore o borghese nel Manifesto del Partito Comunista, e gli altri "socialisti utopici" già citati. Il contrasto Marx-Proudhon porterà al famoso duello di penna che sfocerà negli scritti contrapposti, Filosofia della miseria e Miseria della filosofia.
Non è da trascurare la corrispondenza tra il socialismo originario e la matrice dell'illuminismo, sia in rapporto agli aspetti esteriori che connettono le due dottrine nei tratti unificanti della lotta all'oscurantismo e per l'emancipazione dell'umanità, sia in relazione alle corrispondenze di alcune figure chiave in entrambi i contesti, come Filippo Buonarroti e Adam Weishaupt.
Il termine socialismo utopico, qui usato, come vedremo verrà introdotto solo in un secondo tempo da Marx per distinguere e contrapporre il suo socialismo scientifico, che pretendeva essere fondato su basi logiche, storiche, sociali ed economiche rigorose, certe e verificate, da quelli precedenti alle sue teorie, e all'epoca a volte in contrasto su diverse questioni, definiti da Marx utopisti in quanto, sempre secondo la visione marxiana, non basati su dati scientifici ma su aspirazioni ideali.
Il termine socialismo scientifico viene coniato da Karl Marx per indicare la sua visione del socialismo, illustrata nelle sue numerose opere sulla società, sulla storia e sull'economia. In opposizione al socialismo utopico, Marx riteneva che la prassi del movimento operaio dovesse essere ispirata da una rigorosa analisi.
A Marx si deve la nozione di lotta di classe, illustrata nel Manifesto del Partito Comunista del 1848. Marx si propone nelle sue opere di dimostrare come il capitalismo, gestito dalla borghesia, opprimesse il proletariato (lavoratori industriali) nella fase storica in cui scriveva. Nell'opera Das Kapital (Il Capitale), Marx analizza come i capitalisti comprassero forza lavoro dai lavoratori, ottenendo il diritto di rivendere il risultato dell'attività produttiva ottenendo così profitto (vedi marxismo per i dettagli); questo, secondo Marx, porta ad un'insostenibile sperequazione nella distribuzione della ricchezza.
Per Marx era solo questione di tempo: le classi lavoratrici di tutto il mondo, presa coscienza dei loro comuni obiettivi, si sarebbero unite per rovesciare il sistema capitalista che le opprimeva. Lo considerava un risultato possibile di un processo storico in atto.
Dalle rovine del capitalismo sarebbe sorta, dopo un periodo di transizione (dittatura del proletariato) in cui lo Stato avrebbe controllato i mezzi di produzione, una società in cui la proprietà sarebbe passata alla società stessa nel suo complesso: lo Stato era quindi destinato a dissolversi. La proprietà privata sarebbe stata limitata agli effetti personali. 
La conseguenza della proprietà collettiva dei mezzi di produzione sarebbe stata, nell'ottica di Marx, la fine della divisione della società in classi sociali e, di conseguenza, la fine dello sfruttamento e la piena realizzazione dell'individuo. L'ateismo, caratteristica del socialismo marxista, era una conseguenza logica del materialismo dialettico che il marxismo adottava come metodo.
Dalle teorie di Marx e dei suoi contemporanei originarono molti orientamenti diversi, tutti in qualche modo connessi con le basi fondamentali del pensiero socialista: alcuni presero da Marx solo il metodo di analisi della società, mentre altra parte del movimento socialista ne abbracciò con entusiasmo la parte rivoluzionaria, mettendo in secondo piano il pensiero dei socialisti non marxisti. La nascita di una società di uomini liberi e uguali dal punto di vista dei diritti è il concetto chiave attorno ai quali si articolano tutti i progetti libertari; le idee anarchiche entrarono presto in conflitto sia con le concezioni riformiste del socialismo che con le concezioni marxiste, in particolare per quanto riguarda l'uso dello Stato come mezzo rivoluzionario. Gli anarchici Michail Bakunin e Pëtr Alekseevič Kropotkin, che presero l'avvio dalle idee del socialista utopico di matrice anarchista Pierre-Joseph Proudhon, vengono oggi considerati i principali rappresentanti ottocenteschi del socialismo libertario, ma alcune delle idee basilari affondano le radici in Godwin.
Fra gli italiani, un noto esponente del socialismo libertario è Gino Bianco[2].
Fu nel segno del socialismo ancora unitario che nel 1864 fu creata la Prima Internazionale dei lavoratori o Associazione internazionale dei lavoratori, l'organizzazione che raggruppava i movimenti socialisti di tutta Europa, vedendo al suo interno come principali, ma non sole componenti, tanto la corrente anarchica quanto quella marxista.
L'organizzazione vedeva confluire socialisti, anarcocomunisti, repubblicani, mazziniani, marxisti. I mazziniani, contrari alle teorie che si basavano sulla lotta di classe, pensavano di risolvere i problemi sociali attraverso la solidarietà nazionale, si ritirarono per primi dall'Internazionale (con Giuseppe Garibaldi, socialista nazionale, che si espresse, al contrario, a suo favore) e l'intera organizzazione ebbe successivamente un prevalente orientamento marxista.
La differente visione politica delle due correnti principali sfocerà al congresso dell'Aia del 1872 in una reale spaccatura in seno all'Internazionale e allo sviluppo di movimenti di matrice anarchica, quali, ad esempio, il socialismo libertario. In epoca di Seconda Internazionale, durante il IV congresso di Londra nell'estate del 1896, si consumerà il definitivo allontanamento tra marxisti e libertari.
Fu chiamata revisionista la corrente moderata e riformista del marxismo che sorse verso la fine del XIX secolo, originata dall'osservazione che il comportamento dell'economia capitalistica non sembrava corrispondere alle previsioni del marxismo.
Dopo la depressione degli ultimi decenni del XIX secolo infatti, era iniziato un nuovo periodo di prosperità che sembrava riabilitare il libero commercio e la fiducia nel capitalismo e per questo la componente moderata del socialismo (che all'epoca veniva chiamata indifferentemente socialismo democratico o socialdemocrazia) elaborò la "teoria revisionista", che in pratica si prefiggeva di abbandonare il marxismo per giungere alla completa accettazione dell'economia di mercato, magari con qualche "aggiustatina". Da allora coloro che accettarono il revisionismo e proseguirono sulla via del capitalismo per realizzare riforme nell'interesse dei lavoratori furono indifferentemente chiamati "socialisti democratici" o "socialdemocratici" (un'esatta differenza tra i due termini si avrà solo nella seconda metà del Novecento). Coloro che invece avversavano il revisionismo e la via riformista furono i "socialisti marxisti" e i "comunisti o socialrivoluzionari" (insieme chiamati genericamente "massimalisti"). Il maggior esponente del revisionismo fu il tedesco Eduard Bernstein (1850- 1932).
Si definisce socialdemocrazia quell'insieme di movimenti socialisti che accettano il concetto di economia di mercato, di proprietà privata e il muoversi all'interno delle istituzioni liberali.
La socialdemocrazia si pone tra il socialismo marxista e il riformismo borghese. Essa infatti, in un primo tempo, pur ponendosi in prospettiva critica nei confronti del capitalismo, non ritenne ancora tempo per una sua totale abolizione.
Il ruolo che si assicurarono i partiti socialdemocratici nei decenni tra il XIX e XX secolo fu quello di lottare sia contro il riformismo borghese, che avrebbe portato la classe operaia a legarsi troppo al sistema capitalistico, che contro l'avventurismo rivoluzionario marxista, che avrebbe portato a scontrarsi con le strutture ancora solide del sistema. La socialdemocrazia non tende a farsi garante della sopravvivenza del sistema, ma vuole lavorare al suo interno per portare uno spirito di rinnovamento e di trasformazione costante.
Le evoluzioni successive portano la socialdemocrazia a farsi portatrice del compromesso tra il riformismo liberale dei borghesi e i principi più importanti della dottrina socialista riformista: durante gli anni tra i due conflitti mondiali, con la proposizione di due modelli forti come quello sovietico e quello fascista, i socialdemocratici rappresentarono l'alternativa democratica e riformista. Socialdemocrazia e comunismo giunsero spesso allo scontro frontale, in cui i socialdemocratici vennero trattati da "socialtraditori" o "socialfascisti", per ritrovare successivamente un progetto comune contro il regime fascista e nazista.
Nel secondo dopoguerra, la socialdemocrazia riassume in occidente un ruolo importante tra le forze politiche dominanti nonché il naturale approdo per tutti i socialisti riformisti e i democratici progressisti, essa fu inoltre capace di proporre significative trasformazioni, come la nazionalizzazione di alcuni settori produttivi, l'instaurazione di un'economia mista e il raggiungimento di forme di sicurezza sociale per i lavoratori.
Le socialdemocrazie contemporanee sono partiti politici che hanno abbandonato l'idea della divisione della società in classi contrapposte e ogni progetto di stampo ottocentesco; del vecchio modello rimane solo la prospettiva internazionalista che ribadisce il principio di un'azione comune tra tutte le forze socialiste, socialdemocratiche o genericamente riformiste dei singoli Paesi, nel rispetto delle diverse storie nazionali, delle diverse situazioni economiche e della pluralità delle tradizioni culturali e ideologiche. In molti casi inoltre, anche significative componenti del mondo cristiano sociale e riformista hanno trovato nella socialdemocrazia un ottimo approdo.
Invece il socialismo democratico mira alla completa soppressione del capitalismo però tramite libere elezioni e senza rivoluzioni violente.
I socialisti riformisti pensavano che il socialismo fosse la naturale evoluzione della società occidentale, che sarebbe dovuta evolvere naturalmente da capitalista in comunista per via delle contraddizioni interne del capitalismo, tramite una sequenza di riforme.
Pur concordando su tale evoluzione, i socialisti rivoluzionari come Rosa Luxemburg in Germania o Giacinto Menotti Serrati in Italia pensavano invece che questo cambiamento non sarebbe mai avvenuto spontaneamente, ma avrebbe richiesto una rivoluzione.
I sindacalisti rivoluzionari, affini a questo movimento ma ispirati da Georges Sorel, finirono invece spesso, ad esempio in Italia, per confluire in movimenti di vario tipo, come il fascismo, movimento nazionalista di impianto sociale, fondato e guidato dall'ex socialista rivoluzionario Benito Mussolini.
Dopo la Rivoluzione russa del 1917 e la terza internazionale del 1919 il socialismo rivoluzionario propriamente detto, di radice marxista, coincise sostanzialmente con il comunismo.
In senso generale con socialismo di stato si intende qualsiasi varietà di socialismo che si basa sulla proprietà dei mezzi di produzione da parte dello stato. Il socialismo di stato viene spesso indicato semplicemente come "socialismo"; il termine "di stato" viene solitamente aggiunto solo dai socialisti con una visione differente, desiderosa di criticare il socialismo di stato, come, ad esempio, gli anarchici.
Oggi, molti partiti politici europei della sinistra, sono sostenitori di varie forme di proprietà statale in forma di socialismo democratico. Questi socialisti moderati non sostengono il rovesciamento dello Stato capitalista in una rivoluzione socialista, quindi accettano anche la continuazione dell'esistenza dello Stato capitalista e del sistema economico capitalista, ma rivolto verso fini più sociali.
Dei socialisti democratici di oggi, soltanto un'esigua parte spera ancora su una graduale e pacifica transizione dal capitalismo al (pieno) socialismo, attraverso l'evoluzione piuttosto che la rivoluzione. La maggior parte dei socialisti democratici però ha acquisito integralmente la visione propria della socialdemocrazia: hanno cioè aggiornato il pensiero socialista ottocentesco e non rifiutano tutti gli aspetti del capitalismo, non proponendosi di superarlo nell'immediato, ma di perfezionarlo raggiungendo l'"economia sociale di mercato" oppure l'economia mista. Essendo falliti il socialismo utopico, il socialismo rivoluzionario e il socialcomunismo, tutte le organizzazioni "socialiste" moderne dichiarano di ispirarsi al socialismo democratico e al giorno d'oggi i socialisti democratici sono quelli che chiamiamo a volte "socialdemocratici" e a volte "socialisti": ciò è dovuto al fatto che tutti i socialisti sono approdati al "socialismo democratico" divenendo "riformisti democratici". Per contro, il marxismo pre-revisionista sostiene che una rivoluzione socialista è l'unico modo pratico per implementare cambi radicali nel sistema capitalistico. Inoltre, sostiene che dopo un certo periodo di tempo sotto il socialismo, lo Stato deve "estinguersi", producendo una società comunista.
Naturalmente, lo stato non è svanito negli stati comunisti del XX secolo. Alcuni marxisti difendono ciò sostenendo che semplicemente, il periodo di transizione non si era concluso. Altri marxisti denunciano quegli stati "comunisti" come stalinisti, sostenendo che la loro leadership era corrotta e aveva abbandonato il marxismo conservandone solo il nome. In particolare, alcune scuole trotzkiste del marxismo definiscono questi stati col termine socialismo di stato per contrapporli al vero socialismo; altre correnti trotzkiste usano il termine capitalismo di stato, per enfatizzare l'assenza del vero socialismo.
I socialisti libertari si spingono oltre, deridendo anche il marxismo come socialismo di stato. Essi usano il termine principalmente come contrasto con la loro forma di socialismo, che prevede la proprietà collettiva dei mezzi di produzione senza intervento dello Stato.
In Italia, il socialismo si sviluppa e diffonde con il Partito Operaio Italiano, fondato a Milano nel 1882 e la Lega Socialista Milanese, nonché per mezzo di movimenti e leghe di derivazioni marxiste minori. Nel 1892, nasce a Genova il Partito Socialista Italiano (nato come Partito dei Lavoratori Italiani), sciolto due anni dopo dal primo governo Crispi. Il socialismo ritroverà costituzione nei governi successivi e raccoglierà nel PSI le frange riformiste e rivoluzionarie. Il partito non riesce tuttavia a far fronte alle divisioni interne e si scindono sia le correnti riformiste (la prima delle quali, espulsa nel 1912, fonda il Partito Socialista Riformista Italiano sotto la guida di Leonida Bissolati, mentre la seconda, espulsa nel 1922 diede vita al Partito Socialista Unitario (avente come leader Giacomo Matteotti e Filippo Turati), che quella rivoluzionaria del 1921 (che fonderà col congresso di Livorno il Partito Comunista d'Italia, guidato da Amadeo Bordiga, Antonio Gramsci e Nicola Bombacci ed era affiliato alla Terza Internazionale, nata nel 1919 a Mosca).
Sotto l'Italia fascista, i partiti più rappresentativi del socialismo sono sciolti ma persistono nella clandestinità. Solo con la Resistenza (e quindi a partire dal 1943) l'ideologia socialista ritrova nel Partito Socialista Italiano di Unità Proletaria: un movimento che, nel 1947, riprenderà il nome di Partito Socialista Italiano. Dopo la costituzione della Repubblica, il PSI subisce numerose scissioni, prima con la fondazione del Partito Socialista dei Lavoratori Italiani (che in seguito ingloberà la corrente di destra del PSI, guidata da Ivan Matteo Lombardo, assumendo nel 1952 la denominazione di Partito Socialista Democratico Italiano). Ciò nonostante nel 1966, i due partiti, in vista delle elezioni politiche in Italia del 1968, si riuniscono sotto il cartello elettorale PSI-PSDI Unificati, salvo ridividersi nuovamente nel 1969 con il distacco dei socialisti democratici, che si riuniscono nel Partito Socialista Unitario, il quale a sua volta tornerà a chiamarsi Partito Socialista Democratico Italiano nel 1971. Nel 1964 si era avuta anche la scissione della sinistra del partito (capeggiata da Tullio Vecchietti) che formò il Partito Socialista Italiano di Unità Proletaria, contrario ad appoggiare il primo governo di centro-sinistra organico, che si scioglierà nel 1972, confluendo in larga parte nel Partito Comunista Italiano (una parte però continuò con il Nuovo PSIUP, mentre il resto del partito, specialmente i più legati a Lelio Basso, rientrò nel PSI).
Nel 1976 si ebbe la cosiddetta svolta del Midas, che elesse alla segreteria un rampante Bettino Craxi, leader della corrente di destra (cioè quella autonomista e riformista) del partito, ma che fece confluire molti esponenti e movimenti della sinistra extraparlamentare nel PSI, i quali quindi criticavano il PCI da sinistra: per tutti i sedici anni che lo videro alla segreteria, infatti, egli si pose non solo come ago della bilancia dopo l'esperienza del compromesso storico, ma come punto di riferimento per le opposizioni nei regimi comunisti; mentre in politica interna il craxismo determinò per la prima volta nel Secondo dopoguerra il passaggio di flussi elettorali dall'area comunista a quella socialista. Dopo lo scandalo di Tangentopoli e la successiva inchiesta di "Mani pulite", nel 1992, il Partito Socialista Italiano perde consenso e si sfalda nel giro di pochi anni (subisce persino una prima scissione: Rinascita Socialista), fino al congresso della Fiera di Roma del 1994 che ne decretò lo scioglimento. La diaspora socialista porta esponenti del socialismo nella maggior parte delle attuali forze politiche, a partire dai Socialisti Italiani, la Federazione Laburista, il Partito Socialista Riformista, il Partito Socialista, i Socialisti Democratici Italiani e il Partito Socialista - Nuovo PSI (che subirà nel 2005 una scissione, con a capo Bobo Craxi, il figlio dello storico leader, favorevole al ricongiungimento a sinistra: I Socialisti Italiani), fino ai Democratici di Sinistra e persino in Forza Italia.
Nell'aprile del 2007 durante il congresso dello SDI il partito rifiuta l'ipotesi di adesione al Partito Democratico per dare vita a una costituente socialista con l'intento di riunificare tutti i partiti di ispirazione socialista che si erano smembrati dopo il 1994 per riunirsi in un unico soggetto politico. Il nuovo partito assunse il nome di Partito Socialista, per poi prendere nel 2009 il nome di PSI, come quello del partito storico.
Sempre nel 2007 non tutti i DS vogliono sciogliersi nel PD: per questo dalla corrente di sinistra del partito si scinde Sinistra Democratica che nel 2009 aderirà al progetto Sinistra e Libertà, come anche il PSI, il quale terrà un congresso l'anno successivo in cui confluiranno movimenti della sinistra radicale scissisi da Rifondazione Comunista, dai Comunisti italiani e dai Verdi per costituire il partito Sinistra Ecologia Libertà, che si pone alla sinistra del PD.
Alle elezioni politiche del 13 e 14 aprile 2008 il Partito Socialista, guidato da Enrico Boselli, non supera lo sbarramento del 4%, ottenendo solo l'1% circa e per la prima volta nella storia della Repubblica non entra in parlamento. Il 4-5-6-7 luglio al suo congresso nazionale Riccardo Nencini è eletto Segretario e il suo documento, votato all'unanimità, propone di avvicinarsi al partito Democratico, sostituendosi nell'alleanza all'Italia dei Valori.
Nel 2011 Stefania Craxi, figlia dello storico leader socialista, fonda il movimento Riformisti Italiani, in cui confluiscono anche i Socialisti Uniti, per sostenere lo schieramento della coalizione di centro-destra di Silvio Berlusconi, il quale lo stesso anno si dimette e sostiene col suo Popolo della Libertà (a cui aveva aderito il Nuovo PSI nel 2009) il governo tecnocratico di Mario Monti.
I principali partiti italiani che si richiamano in vari modi al socialismo, dalla sinistra moderata a quella radicale, oggi sono: Articolo Uno, Potere al Popolo!, Partito Socialista Italiano, Partito della Rifondazione Comunista e Sinistra Italiana.
Il Commonwealth delle nazioni o Commonwealth (acronimo CN) è un'organizzazione intergovernativa di 56 Stati indipendenti, quasi tutti accomunati (eccetto Mozambico, Ruanda, Gabon e Togo) dalla passata appartenenza all'Impero britannico, del quale esso rappresenta una sorta di sviluppo su base volontaria. La popolazione complessiva degli Stati che vi aderiscono è di oltre due miliardi di persone. La parola Commonwealth deriva dall'unione di common (comune) e wealth (benessere), cioè benessere comune.
In passato era noto anche come Commonwealth britannico, benché tale definizione esistette formalmente solo dalla fondazione nel 1926 fino al 1948. Come detto, il Commonwealth è il successore dell'Impero britannico e adempie ad una vasta gamma di funzioni.
Nel 1884 Lord Rosebery, mentre visitava Adelaide, nel Sud dell'Australia, descrisse come l'impero stesse cambiando da una situazione di colonialismo a una di maggiore indipendenza: un "Commonwealth di nazioni".
Dal 1887 si sono tenute conferenze dei Primi Ministri britannici e coloniali miranti alla creazione delle "conferenze imperiali" entro la fine degli anni '20. L'istituzione formale del Commonwealth si sviluppò effettivamente a partire da queste conferenze, in particolare dalla conferenza imperiale del 1926, che con la dichiarazione Balfour riconobbe l'indipendenza delle colonie e dei domini: in questo documento i domini e le colonie britannici concordavano di essere "uguali nello status e non inferiori al Regno Unito in alcun aspetto dei loro affari interni ed esteri, sebbene uniti da un'alleanza comune con la Corona e liberamente associati come membri del Commonwealth britannico delle nazioni". Questo rapporto venne formalizzato con lo statuto di Westminster del 1931.
In Irlanda nel 1937 venne introdotta una nuova Costituzione, che la costituiva come Stato completamente sovrano. L'ultimo legame formale con il Regno Unito venne eliminato nel 1948, quando il Parlamento (Oireachtas) approvò il Republic of Ireland Act, che dichiarò l'Irlanda una repubblica; su questa base, nel 1949 l'Irlanda lasciò il Commonwealth britannico.
Il problema dei Paesi con costituzioni indipendenti dalla Corona ma che desideravano essere membri del Commonwealth fu risolto nell'aprile del 1949 ad una riunione di Primi Ministri del Commonwealth a Londra. L'India fu d'accordo che, nel momento in cui fosse diventata una repubblica (il che avvenne nel gennaio del 1950), avrebbe accettato il re come "simbolo della libera associazione dei membri delle sue nazioni indipendenti e come tale capo del Commonwealth". Gli altri Paesi del Commonwealth a loro volta riconobbero all'India il diritto di continuare ad appartenere all'associazione; all'insistenza del Pakistan, si presunse che ad altri Stati sarebbe stato concesso lo stesso trattamento dell'India. La dichiarazione di Londra è vista spesso come punto d'inizio del moderno Commonwealth e, seguendo le orme dell'India, altre nazioni si mossero per divenire repubbliche o monarchie costituzionali sotto la guida di una casa reale diversa.
A causa della crescita del Commonwealth, il Regno Unito e i suoi domini (il termine cadde formalmente negli anni '40) divennero informalmente noti come il "vecchio Commonwealth", in particolare dagli anni '60, quando i domini più ricchi non furono d'accordo con quelli più poveri, africani e asiatici (o "nuovo Commonwealth"), sui vari problemi durante le riunioni dei capi di Stato del Commonwealth[1]. Si accusò il vecchio "Commonwealth dei bianchi" di avere interessi diversi, in particolare, dal Commonwealth delle nazioni africane e vennero a galla sentimenti carichi di razzismo e colonialismo durante gli accesi dibattiti sulla Rhodesia negli anni sessanta e settanta, l'imposizione di sanzioni contro la segregazione razziale in Sudafrica negli anni ottanta e, più recentemente, si è discusso per ottenere riforme democratiche in Nigeria e nello Zimbabwe. Il termine Nuovo Commonwealth venne usato anche nel Regno Unito (specialmente negli anni sessanta e settanta) per riferirsi a Paesi recentemente decolonizzati che sono prevalentemente sottosviluppati e abitati da popolazione non bianca. Il termine venne spesso usato anche nei dibattiti riguardanti l'immigrazione proveniente da questi Paesi.
Nei recenti anni, il termine "Commonwealth dei bianchi" è stato usato in senso spregiativo stando ad indicare che le nazioni più benestanti, con popolazione bianca, del Commonwealth avevano interessi e scopi diversi da quelle "non-bianche", e in particolare dai membri africani. Il presidente dello Zimbabwe Robert Mugabe ha usato il termine frequentemente per dichiarare che i tentativi del Commonwealth di catalizzare cambi politici nel suo Paese sono motivati da razzismo e atteggiamenti colonialisti e che il "Commonwealth dei bianchi" domina il Commonwealth delle Nazioni nella sua totalità. Ci sono stati tentativi fatti da gruppi come la Società del Commonwealth Unito per unire il Commonwealth e trovare collegamenti più stretti sia culturalmente che economicamente, cominciando con il "Commonwealth dei bianchi" ed espandendosi fino ad includere gli altri Stati membri.
Così come l'appartenenza è puramente volontaria, i governi membri possono scegliere in qualsiasi momento di abbandonare il Commonwealth. Il Pakistan rifiutò la partecipazione nel 1972 come protesta al riconoscimento della rottura col Bangladesh da parte del Commonwealth, ma si unì nuovamente nel 1989. Lo Zimbabwe se ne andò nel 2003 quando alcuni capi di governo del Commonwealth rifiutarono di eliminare la sospensione del Paese, per motivi di violazioni di diritti umani e malgoverno intenzionale.
Inizialmente il Commonwealth costituì anche un blocco economico significativo. I Paesi del Commonwealth fecero degli accordi gli uni con gli altri privilegiando l'accesso delle merci ai loro mercati ("Preferenza del Commonwealth"), e si stabilì un libero o preferenziale diritto di migrazione da un Paese ad un altro. All'entrata della Gran Bretagna nella CEE, la Convenzione di Lomé preservò alcuni diritti per le merci in arrivo dai Paesi del Commonwealth.
Negli ultimi anni si è però presentata una reciproca mancanza di interesse nel mantenere attive le relazioni intra-Commonwealth, e l'importanza politica ed economica dell'organizzazione è diminuita. Critici realisti hanno sentenziato che all'organizzazione manca un'appartenenza equilibrata, e hanno indicato che è molto insolito per un organismo internazionale escludere regioni estremamente importanti del mondo come la maggior parte dell'Europa Occidentale e del Sud America.
Nel 2013 la regina Elisabetta ha firmato la Carta del Commonwealth, un documento programmatico che impegna i Paesi membri su valori e obiettivi.
Il Commonwealth è utile come organizzazione internazionale che rappresenta collegamenti culturali e storici significativi tra Paesi del Primo mondo e Stati più poveri con diversa struttura sociale. L'eredità comune della lingua inglese e della letteratura, della legge, e dei sistemi britannici di amministrazione danno forma a delle somiglianze all'interno del Commonwealth.
La nomenclatura attuale di "Commonwealth delle Nazioni" si ritiene sufficiente a distinguerlo da altre organizzazioni quali la Comunità di Stati Indipendenti, detta in inglese Commonwealth of Independent States, o il Commonwealth d'Australia. Esso è presieduto dal re di Gran Bretagna e Irlanda del Nord, che viene riconosciuto indistintamente da ogni Stato e come tale è simbolo di libera associazione dei membri dell'organizzazione. Questa posizione, tuttavia, non concede potere politico soprannazionale. Il re governa simbolicamente il Commonwealth mentre il capo esecutivo dell'organizzazione è il segretario generale del Commonwealth che presiede il Segretariato del Commonwealth.
Il re Carlo III è anche Capo di Stato, separatamente, di quindici membri del Commonwealth, chiamati Reami del Commonwealth. Ogni Reame è indipendente e Carlo III, come monarca, detiene distintamente un titolo per ognuno di essi, sebbene tutti includano alla fine le parole "Capo del Commonwealth". Trentadue membri sono repubbliche del Commonwealth. Sei possiedono un proprio monarca (Brunei, Lesotho, Malesia, Samoa, eSwatini e Tonga).
Il Commonwealth è primariamente un'organizzazione in cui gli Stati con condizioni economiche diverse hanno l'opportunità di interagire tra loro più a stretto contatto e su basi di uguaglianza. Le principali attività del Commonwealth sono progettate al fine di creare un'atmosfera di cooperazione economica tra gli Stati membri, così come promuovere la democrazia, i diritti umani, e un governo equo in queste nazioni. Inoltre esso non è un'unione politica e non permette al Regno Unito di esercitare alcun potere negli affari interni degli altri membri dell'organizzazione. Ogni quattro anni i membri del Commonwealth celebrano i Giochi del Commonwealth, il secondo più grande evento multisportivo dopo i Giochi Olimpici.
     Membri del Commonwealth delle Nazioni     Ex membri del Commonwealth delle Nazioni (Irlanda e Zimbabwe)     Territori d'oltremare britanniciLista dei Paesi aderenti al Commonwealth delle nazioni per anno di adesione.
La Royal Commonwealth Society è un'organizzazione che promuove una maggiore affiliazione politica tra i reami del Commonwealth, rafforza i legami storici e culturali fra i membri costituenti, si oppone ai cambiamenti legislativi che possono essere nocivi ai suoi obiettivi e ai rapporti fra i membri e aumenta la cooperazione tra i suddetti Paesi.
Il termine razzismo, nella sua definizione più semplice, si riferisce ad un'idea preconcetta[1] e scientificamente errata[2], come dimostrato dalla genetica delle popolazioni e da molti altri approcci metodologici, che la specie umana (la cui variabilità fenotipica, l'insieme di tutte le caratteristiche osservabili di un vivente, è per lo più soggetta alla continuità di una variazione clinale) possa essere suddivisibile in razze biologicamente distinte, caratterizzate da diverse capacità intellettive, valoriali, etiche e/o morali, con la conseguente convinzione che sia possibile determinare una gerarchia secondo cui un particolare, ipotetico, raggruppamento razzialmente definito possa essere considerato superiore o inferiore a un altro.[3]
In "senso stretto", il razzismo, come teoria della divisione biologica dell'umanità in razze superiori e inferiori, è un fenomeno relativamente recente. In senso più ampio, invece, si tratta di una generale antica tendenza a discriminare i "diversi" (nazioni, culture, classi sociali inferiori) e la principale funzione del razzismo, in tutte le varianti, fu sempre di giustificare qualche forma di discriminazione o oppressione.[4]
Nel 1950 il documento Dichiarazione sulla razza dell'UNESCO è stato il primo documento ad aver negato ufficialmente la correlazione tra la differenza fenotipica nelle razze umane e la differenza nelle caratteristiche psicologiche, intellettive e comportamentali.[5]
A livello colloquiale, il termine "razza" riferito alla specie umana, provoca frequenti fraintendimenti, anche per l'utilizzo diverso da quello della lingua inglese, che possiede termini come race (anche in senso generico), kind (tipo, razza), breed (nel senso di ceppo zoologico) e progeny (nel senso di progenie, schiatta); con la traduzione nel differente contesto linguistico italiano, si verificano facilmente slittamenti di senso. In senso scientifico (di scienza attuale) e in lingua italiana, le razze umane non esistono, mentre quelle zoologiche sono confinate nel campo zootecnico degli animali domestici. La specie umana, come diverse altre, è soggetta ad una continua variazione clinale, senza soluzione di continuità da un gruppo ad un altro.
Il concetto di cline è stato variamente utilizzato in campo scientifico anche per lo studio di popolazioni del passato.[6] Il clustering genetico, la possibilità di analisi matematica (Cluster analysis) dei parametri biologici di una popolazione e del grado di somiglianza dei dati genetici tra individui e gruppi per inferire strutture di popolazione e quindi assegnare gli individui a gruppi, che spesso corrispondono alla loro discendenza geografica auto-identificata, è fattibile, anche utilizzando l'analisi delle componenti principali. Ci possono essere molteplici varianti di dati geni nella popolazione umana (polimorfismo). Molti geni non sono invece polimorfici, che significa che solo un singolo allele è presente nella popolazione. Queste ed altre tecniche permettono di riunire gli individui in gruppi arbitrari, utili ad esempio per lo studio di determinate patologie, e di identificare incidenze delle stesse, differenti in gruppi differenti. Questi fatti non implicano minimamente una reale suddivisione della specie, continua ed interfeconda.
Non ci sono due esseri umani geneticamente identici. Anche i gemelli monozigoti, che sviluppano da uno zigote, hanno frequenti differenze genetiche dovute a mutazioni che si verificano durante lo sviluppo. Le differenze tra gli individui, anche strettamente correlati, sono la chiave per tecniche come l'impronta genetica. I principali elementi di variazione biologica umana hanno distribuzioni indipendenti e non possono essere compresi se l'ipotetica esistenza di "razze" viene assunta come punto di partenza.[7]
Più analiticamente si possono distinguere diverse accezioni del razzismo:
Tradizionalmente, con il termine razzismo si riconduceva alla composizione di razza, dal latino generatio oppure ratio, con il significato di natura, qualità e ismo, suffisso latino -ismus di origine greca -ισμός (-ismòs), con il significato di "classificazione" o "categorizzazione", qui inteso come astratto collettivo, sistema di idee, fazione e, per estensione, partito politico che può sottintendere significati differenti. Oggi l'etimologia viene in genere interpretata in modo diverso, in quanto si suppone che il termine italiano razza, così come gli equivalenti nelle altre lingue neolatine, derivi dal francese antico haraz o haras, allevamento di cavalli; per falsa divisione del termine unito all'articolo, l'haraz diventa così la razza.[9][10]
Si potrebbe direttamente partire con una dettagliata trattazione lineare storico geografica, ma è utile premettere due paragrafi.
Grazie alla genetica, soprattutto dopo la seconda guerra mondiale, la biologia considera ormai assodato il fatto che tutti i componenti della specie Homo sapiens sapiens costituiscano un solo insieme omogeneo e che due gruppi etnici qualsiasi, il cui aspetto sia stato modificato dall'adattamento ad ambienti esterni diversi, possano essere apparentemente molto diversi, ma, in realtà, assai vicini dal punto di vista genetico.[11][12]
Al contrario, popolazioni che condividono un aspetto simile possono essere geneticamente più distanti rispetto a popolazioni di "razze" diverse ma solo se si utilizzano pochi markers genetici. Qualora invece se ne utilizzino abbastanza, in accordo con le ricerche di Edwards prima e Witherspoon dopo, il caso particolare in cui individui appartenenti a popolazioni geografiche differenti siano più distanti geneticamente che invece individui appartenenti alla medesima popolazione geografica non si verifica mai. Questa apparente contraddizione è nota col nome di fallacia di Lewontin.[13][14]
Il termine razza non è in ogni modo utilizzato in biologia per la classificazione tassonomica ma solo in zootecnia e viene applicato solamente agli animali domesticati.Per fare un esempio, la diffusione di un determinato allele in popolazioni diverse può presentarsi con maggiori somiglianze fra una popolazione europea ("bianca") ed una africana, che fra due popolazioni europee. Le differenze tra le cosiddette "razze" umane riguardano infatti unicamente l'aspetto esteriore, modificato per adattarsi all'ambiente man mano che la specie umana si diffondeva per tutto il mondo; ed ovviamente l'aspetto esteriore è il dato che salta maggiormente all'occhio. Tuttavia esso coinvolge una frazione relativamente insignificante dell'intero genoma dell'uomo. Ecco perché individui che discordano vistosamente su pochi geni, relativi al colore della pelle o al taglio degli occhi, possono poi condividere caratteristiche genetiche molto più complesse ed importanti, anche se non altrettanto vistose.
Anzi, se c'è un aspetto che caratterizza l'Homo sapiens sapiens al paragone con molte specie animali, esso è semmai la straordinaria omogeneità genetica, causata dal fatto che tutti gli esseri umani discendono da un numero ristretto di antenati, evolutisi in un tempo assai recente (circa centomila anni fa), e rimescolatisi di continuo nel corso della loro storia. Eventuali differenze fenotipiche esteriori si possono al più collocare nella cosiddetta variazione geografica o cline, nello studio strettamente tecnico riguardante la genetica delle popolazioni.
Il discorso, di tipo generale, è ugualmente estendibile ad aspetti di ambito medico quali la distribuzione nella popolazione delle patologie, o la relativa diversa sensibilità ai farmaci.[15][16]
Questa premessa non era e non è condivisa dal razzismo. Secondo l'ideologia razzista, le differenze di aspetto rispecchiano la divisione effettiva in razze della specie umana. Particolare non secondario, il razzismo professa sempre la superiorità di una "razza" rispetto ad altre, sostenendo che la "razza" superiore è quella a cui appartiene il sostenitore del razzismo, e giustificando così un'eventuale discriminazione e/o oppressione di coloro i quali sono considerati inferiori.
Il razzismo, inteso come teoria pseudoscientifica, fu una delle giustificazioni ideologiche del colonialismo del XIX e XX secolo, del mantenimento della schiavitù nel XIX secolo, oltre che della discriminazione di gruppi sociali in condizioni di inferiorità, come per esempio nel caso dell'apartheid.
«Ciò che la biologia può definitivamente affermare è che [...] il meccanismo di trasmissione della vita è tale per cui ciascun individuo è unico, gli individui non possono essere gerarchizzati, e la sola ricchezza è collettivitàː essa è fatta di diversità. Tutto il resto è ideologia»
(François Jacob premio Nobel per la medicina nel 1965[17])Razzismo scientifico è l'espressione utilizzata per indicare una particolare forma storica di razzismo organizzato, fondata a partire dal XIX secolo in Europa e nelle Americhe, che nasce in ambito universitario tra le scienze naturali e sociali dell'epoca, prendendo inizio dalla biologia, dalla antropologia, dalla genetica, dalla medicina, dalla criminologia e dalla sociologia, rifacendosi alla teoria evoluzionista di Charles Darwin e al positivismo.
Premessa oggi ritenuta infondata di questa teoria pseudoscientifica fu quella di ritenere che gli esseri umani fossero costituiti da razze diverse, ognuna a un grado diverso di evoluzione rispetto alle altre, e che i metodi di classificazione della zoologia potevano essere utilizzati per indagare le caratteristiche delle stesse. In questa classificazione si ammisero graduatorie che presupponevano alcune "razze" come superiori per livello evolutivo e intellettivo rispetto alle altre. In particolare essa credette di documentare che la cosiddetta "razza bianca" (e all'interno della razza bianca di una razza particolare, la razza ariana) fosse il livello massimo raggiunto dall'evoluzione naturale della specie umana.
Sostenendo l'esistenza di "razze superiori" queste teorie diedero il via alla nascita dell'eugenetica (eu = buona; genia = discendenza), altra pseudoscienza che mirava alla preservazione della purezza del patrimonio genetico dei popoli "sani" privi cioè di mutazioni genetiche o presunte tali che avevano l'effetto di trasmettersi alla prole, sostenendo una campagna politica contro i matrimoni e i rapporti interrazziali che potessero portare alla nascita di figli "razzialmente impuri" e malati. Fine ultimo influenzare l'evoluzione genetica del genere umano eliminando ogni presunto difetto.
Assertori di questa teoria furono esponenti di primo piano, al massimo livello, delle scienze naturali e sociali di tutto il mondo, per oltre un secolo. La classificazione delle cosiddette "razze" fu lungamente utilizzata per ragioni politiche, e dibattuta tra gli scienziati, che non riuscivano a raggiungere risultati universalmente condivisi. Maggioritariamente, dal 1870 al 1936 essa sosteneva la superiorità di una presunta "razza nordica" o germanica, su tutte le altre.
Usate durante il XIX secolo a sostegno del colonialismo e del diritto alla schiavitù, l'esito politico più vistoso di queste teorie nel XX secolo furono le leggi razziali in molte parti del mondo (USA, Francia, Gran Bretagna, Germania, Spagna, Sudafrica, Svezia, Portogallo, Belgio, Canada) le leggi razziali fasciste in Italia, e infine lo sterminio nazista delle razze "inferiori".
Il razzismo scientifico venne rifiutato politicamente e scientificamente solo dopo la fine della seconda guerra mondiale, quando con la pubblicazione della «Dichiarazione sulla razza» nel 1950 l'UNESCO negò in modo ufficiale la correlazione tra la differenza fenotipica nelle razze umane e la differenza nelle caratteristiche psicologiche, intellettive e comportamentali e incoraggiò i numerosi biologi a ricordare costantemente l'assenza di validità scientifica della nozione di "razze umane".
A seguito di ciò le stesse teorie non sono però del tutto scomparse, ma ancora oggi vengono in gran parte riproposte da alcune minoranze politiche estremiste semplicemente sostituendo alla parola "razza" quella di "etnia", "popolo", "cultura" o "civiltà". Sostituendo all'elemento biologico (non più riproponibile scientificamente) quello culturale, essi riescono a mantenere intatta la stessa precedente impostazione "pseudo-scientifica".
Il razzismo scientifico è stato preceduto e seguito da altre forme di razzismo organizzato, detto anche pre-scientifico. Nel merito di quest'ultimo la parola "razza" non è sempre riferita a un tipo biologico, ma al senso più generale di "categoria" o "genere". Quest'altra forma di razzismo non è meno importante, e in dettaglio prende molti nomi specifici a seconda dell'oggetto della discriminazione: classismo se riferito alla discriminazione in base alla classe sociale, casteismo se in base alla casta di appartenenza, sessismo se in base al sesso, ecc.
Le teorie razziste nacquero nel Medioevo quando i sovrani cristiani vollero impadronirsi dei beni dei banchieri ebrei; si svilupparono poi nel XVI secolo, quando Spagna e Portogallo impiegarono schiavi Africani per le loro colonie. Esse assunsero un'importanza politica nel XIX secolo quando cominciò a diffondersi il mito della razza ariana. Questa ipotetica razza servì a Joseph Arthur de Gobineau per giustificare i privilegi dell'aristocrazia e spiegare l'antagonismo tra essa e le masse popolari.
Però la maggior parte delle suddivisioni storiche datano l'inizio della storia moderna al 1492, e anche le radici del razzismo moderno si legano a questa data.  A seguito dell'unificazione delle corone spagnole, il 31 marzo 1492 Ferdinando II d'Aragona ed Isabella di Castiglia firmano il decreto che espelle tutti gli Ebrei dalla Spagna. L'inquisizione spagnola, personificata nella figura di Tomás de Torquemada, diventa il braccio attivo della politica della corona nell'attuazione della epurazione.  Si crea il concetto di purezza del sangue, base ideologica degli statuti di limpieza de sangre promulgati alla fine del secolo.[18]
Nello spirito di questi statuti, tesi a analizzare la stirpe originaria della persona, non il suo credo religioso attuale, si riconoscono infine quelli promulgati nel 1496 da Papa Alessandro VI dove si approva un codice di purezza anche per gli ordini monastici, come quello dei Hieronymiti.[19]  Questi sono primi esempi classici di razzismo ideologico con profonde radici utilitaristiche. Durante il periodo dell'espulsione di alcune centinaia di migliaia di persone, le vittime furono numerose. Con questo atto si pose fine a una lunghissima convivenza produttiva sul territorio iberico di tutte le etnie del mediterraneo. Il massacro di Lisbona del 17 aprile 1506, viene ricordato come un'altra vicenda atroce (migliaia di morti in poche ore, molti dei quali arsi vivi) della penisola Iberica, figlia delle conseguenze delle leggi razziali dell'epoca.
Un fattore da considerare in una prospettiva storica, è che il razzismo è un fenomeno connesso all'età coloniale, quando le grandi potenze europee svilupparono ideologie razziste per risolvere la dissonanza tra valori cristiani di eguaglianza e carità e lo sfruttamento delle popolazioni indigene in America come in Africa.
Prima di quest'epoca la xenofobia può spesso esprimersi direttamente come tale: l'altro è inferiore in quanto "non è come noi" e ci è "quindi" ostile (in greco antico ξενός, "xenos", significa sia "straniero" che "nemico"), perché parla una lingua diversa dalla nostra ("barbaro" in greco significa letteralmente "il balbettante"), perché non professa la nostra religione, perché non si veste come noi (in molte lingue i concetti di "straniero", "strano" ed "estraneo" hanno la stessa radice linguistica, che in italiano è quella del latino "extra": "che viene da fuori").
Tuttavia la società antica preferisce stratificare l'umanità in base a concetti castali, più che razziali: il nobile è ovviamente superiore al plebeo, e il plebeo libero è superiore allo schiavo. Ed ovviamente le caratteristiche dell'individuo inferiore (il suo modo di parlare, di vestire, di comportarsi) "giustificano" pienamente la sua condizione sociale inferiore. Inoltre non va dimenticato che per la gran parte le società premoderne (come ancora molte delle società moderne) sono sessiste, ritenendo cioè che tutti i maschi della razza umana siano biologicamente superiori (più forti, più intelligenti, più morali...), per il solo fatto di essere tali, a tutte le femmine della razza umana.
Ciò detto, la mentalità premoderna in generale non avrebbe giudicato uno schiavo bianco superiore a un nobile - ad esempio - arabo in base alla sua sola appartenenza a una presunta "razza". Se si cercava una superiorità, essa veniva trovata nella cultura, nell'etnia, nella religione: ogni cristiano è superiore ad ogni infedele, dunque anche uno schiavo cristiano è, "moralmente", ma non socialmente, superiore a un principe musulmano. Ma se il principe musulmano si converte al Cristianesimo, viene meno tale inferiorità e prevale nuovamente la superiorità sociale di casta.
La società premoderna considera insomma la "razza" non come un dato immutabile e di primo piano, ma come un dato transitorio e secondario, destinato ad annacquarsi col passare delle generazioni: si ebbero così papi discendenti da famiglie ebraiche convertite, o bastardi di nobili generati con schiave nere (quindi mulatti) legittimati dai loro genitori, come pure ex schiavi "mori" nordafricani (come per esempio Leone Medici/Leone Africano) adottati da nobili famiglie.
Tutto ciò non implica accettazione del diverso: la società antica ha anzi un vero orrore per le novità e la non-conformità; implica però che la diversità motivata dall'appartenenza razziale appare ai nostri avi meno importante di altre diversità, come quelle legate al "rango sociale" o di altro tipo, che invece per la mentalità moderna sono meno importanti. Non a caso il razzismo in quanto ideologia pseudoscientifica sorge nel momento in cui questo antico criterio di valutazione è ormai in piena crisi dopo la Rivoluzione francese, e non è un caso che uno dei suoi fondatori, de Gobineau, sostenga la superiorità della razza germanica solo per giustificare la superiorità della classe sociale che secondo lui ne discende in Francia (la nobiltà, che è la classe a cui egli appartiene ed il cui monopolio assoluto del potere egli vuole giustificare in questo modo).
A questa generalizzazione si oppone la già citata "limpieza de sangre" "purezza di sangue" che la nobiltà iberica propone nel tardo Rinascimento per respingere l'ascesa degli ebrei e dei moriscos convertiti al cristianesimo, e quindi (teoricamente) integrati nella società spagnola dell'epoca. Quindi, una volta di più, il razzismo quattro-cinquecentesco è un'ideologia escogitata da una casta endogama, e non da una "razza", intesa in senso biologico.
Il concetto di "limpieza de sangre" sarebbe stato applicato anche ai danni delle popolazioni indigene dell'America prima, ed agli schiavi neri ivi importati poi, nonché degli iberici spagnoli che si erano mescolati con essi, creando una società in cui la stratificazione sociale era legata anche al gruppo etnico di appartenenza. Una società estremamente conscia dell'appartenenza razziale, al punto da conoscere non solo concetti come quello di "mulatto" o "meticcio", ma anche quelli di quarteron e octavon, cioè di persona con solo un quarto o un ottavo di sangue nero, o di zambo, cioè meticcio metà nero e metà indio, e via via con ulteriori sottodivisioni.
Paradossalmente, però, tale acuta coscienza delle differenze "razziali", che certo non è sbagliato definire "razzista", fu la reazione a un diffusissimo fenomeno di "mescolamento" delle razze da parte degli iberici non appartenenti alla nobiltà, i cui effetti si osservano agevolmente ancora oggi in tutta l'America Latina. Non mancò neppure qualche nobile che non disdegnò il matrimonio con i discendenti della nobiltà indigena India, per acquisire maggiore legittimità nel suo dominio agli occhi della popolazione dominata.
Questo fenomeno mostra quanto il razzismo ("non scientifico") iberico fosse qualitativamente diverso dal successivo razzismo ottocentesco, che fra i suoi primi scopi dichiarati ebbe appunto quello di impedire il mescolamento fra le razze umane, sempre nocivo per la razza "superiore" (cioè i bianchi).
Da questo punto di vista, un passo avanti verso il vero e proprio razzismo, inteso come teoria scientifica, si ebbe piuttosto negli Usa, dove nel dibattito infuocato relativo all'abolizione della schiavitù a metà del XIX secolo, uno degli argomenti azzardati dai suoi sostenitori fu che neri (e indiani) non fossero "davvero" esseri umani, ma andassero catalogati in una categoria diversa, alla quale non si potevano applicare le argomentazioni umanitarie proposte dagli abolizionisti. Non essendo i neri uomini, non aveva senso essere "umanitari" con loro.
L'atteggiamento di discriminazione razziale su base pseudo-scientifica fu rafforzato dalle guerre indiane, per giustificare il genocidio, protratto per decenni, delle popolazioni pellerossa per sottrarre loro le terre: gli indiani non erano "davvero" esseri umani, e quindi nemmeno a loro si applicavano le considerazioni "umanitarie". La conquista del continente americano portò a un totale di morti indigeni che secondo le stime più recenti oscilla tra i sessanta e i cento milioni,[20] di cui venti milioni durante le guerre indiane nel Nord America. Queste cifre lo eleggono tristemente come il più grande genocidio nella storia dell'umanità. L'efficienza dello sterminio indiano americano portò Adolf Hitler a citarlo come esempio pratico per la soluzione finale[21] fin nella prima edizione del Mein Kampf (la mia battaglia),[22] manuale e base ideologica dell'ideologia Nazionalsocialista. Secondo l'antropologo e sostenitore della causa dei nativi Philippe Jacquin la drastica riduzione della popolazione pellerossa fu causata dalle nuove malattie introdotte dai coloni, il maggiore atto di violenza fu quello avvenuto nel 1890 a Wounded Knee, (Dakota) dove in seguito a un'occasionale scontro si ebbero 300 morti fra i pellerossa e una ventina fra i soldati[23].
Nell'America coloniale, ancor prima che la schiavitù coloniale divenisse completamente basata su basi razziali, gli schiavi di origine africana erano usati a fianco dei cosiddetti schiavi bianchi, di solito vincolati da contratti con una scadenza determinata, in gran parte firmati per pagare le spese di trasferimento nel Nuovo Mondo. Alla scadenza di tali contratti gli europei che erano sopravvissuti recuperavano la libertà (non era previsto che i neri potessero recuperare la libertà alla scadenza di un certo periodo di tempo).
A seguito di una serie di rivolte che coinvolsero questo tipo di coloni, però, negli Usa si arrivò a fare a meno degli schiavi bianchi già nel XVIII secolo, riservando la schiavitù alle persone di origine africana, che non potevano contare, a differenza dei bianchi, di solidarietà religiose e etniche da parte di componenti liberi della società bianca dominante. In questo modo, "razza" e condizione sociale vennero a coincidere negli Usa, in modo tale che ancor oggi negli Stati Uniti è difficile separare i due concetti.
Subito dopo l'indipendenza (avvenuta nel 1776) le leggi statunitensi del 1790 sulla naturalizzazione garantivano la cittadinanza solo alle "persone bianche libere", il che significava generalmente che veniva concessa solo a coloro che erano di origine anglosassone.
Quando la popolazione americana divenne culturalmente meno omogenea, verso gli anni '40 del XIX secolo, con l'aumento dell'immigrazione dall'Europa meridionale e orientale, negli USA si rese necessario chiarire chi fossero i "bianchi". Nacque così una suddivisione di quelli che oggi sono chiamati «caucasici» in una gerarchia di diverse razze, stabilite "scientificamente", e al cui vertice erano gli anglosassoni e i popoli nordici.
Il tema del razzismo durante il governo nazionalsocialista in Germania, rivolto alla popolazione ebraica, ma anche verso molti gruppi etnici come Rom, Sinti e diverse categorie sociali (riunite sotto la definizione di Untermenschen) viene ampiamente trattato sotto la voce Olocausto.
Secondo un rapporto presentato all'Assemblea parlamentare del Consiglio d'Europa, "la società italiana ha visto un incremento nelle attitudini razziste, nella xenofobia e contro gli zingari nel discorso pubblico, particolarmente sui media e su internet".[24]
In Polonia i nazisti riuscirono quasi a imporre un dogma mitologico, prima contro gli ebrei poi contro i polacchi, che privava tutti coloro che venivano definiti "non ariani" dei diritti civili e del lavoro. 
Un polacco ebbe a dire: «La fortuna è venuta a noi tramite Hitler. Egli ci sta preparando una Polonia senza Ebrei».[25] Vi furono, tuttavia, alcune eccezioni.[26] Dopo la liberazione, secondo alcune fonti[27] la maggior parte della popolazione conservò un'opinione positiva della repressione. Nel luglio 1946 uno spaventoso pogrom antisemitico nella città polacca di Kielce costò la vita a quarantuno ebrei. In Polonia persino dopo la guerra, alcuni membri della Chiesa cattolica continuarono ad avere una parte di primo piano nell'incoraggiare e nel mantenere vivo l'antisemitismo.[28]
In Giappone i casi di discriminazione e razzismo riguardano soprattutto le minoranze etniche presenti nel Paese, talvolta emarginate e trattate con disparità in ambito lavorativo, scolastico e sociale dai giapponesi di etnia Yamato, questi ultimi considerati i discendenti del gruppo etnico nativo dominante dell'arcipelago giapponese. Secondo un rapporto del 2006 a cura dell'ONU le minoranze più discriminate in Giappone sono la popolazione Ainu, i Burakumin, i Ryukyuani, i discendenti degli immigrati dai paesi vicini (Corea e Cina) e i nuovi immigrati giunti da altri paesi (ad esempio brasiliani, filippini e vietnamiti). Ciò è dovuto principalmente alla tradizionale convinzione dei giapponesi che solo persone del loro ceppo siano in grado di capire e apprezzare la loro cultura.
Nonostante la costituzione giapponese proclami l'uguaglianza di tutti i cittadini davanti alla legge, senza distinzione di razza, genere e religione, il sistema legislativo nipponico non prevede pene ai danni di coloro che compiono attività discriminatorie.
Tradizionalmente, il razzismo russo include l'antisemitismo e la tatarofobia, così come l'ostilità verso varie etnie del Caucaso, dell'Asia centrale ed orientale e dell'Africa.[29] Nel 2006, Amnesty International ha riferito che il razzismo in Russia era "fuori controllo".[30]
In Australia la popolazione aborigena è stata decimata dalla colonizzazione, iniziatasi nel 1788. Una combinazione di omicidi ha ridotto la popolazione aborigena di circa il 90% tra il XIX secolo e il XX secolo. Un'onda di massacri e tentativi di resistenza si mosse con la frontiera. L'ultimo massacro fu a Coniston, nel Territorio del Nord, nel 1928. Anche se i primi colonizzatori furono ben accolti, ci furono violenti scontri.
L'apartheid o separazione in lingua afrikaans è stata la politica di segregazione razziale istituita dal governo di etnie bianche (Afrikaner e di origine inglese) del Sudafrica nel secondo dopoguerra, rimasta in vigore fino al 1994. L'apartheid fu applicato anche alla Namibia, fino al 1990 amministrata dal Sudafrica. La segregazione era applicata a tutti i non bianchi, asiatici e figli di genitori di etnie assortite compresi.
L'apartheid è stato proclamato crimine internazionale da una convenzione delle Nazioni Unite, votata dall'Assemblea Generale nel 1973 e entrata in vigore nel 1976, ed è stato recentemente inserito nella lista dei crimini contro l'umanità perseguibili dalla Corte penale internazionale.
La presunta questione razziale ruandese, per l'informazione occidentale si rivela principalmente nel genocidio del 1994, uno dei più sanguinosi episodi della storia del XX secolo, dove vennero massacrate tra le 800 000 e 1 071 000 persone.
Le vittime furono in massima parte di etnia Tutsi (Watussi); i Tutsi erano una minoranza rispetto agli Hutu, gruppo etnico maggioritario a cui facevano capo i gruppi principalmente responsabili dell'eccidio. I massacri non risparmiarono una larga parte di Hutu moderati. A dispetto dell'atrocità del fatto, si riscontra che dal punto di vista della genetica di popolazione i due gruppi sono estremamente affini, e come nella stragrande maggioranza dei fenomeni razzisti le differenze sono principalmente di tipo sociale e culturale.
La lingua turca (nome nativo Türkçe o Türk dili, Türkiye Türkçesi) è una lingua appartenente al ceppo Oghuz delle lingue turche, lingua ufficiale in Turchia, a Cipro e a Cipro del Nord. Significativi gruppi minori di turcofoni, nativi o immigrati, sono presenti in Iraq, Siria, Germania, Austria, Bulgaria, Macedonia del Nord, Grecia, Caucaso e altre parti dell'Europa e dell'Asia centrale. Al 2022, è parlata da 88,1 milioni di parlanti totali[1].
Il turco era parlato nell'Impero ottomano usando, per la forma scritta, una versione modificata dell'alfabeto arabo. Nel 1928 Mustafa Kemal Atatürk, nei suoi sforzi per modernizzare la Turchia, sostituì l'alfabeto arabo con una versione modificata dell'alfabeto latino. Ora il turco è regolato dall'Organizzazione linguistica turca.
Il turco fa parte di un insieme di lingue tra loro strettamente correlate che include anche il turco balcanico, il gagauzo e il turco khorasani. Appartiene al sottogruppo delle lingue turche meridionali, che a loro volta appartengono al gruppo delle lingue turche, che alcuni linguisti considerano essere parte della disputata famiglia linguistica altaica (che è considerata essere parte dell'ancora più disputata famiglia linguistica uralo-altaica).
Il turco è parlato in Turchia e da minoranze di 35 altri paesi. È usato in stati come l'Azerbaijan, la Bulgaria, la Grecia, la parte settentrionale di Cipro, occupata dalla Turchia fin dal 1974, la Macedonia del Nord, il Kosovo e l'Uzbekistan.
Il turco è la lingua ufficiale della Turchia e della Repubblica Turca di Cipro del Nord e una delle lingue ufficiali di Cipro.
Come conseguenza dell'originaria idea nazionalista di fissare il dialetto di Istanbul come uno standard, la dialettologia rimane una disciplina fortemente immatura in Turchia. La lingua standard è essenzialmente l'ottomano emendato, scritto con l'alfabeto latino (e non più quello arabo), con l'incentivazione dei neologismi e l'esclusione dei prestiti linguistici dall'arabo e dal persiano. La forma colloquiale dominante si chiama İstanbul Türkçesi come testimoniato nei lavori di eminenti panturchisti come Ziya Gökalp (Güzel dil, Türkçe bize / Başka dil, gece bize. / İstanbul konuşması / En saf, en ince bize) e İsmail Gaspıralı. Accademicamente ci si riferisce spesso ai dialetti turchi come ağız o şive, facendo confusione con il concetto linguistico di accento. Il turco manca ancora di un atlante dialettologico completo ed è determinante l'assimilazione entro il turco ufficiale.
I principali dialetti turchi includono:
Dopo l'assunzione dell'Islam come religione ufficiale degli Ottomani, la lingua turca acquisì un vasto numero di prestiti dall'arabo e dal persiano. La letteratura turca, durante il periodo ottomano, specialmente la poesia Diwan, fu fortemente influenzata da forme persiane, con l'adozione dei metri della poesia persiana e infine con l'apporto di un gran numero di parole persiane in turco. Negli oltre seicento anni dell'impero ottomano, la lingua letteraria e ufficiale fu una miscela di turco, persiano e arabo, che differiva considerevolmente dal turco parlato dell'epoca e che viene oggi denominata turco ottomano.
Dopo l'instaurazione della Repubblica, nel 1923 fu istituita un'associazione per la lingua turca (Türk Dil Kurumu, TDK) da parte di Mustafa Kemal Atatürk, allo scopo di condurre ricerche sul turco. Uno dei compiti della neonata associazione fu quella di sostituire i prestiti di origine araba e persiana con equivalenti turchi. La riforma linguistica del 1928 costituì una parte delle più ampie riforme culturali in corso all'epoca (che erano a loro volta una parte della più vasta struttura delle riforme di Atatürk) e inclusero l'abolizione dell'alfabeto arabo a favore del nuovo alfabeto turco derivato da quello latino, che ha molto contribuito ad aumentare il tasso di alfabetizzazione popolare. Vietando l'uso dei prestiti nella stampa, l'associazione riuscì a rimuovere centinaia di parole arabe dalla lingua. Benché la maggior parte delle parole introdotte dal TDK fossero nuove, esso suggerì pure di riutilizzare antichi termini turchi non più in uso da secoli.
I giovani e gli anziani, in Turchia, tendono a esprimersi con un vocabolario differente a causa di questo repentino cambiamento. Mentre i nati prima degli anni quaranta ricorrono ai vecchi termini di origine araba, i più giovani preferiscono le nuove espressioni. Alcuni neologismi non sono usati altrettanto spesso dei loro vecchi equivalenti, o non sono riusciti a riprodurne esattamente il significato. Il dibattito su vecchio e nuovo nella lingua turca ha anche un significato politico, mentre d'altro canto i settori più religiosi della popolazione tendono a far uso di parole arcaiche sia nella stampa sia nella lingua quotidiana. Di conseguenza, il diverso uso del turco è indicativo dell'adozione o della resistenza alle riforme di Atatürk, avvenute ormai più di settant'anni fa. Gli ultimi decenni hanno visto da parte del TDK una continua opera di creazione di nuove parole turche per rappresentare concetti e tecnologie moderne, che tendono a entrare nella lingua come prestiti (principalmente inglesi), ma l'associazione viene talora criticata per il conio di parole che suonano artificiose e "inventate".
Comunque, molte delle parole introdotte dal TDK convivono con gli originali. I vari sinonimi - provenienti dal turco antico o introdotti dall'associazione, di origine araba o persiana, o talora provenienti da altre lingue europee come il francese - sono usati per esprimere significati leggermente diversi, specie allorché si parla di cose astratte. È grossomodo ciò che avviene con l'uso delle parole germaniche e di origine romanza in inglese.
Fra le parole sostituite c'è la terminologia geometrica, i punti cardinali, i nomi di alcuni mesi e molti sostantivi e aggettivi. Molte nuove parole sono state tratte da antiche radici verbali.
Una delle caratteristiche del turco è l'armonia vocalica (se la prima vocale di una parola turca è una vocale palatale, la seconda e le altre vocali della parola o sono la stessa o sono altre vocali palatali; es.: Erdem). Si veda anche la Ğ ("g dolce" o "g morbida"). Nonostante le parole turche siano composte con questa regola, esistono delle eccezioni, che includono i prestiti stranieri.
L'accento, tranne nei prestiti, in alcuni nomi propri di luogo (toponimi), in alcune interrogative e in alcuni avverbi, è sull'ultima sillaba. Se una parola ha già l'accento sull'ultima sillaba, nel momento in cui si crea una catena di suffissi esso si sposterà sull'ultima sillaba del composto. Se il composto ha una radice verbale (e quindi è la voce di un verbo), l'accento cade sul suffisso che stabilisce il tempo, che precede la persona. Se il verbo è negativo, l'accento cade prima del suffisso del negativo.
L'accento è disambiguato nei dizionari ed è orientato verso l'alto (ad esempio, İstánbul).
A volte sopra le vocali di prestiti arabi e persiani o di alcuni nomi propri (ad esempio, "Lâmia", nome proprio femminile) può trovarsi l'accento circonflesso ^ , che fa sì che si leggano più lunghe. Questa grafia, nei prestiti, differenzia la grafia e pronuncia di due parole altrimenti identiche (ad esempio: "hala", zia paterna; " hâlâ ", ancora/di nuovo). Si può trovare pure in aggettivi di derivazione araba come allungamento della "i" finale, che in grafia perde il punto (ad esempio, " millî ", nazionale).
Le consonanti dell'alfabeto turco, inclusa la Y/y semivocalica, sono le seguenti:
Il turco, come il finlandese e l'ungherese, è una lingua agglutinante. Essa possiede moltissimi suffissi e pochi prefissi. La sintassi della frase è Soggetto Oggetto Verbo come nel giapponese. La grammatica turca è sistematica ed ha un unico sostantivo irregolare su (acqua) ed un unico verbo irregolare, "essere", che difetta dell'infinito (come anche delle forme indipendenti, si supplisce con il verbo olmak).
Come si è detto esistono due gruppi vocalici: "e i ö ü" (vocali anteriori) e "a ı o u" (vocali centrali e posteriori). Ogni suffisso e desinenza ha due o quattro forme con una vocale scelta da ciascuno dei gruppi. Considerando l'ultima vocale della parola alla quale deve essere aggiunto il suffisso si sceglierà la forma dello stesso gruppo vocalico. Questa regola è chiamata anche armonia vocalica.
Esempio 1: il suffisso del plurale ha due forme: può essere -lar se nell'ultima sillaba c'è una vocale posteriore o centrale o -ler in presenza di una qualunque vocale anteriore, a prescindere dal fatto che sia arrotondata o no. Nei verbi, il suffisso dell'infinito di un qualunque verbo nel dizionario è, per lo stesso principio, -mak o -mek (ad esempio, okumak, "leggere"; görmek, "vedere")
Esempio 2: un suffisso con cui si creano dei nomi in turco, -lir, ha 4 forme: -lik, -lük, -lık, -luk. La prima si usa dopo una vocale anteriore nella radice (e, i), la seconda se in più è arrotondata, la terza se è centrale o posteriore, la quarta se in più è arrotondata. In generale, i suffissi del turco funzionano tutti in questa maniera e con queste vocali nelle combinazioni, quindi sono divisibili in due grandi classi: a 2 varianti e a 4 varianti. In generale, nella seconda classe, la vocale di ogni combinazione è quella in cui la posizione della punta della lingua è la più alta (ad esempio, la "i" è più alta della "e", idem nelle versioni arrotondate; la "u" ha il dorso della lingua in posizione più sopraelevata della "o").
Come il latino e altre lingue, il turco declina il sostantivo secondo 6 casi: nominativo, genitivo, dativo, accusativo, ablativo e locativo.
*Utilizzato solo con sostantivi definiti, in caso contrario si utilizza il caso nominativo. Es.: Bir kitap okuyorum (leggo un libro), Kitabı okuyorum (leggo il libro).
La coniugazione dei verbi turchi è la seguente:
konuşmak (parlare)
içmek (bere)
söylemek / demek (dire)
Il turco è scritto con una versione modificata dell'alfabeto latino, introdotta nel 1928 da Kemal Atatürk insieme ad altre misure prese per modernizzare la Turchia. Sino al 1928 per scrivere il turco si utilizzava una versione modificata dell'alfabeto arabo (vedi turco ottomano), che divenne illegale dopo quella data.
Per i numeri dall'undici al diciannove, letteralmente sono "dieci uno", "dieci due" e così via.
Il Genji monogatari (源氏物語? lett. "Il racconto di Genji") è un romanzo dell'XI secolo scritto dalla poetessa e scrittrice Murasaki Shikibu vissuta nel periodo Heian, considerato uno dei capolavori della letteratura giapponese così come della letteratura di tutti i tempi. I critici letterari si riferiscono ad esso come al "primo romanzo", il "primo romanzo moderno" o il "primo romanzo psicologico".
Il romanzo narra la vita di Genji, un figlio dell'Imperatore del Giappone, conosciuto anche come Hikaru Genji, Genji lo splendente. Nessuno dei due epiteti tuttavia è il suo vero nome. Genji è semplicemente un modo di leggere il kanji che indica il clan Minamoto, realmente esistito, dal quale Genji era stato adottato per ordine imperiale; per ragioni politiche (Genji era figlio di una moglie secondaria dell'Imperatore) infatti, Genji non poteva appartenere ufficialmente al ramo principale della famiglia imperiale e dovette iniziare la sua carriera politica da semplice funzionario di corte.
Il romanzo ruota intorno alla sua vita amorosa e tratteggia la vita ed i costumi della società di corte del tempo. Pur incarnando il modello tipico del libertino (certamente influenzato dalla figura di Ariwara no Narihira), Genji mostra una particolare lealtà verso tutte le donne della sua vita, non abbandonando mai nessuna delle sue mogli (vigeva la poligamia) o concubine - in un'epoca in cui la perdita di un protettore per molte dame di corte significava l'abbandono ed una vita ai margini della società (fu questa la sorte anche della principale rivale di Murasaki Shikibu, Sei Shōnagon).
Genji era il secondogenito di un Imperatore del Giappone e di una concubina, di basso rango ma dotata di grande avvenenza e leggiadria. La morte della madre, avvenuta quand'era ancora bambino, lascerà in lui la figura materna vacante, e per tutta la vita cercherà una donna ideale spesso vagheggiata. Crederà di trovarla in Dama Fujitsubo, una nuova concubina dell'Imperatore suo padre, giovane e leggiadra, molto somigliante alla madre scomparsa, ma in quanto sua matrigna una donna assolutamente proibita. Nella prima parte del romanzo i due, che si scoprono innamorati, cercheranno di reprimere i loro sentimenti, Fujitsubo chiudendosi nel riserbo e Genji, da poco sposato con la principessa Aoi, sorella del suo miglior amico Tō no Chūjō, lanciandosi in continue avventure che però non riescono mai a soddisfarlo spegnendo il desiderio per la dama.
Per curarsi da una malattia, Genji visita Kitayama, la regione delle colline che cingono a nord Kyoto. È qui che incontra una bambina, Murasaki, che lo incuriosisce e che scopre essere nipote di Fujitsubo. La porta a vivere con sé, curandone l'educazione per trasformarla nella sua dama ideale. Nel frattempo riesce ad incontrare Dama Fujitsubo ed i due finiscono per avere un figlio, che però viene riconosciuto dall'Imperatore e diviene Principe ereditario, rendendo Fujitsubo imperatrice. I due amanti giurano di non rivelare mai il loro segreto.
Genji e la principessa Aoi si riconciliano ed ella dà alla luce un figlio, ma muore poco dopo il parto posseduta dallo spirito di Dama Rokujō, un'antica amante del principe ossessionata dalla gelosia. Genji trova consolazione in Dama Murasaki, ormai cresciuta, che sposa a Kitayama. Alla morte dell'Imperatore, ha il sopravvento a corte un fazione ostile a Genji, che approfitta della prima occasione - lo scandalo che coinvolge lui e la concubina del fratello, l'Imperatore Suzaku - per esiliarlo nella provincia rurale di Harima, lontano dalla capitale. Qui un ricco possidente, Akashi no Nyūdō, ospita Genji e lo incoraggia ad intrecciare una relazione con la figlia, Dama Akashi, che gli darà una figlia - destinata a divenire Imperatrice.
Il perdono del fratello riporta Genji a Kyōto, dove conduce anche Dama Akashi. Il figlio suo e di Fujitsubo (ormai scomparsa) ascende al trono e conoscendo i reali legami di sangue che lo legano a Genji, lo eleva ai più alti onori.
Tuttavia, giunto alla quarantina, la vita di Genji giunge ad uno stallo. La sua posizione a corte è ormai consolidata, ma è la sua vita affettiva a risentire di qualche difficoltà. Seppur un po' controvoglia, Genji sposa una giovane dama dell'alta nobiltà, che però lo tradisce costringendolo a riconoscere un figlio non suo, Kaoru, come era già avvenuto all'Imperatore suo padre. Genji vede in ciò una punizione per i suoi peccati, ma non rescinde quella che rimarrà sempre un'unione non felice.
Dopo non molto tempo Dama Murasaki muore, lasciando a Genji una profonda melanconia ed un senso di solitudine. Nel capitolo seguente, Maboroshi (Illusione), Genji riflette sulla transitorietà della vita, sulla coscienza di vivere in un mondo galleggiante, esprimendo il senso di mono no aware, caducità e perciò stesso bellezza fugace di tutte le cose.
Il resto dell'opera, conosciuto come Capitoli di Uji per via dell'ambientazione, è successivo alla morte di Genji ed ha per protagonisti Kaoru ed il suo miglior amico Niou, principe imperiale figlio della figlia di Genji e di Dama Akashi. Segue le loro avventure e la loro rivalità nel tentativo di sedurre alcune delle figlie di un principe imperiale che risiede ad Uji. La narrazione ha una fine improvvisa, con Kaoru che si chiede se la dama di cui è innamorato sia invece insieme a Niou. Kaoru è stato talvolta definito il primo antieroe della letteratura giapponese.
Poiché fu scritto per venire incontro al gusto delle dame di corte del Giappone dell'XI secolo, l'opera presenta delle asperità per il lettore moderno. Per prima cosa, la lingua di Murasaki, il giapponese parlato a corte nel periodo Heian aveva una grammatica estremamente complessa. Un altro problema è che chiamare qualcuno per nome era considerato volgare nella società del tempo, perciò nessuno dei personaggi viene chiamato col proprio nome nel romanzo; ci si rivolge agli uomini facendo riferimento al loro rango od alla loro posizione a corte, ed alle donne facendo riferimento al colore dei loro abiti, alla loro residenza, alle parole usate in un incontro od al rango o posizione ricoperta da un loro parente uomo. Di conseguenza, a seconda del capitolo si possono trovare per i medesimi personaggi appellativi diversi.
Un altro aspetto del linguaggio è l'importanza che riveste l'uso della poesia nella conversazione. Modificare o rielaborare un classico a seconda della situazione del momento era un comportamento codificato nella vita di corte del tempo, e spesso serviva a comunicare attraverso sottili allusioni. Le poesie nel Genji sono spesso dei waka. La gran parte di essi era ben conosciuta dal lettore di riferimento, perciò ne vengono citati solamente i primi versi, ed il lettore è invitato a completarli da solo, proprio come oggi potremmo dire "tanto va la gatta al lardo..." e lasciare sottinteso il resto del proverbio ("...che ci lascia lo zampino").
Come la stragrande maggioranza delle opere letterarie Heian, il Genji era stato redatto in buona parte (se non interamente) in kana (caratteri fonetici giapponesi) e non in kanji (sinogrammi o caratteri cinesi), poiché era rivolto ad un pubblico prevalentemente femminile. La scrittura in sinogrammi era allora considerata prerogativa maschile e le donne potevano servirsi del cinese solo marginalmente e con discrezione, per non passare per saccenti.
Proprio per questo al di là del lessico relativo alla politica ed al buddhismo, il Genji contiene poche parole prese in prestito dal cinese. Ciò conferisce alla lettura un ritmo più scorrevole ed uniforme, tuttavia crea anche dei problemi di interpretazione, poiché in giapponese sono numerosissime le parole omofone il cui significato è generalmente chiarito dai sinogrammi, perciò per il lettore moderno spesso il contesto è insufficiente per scegliere il significato giusto.
Murasaki Shikibu non fu né la prima né l'ultima autrice del periodo Heian, né il Genji è il primo o l'unico esempio di monogatari. Piuttosto si può affermare che ricopra un'importanza ed un ruolo paradigmatico per tutte le opere del suo tempo, un po' come le commedie di Shakespeare al confronto con il resto della produzione teatrale elisabettiana.
Iniziato nel 1001, è diviso in 54 libri. I primi 41 capitoli, ambientati nella capitale del Giappone Heian Kyō, narrano la vita del principe Genji, il principe splendente, chiamato così per la sua intelligenza, cultura, e bellezza fisica; la trama si fonda sulla fortuna mondana, la caduta, la risalita al potere e infine la morte del principe galante, a cui fanno cornice stupende figure femminili dell'aristocrazia di corte. All'inizio del quarantaduesimo capitolo il lettore viene informato, senza enfasi, della morte di Genji e assiste a un profondo cambio di atmosfera: l'azione si sposta nel villaggio di Uji e i nuovi protagonisti del libro diventano Kaoru, figlio illegittimo della consorte di Genji, e Niou, nipote di Genji.
Grandi scrittori giapponesi di ogni epoca si rivolsero al Genji Monogatari come fonte d'ispirazione letteraria prettamente nazionale; anche alcune tra le opere più conosciute del Teatro Nō traggono il loro tema dal romanzo (come ad esempio Aoi no Ue, La principessa Aoi), e divenne presto oggetto di commenti filologici e critici da parte dei maggiori autori e studiosi giapponesi.
In epoca moderna sono stati numerosi gli scrittori di primo piano che hanno rivalutato l'opera apprezzandone modernità e complessità e si sono dedicati alla sua traduzione in giapponese moderno; tra di essi Akiko Yosano, Enchi Fumiko, Jun'ichirō Tanizaki e Yukio Mishima.
Il Genji inoltre ha ispirato diverse versioni manga: Asaki yumemishi di Waki Yamato (1979), Genji monogatari di Tatsuya Egawa (2001), Gekka no kimi di Ako Shimaki (2002) e la versione parodica Patalliro Genji Monogatari di Mineo Maya (2004), tutti inediti in Italia. 
Risale al 1987 invece il lungometraggio animato The Tale of Genji di Gisaburō Sugii che segue le vicende del romanzo fino all'esilio del protagonista ad Harima; caratteristiche le atmosfere dilatate ed oniriche e il tratto essenziale e pulito; le amanti di Genji hanno fisionomia così similare da apparire appena distinguibili: è così che implicitamente ne viene suggerita la natura d'alter ego. Sarà solo nel finale, nelle allusioni Dama Fujitsubo, che verrà palesato l'oggetto reale della ricerca amorosa del principe: quella figura materno-femminile mancata in infanzia e tragicamente utopica. La colonna sonora di genere hōgaku è firmata da Haruomi Hosono, bassista degli Yellow Magic Orchestra. 
Nel 2009 ne è stata inoltre tratta una serie anime di 11 episodi trasmessa su Fuji TV all'interno di noitaminA, intitolata Genji monogatari sennenki.
Mercurio è il pianeta più interno del sistema solare e il più vicino al Sole[5]. È il più piccolo e la sua orbita è anche la più eccentrica, ovvero la meno circolare, degli otto pianeti[N 4]. Mercurio orbita in senso diretto (in senso antiorario, come tutti gli altri pianeti del sistema solare) a una distanza media di 0,3871 au dal Sole con un periodo siderale di 87,969[1] giorni terrestri. Mercurio è anche in risonanza orbitale-rotazionale: completa tre rotazioni intorno al proprio asse ogni due orbite attorno al Sole[6].
L'eccentricità orbitale è abbastanza elevata e vale 0,205, ben 15 volte quella della Terra. Dalla superficie di Mercurio, il Sole ha un diametro apparente medio di 1,4°, circa 2,8 volte quello visibile dalla Terra, e arriva a 1,8° durante il passaggio al perielio. Il rapporto fra la radiazione solare al perielio e quella all'afelio è 2,3. Per la Terra questo rapporto vale 1,07[6]. La superficie di Mercurio sperimenta la maggiore escursione termica tra tutti i pianeti, con temperature che nelle regioni equatoriali vanno da 100 K (−173 °C) della notte a 700 K (427 °C) del dì; le regioni polari invece sono costantemente inferiori a 180 K (−93 °C). Ciò è dovuto all'assenza dell'atmosfera che, se presente, svolgerebbe un ruolo nella ridistribuzione del calore. La superficie fortemente craterizzata indica che Mercurio è geologicamente inattivo da miliardi di anni.
Conosciuto sin dal tempo dei Sumeri, il suo nome è tratto dalla mitologia romana. Il pianeta è stato associato a Mercurio, messaggero degli dèi, probabilmente a causa della rapidità del suo movimento nel cielo. Il suo simbolo astronomico è una versione stilizzata del caduceo del dio[7].
Trattandosi di un pianeta interno rispetto alla Terra, Mercurio appare sempre molto vicino al Sole (la sua elongazione massima è di 27,8°[8]), al punto che i telescopi terrestri possono osservarlo raramente. La sua magnitudine apparente oscilla tra −2,4[1] e +7,2[4] a seconda della sua posizione rispetto alla Terra e al Sole.
Durante il giorno la luminosità solare impedisce ogni osservazione e l'osservazione diretta è possibile solamente subito dopo il tramonto, sull'orizzonte a ovest, o poco prima dell'alba verso est, oppure eccezionalmente in occasione delle eclissi totali[9]. Inoltre l'estrema brevità del suo moto di rivoluzione ne permette l'osservazione solamente per pochi giorni consecutivi, dopo di che il pianeta è inosservabile dalla Terra. Per evitare danni agli strumenti il telescopio spaziale Hubble non viene mai utilizzato per riprendere immagini del pianeta[10].
Mercurio è visibile solitamente per sei periodi l'anno, con tre apparizioni la mattina prima dell'alba e tre la sera immediatamente dopo il tramonto[11]. A causa dell'inclinazione dell'eclittica sull'orizzonte, i periodi migliori per l'osservazione sono dopo il tramonto attorno all'equinozio di primavera per l'emisfero boreale e prima dell'alba attorno all'equinozio di autunno per l'emisfero australe.[11][12]
I transiti di Mercurio osservati dalla Terra sono molto più frequenti dei transiti di Venere, grazie alla ridotta distanza dal Sole e alla maggiore velocità orbitale: ne avvengono circa tredici ogni secolo[13]. Sin dai tempi antichi il transito fornisce un'ottima occasione per condurre studi scientifici. Nel 1600 i transiti di Mercurio vennero usati per stimare la dimensione del pianeta e per calcolare la distanza tra Terra e Sole, allora sconosciuta[13]. In epoca moderna i transiti sono usati per analizzare dalla Terra la composizione della tenue atmosfera e come valido elemento di confronto per i metodi di individuazione di pianeti extrasolari[13].
Come nel caso della Luna e di Venere, anche per Mercurio dalla Terra è visibile un ciclo delle fasi, sebbene sia abbastanza difficile osservarlo con strumenti amatoriali[14].
Le osservazioni più antiche del pianeta di cui si ha traccia storica sono riportate nelle tavole MUL.APIN, eseguite probabilmente da astronomi assiri intorno al XIV secolo a.C.[15] Il nome utilizzato per designare Mercurio in questi testi, redatti in scrittura cuneiforme, è trascritto come Udu. Idim. Gu\u4.Ud ("il pianeta saltellante")[16]. Le registrazioni babilonesi risalgono al I millennio a.C. I Babilonesi chiamarono il pianeta Nabu (o Nebo), dio della scrittura e della saggezza nella loro mitologia[17].
Gli Egizi e i Greci assegnarono a Mercurio, come anche a Venere, due nomi: uno come stella del mattino, l'altro come stella della sera[18]. Per gli Egizi alle due apparizioni corrispondevano rispettivamente Seth, un dio nefasto che veniva scacciato dalla luce accecante del Sole nascente, e Horus, un dio benigno associato alla figura del faraone e dello Stato. Invece nella tradizione greca sono rintracciabili due coppie di nomi per Mercurio. La più antica, attestata nell'epoca di Esiodo (fine dell'VIII, inizio del VII secolo a.C.), consisteva in Στίλβων (Stilbon, "il brillante"), come stella del mattino, e Ἑρμάων (Hermaon), come stella della sera[19]. Successivamente queste denominazioni furono sostituite rispettivamente da Apollo e Hermes[18]. Alcune fonti attribuiscono a Pitagora (intorno al 500 a.C.) la comprensione del fatto che si trattasse di un unico pianeta[N 5], altre invece propendono per un periodo più tardo, intorno al 350 a.C.[18] I Romani chiamarono il pianeta Mercurio in onore del messaggero alato degli dei, il dio romano del commercio e dei viaggi corrispondente al greco Hermes. Probabilmente il pianeta ricevette questi nomi a causa del suo rapido moto attraverso il cielo, più veloce di quello di tutti gli altri pianeti[5][20].
Tolomeo nel II secolo a.C. scrisse della possibilità che Mercurio transitasse davanti al Sole nelle Ipotesi Planetarie. Suggerì che nessun transito era stato fino ad allora osservato o a causa delle dimensioni del pianeta, troppo piccolo perché il fenomeno risultasse osservabile o perché l'evento era poco frequente[21].
Nell'Antica Cina Mercurio era conosciuto come Chen Xing (辰星), la Stella delle Ore. Era associato con il Nord e l'elemento dell'acqua nel Wu Xing[22]. Nelle moderne culture cinese, coreana, giapponese e vietnamita si è conservato il legame con il Wu Xing e il pianeta è chiamato "la stella dell'acqua" (水星)[23].
Nella mitologia indiana Mercurio era identificato con il dio Budha, che presiedeva il mercoledì[24]. Nella mitologia germanica e norrena il pianeta e il giorno erano dedicati al dio Odino (Woden in germanico)[25]. I Maya potrebbero aver rappresentato il pianeta come un gufo o forse come quattro gufi, due che ne esprimevano le caratteristiche mattutine e altri due per quelle serali, che recavano messaggi all'oltretomba[26].
Nel Surya Siddhanta, un trattato di astronomia indiano del V secolo, è fornita una stima del diametro di Mercurio con un errore rispetto al valore oggi noto inferiore dell'1%. Tuttavia il calcolo era basato sull'inaccurata supposizione che il diametro angolare del pianeta fosse di 3,0 arcominuti.
Nell'astronomia islamica medievale l'astronomo andaluso Al-Zarqali nell'XI secolo descrisse il deferente dell'orbita geocentrica di Mercurio come un ovale; ciò non influenzò in seguito né le sue teorie, né i suoi calcoli astronomici[27][28]. Nel XII secolo Ibn Bajja osservò "due pianeti come macchie scure sulla faccia del Sole". Nel XIII secolo Qotb al-Din Shirazi dell'Osservatorio di Maragheh suggerì che il suo predecessore potesse aver osservato il transito di Mercurio o di Venere sul disco solare[29]. Questi rapporti medievali di transiti planetari furono in seguito reinterpretati come osservazioni di macchie solari[30].
Nel XV secolo l'astronomo indiano Nilakantha Somayaji della Scuola del Kerala sviluppò un modello planetario del sistema solare parzialmente eliocentrico in cui Mercurio orbitava attorno al Sole che a sua volta orbitava attorno alla Terra. Si trattava di un modello simile al sistema ticonico suggerito dall'astronomo danese Tycho Brahe nel XVI secolo[31].
Galileo Galilei compì le prime osservazioni telescopiche di Mercurio all'inizio del XVII secolo. Sebbene fosse riuscito nell'osservare le fasi di Venere, il suo telescopio non era sufficientemente potente da permettergli di cogliere anche quelle di Mercurio, che furono scoperte nel 1639 da Giovanni Battista Zupi fornendo la prova definitiva che Mercurio orbita intorno al Sole. Intanto nel 1631 Pierre Gassendi era stato il primo a osservare un transito di Mercurio innanzi al Sole, secondo le previsioni fornite da Giovanni Keplero[32].
Evento raro nell'astronomia è il passaggio di un pianeta davanti a un altro (occultazione) visto dalla Terra. Mercurio e Venere si occultano ogni pochi secoli e l'evento del 28 maggio 1737 rilevato da John Bevis all'Osservatorio di Greenwich è l'unico storicamente osservato[33]. La prossima occultazione di Mercurio da parte di Venere avverrà il 3 dicembre 2133[34].
Le difficoltà insite nella osservazione di Mercurio lo hanno reso il pianeta meno studiato tra gli otto del sistema solare. Nel 1800 Johann Schröter compì alcune osservazioni delle caratteristiche superficiali e affermò di aver osservato montagne alte 20 km. Friedrich Wilhelm Bessel utilizzò i disegni di Schröter e stimò erroneamente un periodo di rotazione di 24 ore e un'inclinazione dell'asse di rotazione di 70°[35]. Negli anni ottanta dell'Ottocento Giovanni Schiaparelli compose mappe più accurate della superficie e suggerì che il periodo di rotazione del pianeta fosse di 88 giorni[36], uguale a quello di rivoluzione, e quindi che il pianeta fosse in rotazione sincrona con il Sole così come la Luna lo è con la Terra. L'impegno nel mappare la superficie di Mercurio fu proseguito da Eugène Michel Antoniadi che pubblicò le sue mappe e osservazioni in un libro nel 1934[37]. Molte caratteristiche superficiali del pianeta, e in particolare quelle di albedo, prendono il loro nome dalle mappe di Antoniadi[38].
L'astronomo italiano Giuseppe Colombo osservò che il periodo di rotazione era circa due terzi di quello orbitale e propose una risonanza 3:2 invece che l'1:1 prevista dalla teoria della rotazione sincrona[39].
Nel giugno del 1962 ricercatori sovietici dell'Istituto di radio-ingegneria ed elettronica dell'Accademia delle Scienze dell'URSS diretto da Vladimir Kotel'nikov furono i primi a eseguire osservazioni radar del pianeta[40][41][42]. Tre anni dopo ulteriori osservazioni radar condotte con il radiotelescopio di Arecibo dagli statunitensi Gordon Pettengill e R. Dyce indicarono in modo conclusivo che il pianeta completa una rotazione in 59 giorni circa[43][44]. La scoperta risultò sorprendente perché l'ipotesi che la rotazione di Mercurio fosse sincrona era ormai ampiamente accettata e vari astronomi, riluttanti ad abbandonarla, proposero spiegazioni alternative per i dati osservativi. In particolare la temperatura notturna della superficie del pianeta risultò molto più alta rispetto al valore atteso nel caso di rotazione sincrona e, tra le varie ipotesi, fu proposta l'esistenza di venti estremamente potenti che avrebbero ridistribuito il calore dalla faccia illuminata a quella buia[45].
I dati raccolti dalla missione spaziale Mariner 10 confermarono la previsione di Colombo[46] e l'esattezza delle mappe di Schiaparelli e Antoniadi. Gli astronomi rilevarono le stesse caratteristiche di albedo ogni seconda orbita e le registrarono, ma non dettero importanza necessaria a quelle dell'altra faccia di Mercurio a causa delle condizioni osservative scarse nel momento in cui le guardavano.
Le osservazioni dalla Terra non permisero di acquisire maggiori informazioni su Mercurio e le sue principali caratteristiche rimasero ignote finché non fu visitato dal Mariner 10, la prima sonda spaziale a visitare il pianeta. Tuttavia recenti progressi tecnologici hanno migliorato anche le osservazioni dalla Terra e, grazie alle osservazioni condotte dall'Osservatorio di Monte Wilson con la tecnica del lucky imaging nel 2000, è stato possibile risolvere per la prima volta dettagli superficiali sulla porzione di Mercurio che non era stata fotografata dal Mariner 10[47]. Osservazioni successive hanno permesso di ipotizzare l'esistenza di un cratere d'impatto più grande del Bacino Caloris nell'emisfero non fotografato dal Mariner 10, cratere a cui è stato informalmente dato il nome di Bacino Skinakas[48]. La maggior parte del pianeta è stata mappata dal radiotelescopio di Arecibo, con una risoluzione di 5 km, compresi depositi polari in crateri in ombra che potrebbero essere composti da ghiaccio d'acqua[49].
Mercurio fu visitato per la prima volta nel 1974 dalla sonda statunitense Mariner 10 che teletrasmise a Terra fotografie registrate nel corso di tre successivi sorvoli.
Concepito per l'osservazione di Venere e Mercurio, il Mariner 10 venne lanciato il 3 novembre 1973 e raggiunse il pianeta nel 1974, usando per la prima volta nella storia la manovra di fionda gravitazionale[50][51]. La sonda effettuò il primo sorvolo il 29 marzo a una distanza minima di 700 km, fornendo le prime immagini inedite del pianeta e risultati scientifici inaspettati: la sonda registrò un campo magnetico rilevante che si pensava fosse quasi del tutto assente[52]. Il secondo sorvolo, il 21 settembre, fu ben più lontano del primo. Si decise di risparmiare carburante per permettere un terzo sorvolo che avrebbe permesso di capire la natura del campo magnetico: se intrinseco come quello della Terra o indotto dal vento solare come quello di Venere[53]. Il sorvolo avvenne a circa 50000 km dalla superficie e fornì ulteriori immagini della superficie illuminata e dettagli del polo sud[53]. Le manovre preparatorie per il terzo sorvolo non furono prive di incidenti, ma riuscirono comunque a portare la sonda statunitense alla minima distanza da Mercurio il 16 marzo 1975, quando passò a soli 327 km dalla superficie, confermando la natura intrinseca del campo magnetico e l'esistenza di una magnetosfera[53]. La sonda abbandonò il pianeta dopo aver fotografato il 41% della superficie del pianeta, fu spenta e rimase in orbita eliocentrica.
La NASA lanciò nel 2004 la sonda MESSENGER il cui primo passaggio ravvicinato di Mercurio, avvenuto il 14 gennaio 2008, fu preceduto da un sorvolo ravvicinato della Terra e da due di Venere e fu seguito da tre manovre di fionda gravitazionale su Mercurio prima dell'ingresso in orbita attorno al pianeta il 18 marzo 2011[54]. In seguito al primo fly-by di Mercurio, la sonda MESSENGER inviò alla Terra le prime immagini dell'emisfero "sconosciuto" di Mercurio. La missione permise di scoprire la composizione della superficie, di rivelare la sua storia geologica, di analizzare il suo campo magnetico e di verificare la presenza di ghiaccio ai poli[55]. La missione si concluse con il decadimento orbitale e l'impatto ad alta velocità sulla superficie, creando presumibilmente un nuovo cratere dal diametro di 16 metri[56].
Il 20 ottobre 2018 è avvenuto il lancio da parte dell'ESA della missione spaziale BepiColombo[57], così battezzata in onore dello scienziato, matematico e ingegnere Giuseppe Colombo (1920-1984). La missione è volta esclusivamente all'esplorazione del pianeta più interno[58]. La missione ha l'obiettivo di approfondire lo studio del pianeta e di testare la teoria della relatività generale; consiste di due orbiter, uno che si stabilizzerà in un'orbita con un apoermeo di 1500 km[59] per lo studio ravvicinato del pianeta e uno con apoermeo di 11600 km[60] per lo studio della magnetosfera.
L'orbita di Mercurio risulta essere ellittica solo in prima approssimazione, è infatti soggetta alla precessione del perielio, effetto che mise in difficoltà gli astronomi e i calcoli della fisica classica del XIX secolo. Le anomalie osservate nell'orbita del pianeta fecero ipotizzare a Urbain Le Verrier nel 1859 l'esistenza di un altro pianeta, che chiamò Vulcano[61]; si supponeva che l'orbita di Vulcano si svolgesse interamente all'interno di quella di Mercurio. Il primo a dare una spiegazione corretta delle anomalie della precessione del perielio dell'orbita di Mercurio fu Albert Einstein grazie alla relatività generale nel 1915[62], che proprio su questo fenomeno ha avuto uno dei suoi banchi di prova.
Mercurio si muove su un'orbita di eccentricità 0,2056, a una distanza dal Sole compresa fra 46000000 e 69820000 km[1], con un valore medio di 58000000 km (rispettivamente 0,307, 0,466 e 0,387 au). Il periodo siderale di Mercurio è di 88 giorni[1], mentre il periodo sinodico è di 115,9 giorni[1]. Il piano orbitale è inclinato sull'eclittica di 7°[1].
La velocità media siderale del pianeta è pari a 47 km/s[1]; si tratta della più alta fra i pianeti del sistema solare.
Il moto di rotazione mercuriano è molto lento: esso impiega 58,6 giorni per compiere un giro su sé stesso, e completa quindi tre rotazioni ogni due rivoluzioni, in risonanza orbitale 3:2[63], questo fa sì che la durata del giorno solare (176 giorni) sia il doppio della durata dell'anno (88 giorni); Mercurio è l'unico pianeta del sistema solare sul quale la durata del giorno è maggiore del periodo di rivoluzione.
Al perielio, la velocità orbitale molto elevata diventa la componente predominante del moto solare apparente per un osservatore sulla superficie, il quale dapprima vedrebbe il Sole stazionare nel cielo, poi invertire il suo cammino muovendosi da ovest verso est e infine riprendere la sua traiettoria ordinaria[64].
Mercurio è il più piccolo pianeta del sistema solare in termini di dimensioni e massa. In termini di dimensioni è più piccolo[65] anche di Titano e Ganimede, satelliti naturali di Saturno e Giove e, a causa delle dimensioni ridotte e della sua vicinanza al Sole, l'attrazione gravitazionale del pianeta non è riuscita a trattenere un'atmosfera consistente. La sua forma è grossomodo sferica e non presenta la caratteristica forma geoidale (schiacciamento ai poli e rigonfiamento all'equatore) degli altri pianeti[66]. Il pianeta non possiede né satelliti naturali né anelli planetari, sebbene nel 1974 poco prima del sorvolo ravvicinato della sonda Mariner 10 un'errata interpretazione di alcuni dati ricevuti lasciò immaginare la presenza di una luna di notevoli dimensioni[67].
La densità di Mercurio, pari a 5,43 g/cm³, si discosta molto da quella lunare e, al contrario, è molto vicina a quella terrestre. Questo lascia supporre che, nonostante le somiglianze con la Luna, la struttura interna del pianeta sia più vicina a quella della Terra. Mentre l'alta densità terrestre è il risultato della forte compressione gravitazionale, Mercurio è molto più piccolo e le regioni interne non sono compresse come quelle terrestri, pertanto per avere una tale densità, si suppone che il suo nucleo debba essere relativamente grande e ricco di ferro[68].
I geologi stimano che il nucleo di Mercurio occupi circa il 42% del suo volume, mentre per la Terra questa percentuale è del 17%. Una ricerca pubblicata nel 2007, unita alla presenza del debole campo magnetico, suggerisce che Mercurio possieda un nucleo metallico fuso elettricamente conduttore[69][70][71], circondato da un mantello dello spessore di 500–700 km composto da silicati[72][73]. Sulla base dei dati di Mariner 10 e di osservazioni compiute dalla Terra, la crosta di Mercurio è ritenuta essere spessa 100–300 km[74]. Una caratteristica distintiva della superficie di Mercurio è la presenza di numerose creste strette, che si estendono fino a diverse centinaia di chilometri in lunghezza. Si ritiene che queste si siano formate dal raffreddamento e dalla contrazione di nucleo e mantello, successivi alla solidificazione della crosta[75].
Il nucleo di Mercurio ha un contenuto di ferro superiore a quella di qualsiasi altro grande pianeta del sistema solare, e diverse teorie sono state proposte per spiegare questa caratteristica. La teoria più accreditata è che in origine Mercurio avesse un rapporto metalli-silicati simile alle comuni meteoriti condriti, che costituiscono il tipico materiale roccioso presente nel sistema solare, e avesse una massa di circa 2,25 volte quella attuale[76]. Quando il sistema solare si stava formando, Mercurio potrebbe essere stato colpito da un planetesimo di circa 1/6 della sua massa e di diverse migliaia di chilometri di diametro. L'impatto avrebbe spazzato via gran parte della crosta e del mantello presenti a quel tempo, lasciando il nucleo come componente predominante del corpo celeste. Un processo simile, noto come teoria dell'impatto gigante, è stato proposto per spiegare la formazione della Luna[76].
Un'altra ipotesi suggerisce che Mercurio potrebbe essersi formato dalla nebulosa solare prima che la produzione di energia del Sole si stabilizzasse. In questa ipotesi Mercurio avrebbe avuto inizialmente due volte la sua massa attuale, ma dopo la contrazione del protosole, le temperature si alzarono a 2500-3500 K e forse anche più (10000 K). A tali temperature gran parte delle rocce superficiali di Mercurio sarebbero vaporizzate e sarebbero state poi spazzate via dal vento solare[77].
Una terza ipotesi propone che le perturbazioni dovute alla nebulosa solare causarono la perdita delle particelle più leggere, che non furono raccolte da Mercurio[78]. Ciascuna ipotesi predice una diversa composizione della superficie. Una risposta conclusiva potrebbe provenire dal confronto tra i risultati delle osservazioni che saranno condotte dalla missione BepiColombo con quelli ottenuti dalla missione MESSENGER[79][80]. La sonda MESSENGER ha rilevato in superficie livelli di potassio e zolfo superiori alla norma, che sembrerebbero escludere l'ipotesi dell'impatto gigante, e la conseguente vaporizzazione della crosta e del mantello. I risultati sembrerebbero dunque favorire la terza ipotesi; a ogni modo, occorrono ulteriori studi per confermarla[81].
Le prime fotografie della superficie si devono all'astronomo greco-francese Eugène Michel Antoniadi (1870-1944) che all'inizio del ventesimo secolo disegnò delle mappe di questo pianeta[82].
Similmente alla Luna, il suolo di Mercurio è ampiamente craterizzato a causa dei numerosi impatti di asteroidi che hanno contrassegnato il suo passato e presenta bacini riempiti da vecchie colate laviche, ancora evidenti a causa della mancanza quasi assoluta di un'atmosfera[83]. Alcuni crateri sono circondati da raggi. Si esclude la presenza sul pianeta di placche tettoniche.
Mercurio, come la Luna, ha subito urti con meteoriti ed è normale che i pianeti in possesso di un'atmosfera consistente risentano in misura assai minore dell'effetto degli impatti, poiché i corpi incidenti vengono fortemente erosi dall'attrito atmosferico[84]. Inoltre l'atmosfera stessa erode lentamente la superficie del pianeta, cancellando le tracce dell'urto[85]. Oltre all'atmosfera ci sono diversi elementi che cancellano i crateri causati da asteroidi che non sono infatti presenti su Mercurio, come il vento e l'acqua.
Inoltre un numero così ampio di crateri induce a supporre che il pianeta, come la Luna, manchi da numerosi secoli di attività interna.
Sulla superficie di Mercurio l'accelerazione di gravità è mediamente pari a 0,378 volte quella terrestre[1]. A titolo di esempio si potrebbe affermare che un uomo dalla massa di 70 kg che misurasse il proprio peso su Mercurio facendo uso di una bilancia tarata sull'accelerazione di gravità terrestre registrerebbe un valore pari a circa 25,9 kg.
La ridotta distanza di Mercurio dal Sole e l'assenza di un'atmosfera consistente lo rendono un pianeta con una grande escursione termica, con temperature superiori a 350 °C nella zona esposta al Sole, contro i −170 °C nella parte in ombra. Inoltre, l'insolazione media della superficie mercuriana è pari a circa 6 volte e mezzo quella della Terra; la costante solare ha un valore di 9,2 kW/m²[86].
Alcuni tra i più grandi crateri di Mercurio superano i 200 km e prendono il nome di bacini. Al centro di molti crateri, spesso riempiti da antiche colate laviche ancora evidenti, s'innalzano piccole formazioni montuose. Il bacino più grande e più noto è la Caloris Planitia, dal diametro di circa 1 500 km: si tratta di una grande pianura circolare circondata da anelli di monti[87][88]. Questo bacino deve il suo nome al fatto che si trova sempre esposto alla luce del Sole durante il passaggio di Mercurio al perielio e pertanto è uno dei punti più caldi del pianeta. Dal cratere fuoriescono gas a base di potassio e sodio che contribuiscono alla tenue atmosfera del pianeta[89].
Agli antipodi del bacino Caloris si trova un tipo di terreno collinare del tutto insolito, assente sul resto della superficie, di età stimata pari a quella dello stesso bacino antipodale. Si è formato probabilmente quando un grosso asteroide, impattando su Mercurio, ha generato il bacino Caloris provocando un'onda d'urto che ha convogliato agli antipodi[90].
Alcuni crateri del polo nord, invece, sono in grado di schermare completamente la luce solare in alcune zone al loro interno, grazie anche alla scarsa inclinazione dell'asse orbitale, mantenendo la temperatura considerevolmente bassa per migliaia e milioni di anni, fino a circa −220 °C, e conservare così grosse risorse di acqua allo stato solido[91].
Confrontando i dati dalle sonde Mariner 10 e MESSENGER a 30 anni di differenza, si è rilevato un restringimento del diametro del pianeta dai 3 ai 14 chilometri[92]. Il tutto si basa sul fatto che il suo nucleo di liquido ferroso si stia raffreddando, così facendo esso si solidifica e di conseguenza il volume dell'intero pianeta diminuisce. Queste modifiche si fanno sentire anche in superficie frastagliando la crosta[93] e creando rupēs di notevoli dimensioni, fino a 1000 km di lunghezza e tre di profondità[92].
L'osservazione dal radiotelescopio di Arecibo ha rilevato delle formazioni strane all'altezza dei poli, molto riflettenti, simili a quelle che si ottengono osservando oggetti ghiacciati all'esterno del sistema solare[94]. I valori osservati sono compatibili con la presenza di ghiaccio coperto da un sottile strato di regolite. Data la ridotta inclinazione della rotazione di Mercurio, i crateri ai poli conservano delle zone perennemente oscurate dalla radiazione solare e hanno permesso al ghiaccio di conservarsi per miliardi di anni[94]. Questo ghiaccio ai poli è in una forma relativamente pura, ha lo spessore di almeno un metro (una stima dello spessore massimo non è possibile con sole osservazioni radar) e si estende per un'area di 30000 km² se si considerano entrambi i poli; l'origine è probabilmente dovuta a impatti di comete[94].
L'Unione Astronomica Internazionale (UAI) è l'ente che controlla la nomenclatura dei pianeti; per l'assegnazione dei nomi delle caratteristiche geologiche di Mercurio, l'ente ha scelto un tema diverso per ogni caratteristica[95]:
L'UAI ha anche realizzato una cartografia suddividendo la superficie del pianeta secondo un reticolato adatto a una rappresentazione in scala 1:5 000 000, che definisce 15 maglie[96] per meglio localizzare le peculiarità della superficie.
Per via della sua bassa attrazione gravitazionale Mercurio è sprovvisto di una vera e propria atmosfera come quella terrestre, fatta eccezione per esili tracce di gas probabilmente frutto dell'interazione del vento solare con la superficie del pianeta[98]. La composizione atmosferica è stata determinata come segue: ossigeno (42%), sodio (29%), idrogeno (22%), elio (6%), potassio (0,5%) e tracce di argon, anidride carbonica, vapore acqueo, azoto, xeno, kripton, neon, calcio e magnesio[97]. La pressione atmosferica al suolo, misurata dalla sonda Mariner 10, è nell'ordine di un millesimo di pascal.
La bassa densità dell'atmosfera non le permette di innescare un meccanismo di distribuzione del calore ricevuto dal Sole; per questo motivo e per la rotazione estremamente lenta, che espone lo stesso emisfero alla luce solare diretta per lunghi periodi, l'escursione termica su Mercurio è la più elevata finora registrata nell'intero sistema solare: l'emisfero illuminato raggiunge i 600 K (700 K nelle zone equatoriali), quello in ombra scende spesso fino a 90 K[14].
L'azione intensa del vento solare produce un fenomeno assente negli altri pianeti ma presente nelle comete quando si avvicinano al Sole: la presenza di una coda cometaria. Il vento solare espelle atomi neutri dalla prossimità del pianeta rendendo misurabile una coda fino a distanze di oltre un milione di chilometri, composta principalmente da atomi di sodio[99].
A dispetto delle sue ridotte dimensioni e del lento moto di rotazione, Mercurio possiede un campo magnetico stabile, significativo e apparentemente globale. Le misurazioni delle sonde Mariner 10 e MESSENGER indicano un'intensità pari a circa l'1% del campo terrestre e lasciano presupporre che l'intensità all'equatore del pianeta sia compresa tra 250 e 290 nT[100]. Come quello della Terra, il campo magnetico di Mercurio è dipolare[101], con inclinazione dell'asse magnetico rispetto a quello di rotazione inferiore ai 5°[100].
È probabile che il campo magnetico sia generato con un effetto dinamo, in modo simile a quanto accade per la Terra[102], sebbene siano state proposte anche alcune differenze[103][104]. Il campo magnetico sarebbe generato dalla circolazione dei fluidi del mantello ricco di ferro. In particolare, i forti effetti mareali, causati dalla relativamente elevata eccentricità dell'orbita del pianeta, fornirebbero l'energia necessaria a mantenere il nucleo allo stato liquido[105].
Il campo magnetico di Mercurio è sufficientemente forte da deflettere il vento solare e creare una magnetosfera di ridotte dimensioni attorno al pianeta, tanto piccola che la Terra riuscirebbe a contenerla[101]. La sua presenza riduce l'erosione cui è soggetta la superficie da parte del vento solare, sebbene non riesca a impedirla[106]. Le misurazioni del Mariner 10 lasciano pensare che il pianeta non sia circondato da fasce di radiazione (analoghe alle fasce di Van Allen della Terra), mentre hanno fornito prova della dinamicità della magnetosfera mercuriana la cui coda è interessata da intense tempeste magnetiche dalla durata di un minuto[107].
Che la magnetosfera di Mercurio "perda" è stato confermato anche nel corso del secondo sorvolo della sonda MESSENGER, avvenuto il 6 ottobre 2008[108]. La sonda ha incontrato "tornado" magnetici ampi fino a 800 km (un terzo del raggio del pianeta). Questi si formano in conseguenza dell'interazione tra il campo magnetico trasportato dal vento solare e quello planetario. I fenomeni di connessione cui sono soggetti i due campi, sotto le azioni di trasporto del vento solare, danno origine a strutture vorticose, tubi magnetici contorti su sé stessi, che aprono delle finestre nello scudo magnetico del pianeta, permettendo alle particelle del vento solare stesso di impattare direttamente sulla superficie di Mercurio. Si parla in tal caso di flux transfer event o "eventi di trasferimento di flusso"[108].
MESSENGER ha inoltre rilevato che questi fenomeni si verificano con una frequenza dieci volte superiore che sulla Terra, dato che può essere solo parzialmente spiegato con la maggiore vicinanza al Sole di Mercurio[108].
Il cielo di Mercurio sarebbe nero anche di giorno, non avendo il pianeta un'atmosfera che lo circonda[109]. La differenza più grande rispetto al cielo terrestre è la maggior grandezza apparente del Sole, il cui diametro angolare può variare da 1,14° all'afelio a 1,73° quando si trova al perielio, cioè rispettivamente 2,1 e 3,2 volte più grande rispetto al Sole visto dalla Terra. L'orbita di Mercurio è infatti piuttosto eccentrica, e la distanza del pianeta dalla nostra stella varia considerevolmente nel corso del "suo" anno, durante cioè il moto di rivoluzione attorno al Sole[110].
Mercurio ruota sul proprio asse più lentamente che attorno al Sole, con una risonanza di 3:2 che perdura il giorno solare 176 giorni terrestri: è questo il periodo necessario per rivedere il Sole al medesimo meridiano. Il moto del Sole nel cielo di Mercurio non è tuttavia rettilineo e costante, perché quando il pianeta si avvicina al perielio, la velocità orbitale aumenta, superando la velocità di rotazione, con il risultato che il Sole appare fermarsi in cielo e spostarsi per un breve periodo nella direzione opposta, per poi riprendere il suo normale scorrere da est a ovest[110].
Sole a parte, l'oggetto più luminoso nei cieli di Mercurio sarebbe Venere, il pianeta più vicino, ancor più luminoso che visto dalla Terra. Da Mercurio infatti, oltre alla minore distanza, Venere sarebbe un pianeta esterno e arriverebbe all'opposizione mostrando il suo disco completamente illuminato, arrivando a brillare di magnitudine −7,7. La Terra sarebbe comunque anch'essa molto luminosa, di magnitudine −5[111], accompagnata dalla Luna, di magnitudine −1,2[N 6]. La separazione angolare massima tra la Terra e la Luna viste da Mercurio sarebbe di circa 15′.
Marte, meno brillante che visto dalla Terra, alla massima vicinanza raggiungerebbe una magnitudine −0,7, mentre gli altri pianeti del sistema solare apparirebbero sostanzialmente come visti dalla Terra e leggermente meno luminosi, vista la maggiore distanza.[N 6]
Il nome Mercurio deriva dalla mitologia romana, e sebbene fosse di derivazione etrusca (Turms), era il corrispondente del dio greco Ermes, che secondo la mitologia greca era nato da una relazione fugace tra Zeus e Maia, la più bella delle Pleiadi. Solitamente rappresentato come un giovane snello e atletico con in capo un elmetto alato, simbolo di velocità, era considerato il veloce messaggero degli dei, così come il pianeta è il più rapido nel suo moto di rivoluzione attorno al Sole. Mercurio ruota infatti attorno alla nostra stella in appena 88 giorni, e per la sua vicinanza al Sole può essere osservato solo per brevi periodi all'alba o al tramonto. Nella mitologia romana Mercurio possedeva caratteristiche simili a Ermes, e inoltre era il protettore del commercio e dei ladri, nonché simbolo della medicina[112].
Dato il suo veloce movimento apparente in cielo Mercurio rimane solo 7,33 giorni in ogni costellazione dello zodiaco e astrologicamente è il pianeta dominante del segno dei Gemelli (domicilio diurno) e della Vergine (domicilio notturno). Esso governa la comunicazione, la razionalità, la rapidità, l'astuzia, l'intelligenza e l'apprendimento rapido[113].
Nell'astrologia cinese, Mercurio domina l'acqua, uno dei cinque elementi essenziali assieme a legno, fuoco, terra e metallo e che simboleggia la vita e la purificazione[114].
Nella letteratura classica Mercurio, come gli altri principali pianeti conosciuti fin dai tempi antichi, compare in numerose opere. Dante Alighieri nella Divina Commedia chiama il Secondo Cielo Cielo di Mercurio. Il Sommo Poeta lo descrive come il luogo dove abitano gli arcangeli e le anime che si attivarono per la gloria terrena, come l'imperatore Giustiniano I. Dante considerava Mercurio la "sua stella", perché Mercurio rappresenta la dialettica, in quanto è il pianeta più piccolo e più vicino al Sole e come scrisse lui stesso nel Convivio, è quello che "più va velata de li raggi del Sole che null'altra stella"[115].
Essendo uno dei pianeti più vicini alla Terra, Mercurio è stato citato in numerose opere fantascientifiche, soprattutto prima del 1965, quando gli astronomi scoprirono che non era in rotazione sincrona come invece si pensava fino a quel momento[44]. Prima del 1965 molte opere lo descrivono infatti come un pianeta che volgeva sempre la stessa faccia al Sole e quindi metà della sua superficie era perennemente illuminata e l'altra metà sempre oscura.
Uno dei primi romanzi di fantascienza fu Entretiens sur la pluralité des mondes di Bernard le Bovier de Fontenelle, che descrive l'esistenza di mondi extraterrestri su Mercurio, Venere e Saturno.
Anche Isaac Asimov ha ambientato alcune delle sue storie su Mercurio. In Circolo vizioso, racconto del 1942 e riproposto nell'antologia Io, robot, due astronauti devono riparare delle miniere servendosi di un sofisticato robot. Conclusione errata è un giallo, dove per la morte di uno scienziato vengono indagati tre suoi colleghi, che erano stati rispettivamente sulla Luna, su Mercurio e sull'asteroide Cerere.
In Lucky Starr e il grande sole di Mercurio, lo scenario è un luogo posto al confine tra l'emisfero in ombra e quello alla luce perenne del pianeta (il romanzo è del 1956 e non si era ancora scoperto che Mercurio non è in rotazione sincrona). Sempre nel 1956 Alan E. Nourse scrive Brightside Crossing (Traversata luminosa), dove un gruppo di spedizione progetta di attraversare la superficie di Mercurio al perielio seguendo la linea equatoriale[116].
Dopo che fu scoperto che la rotazione non era sincrona e in realtà Mercurio non volgeva sempre la stessa faccia al Sole, la descrizione di Mercurio nelle opere letterarie si aggiornò al passo con le conoscenze scientifiche del pianeta.
Fra le varie citazioni in romanzi e racconti, tra cui la menzione di una civiltà mercuriana di Arthur C. Clarke in Incontro con Rama, che tenta di distruggere l'astronave aliena senza riuscirci, Mercurio è lo scenario principale del romanzo di David Brin, Spedizione Sundiver, del 1980, dove i protagonisti trascorrono buona parte del tempo su Mercurio, base più vicina per studiare forme di vita intelligenti scoperte sul Sole. In Manifold: Space Mercurio è invece l'ultimo avamposto rimasto all'umanità, dopo che una potente razza aliena ha distrutto la razza umana dal resto del sistema solare[117].
La specie è alla base della classificazione degli organismi viventi, trattandosi del livello tassonomico obbligatorio gerarchicamente più basso. La scelta di un criterio univoco e universale per identificare le specie è però difficile, soprattutto in quanto esse sono entità non statiche, ma che si modificano nel tempo e nello spazio e, pertanto, ciò che osserviamo è un momento di un processo evolutivo che è in realtà continuo; da qui la difficoltà a creare confini certi e di conseguenza l'incertezza nella definizione. Quello di specie è un concetto multidimensionale sotto il quale ricadono varie definizioni che dipendono dall'aspetto che si considera: la specie può essere dunque biologica, morfologica, tipologica, cronologica e filofenetica.
La "specie biologica" è la più diffusa, usata in zoologia. Essa pare la più completa in quanto si basa su un criterio che è insieme temporale e spaziale: una specie è infatti definita sulla base di una prossimità filogenetica tra i membri componenti (cioè il fatto di possedere un antenato comune più recente di quello condiviso coi membri di altri gruppi), ma anche dalla presenza di meccanismi di isolamento riproduttivo rispetto ad altri gruppi (questo garantisce una discontinuità fenotipica e genotipica che concorre a definire la specie stessa). Dalla definizione di Dobžanskij e Mayr, la specie è rappresentata da quegli individui che incrociandosi tra loro generano potenzialmente una prole illimitatamente feconda. Ovviamente, come si amplierà più sotto, il termine, si basa su un modello necessariamente artificiale, e non è valido per tutti i casi di organismi in cui sia assente la riproduzione sessuale. In questi casi, tipici ad esempio in microbiologia, la definizione è più articolata, ed è reperibile su testi di tassonomia batterica.
Il concetto di "illimitatamente" e "feconda" è a fondamento della classificazione artificiale attuata dall'uomo che, come tale, lascia aperto il campo a molte eccezioni di ibridi interspecifici o intergenerici sani e fecondi. Va posta attenzione sul fatto che la definizione di specie come composta da individui "illimitatamente fecondi tra di loro" non esclude che individui che possono creare prole (ibrida, per quanto segue nella frase) "illimitatamente feconda", trovandosi  in condizioni particolari (es.: in cattività, ma non solo), possano comunque essere classificati come specie diverse, in quanto "in natura" non entrano mai (o quasi) in contatto riproduttivo (e quindi non creano ibridi) . È noto a tutti che l'asino e la cavalla generano il mulo, che è sterile; non così però l'incrocio, ad esempio, del grizzly con l'orso polare, che pure continuano ad essere considerate due specie diverse nonostante la loro prole sia fertile.[1] In linea generale, il fatto che gli ibridi nati in condizioni di cattività siano fertili non può essere di per sé considerata un'evidenza invalidante della sussistenza di due specie separate, nel caso in cui una barriera riproduttiva sia effettivamente presente "in natura".[2] Tale conclusione può essere tratta dall'affermazione formulata da Ernst Mayr, secondo il quale le specie animali "non si incrociano in condizioni naturali".
Ciò non esclude dunque la possibilità che possano farlo, e con esiti positivi, in condizioni artificiali. Gli accoppiamenti che sono il risultato della deliberata azione dell'uomo, così come il caso più generale di specie che sarebbero fisiologicamente e geneticamente in grado di generare prole ma che per vari motivi non lo fanno in natura (es.: specie geneticamente simili che vivono in luoghi geograficamente separati ma anche specie che occupano gli stessi luoghi ma che hanno sistemi di corteggiamento diversi, che occupano nicchie ecologiche diverse, che hanno ritmi di attività asincroni etc.), non possono rappresentare evidenze a sostegno di una supposta impossibilità di elevare due popolazioni al rango di specie separate.[3] L'idea dunque che specie differenti non possano incrociarsi o che la prole di un tale incrocio debba essere in tutti i casi sterile rappresenta un travisamento del concetto di specie biologica formulato da Ernst Mayr nel 1942,[4] come messo in evidenza da P. Mohelman: «Molti non-tassonomi si basano su un fraintendimento del concetto biologico di specie di Mayr (1942). Il fraintendimento popolare è che specie differenti non possono incrociarsi; alcuni fanno un passo avanti, credendo che le specie possono talvolta incrociarsi, ma che gli ibridi debbano essere sterili. Questo non è quanto Mayr ha affermato. Egli propose che le specie "non si ibridano sotto condizioni naturali", enfatizzando che questo isolamento riproduttivo può essere il risultato di meccanismi di isolamento pre- o post-copula (...) Il meccanismo pre-copula include cose come meccanismi etologici che possono essere rotti in condizioni non naturali, come la cattività».
D'altra parte, la generazione di prole fertile come risultato dell'incrocio di due specie rappresenta un'evidenza della vicinanza filogenetica delle stesse. In accordo con Mayr, l'elemento chiave per la definizione di una specie biologica sarebbe dunque la sussistenza di un isolamento riproduttivo "in natura" rispetto ad altre popolazioni, assieme ad una coesione riproduttiva interna alla popolazione stessa.
Tuttavia tale definizione, per quanto rigorosa, non è rigidamente applicabile in campo botanico. Molte forme vegetali, pur presentando evidenti diversità, tali da non poter essere considerate della medesima specie, si incrociano originando ibridi illimitatamente fertili. In questi casi l'applicabilità di tale definizione tassonomica risulta limitata e si ricorre a diverse classificazioni, basate sulle diversità somatiche e/o filogenetiche.
La specie "morfologica" è quella basata su caratteri morfologici. Viene generalmente usata per le specie attuali e per quelle fossili. Quando si hanno a disposizione molti esemplari (minimo 50) i caratteri rappresentabili da numeri possono essere indagati con metodi statistici. In passato strettamente connessa al concetto di specie tipologica oggi è sempre più rimpiazzata, perlomeno nelle specie viventi, da studi di ordine molecolare e genetico. È infatti ovvia la difficoltà di applicazione di tale definizione a criptospecie e a specie con una variabilità morfologica molto marcata. Il dimorfismo sessuale unito a variabilità morfologica, ad esempio, possono apparentemente accomunare esteriormente organismi appartenenti a specie totalmente differenti.
Tipico è ad esempio il caso di maschi di dimensioni ridotte di alcuni coleotteri che tendono a rassomigliare a femmine di specie differenti. Portando alle estreme conseguenze l'applicazione del concetto di specie morfologica, si rischia di cadere in situazioni paradossali. Ad esempio, due individui possono essere molto diversi pur appartenendo alla stessa popolazione o addirittura alla stessa nidiata: è questo il caso delle specie polimorfiche.[5] Dal lato opposto, due individui possono essere morfologicamente quasi identici pur appartenendo a due popolazioni diverse e geneticamente incompatibili: è questo il caso delle specie sorelle (sibling species).
Per questi motivi il criterio morfologico viene applicato in biologia solo in quanto riflesso (e indicatore) dei rapporti filogenetici tra i gruppi presi in considerazione, non diversamente da come il grado di parentela in un albero genealogico viene ricostruito sulla base dei trascorsi storici della linea familiare piuttosto che sulla similarità di aspetto (per quanto mediamente possa essere maggiore tra individui strettamente imparentati che tra non imparentati). Similmente, i delfini vengono considerati mammiferi e non pesci in base alla presenza di alcuni caratteri morfologici tra cui le ghiandole mammarie: questi caratteri sono stati scelti su altri caratteri (ad esempio, la presenza di pinne e la forma del corpo) per sancire l'appartenenza alla stessa Classe in quanto più conservati degli altri e quindi maggiormente indicativi dei rapporti di parentela all'interno del gruppo.
La "specie tipologica" è quella fondata su un tipo, definito olotipo, cioè su un esemplare che la rappresenta e che dovrebbe essere in un museo pubblico a disposizione degli studiosi. L'esemplare quindi può servire per i confronti; ma non è sempre così, perché ad es. può perdersi. In questo caso può essere rimpiazzato da un neotipo. Quindi, per definizione, il concetto di specie tipologica non implica necessariamente il fissismo di Linneo, perché al tipo se ne possono aggiungere altri, paratipi, che danno l'idea della variabilità. Questo concetto, sebbene oggi comunemente utilizzato in tassonomia, è formalmente incompleto e di utilizzo più pratico che teorico, in quanto criticato aspramente da Lamarck in poi, che con la teoria nominalistica mette in discussione l'idea stessa di archetipo.
La specie "cronologica" è basata sul concetto "tempo" ed è il classico campo di studi sulla paleontologia sistematica e biostratigrafia.
Si possono indicare vari esempi da sezioni stratigrafiche affidabili. Uno di questi, molto significativo è il concetto di cronospecie per l'ammonite del genere Hildoceras (che si può considerare una specie il cui ambito morfologico è quello della specie tipo Hildoceras bifrons). Questo discorso è legato al limite, all'interno del piano Toarciano, tra la zona a Hildaites undicosta e quella a Hildoceras bifrons. La prima comparsa degli ammoniti del genere Hildoceras, che sono in realtà Hildoceras primitivi senza solco giro-laterale, è basata su un criterio morfologico-evolutivo. Cioè sulla comparsa all'interno della sottofamiglia Hildoceratinae delle forme con coste anguliradiate.[6] Prima del limite non ci sono forme con coste anguliradiate, dopo il limite compaiono forme dubbie o con coste anguliradiate. La zona a Bifrons, nota in gran parte dell'Europa, indagata in Appennino (Rosso Ammonitico umbro-marchigiano) è rappresentata circa da 40 livelli fossiliferi, tutti con fossili ben conservati come modelli interni conchigliari e campionati dettagliatamente.[7] Sono posti nel membro rosso ammonitico nodulare-marnoso. Tutti e 40 quasi, in 2 m circa di spessore, contengono ammoniti del genere Hildoceras, generalmente inteso con il solco giro-laterale e parte interna della spira liscia. Negli ultimi 2-3 livelli dei 40 il genere è rappresentato da forme debolmente ornate, involute, subdiscoidali e con area ventrale stretta non solcata. Con queste forme si definisce il limite superiore della zona. Sopra la zona a Hildoceras bifrons, così come noi la intendiamo per esperienza, il genere Hildoceras è assente per non più poi ricomparire.
È questo un concetto concreto di specie, definita con le sue comparsa e scomparsa; però una documentazione così ricca e varia al riguardo (varie centinaia di campioni) è tipica dell'Italia e cioè del Rosso Ammonitico, unità che può essere considerata continua o quasi; manca infatti anche se parzialmente nello stratotipo del Toarciano francese.[8]
La "specie filofenetica" è basata sulla combinazione della metodologia fenetica con la teoria evolutiva, considerando nell'analisi delle similitudini anche le relazioni filogenetiche.
La specie fenetica applica algoritmi di analisi delle similitudini e dei caratteri comuni, rendendo questa metodologia in grado di analizzare anche esseri inanimati. Utile per i fossili, anche questa definizione non tiene conto delle relazioni filogenetiche tra i rami evolutivi e le specie.
In posizione variabile:Clado · Legione · Coorte · Sezione · Sottosezione
Qui, nella figura annessa, si consideri che i generi citati sono da considerare specie morfo-cronologiche, quindi indagabili statisticamente per la loro variabilità.
Sicuramente due organismi per appartenere alla stessa specie devono condividere caratteristiche di base e numerose particolarità, talora prive di importanza adattativa ("caratteri meristici").
Poiché ci si trova spesso di fronte a varie popolazioni apprezzabilmente differenziate, la "creazione" di specie separate o la loro unificazione in una sola specie, a causa del polimorfismo, dipende dalla esperienza dei ricercatori che valutano la diversità intra ed extra-specifica.
La definizione attualmente più utilizzata è quella del russo Teodosij Dobžanskij e del tedesco Ernst Mayr, basata sulla capacità di organismi cospecifici di incrociarsi e dare prole fertile. Benché funzioni nella maggior parte dei casi, questo criterio non si applica o lascia dubbi nei casi di:
In pratica si individuano le specie basandosi su criteri gestiti dall'esperienza e dal buon senso. Dal punto di vista dell'evoluzione, per l'idea darwiniana, la formazione di una specie è spesso un fenomeno graduale e implicava entità naturali che cambiavano, adattandosi continuamente a fattori ambientali. Linneo, invece era un fissista, perché le specie naturali per lui erano materializzazioni di idee immutabili ben distinte (ispirazione della filosofia platonica).  I paleontologi del '900, tenendo conto che le sequenze evolutive erano affette da salti e che tra le specie non si trovavano forme intermedie, hanno cercato di spiegare il fenomeno con le stasi evolutive e le comparse improvvise  (vedi equilibri punteggiati di Gould e Eldredge). Però la documentazione paleontologica reperibile nelle successioni marine a strati, anche se lacunose per quel che riguarda l'evoluzione, presenta talora la continuità darwiniana: vedi ad es. le serie evolutive concrete degli Echinoidi MIcraster del Cretaceo superiore inglese[9][10] e degli ammoniti Hildoceratidae citate sopra. La loro continuità di documentazione si manifesta nella obbiettiva difficoltà di classificazione, che pone ai paleontologi problemi di difficile soluzione. Quindi quando si ha, nelle serie evolutive concrete, oltre alle specie note, una grande varietà di forme, intermedie e non, in ciò è il carattere dell'evoluzione gradualistica in cui Darwin credeva, anche se in modo teorico. 
Sulla sostanziale arbitrarietà di un qualsiasi tipo di classificazione è chiara la posizione di Darwin, che ha avuto grande lungimiranza influenzato come era dall'evoluzione che stava studiando, posizione che oggi appare, però, sotto questo profilo in parte superata:
«[...] io considero il termine specie come una definizione arbitraria che, per motivi di convenienza, serve a designare un gruppo di individui strettamente simili tra di loro, per cui la specie non differisce granché dalla varietà, intendendosi con questo termine le forme meno distinte e più fluttuanti. Inoltre, anche il termine di varietà viene applicato arbitrariamente per pura praticità nei confronti delle semplici variazioni individuali.»
(Charles Darwin, L'origine delle specie, cap. 2, "La variazione in natura")Altri progetti
Il termine muscolo (derivante dal latino musculus) identifica un organo composto in prevalenza da tessuto muscolare, ovvero un tessuto biologico con capacità contrattile; composti da fibre, le quali sono classificate in fibre bianche, ossia quelle a contrazione rapida che garantiscono velocità, e fibre rosse, fibre specializzate in contrazione lenta garantendo resistenza, il muscolo ha quattro funzioni: protegge le ossa, riscalda il nostro corpo quando si contrae, lo sostiene e ne permette il movimento; l'insieme dei muscoli costituisce l'apparato muscolare, che fa parte insieme allo scheletro e alle articolazioni dell'apparato locomotore.
Ci sono diversi tipi di muscoli.
In base alla morfologia, possiamo distinguere:
I muscoli lisci (salvo pochissime eccezioni) sono involontari, cioè la contrazione di questi avviene in maniera indipendente dalla volontà: sotto il controllo di ormoni, stimoli esterni o in seguito a impulsi provenienti dal sistema nervoso autonomo.
In base alla funzione possiamo distinguere:
Il muscolo scheletrico è costituito da fibre muscolari di forma allungata, unite alla loro estremità a tessuto connettivo denso che rappresenta la componente tendinea della fibra. Il citoplasma di tali fibre è occupato da fasci di miofibrille deputate alla contrazione e al rilassamento del muscolo. A un esame microscopico si possono individuare nelle fibrille diverse bande chiare e bande scure che si ripetono regolarmente. Queste bande sono poi delimitate da due linee sottili, dette linee Z, costituite da proteine di ancoraggio.I sarcomeri (così si chiamano queste unità) sono poi costituiti da fasci di filamenti paralleli e alterni di due tipi: 
Quando un muscolo è rilassato, i filamenti sottili e quelli spessi sono vicini, ma non collegati, mentre durante la fase di contrazione interagiranno assieme.
In fisiologia si distinguono sette movimenti realizzati dai muscoli striati scheletrici:
Il miocardio è formato da fibre muscolari striate simili a quelle del muscolo scheletrico, ma con significative differenze. Esse contengono i nuclei in posizione centrale, sono più piccole, non sono isolate fra loro ma sono connesse l'una all'altra. Alcune cellule si diramano in modo che una cellula si connetta ad altre due cellule. Le aree di contatto sono denominate dischi intercalari. Nella parte citoplasmatica dei dischi intercalari c'è la linea Z. L'unione delle fibre è sia meccanica che elettrica. L'unione meccanica è dovuta principalmente a desmosomi, l'unione elettrica a gap junction che permettono il passaggio di ioni calcio e piccole molecole fra le cellule. Le gap junction creano una sinapsi elettrica che permette il passaggio di un potenziale d'azione da una fibra muscolare all'altra. Quando un potenziale d'azione è generato, questo si propaga a tutte le cellule del miocardio; i miocardiociti sono quindi interconnessi in modo analogo a quanto succede nelle cellule muscolari lisce.
Il tessuto muscolare liscio è principalmente responsabile della muscolatura degli organi interni: le cellule sono fusiformi, il nucleo è centrale, ma i miofilamenti sono disposti in maniera irregolare e per questo motivo non notiamo le striature che caratterizzano il muscolo scheletrico.Per quanto riguarda l'attività del muscolo liscio notiamo molte differenze rispetto al tessuto analizzato in precedenza:
Possiamo suddividere la contrazione muscolare in tre fasi principali:
La contrazione è il risultato di una serie di modificazioni intracellulari coordinate che porta al movimento della fibra muscolare e, di conseguenza, del muscolo stesso. La contrazione avviene in tutti i tipi di muscoli; è meglio rappresentata nel muscolo scheletrico, dove esiste una struttura metamerica (il sarcomero) dotata di particolarità morfologiche e funzionali. La contrazione muscolare di un muscolo scheletrico ha inizio quando il segnale elettrico, proveniente dai motoneuroni del sistema nervoso centrale (nuclei dei nervi cranici con componente motoria, o neuroni motori delle teste delle corna anteriori del midollo spinale) arriva ai bottoni sinaptici. Questi liberano nello spazio subsinaptico (tra membrana presinaptica e postsinaptica) una sostanza, l'acetilcolina, che agisce sui recettori colinergici nicotinici presenti nella placca neuromuscolare (membrana postsinaptica) determinando il potenziale d'azione. Il potenziale d'azione, che si propaga lungo il sarcolemma (ovvero la membrana cellulare del muscolo scheletrico), va a colpire canali voltaggio dipendenti intermembrana (canali della diidropiridina) i quali comunicano sul lato citoplasmatico con un complesso proteico, il recettore per la rianodina, che determina l'apertura dei canali Ca+2 contenuti nel reticolo sarcoplasmatico, che vengono così liberati. L'acetilcolina agisce inoltre sulle membrane che racchiudono i fasci di miofibrille, rendendole così permeabili agli ioni Ca+2, che hanno una fondamentale azione catalizzatrice per importanti reazioni chimiche. La liberazione di Ca+2 induce un processo di feedback positivo con amplificazione della concentrazione citoplasmatica di calcio: ioni Ca+2 stimolano pompe per l'estrusione di altro calcio.
Dai mitocondri della fibra muscolare, viene poi liberato ATP, e da altri organuli viene liberata la troponina. Tale sostanza andrà ad agire sui filamenti sottili, infatti avverrà una reazione catalizzata dagli ioni Ca+2, che permetterà alla troponina di legarsi alla tropomiosina, che lascerà libero il sito di attacco per la miosina. L'ATP agirà invece sui filamenti spessi: mediante una reazione di fosforilazione, e quindi mediante una reazione esoergonica, l'ATP diventa ADP, libera un gruppo fosfato, una grande quantità di energia, e si lega alla testa di miosina, la quale sfrutta tale energia per saltare dal suo loco, e andare ad occupare il sito di attacco nel filamento sottile, lasciato libero dalla tropomiosina. Durante lo scorrimento le teste di miosina si legano a quelle di actina con una precisa angolazione di 45°. Durante questo processo avvengono cambiamenti neoclitini, derivanti dall'assimilazione di proteine. Il processo fa quindi variare l'angolazione di actina di 15° facendola arrivare a 60°.
Nella fase di rilassamento, il procedimento avviene in modo contrario a quello della contrazione e sembra che la parvalbumina sia coinvolta nel processo.
La fase latente è quella che segue lo stimolo, ma nella quale non c'è risposta. Ciò è dovuto al fatto che i canali voltaggio dipendenti che hanno fatto entrare gli ioni sodio per dare inizio al potenziale d'azione sono ora nella fase inattivata, pertanto non sono sensibili ad ulteriori perturbazioni elettriche: questo è detto "periodo refrattario (altro modo per indicare la fase latente) assoluto". Segue immediatamente un "periodo refrattario relativo" dovuto al fatto che la cellula subisce un'iperpolarizzazione che fa scendere il suo potenziale al di sotto di quello che sarebbe il suo potenziale di riposo, pertanto una nuova contrazione è possibile, ma è necessaria una perturbazione elettrica maggiore perché si raggiunga il potenziale d'azione.
Le funzioni della muscolatura sono principalmente sei: la determinazione del movimento, il mantenimento della postura, la stabilizzazione delle articolazioni, la produzione di calore, la protezione di strutture ossee ed organi interni e il movimento di liquidi e sostanze.
I movimenti che noi compiamo ogni giorno sono il risultato della contrazione muscolare. Infatti, l'attività dei muscoli ci consente di rispondere a qualsiasi cambiamento dell'ambiente; per esempio la rapidità con cui i muscoli si contraggono ci permette di scappare da una situazione di pericolo.
Grazie all'enorme lavoro che i muscoli effettuano in sequenza, per aggiustare la nostra posizione, ci permettono di mantenere la posizione eretta o la posizione da seduti, malgrado la forza di gravità.
Mentre esercitano trazione sulle ossa per determinare il movimento, i muscoli stabilizzano le articolazioni dello scheletro. Come i tendini, particolarmente importanti per rinforzare e stabilizzare quelle articolazioni le cui superfici sono poco congruenti.
Quando avviene la contrazione muscolare, viene utilizzato l'ATP e circa i tre quarti di questa energia viene liberata sotto forma di calore. Questa funzione è di vitale importanza per mantenere la temperatura corporea costante, circa 37 gradi.
In presenza di alcuni traumi esterni, i muscoli possono svolgere la funzione di barriera/cuscinetto verso le strutture ossee od organi interni ad essi sottostanti.
Come il cuore ha la funzione di "muovere" il sangue tramite i vasi sanguigni dal "centro" del corpo alla periferia, anche altri muscoli tramite la loro contrazione, svolgono la medesima azione "spremendo" i vasi sanguigni e linfatici ad essi adiacenti.
La sordità è la disfunzione o lesione dell'apparato uditivo che comporta una riduzione più o meno grave dell'udito. Può essere causata da: malattia, esposizione eccessiva ai rumori, assunzione di determinati farmaci e antibiotici, lesioni all'orecchio. La patologia interessa il genere umano ed animale; può presentarsi già alla nascita oppure durante la vita, a seguito di un trauma.
Viene detta anche «handicap della comunicazione» e «handicap invisibile», in quanto non immediatamente percepibile dall'ambiente esterno.[1]
La valutazione clinica della sordità avviene attraverso collaborazione di un otorinolaringoiatra, audiologo, genetista clinico, e altri specialisti in quanto la sordità può essere legata a fattori di varia natura come fattori cardiaci, neurologici, tiroidei ed altri. La storia medica, ottenuta attraverso il raggruppamento delle informazioni riguardanti il paziente e quindi con un lavoro olistico di équipe, è fondamentale perché la sordità può scaturire da elementi come la prematurità, iperbilirubinemia, sottopeso alla nascita, meningite ed altro.
La diagnosi si effettua entro i primi 6 mesi di vita quando il cervello presenta ancora quella plasticità indispensabile all’acquisizione del linguaggio che progressivamente inizia a venir meno a partire dai 3 anni di vita.
Lo sviluppo di apparecchiature audiometriche altamente specializzate ha permesso l’esecuzione dello screening neonatale e l’analisi della funzione uditiva nel corso della degenza post-partum entro il terzo giorno di vita. Questa novità ha permesso le diagnosi precoci e di conseguenza anche gli interventi.
Vi sono due tipi fondamentali di perdita di udito. Da un lato il tipo sindromico, ammontante a circa il 30% dei casi, che associa la perdita dell’udito ad altre malattie comorbide o anomalie corporee, mentre il restante 70% è di tipo non sindromico e quindi la perdita dell’udito non può essere associata ad altre patologie. 
La struttura del cervello che merita maggiore attenzione è la coclea in quanto sede fondamentale nello sviluppo dell’apparato uditivo.
Le persone nate sorde o diventate tali nei primi anni di vita (sordità prelinguale) riscontrano difficoltà nell'apprendere la lingua parlata, che non acquisiscono in maniera naturale ma che deve essere insegnata loro attivamente. Per favorire il successo di interventi riabilitativi sulla sordità congenita si ricorre, sempre più, allo screening uditivo neonatale: in tal modo è possibile velocizzare operazioni di diagnosi, apparecchio acustico, impianto cocleare, preliminari ai percorsi riabilitativi ed apprendimento linguistico.
Per l’acquisizione del linguaggio ci sono diversi metodi:
I bambini sordi seguono lo stesso sviluppo linguistico[3] e comunicativo dei bambini udenti: hanno infatti lo stesso processo di acquisizione, compiono le stesse tappe, ad età confrontabili, a prescindere dalla lingua a cui sono esposti. Si osserva un parallelismo tra le tappe di un bambino udente e quelle di un bambino sordo: il bambino sordo elabora stimoli visivi ed ha un apprendimento attraverso il canale visivo-gestuale mentre il bambino udente elabora stimoli uditivi ed ha un apprendimento tramite il canale uditivo; il bambino sordo produce una sorta di lallazione manuale che richiama quello che i bambini udenti producono sul piano vocale; intorno al primo anno di vita i bambini sordi producono i primi segni, così come i bambini udenti producono le prime parole. Intorno al primo anno di vita, i bambini sordi hanno le stesse potenzialità dei bambini udenti: la capacità dell’essere umano di utilizzare il linguaggio può avvenire sia attraverso il canale visivo-gestuale sia attraverso quello acustico-vocale; dipende dal contesto in cui è immerso il bambino e dalla lingua a cui viene esposto. In sostanza, la facoltà di linguaggio delle persone sorde è riuscita a realizzarsi in modo spontaneo in un’altra modalità. Un bambino sordo può comunque imparare a produrre e comprendere il linguaggio orale, ma è necessaria una protesizzazione precoce e un allenamento sistematico tramite intervento logopedico, mentre il bambino udente acquisisce la lingua orale a cui è esposto in modo naturale e senza un insegnamento specifico. 
Lo sviluppo linguistico dei bambini sordi si può compromettere a seconda delle tempistiche con cui vengono esposti ad un input linguistico.[4] Diversi studi evidenziano come nei bambini sordi con genitori udenti ci sia un ritardo complessivo nello sviluppo del linguaggio e una variabilità individuale più accentuata rispetto ai bambini udenti. Sono molteplici i fattori che influenzano l’evoluzione del linguaggio nei bambini: la diagnosi tempestiva, il livello di sordità, l’eventuale tipologia di protesizzazione, la tipologia di intervento logopedico congiuntamente a fattori ambientali ed individuali.
Non vengono messe in risalto particolari differenze nei primi 7 mesi di vita dei bambini: sia bambini sordi che udenti utilizzano gli stessi comportamenti vocali e gestuali, quindi lo sviluppo appare tipico. Dagli 8 mesi in poi invece, a causa del mancato input acustico, diminuisce la produzione di consonanti e solitamente anche la lallazione spontanea tende a sparire. A 13 mesi non compare la capacità di utilizzare parole e gesti come simboli decontestualizzati dal normale contesto di apprendimento. Dai 17 mesi in poi risulta particolarmente evidente la difficoltà ad ampliare il vocabolario e formulare le prime frasi. Da questo momento in poi, nel caso in cui non sia stata già accertata clinicamente, la sordità del bambino diventa molto più evidente e impossibile da evitare per i genitori.
Il danno riportato dall'udito può essere lieve, medio, grave o addirittura profondo: un soggetto in questa condizione non percepisce nemmeno suoni e rumori di elevata intensità. L'entità della perdita uditiva[5] è espressa in decibel (dB). Si ha:
I diversi gradi di sordità sono correlati, in ordine decrescente, alla possibilità di percepire i suoni e di sfruttare i residui acustici attraverso l'utilizzo delle protesi.
Quando la sordità interessa un solo orecchio si parla di "anacusia", altrimenti di "cofosi". La sordità parziale è invece nota col nome di ipoacusia, la quale può essere indotta dai danni relativi ai rumori (in inglese, noise-induced hearing loss o NIHL)[6][7] oppure dall'invecchiamento (ARHL, o presbiacusia).
Oltre che per l'entità della riduzione uditiva, l'ipoacusia viene classificata in base alla sede del danno che l'ha prodotta:
Nel caso di compresenza di una perdita uditiva di tipo trasmissiva e neurosensoriale si parla di sordità mista.
Conoscere l’epoca di insorgenza della sordità[8] è di fondamentale importanza. Tanto più essa sopraggiungerà precocemente, tanto più gravi saranno le conseguenze della deprivazione uditiva, tra queste soprattutto la possibilità di acquisire facilmente una lingua vocale. Rispetto a quest’ultima le sordità si distinguono in:
È evidente come sia diversa la situazione di coloro che sono nati sordi o che hanno perso l’udito prima dell’acquisizione del linguaggio, rispetto a coloro che sono diventati sordi dopo aver fatto esperienza del suono e aver imparato il linguaggio. Il sordo prelinguistico rischia di subire un grave ritardo nell’acquisizione del linguaggio se non si interviene precocemente con un adeguato iter logopedico.
Tra le cause della sordità[9] (valide anche per la sordità acquisita) abbiamo:
Inoltre la sordità può essere:
Oggigiorno, si conoscono più di 400 sindromi associate alla perdita dell’udito, ma tra quelle più comuni vi sono la Sindrome di Usher la quale consiste nell’associazione tra sordità e degenerazione dell’apparato visivo. La sindrome di Pendred: dovuta ad un’anomalia endocrina che provoca la malformazione dell’orecchio interno e causa sordità. Sindrome di Jervel Lange-Nielsen: associazione tra sordità sensori-neurale e anomalia cardiaca. In Italia, studi recenti hanno verificato che la prevalenza di persone affette da sordità ammonta a circa 70 mila persone equivalente a circa 1 bambino su 1000. Tra esse, circa il 50% presenta cause mentre la restante parte trova la causa in fattori ambientali, come droghe, prematurità embrionale e trauma. In particolare, in Italia ogni mese nascono tra i 50 e i 100 bambini sordi.[11]
Vi sono dei criteri che vengono applicati entro i primi 28 giorni di vita che permettono di controllare i seguenti fattori di rischio:
Altri metodi preventivi sono la vaccinazione anti-rosolia obbligatoria, determinazione del gruppo sanguigno, informazione genetica parentale per evitare sordità ereditaria, controllo durante la gestazione, controllo della popolazione nei primi 9 mesi di vita.
L’applicazione dell'apparecchio acustico deve essere precoce (tra i 3 e i 6 mesi di vita) per ridurre al minimo il periodo di deprivazione uditiva. L’applicazione dell’impianto cocleare avverrà successivamente, quando non ci saranno più dubbi sulla diagnosi, e quindi non prima dei 12 mesi di vita, dopo un periodo di uso delle protesi. L’uso dell'apparecchio acustico o impianto non è, in ogni caso, in grado di ripristinare al 100% il funzionamento dell’orecchio. 
L’uso dell’impianto cocleare va sempre associato alla terapia logopedica.
La terapia ha come finalità quella di riabilitare l’uso e le proprietà del linguaggio così da favorire la comunicazione. Tra gli obiettivi fondamentali vi è il superamento della fase di reazione alla sordità del bambino, in particolar modo per genitori udenti, attraverso percorsi di psicoterapia e osservazione della relazione caregiver-bambino. Solo in seguito sarà possibile avviare un processo di rimarginazione delle abilità cognitive e sensoriali che possono aver subito un rallentamento nel loro sviluppo. In base a quando viene eseguita la diagnosi e l’adattamento dell'apparecchio acustico, l’intervento terapeutico si distingue in educazione quando l’intervento avviene entro i 18 mesi di vita in quanto i processi di acquisizione del linguaggio non sono ancora stati compromessi, e rieducazione quando il linguaggio è solo parzialmente strutturato. 
La theraplay[12] si basa sulla teoria dell'attaccamento di John Bowlby la quale ritiene di particolare importanza la relazione tra genitore e bambino per il futuro sviluppo delle interazioni del bambino. La theraplay viene usata in formati differenti quali il format individuale, familiare e di gruppo. Questi format a loro volta possono svolgersi in ambienti diversi quali centri di riabilitazione, cliniche e scuole. Di particolare interesse è la theraplay di gruppo, un metodo basato sul gioco che incoraggia l’interazione bambino-genitore e favorisce lo sviluppo dell’autostima del bambino. Questo tipo di terapia è stata supportata in quanto si adatta a vari range di età quindi segue il naturale sviluppo cognitivo ed emotivo dei bambini adattando le attività ludiche alla fascia d’età. 
L’obiettivo di questa terapia è quello di modificare l’atteggiamento del bambino e stimolare atteggiamenti di empatia, amore e azioni costruttive al fine di migliorare il benessere psicologico e la regolazione emotiva.
Il canale comunicativo maggiormente utilizzato in theraplay è quello tattile attraverso attività di contatto tra i partecipanti.
Nei bambini sordi, la musicoterapia favorisce lo sviluppo linguistico[13], cognitivo, sociale ed emozionale in quanto può essere praticata di gruppo creando automaticamente una comunità con interessi condivisi. Inoltre, la ricerca ha dimostrato che i bambini sordi riescono a raggiungere capacità ritmiche superiori rispetto ai bambini udenti in quanto essi percepiscono non il suono in sé ma le vibrazioni che emette. 
Tra i metodi utilizzati vi sono: la lettura e comprensione dei testi, il canto terapeutico, suonare strumenti, musica di gruppo, e terapia del movimento. È evidente che tutti questi aspetti concorrono a migliorare l’esperienza di vita del bambino sordo offrendo strumenti comunicativi alternativi che stimolano quelle facoltà che possono essere state influenzate dal deficit uditivo.
L'ipoacusia professionale o ipoacusia da rumore è la patologia professionale più frequentemente registrata in Italia e nel mondo. Dai dati INAIL la malattia professionale “Ipoacusia e sordità da rumori” rappresenta circa il 40% dei casi di tutte le malattie professionali denunciate nel ramo industria, servizi e agricoltura. Si tratta di una patologia totalmente prevenibile tramite insonorizzazione, abbattimento del rumore e utilizzo di dispositivi di protezione personale.[14][15][16]
La tubercolosi (in sigla TBC) è una malattia infettiva causata da vari ceppi di micobatteri, soprattutto dal Mycobacterium tuberculosis, chiamato anche Bacillo di Koch.[1]
Considerata fino alla metà del XX secolo una grave malattia, invalidante e alla lunga mortale se non tempestivamente diagnosticata e curata, divenuta oggi nei paesi occidentali più facilmente diagnosticabile e curabile, la tubercolosi attacca solitamente i polmoni (tubercolosi polmonare), ma può colpire anche altre parti del corpo (tubercolosi extrapolmonare). Si trasmette per via aerea attraverso goccioline di saliva emesse con la tosse secca.[2] La maggior parte delle infezioni che colpiscono gli esseri umani risulta essere asintomatica, cioè si ha un'infezione latente. Circa 1/10 delle infezioni latenti alla fine progredisce in malattia attiva, che, se non trattata, uccide più del 50% delle persone infette.
I sintomi classici sono una tosse cronica con espettorato striato di sangue, febbre di rado elevata, sudorazione notturna e perdita di peso. L'infezione di altri organi provoca una vasta gamma di sintomi. La diagnosi si basa sull'esame radiologico (comunemente una radiografia del torace), un test cutaneo alla tubercolina, esami del sangue e l'esame microscopico e coltura microbiologica dei fluidi corporei. Il trattamento può essere talvolta difficile e richiedere l'assunzione di antibiotici multipli per qualche tempo. La resistenza agli antibiotici è un problema crescente nell'affrontare la malattia. La prevenzione si basa su programmi di screening e di vaccinazione con il bacillo di Calmette-Guérin.
Si ritiene che un terzo della popolazione mondiale sia stata infettata con M. tuberculosis,[3][4] e nuove infezioni avvengono ad un ritmo di circa una al secondo.[3] Nel 2007 vi erano circa 13,7 milioni di casi cronici attivi[5] e nel 2010 8,8 milioni di nuovi casi e 1,45 milioni di decessi, soprattutto nei paesi in via di sviluppo.[6] Il numero assoluto di casi di tubercolosi è in calo dal 2006 e di nuovi casi dal 2002.[6] Inoltre, le popolazioni dei paesi in via di sviluppo contraggono la tubercolosi più facilmente, poiché hanno spesso un sistema immunitario più compromesso a causa degli alti tassi di AIDS.[7] La distribuzione della tubercolosi non è uniforme in tutto il mondo, circa l'80% della popolazione residente in molti paesi asiatici e africani risulta positiva nei test alla tubercolina, mentre solo il 5-10% della popolazione degli Stati Uniti ne è affetta.[1]
La tubercolosi è stata presente negli umani sin dall'antichità. La prima scoperta certa del Mycobacterium tuberculosis è nei resti di un bisonte di circa 18.000 anni fa.[8] Tuttavia se la tubercolosi abbia avuto origine nel bestiame e sia mutato trasmettendosi agli umani, o se sia derivato da un antenato comune non è ancora chiaro.[9] Resti scheletrici mostrano che gli uomini preistorici avevano la tubercolosi già nel 4000 a.C., e tracce di decadimento dovuto alla tubercolosi sono state ritrovate nella spina dorsale di alcune mummie del 3000-2400 a.C.[10] Phthisis è un termine greco per indicare la tubercolosi, dal quale sarebbe poi derivato il termine odierno tisi; attorno al 460 a.C., Ippocrate aveva identificato la tisi come la più diffusa malattia di tutti i tempi, causa di febbre ed emottisi, quasi sempre fatale.[11] Studi genetici suggeriscono che la tubercolosi fosse presente in Sudamerica da circa 2000 anni.[12] In Sudamerica, la prima prova della presenza di tubercolosi è associata alla cultura Paracas (dal 750 a.C. al 100 d.C. circa).[13]
Lo studio della tubercolosi risale a Il canone della medicina scritto da Avicenna nel X secolo. Fu il primo medico a identificare la tubercolosi polmonare come una malattia infettiva, il primo a riconoscerne l'associazione col diabete ed il primo a suggerire che si potesse diffondere attraverso il contatto con il suolo e l'acqua.[14][15] Sviluppò inoltre il metodo della quarantena per limitare la diffusione della tubercolosi.[16]
Nonostante fosse già stabilito dal dottor Richard Morton nel 1689 che la forma polmonare era associata con dei tubercoli,[17][18] a causa della varietà dei suoi sintomi, la tubercolosi non venne identificata come una singola malattia fino al 1820 circa, e non venne chiamata tubercolosi fino al 1839 da Johann Lukas Schönlein[19] Durante gli anni 1838-1845, il dottor John Croghan, proprietario della Mammoth Cave, portò un gruppo di infetti di tubercolosi nella caverna sperando di curarli dalla malattia con la sua temperatura costante e la purezza dell'aria; morirono tutti nel giro di un anno.[20] Il primo sanatorio per la tubercolosi aprì nel 1859 a Görbersdorf, all'epoca in Germania (oggi Sokołowsko e compresa nel territorio polacco), di proprietà di Hermann Brehmer.[21]
Riguardo a questa dichiarazione, il Times del 15 gennaio 1859 mise a pagina 5 una pubblicità in cui si cercavano fondi per il Bournemouth Sanatorium per la consunzione, facendo riferimento al bilancio dell'anno precedente e offrendo un resoconto annuale ai possibili donatori, implicando che l'esistenza di questo sanatorio risalirebbe perlomeno al 1858.
Il batterio che causa la tubercolosi, Mycobacterium tuberculosis, venne identificato e descritto il 24 marzo 1882 da Robert Koch. Questi ricevette il Premio Nobel per la medicina nel 1905 per la scoperta.[22] Koch non credeva che la tubercolosi bovina (del bestiame) e quella umana fossero simili, il che ritardò il riconoscimento del latte infetto come fonte di infezione. Più tardi questa fonte venne eliminata dal processo di pastorizzazione. Koch annunciò un estratto in glicerina del batterio della tubercolosi come "rimedio" per la tubercolosi nel 1890, chiamandolo tubercolina. Non era efficace, ma venne adottato in seguito come test per la tubercolosi pre-sintomatica.[23]
Il primo vero successo nell'immunizzazione contro la tubercolosi venne sviluppato da un ceppo attenuato di tubercolosi bovina da Albert Calmette e Camille Guérin ottenuto attraverso una serie di passaggi in terreno di coltura durati molti anni a partire dal 1908[24]. Era chiamato "BCG" (Bacillo Calmette-Guérin). Il vaccino BCG venne utilizzato per la prima volta sugli umani nel 1921 in Francia,[25] ma solo dopo la seconda guerra mondiale ricevette un ampio consenso negli Stati Uniti, nel Regno Unito e in Germania.[26]
La tubercolosi, o "consunzione" come veniva comunemente chiamata, causò la maggior preoccupazione pubblica nel XIX e inizi del XX secolo come malattia endemica del ceto povero. Nel 1815, una morte su quattro in Inghilterra era causata dalla consunzione; entro il 1918 una morte su sei in Francia era ancora causata dalla tubercolosi. Nel XX secolo la tubercolosi ha ucciso circa 100 milioni di persone.[27] Dopo la certezza nel 1880 che la malattia era contagiosa, la tubercolosi venne resa in Gran Bretagna una malattia "con obbligo di notifica", cioè una malattia che deve essere portata a conoscenza delle autorità competenti; vennero diffuse campagne contro lo sputare in luoghi pubblici, e gli infetti vennero "incoraggiati" a entrare in sanatori che ricordavano prigioni; i sanatori per le classi medio-alte offrivano eccellenti cure e una costante osservazione medica.[21] Qualunque fossero i supposti benefici dell'aria fresca e del lavoro manuale nei sanatori, persino sotto le migliori condizioni, il 50% delle persone entrate morirono entro cinque anni (1916).[21]
La promozione di francobolli natalizi iniziò in Danimarca durante il 1904 come mezzo per raccogliere fondi per programmi contro la tubercolosi. Essa si estese agli Stati Uniti e al Canada nel 1907-1908 per aiutare l'Associazione Nazionale della Tubercolosi (rinominata in seguito Associazione Americana dei Polmoni).
Negli Stati Uniti la preoccupazione della diffusione della tubercolosi giocò un ruolo nel movimento per proibire lo sputare in pubblico, salvo usare le sputacchiere.
In Europa le morti da tubercolosi crollarono da 500 ogni 100.000 casi nel 1850 a 50 ogni 100.000 casi nel 1950. Miglioramenti nella salute pubblica ridussero la tubercolosi ancor prima dell'arrivo degli antibiotici, anche se la malattia rimase una considerevole minaccia alla salute pubblica, tanto che quando il Medical Research Council (consiglio medico della ricerca) venne formato nel Regno Unito nel 1913, il suo scopo principale era la ricerca sulla tubercolosi.[28]
Non fu che dopo il 1946, con lo sviluppo dell'antibiotico streptomicina, che un trattamento efficace e una cura divennero possibili. Prima dell'introduzione di questa medicina, l'unico trattamento oltre ai sanatori erano gli interventi chirurgici, compreso la tecnica del pneumotorace, in cui si faceva collassare un polmone infetto per farlo "riposare" e permettere la guarigione delle lesioni, e che risultò di minimo beneficio, tanto che venne interrotta a partire dal 1950.[29] L'emergere di tubercolosi multiresistente ha introdotto di nuovo l'operazione chirurgica come parte del trattamento per queste infezioni. La rimozione delle cavità del torace riduce il numero di batteri nei polmoni, e incrementa l'esposizione dei restanti batteri al flusso sanguigno, provocando in teoria un incremento dell'efficacia della chemioterapia.[30]
La speranza che la malattia potesse essere definitivamente sconfitta è stata schiacciata dall'insorgenza di ceppi resistenti agli antibiotici negli anni ottanta. Per esempio, i casi nella Gran Bretagna di tubercolosi, attorno ai 117.000 nel 1913, erano crollati a circa 5.000 nel 1987, ma sono risaliti, raggiungendo i 6.300 casi nel 2000 e i 7.600 casi nel 2005.[31] A causa dell'eliminazione delle strutture di salute pubblica a New York e all'emergere dell'HIV, un ritorno della malattia è avvenuto negli anni ottanta.[32] Il numero di coloro che non riescono a completare il ciclo di farmaci è elevato. New York ha avuto a che fare con più di 20.000 pazienti tubercolosi "non necessari" con ceppi multiresistenti (resistenti, perlomeno, a Rifampicina e Isoniazide). Il risorgere della tubercolosi ha causato la dichiarazione dello stato di emergenza globale della salute pubblica da parte della Organizzazione Mondiale della Sanità nel 1993.[33]
Secondo l'Organizzazione Mondiale della Sanità, circa due miliardi di persone, cioè un terzo della popolazione mondiale, sono stati esposti al patogeno della tubercolosi.[35] Annualmente 8 milioni di persone si ammalano di tubercolosi, e 2 milioni muoiono a causa della malattia in tutto il mondo.[36] Nel 2004, circa 14,6 milioni di persone avevano la tubercolosi attiva, con 9 milioni di nuovi casi. Il tasso di incidenza annuale varia da 356 ogni 100.000 abitanti in Africa a 41 ogni 100.000 abitanti in America.[3] La tubercolosi è l'infezione più grave del mondo per numero di morti di donne in età riproduttiva e la causa di morte principale nelle persone affette da HIV o AIDS.[37]
Nel 2005, il paese con l'incidenza più elevata di tubercolosi era lo Swaziland, con 1262 casi ogni 100.000 persone. L'India ha il più elevato numero di infezioni, con oltre 1,8 milioni di casi.[38] Nei paesi sviluppati la tubercolosi è molto meno diffusa, ed è principalmente una malattia urbana. Nel Regno Unito, l'incidenza di tubercolosi varia da 40 persone infette ogni 100.000 abitanti a Londra a meno di 5 ogni 100.000 abitanti nel Sudovest rurale dell'Inghilterra;[39] la media nazionale è 13 ogni 100.000 abitanti. Il tasso più alto nell'Europa occidentale è in Portogallo (42 ogni 100.000) e Spagna (20 ogni 100.000). Queste incidenze vanno confrontate con i 113 abitanti infetti ogni 100.000 in Cina e i 64 ogni 100.000 in Brasile. Negli Stati Uniti l'incidenza media era di 4,9 abitanti ogni 100.000 nel 2004.[36]
Nel 2011, nei 27 Stati membri dell'Unione europea e dell'SSE vi sono stati 72.334 casi di tubercolosi (14,2 per 100.000 abitanti), il 4% in meno rispetto al 2010. L'80% di questi casi sono state nuove diagnosi, mentre il 23% era di origine straniera. In Italia, nel 2008, si sono registrati 4418 casi, con una diminuzione del 2,4% dall'anno precedente.[41]
L'incidenza della tubercolosi varia con l'età. in Africa, la tubercolosi colpisce prevalentemente gli adolescenti e i giovani adulti.[42] Tuttavia, nei paesi dove la tubercolosi è passata da alta a bassa incidenza, come negli Stati Uniti, la tubercolosi è prevalentemente una malattia delle persone anziane.[43]
Ci sono vari fattori noti che rendono le persone più suscettibili all'infezione tubercolare: nel mondo la causa maggiore è l'HIV. La co-infezione con l'HIV della tubercolosi è un problema soprattutto nell'Africa subsahariana, a causa dell'alto numero di persone infette da HIV di queste nazioni.[34][44] Fumare oltre 20 sigarette al giorno incrementa il rischio di tubercolosi da due a quattro volte.[45][46] Il diabete mellito è anch'esso un fattore di rischio importante e in costante crescita di importanza nei paesi sviluppati.[47]
Nel 2004 le statistiche di mortalità e morbosità mostravano 14,6 milioni di casi attivi, 8,9 milioni di casi nuovi e 1,6 milioni di morti, concentrati soprattutto nei paesi in via di sviluppo.[3] Inoltre, un sempre crescente numero di persone nei paesi sviluppati contraggono la tubercolosi poiché il loro sistema immunitario è compromesso da sostanze immunosoppressori, abuso di droga o HIV/AIDS.
L'aumento delle infezioni di HIV e la mancanza di programmi di controllo della tubercolosi hanno permesso la ricomparsa della tubercolosi.[48] L'emergere di ceppi resistenti agli antibiotici ha a sua volta contribuito a questa nuova epidemia, con il 20% dei casi di tubercolosi resistenti ai trattamenti standard e il 2% resistenti a farmaci di seconda linea.[49] L'incidenza di tubercolosi varia notevolmente anche tra stati confinanti, apparentemente a causa delle differenze tra le varie assistenze sanitarie.[50] L'Organizzazione mondiale della sanità ha dichiarato la tubercolosi un'emergenza sanitaria globale nel 1993, e la Stop TB Partnership ha sviluppato un "Piano mondiale di lotta alla Tubercolosi" che prevede di salvare 14 milioni di vite tra il 2006 e il 2015.[51]
L'agente eziologico principale della tubercolosi, il Mycobacterium tuberculosis (MTB), è un batterio aerobiotico che si divide ogni 16-20 ore, una velocità estremamente lenta in confronto ad altri batteri, che solitamente si dividono in meno di un'ora (uno dei più veloci batteri a replicarsi è un ceppo del batterio Escherichia coli, che si divide circa ogni 20 minuti).[52] Poiché l'MTB ha una parete cellulare, ma non una membrana esterna, viene classificato come un batterio Gram-positivo. Tuttavia, se viene applicata una colorazione di Gram, l'MTB risulta o Gram-positivo in modo estremamente debole, o non mantiene la colorazione, a causa dell'elevato contenuto di lipidi e acido micolico della sua parete cellulare.[53] L'MTB è un piccolo bacillus a forma di bastoncello, che può resistere a deboli disinfettanti e sopravvivere in uno stato disidratato per settimane. In natura, il batterio può crescere solo all'interno delle cellule di un organismo ospite, ma l'MTB può essere coltivato in vitro.[54]
Usando pigmenti istologici su campioni di espettorato, gli scienziati possono identificare l'MTB con un normale microscopio. Poiché l'MTB conserva certi pigmenti dopo essere stato trattato con soluzioni acide, viene classificato come un bacillus acido-alcolico.[53] La tecnica di pigmentazione più comune, la colorazione di Ziehl-Neelsen, tinge i bacilli acido-alcolici di un rosso acceso che risalta chiaramente su sfondo blu. Altri metodi per evidenziare questi bacilli sono la colorazione con auramina-rodamina e l'osservazione mediante microscopio a fluorescenza.
Il complesso MTB include tre micobatteri causa di tubercolosi: Mycobacterium bovis, Mycobacterium africanum e Mycobacterium microti. I primi due causano la malattia in persone immunocompetenti solo in casi rarissimi. Tuttavia, nonostante il M. microti non sia normalmente patogenico, è possibile che la prevalenza di infezioni da esso causate sia stata sottovalutata.[55]
Altri micobatteri patogenici conosciuti comprendono Mycobacterium leprae, Mycobacterium avium complex e Mycobacterium kansasii. Gli ultimi due fanno parte del gruppo di micobatteri non tubercolari (MOTT, mycobacteria other than tuberculosis). I micobatteri non tubercolari non causano tubercolosi o lebbra, ma provocano malattie polmonari simili alla tubercolosi.[56]
Circa il 90% delle persone infette dal Mycobacterium tuberculosis ha un'infezione tubercolosi asintomatica (chiamata anche LTBI, da latent tuberculsis infection), e solamente il 10% di possibilità nella vita che un'infezione latente si sviluppi in tubercolosi. Tuttavia, se non trattata, il tasso di mortalità dei casi attivi di tubercolosi è superiore al 50%.[57]
L'infezione tubercolare inizia quando i micobatteri raggiungono gli alveoli polmonari, dove attaccano e si replicano all'interno dei macrofagi alveolari.[58] Il sito primario di infezione nei polmoni è chiamato focolaio di Ghon. I batteri vengono raccolti dalle cellule dendritiche, che non permettono la loro replicazione ma che possono trasportare i bacilli ai linfonodi mediastinici locali. L'ulteriore diffusione attraverso il flusso sanguigno si dirige verso i tessuti e gli organi più distanti, dove lesioni secondarie di tubercolosi si possono sviluppare negli apici polmonari, nei linfonodi periferici, nei reni, nel cervello e nelle ossa.[59] Ogni parte del corpo può essere influenzata dalla malattia, che tuttavia molto raramente colpisce il cuore, i muscoli scheletrici, il pancreas e la tiroide.[60]
La tubercolosi è classificata come una delle condizioni infiammatorie granulomatose. Macrofagi, linfociti T, linfociti B e fibroblasti sono le cellule aggredite che formano il granuloma, con i linfociti che circondano i macrofagi infetti. Il granuloma non solo impedisce la diffusione dei micobatteri, ma fornisce un ambiente locale per la comunicazione delle cellule del sistema immunitario. Dentro al granuloma, i linfociti T (CD4+) producono citochine come l'interferone gamma, che provoca un tentativo di distruzione da parte dei macrofagi dei batteri fagocitati, senza però riscontri significativi, dal momento che i Mycobacterium tuberculosis sono batteri Catalasi positivi (resistenti quindi agli enzimi killer dei polimorfonucleati)[61] I linfociti T (CD8+) possono anche uccidere direttamente le cellule infette.[58]
Significativamente, i batteri non vengono sempre eliminati all'interno del granuloma, ma possono diventare dormienti, e svilupparsi in infezione latente. Un'altra caratteristica dei granulomi della tubercolosi umana è lo sviluppo di necrosi, cioè della morte delle cellule, al centro dei tubercoloma. A occhio nudo la necrosi ha l'aspetto di formaggio bianco, ed è stata quindi chiamata necrosi caseosa.[62]
Se i batteri della tubercolosi riescono ad accedere al flusso sanguigno da un'area di tessuto danneggiato, si diffondono nell'organismo e creano molti focolai di infezione, tutti con l'aspetto di piccoli tubercoli bianchi nei tessuti. Questa grave forma di tubercolosi è molto diffusa nei bambini e negli anziani, ed è chiamata tubercolosi miliare. I pazienti con la tubercolosi disseminata hanno una mortalità del 20% circa, persino con un trattamento intensivo.[63]
In molti pazienti l'infezione cresce e diminuisce. La distruzione dei tessuti e la necrosi è bilanciata dalla guarigione e dalla fibrosi,[62] con i tessuti affetti che vengono rimpiazzati da cicatrici e le cavità riempite di materiale necrotico bianco. Nella malattia attiva parte del materiale necrotico si unisce all'aria passante per i bronchi, e questo viene tossito. Esso contiene batteri attivi, e quindi può diffondere l'infezione. Un trattamento con antibiotici appropriati uccide i batteri e permette la guarigione. Durante questa, le aree affette vengono lentamente rimpiazzate da tessuto cicatriziale.
La tubercolosi può infettare molte parti del corpo, ma più comunemente colpisce i polmoni, prendendo il nome di tubercolosi polmonare.[64] La tubercolosi extrapolmonare si verifica quando vi è un'infezione all'esterno dei polmoni. La tubercolosi extrapolmonare può coesistere con la tubercolosi polmonare.[64] Sintomi sistemici includono febbre, brividi, sudorazione notturna, perdita di appetito, perdita di peso, pallore, e una tendenza ad affaticarsi molto facilmente (astenia).[3]
In caso di infezioni ai reni è possibile che si verifichi anemia normocitica e normocromica per carenza di produzione di eritropoietina da parte dei reni.[2]
Nelle infezioni tonsillari si riscontra linfoadenopatia cervicale con periadenite permanente. La mucosa tonsillare si presenta ipertrofica, iperemica, ciclicamente ulcerata con necrosi caseose benigne che si risolvono senza esiti evidenti.[65]
Negli stati avanzati di malattia questa può portare pressione bassa, frequenza cardiaca accelerata e dita ippocratiche dette anche a "bacchetta di tamburo".[66]
Nonostante la tubercolosi extrapolmonare non sia affatto contagiosa può coesistere con la tubercolosi polmonare che invece lo potrebbe essere se è in una fase attiva e se la saliva del soggetto è bacillifera.[67]
Se una infezione tubercolare diventa attiva, molto probabilmente coinvolge i polmoni (in circa il 90% dei casi).[7][68] I sintomi possono includere dolore al petto e una tosse prolungata con produzione di espettorato. Circa il 25% delle persone può non avvertire alcun sintomo (cioè rimanere "asintomatica").[7] Di tanto in tanto, le persone possono tossire sangue (emottisi) in piccole quantità, e in casi molto rari, l'infezione può erodere l'arteria polmonare, con conseguente emorragia massiva (aneurisma di Rasmussen).[69][70]
La tubercolosi può diventare una malattia cronica e causare cicatrici estese nei lobi superiori dei polmoni. I lobi polmonari superiori sono, infatti, più frequentemente colpiti rispetto a quelli inferiori.[64] La ragione di questa differenza non è del tutto chiara[1] ma potrebbe essere spiegata dalla presenza di un maggior flusso d'aria migliore,[1] o dallo scarso drenaggio linfatico presente nei lobi superiori.[64]
Nel 15-20% dei casi attivi, l'infezione si diffonde al di fuori delle vie respiratorie, causando altri tipi di tubercolosi.[71] Questi sono comunemente indicate come "tubercolosi extrapolmonare".[72] La tubercolosi extrapolmonare si verifica più comunemente nei soggetti immunocompromessi e nei bambini piccoli. Negli individui affetti da HIV, ciò si verifica in più del 50% dei casi.[72]
Le infezioni extrapolmonari da Mycobacterium tuberculosis possono interessare tutto l'organismo anche se, essendo micobatteri aerobi, colpiscono maggiormente organi concavo cavernosi. Siti più frequenti di infezione extrapolmonare includono la pleura (pleurite tubercolare), sistema nervoso centrale (meningite tubercolare), sistema linfatico (adenite tubercolare), apparato genito-urinario (tubercolosi urogenitale) e nelle ossa e articolazioni (Malattia di Pott). Quando vi è un coinvolgimento dell'apparato scheletrico, la malattia prende il nome di "tubercolosi ossea",[73] una forma di osteomielite.[1] A volte, lo scoppio di un ascesso tubercolare attraverso la pelle dà origine ad una ulcera tubercolare.[74]
I sintomi della tubercolosi extrapolmonare sono vari e di varia entità in relazione all'organo colpito, al tipo o ai tipi di micobatterio e al modo in cui reagisce il sistema immunitario.[75] In caso di infezioni intestinali si possono avere: ernia iatale, reflusso gastro esofageo, stenosi intestiale, megacolon, stipsi. Questa forma è spesso confusa e trattata per malattia di Crohn, celiachia o intolleranze alimentari.[76][77][78]
Nelle infezioni tonsillari si riscontrano linfoadenopatie cervicali satelliti con evidenti periadeniti permanenti. La mucosa tonsillare si presenta ipertrofica e iperemica e ciclicamente si ulcera con necrosi caseose tendenti alla guarigione senza lasciare traccia. Nella tubercolosi esofagea, a causa della atonia causata dai patogeni infiltrati, si riscontra disfagia spesso dolorosa.[79][80][81]
Potenzialmente più grave vi è una forma di tubercolosi diffusa, comunemente nota come tubercolosi miliare.[64][82][83] Questa forma costituisce circa il 10% dei casi extrapolmonari della malattia.[84]
Quando persone che soffrono di tubercolosi polmonare attiva tossiscono, starnutiscono, parlano o sputano, espellono goccioline di aerosol da 0,5 a 5 µm di diametro. Un singolo starnuto, per esempio, può rilasciare fino a 40.000 particelle.[85] Ognuna di queste gocce può trasmettere la malattia, poiché la dose infettiva di tubercolosi è molto piccola e l'inalazione di un singolo batterio può creare una nuova infezione.[86] In caso di tubercolosi renale il batterio può trasmettersi attraverso le urine.[87] Prolungati contatti con persone affette da tale malattia sono a particolare rischio di infezione, con una percentuale del 22% circa di contagio. Una persona con tubercolosi attiva, ma non trattata può infettare 10-15 persone all'anno.[3] Altri soggetti a rischio includono persone che vivono in aree in cui la tubercolosi è molto diffusa, persone che si iniettano sostanze utilizzando aghi non disinfettati, residenti e impiegati in luoghi di raduno ad alto rischio, pazienti immunocompromessi da malattie come l'AIDS, persone che prendono farmaci immunosoppressori e personale di assistenza sanitaria che trattano pazienti di questo tipo.[88]
La trasmissione può avvenire solamente (da alcuni anni ricercatori considerano anche la T. "latente" contagiosa, sia in soggetti ordinari e specialmente in vaccinati BCG spesso senza sintomi e possibili portatori transitori e temporanei) da persone (vista la resistenza del batterio in ambiente la trasmissione può avvenire indirettamente per molteplici vie transitorie, nonché acqua e terreno, nonché animali domestici e selvatici infetti/vi) con tubercolosi attiva. La possibilità di infezione tra due soggetti dipende dal numero di particelle infette emesse dal portatore, dall'efficacia del sistema di ventilazione, dalla durata di esposizione e dalla virulenza del ceppo di MTB.[67] La catena di trasmissione può quindi essere interrotta isolando pazienti con la malattia attiva e iniziando un'efficace cura anti-tubercolare. Dopo due settimane di trattamento, le persone con tubercolosi attiva non resistente cessano di essere contagiosi. Se qualcuno viene infettato, saranno necessari almeno 21 giorni, o 3-4 settimane prima che questo possa trasmettere la propria malattia agli altri.( il batterio a crescita lenta di 15-20 ore per replicazione pertanto trasmissione, 3-4 settimane è il tempo necessario per l'ottenimento di colonie consistenti di facile visibilità ad occhio nudo ed ottico, in quanto pochi laboratori dispongono di microscopi elettronici) [89] La tubercolosi può essere trasmessa anche dall'ingestione di carne o latte bovino se il bestiame è infetto da tubercolosi. Il responsabile di questa infezione è il Mycobacterium bovis.[90]
Antonio D'Azevedo Maia ha sviluppato alcune teorie circa la predisposizione per l'insorgenza della tubercolosi negli esseri umani, sottolineando che potesse essere ereditaria o acquisita.[senza fonte]
La tubercolosi può essere una malattia difficile da diagnosticare, soprattutto a causa della difficoltà di coltivare questo organismo a lenta crescita in laboratorio (4-12 settimane in coltura arricchita). Una completa valutazione medica della tubercolosi deve comprendere anche la storia medica del paziente, una radiografia del torace, e un esame medico. Oltre alle indagini cliniche e radiologiche vi sono anche possibili esami di laboratorio. Questi possono includere test cutanei alla tubercolina, test sierologici, strisci microbiologici e colture di batteri. L'interpretazione dei test cutanei alla tubercolina dipendono dai fattori di rischio della persona per l'infezione e la progressione della tubercolosi, come l'esposizione ad altri casi di tubercolosi e l'immunosoppressione.[67]
Attualmente l'infezione latente viene diagnosticata in una persona non immunizzata con il test cutaneo, che provoca una reazione ritardata di tipo ipersensitivo a un estratto di M. tuberculosis oppure con i test ematici "Elispot tubercolosi" e "Quantiferon tubercolosi Gold". Gli immunizzati alla tubercolosi o quelli con una infezione terminata in precedenza risponderanno al test cutaneo con una ipersensibilità ritardata identica a coloro che hanno attualmente l'infezione attiva, quindi il test deve essere utilizzato con cautela, specialmente sulle persone provenienti da paesi dove l'immunizzazione alla tubercolosi è diffusa.[91] Nuovi test per la tubercolosi vengono sviluppati alla ricerca di metodi più economici, veloci e accurati. Questi test utilizzano il rilevamento della reazione a catena della polimerasi di DNA batterico e campioni di anticorpi per rilevare il rilascio di interferone gamma in risposta ai micobatteri.[92] Tali metodiche non sono condizionate dall'immunizzazione, e quindi generano meno falsi positivi.[93]
Diagnosi sempre più rapide ed economiche sono particolarmente importanti nei paesi in via di sviluppo, dove la possibilità di test costosi limita la diagnosi, e quindi la possibile cura, a un numero estremamente limitato di persone. In alcuni Paesi africani, per diagnosticare la tubercolosi vengono impiegati i ratti giganti del Gambia addestrati dalla ONG APOPO, con sede in Belgio e in Tanzania. Lo straordinario olfatto di questi roditori ha permesso di diagnosticare con discreto successo la malattia analizzando campioni di saliva di soggetti a rischio.[94][95]
La progressione dall'infezione tubercolosa alla malattia avviene quando i bacilli della tubercolosi prevalgono sulle difese del sistema immunitario e iniziano a moltiplicarsi. Nella tubercolosi primaria (1-5% dei casi) questo avviene poco dopo l'infezione. Tuttavia, nella maggior parte dei casi, si verifica un'infezione latente che non ha sintomi chiari. Questi batteri dormienti possono produrre tubercolosi nel 2-23% dei casi latenti, spesso diversi anni dopo l'infezione.[96] Il rischio di riattivazione aumenta con l'immunosoppressione, causata da fattori come l'HIV. In pazienti infettati sia da M. tuberculosis che da HIV, il rischio di riattivazione aumenta del 10% all'anno.[57]
Altre condizioni che aumentano il rischio comprendono l'assunzione di droghe, in particolare quelle intravenose; una recente infezione di tubercolosi o una storia medica di tubercolosi inadeguatamente trattata; diabete mellito; silicosi; terapie prolungate di corticosteroidi e altre terapie immunosoppressive; cancro alla testa e al collo; malattie ematologiche e reticoloendoteliali come la leucemia e il linfoma di Hodgkin; malattie terminali ai reni; bypass intestinale o gastrectomia; sindromi da malassorbimento croniche; peso corporeo ridotto.[67]
Studi gemelli degli anni cinquanta mostravano che il percorso dell'infezione tubercolare era altamente dipendente dalla genetica. A quell'epoca infatti era molto raro che uno dei gemelli identici sopravvivesse e l'altro morisse: entrambi subivano lo stesso destino.[97]
Alcuni farmaci, inclusi quelli per l'artrite reumatoide che agiscono bloccando il fattore di necrosi tumorale (una citochina causa d'infiammazione sistemica), incrementano il rischio di attivare un'infezione latente a causa dell'importanza di questa citochina nella difesa immunitaria contro la tubercolosi.[98]
Il trattamento per la tubercolosi utilizza gli antibiotici per uccidere i micobatteri. Gli antibiotici più utilizzati sono la rifampicina, la pirazinamide, l'etambutolo e l'isoniazide. Sono i quattro farmaci che si usano, secondo le linee guida, nei primi due mesi di terapia, nella cosiddetta "fase d'attacco".
Gli schemi terapeutici più diffusi prevedono una terapia iniziale con isoniazide (300 mg), rifampicina (600 mg), pirazinamide (2000 mg) ed etambutolo (1200 mg), somministrati in associazione giornalmente.
Dopo i due mesi, i farmaci che si usano sono i soli isoniazide (600 mg) e rifampicina (600 mg), tre volte alla settimana per almeno altri 4 mesi. Infatti, rispetto al breve periodo di cure di antibiotici tipicamente utilizzato per altre infezioni batteriche, la tubercolosi necessita di periodi molto più lunghi (dai 6 ai 12 mesi) per eliminare completamente i micobatteri dall'organismo.[67] Il trattamento per la tubercolosi latente utilizza solitamente un singolo antibiotico (chemioprofilassi preventiva), mentre la tubercolosi attiva viene curata in modo più efficace con la combinazione di diversi antibiotici, per ridurre la possibilità che i batteri sviluppino una resistenza agli antibiotici.[99] Persone con infezioni latenti vengono curate per prevenire la possibile evoluzione della tubercolosi nella sua forma attiva.
Sebbene il trattamento antitubercolare abbia rappresentato una svolta nell'epidemiologia della malattia, una volta un vero e proprio flagello per i paesi occidentali (lo è ancora per i paesi in via di sviluppo), la terapia utilizzante la rifampicina e l'isoniazide non è senza rischi. I Centers for Disease Control and Prevention (CDC) hanno fornito agli operatori sanitari delle raccomandazioni contro l'utilizzo di rifampicina e pirazinamide per il trattamento dell'infezione tubercolosa latente, a causa dell'alto numero di ospedalizzazioni e decessi da danni al fegato associati con l'utilizzo combinato di questi due farmaci.[100]
La tubercolosi resistente ai farmaci si trasmette allo stesso modo della normale tubercolosi. La resistenza primaria avviene nelle persone che sono infette da un ceppo resistente di tubercolosi. Un paziente con tubercolosi normale sviluppa una resistenza secondaria (o resistenza acquisita) durante la terapia contro la tubercolosi a causa del trattamento inadeguato, del non mantenimento delle cure prescritte o dell'utilizzo di medicine di bassa qualità.[99] La tubercolosi resistente ai farmaci è un problema in molti paesi in via di sviluppo, poiché il trattamento è più prolungato e richiede farmaci più costosi. La tubercolosi multiresistente (MDR-TB) è definita come tubercolosi resistente ai due medicinali più efficaci di prima linea: la rifampicina e l'isoniazide.[101] La tubercolosi estensivamente resistente ai farmaci (XDR-TB) è immune anche a tre o più dei farmaci di seconda linea.[49] La tubercolosi totalmente resistente ai farmaci (TDR-TB) è resistente, come riporta la sua definizione, a tutti i farmaci, ed è ritenuta incurabile. Al 2012, questa forma è stata rilevata in sole tre nazioni: India, Iran e Italia.[102][103][104][105]
Nel caso di meningite tubercolare, si deve ricorrere a farmaci in grado di passare attraverso la barriera emato-encefalica.[106] Talvolta può essere necessario la somministrazione di tali farmaci attraverso un serbatoio di Ommaya.[107]
Nei tempi antichi i trattamenti disponibili si concentravano particolarmente sui parametri dietetici. Plinio il Vecchio descrisse diversi metodi nella sua Naturalis Historia: il fegato di lupo preso in vino povero, il lardo di una scrofa nutrita con erba, o la carne di asina con il brodo.[108] Nonostante questi metodi particolari non siano stati testati scientificamente, è stato dimostrato che topi di laboratorio nutriti con una dieta al 2% di proteine soffrivano di mortalità ben più alta di topi con una dieta al 20% di proteine a cui era stata somministrata la stessa dose di batteri, e che il progresso verso la morte delle cavie poteva essere invertito restaurando una dieta normale.[109] Inoltre, le statistiche degli immigrati di South London rivelano un incremento di 8,5 volte del rischio di tubercolosi nei latto-vegetariani, prevalentemente indiani e asiatici, cioè persone che si nutrono solamente di vegetali e derivati caseari, rispetto ai musulmani che mangiavano carne e pesce quotidianamente.[110] Pare comunque più accreditata l'ipotesi che i responsabili siano le carenze di vitamine, come la B12 o la D.
Come detto, esistono alcune forme di tubercolosi tendenzialmente resistenti al trattamento convenzionale con antibiotici. La tubercolosi resistente viene classificata come[111][112]:
In presenza tubercolosi multiresistente, la strategia da adottare è l'estensione dei principi attivi da somministrare, quali ad esempio possono essere gli amminoglicosidi come la capreomicina e la kanamicina, o ai fluorochinoloni come l'ofloxacina, la ciprofloxacina, la moxifloxacina e la levofloxacina, il tionamidi etionamide Prothionamid e agenti batteriostatici, para-aminosalicilico acido (PAS) e cicloserina. Possono essere prescritti anche l'acido 4-amminosalicilico e la cicloserina.[113][114]
L'antibiotico linezolid è ancora oggi spesso prescritto nei casi più gravi di tubercolosi multi-resistente. Tuttavia, in un recente studio l'82% dei pazienti seguiti ha sviluppato effetti collaterali potenzialmente associati al farmaco. Le reazioni avverse più comuni sono mielosoppressione con anemia e neutropenia, neuropatia ottica e periferica.[114]
Il trattamento della MDR-TB consiste nell'assunzione di una terapia farmacologica multipla contemporanea per un periodo di almeno 21 mesi. Nei primi tre mesi, i pazienti ricevono una combinazione di cinque diversi farmaci. Le possibilità di successo del trattamento della tubercolosi multiresistente è inferiore al trattamento della tubercolosi semplice, anche se i pazienti ricevono una terapia più efficace.
In uno studio effettuato in Turchia, l'uso supplementare della resezione polmonare su pazienti con tubercolosi multiresistente, ha portato alla guarigione 12 casi su 13. Uno studio analogo è stato condotto in Sudafrica.[115][116]
La terapia per la tubercolosi è lunga e complessa. Un ciclo di cure può durare da 6 mesi a 18-24 mesi a seconda dell'aderenza del paziente alla prescrizione. Perché il trattamento sia efficace e per evitare che si instauri una resistenza ai farmaci antitubercolari, l'Organizzazione Mondiale della Sanità ha proposto una strategia denominata Directly Observed Therapy (terapia osservata direttamente) o DOT, che consiste in un regime terapico in cui vi sia un sanitario che si assicuri che il paziente assuma regolarmente la sua dose di farmaci, così come previsto dalla prescrizione. Diversi studi hanno dimostrato che la strategia DOT è in grado di ridurre la durata della cura a 6-8 mesi.[75]
     no dati     ≤10     ≥10–25     ≥25–50     ≥50–75     ≥75–100     ≥100–250     ≥250–500     ≥500–750     ≥750–1000     ≥1000–2000     ≥2000–3000     ≥ 3000La progressione da infezione tubercolare a malattia tubercolosi conclamata si verifica quando i bacilli superano le difese del sistema immunitario e iniziano a moltiplicarsi. Nella malattia primaria (1-5% dei casi), questo si verifica subito dopo l'infezione iniziale.[1] Tuttavia, nella maggior parte dei casi, una infezione latente si verifica senza sintomi evidenti.[1] Questi bacilli dormienti producono tubercolosi attiva nel 5-10% dei casi latenti, spesso molti anni dopo l'infezione.[118]
Il rischio di riattivazione aumenta se vi è una situazione di immunosoppressione, come nel caso di infezione da HIV. Negli individui con coinfezione da M. tuberculosis e HIV, il rischio di riattivazione aumenta del 10% l'anno.[1] Gli studi che utilizzano il DNA fingerprinting, un metodo di comparazione del DNA, su ceppi di M. tuberculosis hanno dimostrato che le reinfezioni avvengono più frequentemente di quanto si pensasse rispetto alla riattivazione.[119][120] La possibilità di morte per un caso di tubercolosi è di circa il 4%, al 2008, in calo rispetto all'8% del 1995.[7]
La prevenzione e il controllo della tubercolosi hanno due approcci paralleli. Nel primo, le persone con la tubercolosi e le persone a loro vicine vengono identificate e trattate. L'identificazione delle infezioni spesso implica l'esame dei gruppi ad alto rischio per la tubercolosi. Nel secondo approccio, i bambini vengono vaccinati per proteggerli dalla tubercolosi. Sfortunatamente nessun vaccino disponibile garantisce una protezione affidabile per gli adulti. Tuttavia, nelle aree tropicali dove i livelli di altre specie di micobatteri sono elevati, l'esposizione a micobatteri non tubercolari dà una parziale protezione alla tubercolosi.[121]
Dopo il vaccino Maragliano, sviluppato da Edoardo Maragliano e utilizzato sull'uomo fin dai primi anni del Novecento, costituito da micobatteri uccisi al calore, i primi esperimenti per ottenere un vaccino costituito da micobatteri vivi attenuati di tubercolosi di razza bovina furono sviluppati da Albert Calmette e Camille Guérin all'Istituto Pasteur in Francia tra il 1908 e il 1921.[25] Venne chiamato "BCG" (bacillo di Calmette-Guérin). Il vaccino BCG venne usato sull'uomo nel 1921 in Francia, ma non ricevette diffusione e consenso negli Stati Uniti, Gran Bretagna e Germania fino alla seconda guerra mondiale.[26]
Molte nazioni utilizzano il BCG come parte dei loro programmi di controllo della tubercolosi, specialmente per i bambini. L'efficacia protettiva del BCG per prevenire forme gravi di tubercolosi (per esempio la meningite) nei bambini è maggiore dell'80%; la sua efficacia protettiva per prevenire tubercolosi polmonare negli adolescenti e negli adulti varia dallo 0 all'80%.[122]
In Sudafrica, il paese con la più alta concentrazione di tubercolosi, il vaccino viene dato a tutti i bambini sotto i tre anni.[123] Tuttavia il BCG è meno efficace in aree dove i micobatteri sono meno prevalenti, quindi il BCG non viene distribuito all'intera popolazione di queste nazioni. Negli Stati Uniti per esempio, il vaccino BCG non è raccomandato tranne che per persone con specifiche caratteristiche:[67]
Il BCG protegge parzialmente contro alcune forme gravi di tubercolosi pediatrica, ma si è dimostrato inefficace contro la tubercolosi polmonare adulta, che compone la maggior parte dei casi mondiali. Attualmente ci sono più casi di tubercolosi sul pianeta di quanti ce ne siano stati in qualunque altra epoca storica, e molti concordano nell'urgenza dello sviluppo di un nuovo vaccino più efficace, che prevenga tutte le forme di tubercolosi, compresi i ceppi resistenti, in ogni fascia d'età, e tra le persone affette da HIV.[124]
L'Organizzazione Mondiale della Sanità ha dichiarato, nel 1993, la tubercolosi una "emergenza sanitaria globale"[7] e nel 2006, la Stop TB Partnership ha sviluppato un piano globale per fermare la tubercolosi, che mira a salvare 14 milioni di vite tra il suo lancio e il 2015.[125] Tuttavia il numero prefissato non potrà essere raggiunto entro il 2015, principalmente a causa dell'aumento della tubercolosi associata all'HIV e all'emergere di molteplici tubercolosi resistenti ai farmaci (MDR-TB).[7] Un sistema di classificazione sviluppato dalla American Thoracic Society viene utilizzato comunemente nei programmi di salute pubblica.[126]
Diversi vaccini per prevenire le infezioni di tubercolosi sono in corso di sviluppo. Il primo vaccino ricombinante è entrato nella fase di studio clinico negli Stati Uniti nel 2004, sponsorizzato dal National Institute of Allergy and Infectious Diseases (NIAID).[127] Uno studio del 2005 ha mostrato che un vaccino genetico per la tubercolosi somministrato con una chemioterapia convenzionale può accelerare la scomparsa dei batteri e proteggere da una successiva infezione nei topi; potrebbero volerci 4-5 anni prima che sia disponibile per gli esseri umani.[128] Un vaccino molto promettente per la tubercolosi, l'MVA85A, è attualmente allo studio di fase II in Sudafrica da un gruppo della Oxford University,[129] ed è basato su un vaccinia virus geneticamente modificato. Molte altre strategie vengono utilizzate per sviluppare nuovi vaccini.
Per incoraggiare ulteriori ricerche, i ricercatori stanno promuovendo nuovi modelli economici di sviluppo dei vaccini, compresi premi, incentivi sulle tasse e Advanced market Commitment.[130][131]
Un certo numero di gruppi, tra cui la Stop TB Partnership,[132] del South African Tuberculosis Vaccine Initiative e l'Aeras Global TB Vaccine Foundation sono fortemente coinvolti nella ricerca.[133] Tra questi, l'Aeras ha ricevuto una donazione di più di 280 milioni di dollari statunitensi dalla Fondazione Bill & Melinda Gates per lo sviluppo e per la concessione in licenza di un vaccino contro la tubercolosi per l'uso in paesi ad alta incidenza.[134][135]
La tubercolosi può essere portata da altri mammiferi; specie addomesticate, come cani e gatti, sono in genere immuni dalla tubercolosi, ma gli animali selvatici possono esserne portatori. In alcuni luoghi le norme mirate a prevenire il diffondersi della tubercolosi limitano il possesso di animali esotici; per esempio, lo stato della California proibisce il possesso dei gerbilli.[136]
La tubercolosi nel bestiame è causata dal Mycobacterium bovis. Uno sforzo per eliminare la tubercolosi bovina dal bestiame e dai branchi di cervi della Nuova Zelanda è in corso. È stato scoperto infatti che le infezioni del bestiame sono più probabili nelle aree in cui le specie vettore come l'opossum volpino australiano entrano in contatto con il bestiame ai confini delle fattorie.[137] Controllare i vettori attraverso l'eradicamento dell'opossum e monitorare il livello di malattia nel bestiame attraverso una regolare sorveglianza è l'approccio a due direzioni per eliminare la malattia dalla Nuova Zelanda.
In Irlanda e nel Regno Unito, una specie vettore per la diffusione della tubercolosi è stata identificata nel tasso. Come risposta, i governi sono stati messi sotto pressione da alcune fazioni, in particolare dagli allevatori, per creare una campagna attiva di eradicazione dei tassi in alcune aree con lo scopo di ridurre l'incidenza della tubercolosi bovina. L'effettività della parziale eliminazione dell'animale sull'incidenza della tubercolosi nel bestiame è incerta, visto che sia sostenitori che detrattori citano i loro studi per supportare le loro posizioni.[138][139][140] Per esempio, uno studio di un gruppo indipendente sul parziale abbattimento ha riportato il 18 giugno 2007 che la sua efficacia era improbabile e avrebbe fatto solamente una "lieve differenza" nella diffusione della tubercolosi, e che "l'abbattimento dei tassi non può contribuire significativamente al controllo futuro della tubercolosi del bestiame"; al contrario, un altro rapporto concludeva che questa politica avrebbe avuto un significativo impatto.[141] Il 4 luglio 2008 il governo inglese ha deliberato contro una proposta per la selezione e l'abbattimento dei tassi.[142]
Prima della Rivoluzione industriale, la tubercolosi era talvolta associata al vampirismo. Quando un membro di una famiglia ne moriva, gli altri membri avrebbero iniziato ad ammalarsi lentamente. La gente credeva che questo fosse causato dalla vittima originaria, che succhiava la vita dagli altri membri della famiglia. Inoltre, persone che avevano la tubercolosi mostravano sintomi simili a quelli che le persone reputavano essere tratti vampirici. Le persone che soffrono di tubercolosi hanno spesso occhi arrossati e gonfi (che, a loro volta, causano sensibilità alla luce intensa), un colorito pallido e tossiscono sangue, il che può suggerire, quale unico metodo per ripristinare questa perdita di sangue, di succhiarlo da altri.[143] Un'altra credenza popolare asseriva che i tubercolotici fossero costretti, di notte, ad assistere alle feste delle fate, così che la vittima veniva consumata dalla mancanza di sonno; questa credenza era molto diffusa quando si trovava un grosso collegamento tra le fate e i morti.[144] Allo stesso modo, ma meno comunemente, la tubercolosi era attribuita all'essere "cavalcati dalle streghe"; trasformati in cavalli dalle streghe per portarle ai loro raduni, le vittime subivano di nuovo la mancanza di sonno.[144]
La tubercolosi venne romanticizzata nel XIX secolo. Molte persone credevano che la tubercolosi causasse sensazioni di euforia definite come spes phthisica, o "speranza del consunto". Si pensava che le vittime di tubercolosi che erano artisti avessero scoppi di creatività mentre la malattia progrediva.[145] Agli inizi del XX secolo, alcuni credevano che la tubercolosi fosse causata dalla masturbazione.[146]
Fra i numerosi letterati, artisti e musicisti morti di tisi, la maggioranza in giovane età, si ricordano Giovan Battista Pergolesi (1710-1736), Giovanni Battista Grazioli (1746-1820), Novalis (1772-1801), John Keats (1795-1821), Giuseppe Giusti (1809-1850), Fryderyk Chopin (1810-1849), Saverio Costantino Amato (1816-1837), Emily Brontë (1818-1848), Anne Brontë (1820-1849), Charlotte Brontë (1816-1855), Jens Peter Jacobsen (1847-1885), Niccolò Paganini (1782-1840), Anton Pavlovič Čechov (1860-1904), Guido Gozzano (1883-1916), Franz Kafka (1883-1924), Amedeo Modigliani (1884-1920), Sergio Corazzini (1886-1907), Giovanni Boine (1887-1917), Katherine Mansfield (1888-1923) e George Orwell (1903-1950).
Al contempo, la passione per le storie d'amore e morte ha portato alla celebrità personaggi di poesie, romanzi e opere, morti di tisi, quali la destinataria del componimento A Silvia, di Giacomo Leopardi, Marguerite Gautier della Signora delle camelie di Alexandre Dumas figlio, Violetta de La traviata di Giuseppe Verdi, Mimì della Bohème di Giacomo Puccini, la contessa russa (Nata) della Tigre reale di Giovanni Verga e il piccolo Ilja dei Fratelli Karamàzov di Dostoevskij. Anche opere moderne, ma ambientate a cavallo tra diciottesimo e diciannovesimo secolo, hanno incluso personaggi ammalati di tisi (ad esempio Oscar, protagonista nell'omonimo manga Lady Oscar), usando la malattia quasi come un topos di quel particolare periodo storico. In ambito cinematografico invece, si può pensare per esempio a Enrico Salvatore Rizzo (interpretato da Dustin Hoffman) in Un uomo da marciapiede di John Schlesinger e a Lucilia (impersonata da Cacilda Becker in Floradas na serra, opera prima di Luciano Salce) mentre in quello videoludico a Arthur Morgan, personaggio principale di Red Dead Redemption II. Si ricorda inoltre il protagonista della telenovela brasiliana Fiore selvaggio, interpretato da Fabio Jr..
In passato la tubercolosi è stata chiamata "mal sottile" o "consunzione"[147], poiché sembrava consumare le persone da dentro, con fuoriuscita di sangue dalla bocca, febbre, pallore e un lungo deperimento. Altri nomi includono "tisi" (da φθίσις phthisis[147] "consunzione" in greco) e "tisi polmonare" (da phthisis pulmonalis[147]); scrofula[147] (negli adulti), che colpiva il sistema linfatico e provocava il gonfiore delle ghiandole del collo; tabes mesenterica[147], tubercolosi dell'addome, e lupus vulgaris, tubercolosi della pelle; "malattia del deperimento"[147]; "peste bianca", poiché le vittime avevano un aspetto pallido; "male del re", perché era credenza popolare che il tocco di un re potesse curare la scrofula; e "malattia di Pott" o "gobba" per la tubercolosi ossea.[148][149] La "tubercolosi miliare"[147], conosciuta comunemente come "tubercolosi disseminata", sopraggiunge quando l'infezione invade il sistema circolatorio, provocando lesioni che hanno l'aspetto, ai raggi X, di chicchi di miglio.[148][150]
I mammiferi (Mammalia Linnaeus, 1758) sono una classe di vertebrati a diffusione cosmopolita caratterizzata dall'allattamento della prole.
La classe dei mammiferi conta 5 500[1] specie attualmente viventi, variabili in forma e dimensioni: dai pochi centimetri e due grammi di peso del mustiolo agli oltre 30 metri e 150 tonnellate della balenottera azzurra, il più grande mammifero finora apparso sulla Terra. I mammiferi colonizzano praticamente ogni ambiente, dalle calotte glaciali ai caldi deserti: alcuni gruppi (sirenii, pinnipedi, cetacei) sono riusciti a colonizzare con successo anche l'ambiente acquatico, mentre altri hanno sviluppato delle ali membranacee e sono perciò in grado di volare (chirotteri).
Nonostante tali differenze di dimensioni e abitudini di vita, tutti i mammiferi sono accomunati dall'essere omeotermi ovvero endotermi, dal presentare viviparità (con l'eccezione dei monotremi, che sono ovipari) e dall'avere cure parentali che prevedono anche l'allattamento della prole: tutti fattori che sono stati determinanti per consentire a questa classe di espandere notevolmente il proprio areale nelle nicchie rimaste vuote dopo la scomparsa dei dinosauri.
I mammiferi sono un gruppo monofiletico, ossia tutte le specie attualmente viventi discendono da un antenato comune: anche i tre gruppi in cui vengono tradizionalmente suddivisi i mammiferi (vale a dire monotremi, marsupiali e placentati) sono monofiletici, con gli ultimi due classificati insieme dalla maggior parte degli studiosi per differenziarli dal primo.
I mammiferi si svilupparono a partire da un gruppo di Amnioti.
I primi amnioti apparvero intorno al tardo Carbonifero, da rettiliomorfi ancestrali. In pochi milioni di anni, da essi si distinsero due importanti linee evolutive: i Sauropsidi, dai quali discesero i rettili e gli uccelli, e i Sinapsidi, considerati i progenitori dei Mammiferi[2]. La tecnica dell'orologio molecolare ha consentito di datare la separazione tra i due raggruppamenti a circa 310 milioni di anni.[3]
I Sinapsidi, vissuti durante il Permiano, sono animali caratterizzati dalla presenza di una singola finestra temporale su ciascun lato del capo, posta nei pressi dell'attaccatura dei muscoli della mascella, (a differenza dei diapsidi, che possiedono due finestre temporali per ogni lato del capo, e degli anapsidi, del tutto sprovvisti di finestre temporali). La finestra temporale, con il tempo, si è rimpicciolita fino quasi a chiudersi: la sua esistenza è testimoniata attualmente dalla presenza nel cranio dei mammiferi dello zigomo.
Proprio da alcuni sinapsidi primitivi (come Archaeothyris) si sviluppò un ramo, quello degli Sfenacodonti, che condusse fino ai probabili precursori dei mammiferi, i Terapsidi, più specificatamente gli Eucinodonti, vissuti circa 220 milioni di anni fa, nel Triassico.[4]
Con l'evoluzione la finestra temporale dei sinapsidi aumentò di dimensioni. Nei Cinodonti era già molto più estesa rispetto, ad esempio, ai Pelicosauri. La postura eretta fu adottata verso la metà del Permiano dai terapsidi, assieme al secondo palato (ad esempio i Terocefali avevano entrambe queste caratteristiche) e il pelo, che a differenza delle penne degli uccelli non si è evoluto a partire dalle squame rettiliane, ma che probabilmente ne è stato un annesso.
Gli organi uditivi iniziarono a evolversi nella forma attuale probabilmente all'inizio del Triassico, in seguito alla trasformazione della mascella in un osso unico[5] (animali come sinapsidi e terapsidi avevano tre ossa nella mascella, così come i rettili attuali). Infatti, le due ossa residue della mascella iniziarono a rimpicciolirsi e, pur restando nella loro sede originaria, iniziarono a essere utilizzate per captare suoni (un esempio è il Probainognathus), per poi (sicuramente nell'Hadrocodium, probabilmente già in Morganucodon) unirsi all'unico osso dell'orecchio per formare gli attuali martello, incudine e staffa.
Il titolo di mammifero più antico è conteso da vari animali, in quanto la sua attribuzione varia a seconda della parte anatomica presa in considerazione: alcuni studiosi valutano la struttura del canale auricolare per definire la fine della transizione da rettile a mammifero, mentre altri ritengono più attendibile la costituzione e l'articolazione della mandibola o la struttura dei denti.
Fra le specie annoverabili fra i primi mammiferi, vengono generalmente incluse le seguenti:
La maggior parte dei primi mammiferi (come Megazostrodon, ma anche altre specie come Morganucodon, Adelobasileus, Eozostrodon, Sinoconodon, Hadrocodium e Fruitafossor) avevano dimensioni e comportamento simili a quelli dei toporagni (Hadrocodium probabilmente non superava i 2 g di peso da vivo): significative eccezioni sono rappresentate da Steropodon, Kollikodon, Repenomamus e Castorocauda, che presentavano dimensioni superiori al mezzo metro di lunghezza.
Per le caratteristiche intermedie fra mammiferi e rettili, alcuni studiosi classificano tutte queste forme di transizione nel clado dei Mammaliaformes.
Nel corso del Mesozoico i mammiferi si svilupparono in una quantità di forme e adattamenti per ambienti diversi, ma mantennero comunque un piano corporeo basilare e di solito le loro dimensioni erano ridotte, di rado superando quelle di un attuale ratto. Già nel Giurassico esistevano molti gruppi primitivi, come i sopracitati docodonti, i simmetrodonti (Symmetrodonta), i triconodonti (Triconodonta) e i driolestidi (Dryolestidae), tutti riconoscibili in base al tipo di dentatura e alla forma dei denti; tutti i gruppi sopracitati si estinsero però nell'arco di alcuni milioni di anni.
Tra i gruppi attuali, i primi a differenziarsi dovettero essere con molta probabilità i monotremi, mammiferi eccezionalmente primitivi: i resti fossili più antichi riconducibili a questi animali, tuttavia, risalgono solo a circa 120 milioni di anni fa (Cretaceo superiore). Alla stessa epoca sembrano risalire anche i marsupiali e i placentati, il che vuol dire che i monotremi si sono staccati precocemente dalla linea evolutiva principale dei mammiferi, seguendo un proprio percorso indipendente, piuttosto che essersi evoluti in seguito negli attuali marsupiali e placentati come spesso si è portati a credere.
Un altro gruppo primitivo, quello dei multitubercolati, comprendeva animali simili a scoiattoli e topi: la loro comparsa è riconducibile perlomeno al Giurassico medio (circa 160 milioni di anni fa), mentre la loro sparizione avvenne durante l'Oligocene (30 milioni di anni fa); rappresentano quindi il più longevo gruppo di mammiferi. Alcuni studiosi sostengono che i multitubercolati (come l'intero superordine – o sottoclasse, a seconda della classificazione – degli Allotheria) non siano in realtà dei mammiferi veri e propri, ma un ramo collaterale di cinodonti che, per evoluzione convergente, ha sviluppato forme simili a essi.
Dopo l'estinzione di massa del Cretaceo, avvenuta 65,7 milioni di anni fa, i mammiferi diedero luogo, per un fenomeno di radiazione adattativa, a una rapidissima diversificazione di forme e dimensioni, per andare a riempire le nicchie rimaste vuote: per tutto il Paleocene, tuttavia, i piccoli mammiferi continuarono a dominare la scena. È il caso, ad esempio, di Palaeoryctes (simile agli attuali soricomorfi) e Carpolestes (un primate primitivo). Le eccezioni, in ogni caso, non mancavano: i pantodonti, ad esempio, erano un gruppo che comprendeva anche forme lunghe due metri, come Barylambda. Si ritiene che le piccole dimensioni non siano state una forzatura imposta dalla presenza dei dinosauri (o che almeno questa non ne sia l'unica causa), quanto piuttosto una necessità dovuta alla mancanza di sistemi di termoregolazione e metabolismo ancora non del tutto evoluti e pertanto inefficienti.
Nel corso dell'Eocene si sviluppò un gran numero di mammiferi primitivi, che non hanno però lasciato discendenti nella fauna attuale: tra questi gruppi, da citare i teniodonti e i tillodonti, che potevano raggiungere le dimensioni di un orso ma con musi che li facevano assomigliare a giganteschi roditori, i creodonti e gli acreodi (carnivori dall'enorme cranio), i dinocerati (simili a rinoceronti mostruosi, come Uintatherium) e i pantolesti, strani animali simili a lontre comprendenti anche forme velenose. Tutti questi "esperimenti", tuttavia, si estinsero presto, mentre iniziarono a svilupparsi i primi rappresentanti degli ordini che hanno resistito fino ai giorni nostri, tra cui i chirotteri (Icaronycteris) e i cetacei (Indohyus, Basilosaurus).
Intanto, in Sudamerica e Australia, gigantesche isole separate dal resto dei continenti, cominciarono a svilupparsi faune endemiche; in Australia i marsupiali e i monotremi, in Sudamerica i marsupiali e alcuni placentati primitivi, come xenartri e meridiungulati.
L'inizio dell'Oligocene vede il progressivo diradarsi delle foreste su tutto il pianeta, e la comparsa di forme di mammiferi gigantesche: a questo periodo risale il Paraceratherium, il più grande mammifero terrestre mai esistito, lontano parente degli attuali rinoceronti. Alcuni gruppi attuali iniziarono a prosperare, dando vita a forme bizzarre: è il caso degli artiodattili (come Archaeotherium simile a un gigantesco maiale corridore) e dei perissodattili (con i brontoteri, dal corno a Y, e gli ancilopodi, dotati di artigli e di un muso da cavallo), ma anche dei carnivori (con le famiglie dei nimravidi e degli anficionidi).
Il culmine della diversificazione dei mammiferi si ebbe durante il Miocene, il periodo in cui le faune iniziarono a essere molto simili a quelle attuali; l'avvento delle praterie, inoltre, portò alla progressiva scomparsa di animali dall'habitat forestale ma favorì l'enorme sviluppo degli artiodattili e degli equidi. Nel corso di questo periodo ebbero un grande successo anche le scimmie antropomorfe (Proconsul), da alcune delle quali si svilupparono i primi ominidi. Alla fine del periodo, nei continenti settentrionali si estinsero gli ultimi ordini aberranti (Desmostylia), mentre in Sudamerica i mammiferi endemici continuarono a prosperare, dando vita a forme specializzate (Astrapotheria, Litopterna, Notoungulata). L'Australia, invece, fu teatro di una grande radiazione di marsupiali.
L'inizio del Pliocene (circa 5 milioni di anni fa) portò un considerevole abbassamento delle temperature e la conseguente estinzione di molte specie di mammiferi adattati al clima caldo, in un preludio alle successive glaciazioni. In Africa si svilupparono gli australopitechi, vicini all'origine dell'uomo.
Il Pleistocene vide la comparsa e il veloce sviluppo del genere umano, ma anche una drastica riduzione della megafauna sviluppatasi nel corso del periodo. Tra i più tipici esempi di questa fauna di mammiferi giganti, da ricordare i mammut, il rinoceronte lanoso, il cervo gigante Megaloceros, il leone delle caverne, l'orso delle caverne, il vombato gigante Diprotodon e il canguro gigante Procoptodon. Alla fine del Pleistocene (fra i 50 000 e i 10 000 anni fa, anche se in Australia il processo avvenne fra i 51 000 e i 38 000 anni fa e in Sud America fra gli 11 000 e gli 8 000 anni fa), si calcola che praticamente tutti i mammiferi di peso superiore alla tonnellata si estinsero, così come sparì l'80% delle specie di peso superiore al quintale: questa estinzione di massa toccò però solo superficialmente il continente africano e il Sud-est Asiatico.
Questo avvenne perché i cambiamenti climatici, che culminarono nelle ere glaciali, ebbero come conseguenza nell'immediato la formazione di habitat del tutto nuovi, che la maggior parte dei mammiferi non riuscì a colonizzare in tempo, andando incontro all'estinzione: altri mammiferi, più veloci a riprodursi e adattarsi ai cambiamenti, ampliarono invece enormemente la propria diffusione, complice la sparizione di molti accaniti concorrenti.
Un altro fattore che probabilmente portò numerose specie all'estinzione fu la presenza umana: l'estinzione di numerose specie, infatti, sembrerebbe coincidere con l'arrivo di esseri umani nella zona, i quali cacciando indiscriminatamente questi animali a ritmi superiori al tasso riproduttivo ne provocarono un rapido crollo. A favore dell'ipotesi che vede le estinzioni di massa collegate all'arrivo dell'uomo, vi sono gli esempi delle isole colonizzate solo in tempi recenti, come il Madagascar, nel quale l'arrivo dell'uomo è coinciso con l'estinzione di tutti i grandi lemuri. Questa ipotesi, tuttavia, può essere ritenuta valida nel caso di ambienti circoscritti e non eccessivamente estesi, come appunto l'isola malgascia, mentre risulta piuttosto arduo credere che la presenza di pochi uomini muniti di armi rudimentali abbia potuto da sola determinare un'estinzione di massa, tanto più che in Africa, culla dell'umanità (e pertanto, secondo l'ipotesi dell'estinzione per mano umana, la terra che più di altre avrebbe dovuto subire i danni apportati dall'uomo primitivo), tale estinzione non vi è addirittura stata.
Con tutta probabilità, l'uomo diede solo il colpo di grazia a specie già sull'orlo dell'estinzione a causa dei mutamenti climatici: l'estinzione di alcune specie alterò ulteriormente l'ecosistema, provocando effetti domino con esiti disastrosi.
La monofilia della classe Mammalia diviene meno scontata man mano che si cerca di risalire lungo la scala evolutiva, per individuare i primi rappresentanti di questi animali: gli unici resti che pervengono agli studiosi sono infatti principalmente frammenti della mandibola e denti, in base alla morfologia dei quali è stata impostata la sistematica dei mammiferi ancestrali. Ciò vuol dire che anche altri animali che hanno evoluto dentizione simile a quella dei mammiferi potrebbero essere stati classificati come tali, pertanto gli studiosi sono molto cauti sull'attribuzione di ogni singola specie a determinati taxa assimilabili ai mammiferi.
Generalmente, è dato per scontato che i mammiferi siano divisi in tre sottoclassi (Monotremi, Marsupiali e Placentati), oppure due sottoclassi (Prototeri, ossia i monotremi, e Teri, ossia marsupiali e placentati), per un totale di ordini che oscilla, a seconda della classificazione utilizzata, fra i 25 e i 30.
Il primo tentativo di fare una classificazione completa dei mammiferi fu fatto da George Gaylord Simpson nel 1945 prendendo spunto dalle presupposte affinità fra le famiglie animali diffuse all'epoca. Su questa classificazione sono infuriate molte polemiche non ancora sopite, soprattutto dopo l'avvento della nuova concezione della cladistica.
Nonostante l'opera di Simpson sia uscita progressivamente di scena con l'avvento delle nuove teorie, ha ancora un grande valore per la classificazione dei mammiferi.
Nei libri di mammologia viene adottato un sistema standardizzato di classificazione dei mammiferi:
Classe Mammalia
Nonostante i nomi Prototheria, Metatheria ed Eutheria siano stati privati di validità (presuppongono il concetto che i placentati derivino dai marsupiali, che a loro volta discenderebbero dai monotremi), questa sistematizzazione è utilizzata dalla maggior parte dei testi scolastici e universitari, oltre che in paleontologia (specialmente nell'ambito degli animali del Mesozoico).
Nel 1997 due studiosi, Malcolm McKenna e Susan Bell, utilizzarono le sistematiche precedenti e le relazioni fra i vari gruppi di mammiferi (viventi ed estinti) per realizzare una nuova classificazione della classe, basata su una gerarchia fra i vari taxon.
La nuova classificazione (detta McKenna/Bell) fu accettata da larga parte dei paleontologi, poiché rifletteva fedelmente il percorso storico dei mammiferi. Tale classificazione comprende sia generi estinti che ancora viventi; inoltre vengono introdotti i nuovi ranghi di legione e sublegione, posizionati fra classe e ordine.
I gruppi estinti sono contrassegnati da una croce (†).
Recenti studi basati sull'analisi del DNA, specialmente tramite l'analisi dei retrotrasposoni, hanno rivelato nuove parentele inaspettate fra le varie famiglie animali. Tali parentele non hanno ancora trovato dimostrazione a livello fossile, quindi non ci sono ancora prove tangibili che corroborino queste nuove ipotesi.
Secondo i risultati delle analisi, il primo gruppo a divergere dai placentati del Cretaceo fu quello degli Afrotheria, 110-100 milioni di anni fa. Gli Afrotheria continuarono a evolversi nell'isolamento del continente Afro-arabico; nel frattempo (100-95 milioni di anni fa) gli Xenarthra sudamericani si staccarono dai Boreoeutheria.
Secondo un'osservazione recente, gli Afrotheria e gli Xenarthra sono strettamente collegati fra loro, tanto da formare un gruppo (Atlantogenata) parallelo a Boreoeutheria. Questi ultimi si divisero in Laurasiatheria ed Euarchontoglires 95-85 milioni di anni fa; entrambi questi gruppi vivevano nel supercontinente della Laurasia.
Dopo la collisione dell'Africa-Arabia con l'Eurasia, vi fu un rimescolamento di Afrotheria e Boreoeutheria: con la comparsa dell'Istmo di Panama, inoltre, facilitò il grande scambio americano.
Questa nuova classificazione manca di prove morfologiche e quindi non è accettata da alcuni scienziati, tuttavia l'analisi della presenza dei retrotrasponsoni suggerisce che l'ipotesi degli Epitheria (che propone gli Xenarthra come primo gruppo a differenziarsi) potrebbe essere vera.
Supergruppo Atlantogenata
Supergruppo Boreoeutheria
Per le voci di Wikipedia è stata adottata la seguente classificazione:
I Mammiferi sono dotati di varie caratteristiche comuni che consentono di separarli dalle altre classi di vertebrati:
La presenza di pelo è una delle caratteristiche più importanti dei mammiferi: la maggioranza dei mammiferi, infatti, ha il corpo ricoperto per percentuali più o meno elevate di pelo, e anche coloro i quali ne sono apparentemente sprovvisti (come i cetacei) presentano allo stadio embrionale degli accenni di crescita di pelo, che regrediscono poi con il procedere della gravidanza.
I peli dei mammiferi hanno composizione prevalentemente proteica: in particolare essi sono costituiti per la quasi totalità da cheratina. Il pelo nei mammiferi ha numerose funzioni:
A fianco al pelo, i mammiferi hanno evoluto delle ghiandole sebacee, le quali sono preposte alla secrezione del sebo, una sostanza grassa che serve a lubrificare il pelame.
I mammiferi sono gli unici animali ad allattare la propria prole almeno fino a quando questa non è in grado di nutrirsi di cibo solido in modo autonomo. Il latte è prodotto in apposite ghiandole dette ghiandole mammarie, organizzate negli euteri in mammelle, dalle quali prende il nome l'intera classe.
Le mammelle consistono in complessi ghiandolari con sbocco esterno (capezzolo) al quale il piccolo può aggrapparsi durante la suzione: fanno eccezione i monotremi, in cui le ghiandole mammarie sfociano all'esterno tramite un poro e perciò il latte è un essudato che viene leccato dai piccoli. Ciascuna specie ha un numero diverso di capezzoli, in funzione del numero medio di cuccioli partoriti per nidiata: nei primati e negli equidi, per esempio, vi sono solo due capezzoli, mentre i tenrec ne possiedono fino a due dozzine.
L'allattamento rappresenta un grande vantaggio, in quanto i piccoli possono ricevere una sostanza molto nutriente e senza grandi sforzi, che garantisce una crescita veloce e una maggiore probabilità di sopravvivenza: d'altro canto, la femmina spende grandi energie per allattare i cuccioli ed è perciò costretta a nutrirsi più del necessario per integrare le energie profuse in questo sforzo.
Le femmine generalmente allattano unicamente i propri cuccioli, scacciando anche violentemente altri piccoli in cerca di cibo: fanno eccezione poche specie in cui si possono osservare delle balie, come i leoni e l'uomo.
A differenza dei loro progenitori rettili che avevano una dentatura laterale semplice, i mammiferi sono solitamente provvisti di dentatura eteromorfa, con presenza di quattro tipi di denti:
Ciascuno di questi quattro tipi di dente è presente in numero variabile a seconda delle abitudini alimentari della specie.
Presso la maggioranza delle specie di mammiferi, si ha un unico cambiamento della dentizione (difiodontia), quando la dentatura decidua (i cosiddetti "denti da latte") viene sostituita dalla dentatura permanente. Alcuni gruppi di mammiferi possiedono denti privi di radici e a crescita costante: è il caso delle zanne di elefanti, suidi, trichechi e narvali, o degli incisivi dei roditori.
I monotremi, invece, non possiedono affatto denti nella fase adulta, mentre i cuccioli possiedono il cosiddetto "dente di diamante", che analogamente agli uccelli consente loro di bucare il guscio dell'uovo in cui si trovano. I mammiferi marsupiali presentano dentizione differente rispetto ai placentati: i marsupiali primitivi avevano una formula dentaria pari a 5/4-1/1-3/3-4/4, pari cioè a cinquanta denti, mentre le forme attuali hanno un numero di denti variabile, ma compreso fra i 40 e i 50, ossia in numero maggiore rispetto alla maggior parte dei placentati.
I primi placentati avevano formula dentaria pari a 3/3-1/1-4/4-3/3, per un totale di 44 denti: tale formula si ritrova attualmente solo in alcuni animali (come il cinghiale), mentre nella maggior parte degli altri mammiferi si è avuta una specializzazione alimentare che ha portato alla riduzione del numero dei denti, fino addirittura alla totale sparizione di questi ultimi (è il caso degli sdentati). Solo in pochi casi il numero dei denti è aumentato rispetto alla formula originaria: è il caso dell'armadillo gigante, provvisto di un centinaio di denti, o dei cetacei odontoceti, nei quali si è avuto un ritorno all'omomorfia (denti tutti uguali, come nei rettili) e si possono contare fino a 270 denti.
La presenza di meccanismi complessi di interazione fra i vari individui hanno portato a una modifica importante della muscolatura facciale dei mammiferi: in tutte le specie, infatti, presentano, o hanno presentato durante il corso del proprio percorso evolutivo, delle labbra e delle guance, che vanno a formare una fascia muscolare che circonda l'apertura della bocca.
Le labbra, le guance e lo spazio che le separa dalla chiostra dentaria (il cosiddetto vestibulum oris) sono legate essenzialmente alla ricerca del cibo: già a partire della nascita, l'animale contraendo in maniera sincrona i muscoli labiali e guanciali provoca la diminuzione della pressione nel proprio vestibulum oris, la quale permette la suzione del latte materno.
In età adulta, la faccia diventa un essenziale mezzo di comunicazione fra i vari individui della stessa specie, e spesso, tramite messaggi universali, anche fra animali di specie diverse.
I mammiferi, oltre a essere gli unici animali dotati di un orecchio esterno con funzione di incanalare i suoni, sono anche gli unici animali a possedere la famosa "triade" martello/incudine/staffa, situati nell'orecchio medio e con funzione di ricevere le vibrazioni del timpano e inoltrarle alla finestra ovale dell'orecchio interno.
Tali ossa derivano da una modifica dell'arco branchiale a livello embrionale: la staffa proviene dall'osso iomandibolare, mentre l'incudine e il martello provengono dall'osso quadrato in combinazione con la cartilagine di Meckel. Negli altri vertebrati, tali strutture vanno a formare l'articolazione mandibolare, che nei mammiferi è invece composta dagli ossi dentale e squamoso, mentre la mandibola va ad articolarsi direttamente al cranio.
I mammiferi, così come anche gli uccelli, hanno una circolazione sanguigna doppia completa: ciò significa che il cuore è suddiviso in quattro scomparti ben distinti (a eccezione del feto, dove ha una separazione incompleta con presenza di un forame ovale), due atri e due ventricoli, e che il sangue passa due volte al suo interno, una volta nella parte destre sotto forma di sangue venoso da pompare verso i polmoni per essere ossigenato, e una seconda volta nella parte sinistra sotto forma di sangue arterioso da pompare verso le zone periferiche del corpo. I globuli rossi dei mammiferi, tuttavia, a differenza di quelli degli altri vertebrati sono sprovvisti di nucleo e di organelli, pertanto vengono continuamente prodotti dagli organi ematopoietici.
Gli arti dei mammiferi sono attaccati al di sotto del corpo, e non lateralmente rispetto a esso (come accade ad esempio nei rettili): pertanto, durante il movimento dell'animale gli arti si trovano disposti perpendicolarmente alla colonna vertebrale, che viene piegata verticalmente piuttosto che lateralmente. Questa caratteristica permette ai mammiferi movimenti veloci anche prolungati nel tempo, che consentono ai mammiferi azioni come la corsa (utile sia per cacciare le prede che per sfuggire ai predatori) o dei movimenti migratori.
La cavità toracica, grazie alla diversa attaccatura degli arti, perde la sua funzione motoria, potendo così dedicarsi a pieno alla funzione respiratoria: nei mammiferi si ha la comparsa del diaframma, una lamina muscolare che divide il torace dall'addome e contribuisce alla respirazione, in quanto contraendosi crea uno scompenso pressorio che spinge i polmoni a espandersi (inspirazione). I mammiferi possiedono polmoni a struttura alveolare, la quale ben si adatta a cambiamenti continui di volume.
Grazie alle loro caratteristiche di omeotermia ed endotermia, i mammiferi sono riusciti a colonizzare praticamente in qualsiasi habitat presente al mondo: mentre i monotremi sono limitati ad alcune aree di Australia e Nuova Guinea e i marsupiali si trovano unicamente in Oceania e nel continente americano, attualmente i mammiferi placentati sono diffusi in tutti i continenti e a tutti i climi, così come anche negli oceani, nei cieli, nel sottosuolo e nella maggior parte delle isole oceaniche.
Spesso l'espansione dei mammiferi placentati è avvenuta al seguito dell'uomo, tramite introduzione deliberata in nuove terre oppure grazie a introduzioni casuali, com'è avvenuto per esempio nel caso dei ratti. Le uniche aree in cui non vi è una presenza stabile di mammiferi sono le aree più interne dell'Antartide, abitate solo in alcuni periodi da un basso numero di studiosi.
I mammiferi possiedono tutti e cinque i sensi, ma raramente essi funzionano tutti in modo egregio: ad esempio, la talpa ha un udito finissimo (al punto di poter sentire i lombrichi quando spuntano dalle pareti della sua tana), mentre la sua vista è proverbialmente povera, non andando al di là della distinzione fra presenza e assenza di luce.
La necessità di mantenere la temperatura corporea stabile costringe i mammiferi a doversi nutrire regolarmente: a seconda delle dimensioni dell'organismo, il metabolismo può essere più o meno veloce consentendo all'animale di sopportare periodi più o meno lunghi di digiuno (ad esempio un toporagno muore dopo alcune ore di digiuno, mentre un uomo può sopravvivere anche alcune settimane senza cibo).
Tra i mammiferi vi è un'enorme varietà nella dieta: si trovano specie erbivore, carnivore e onnivore. La dieta di ciascuna specie può essere determinata in base alla lunghezza del tubo digerente e al numero e alla disposizione dei denti: mentre i carnivori hanno canini molto sviluppati e intestino piuttosto corto (per un veloce transito del cibo, ai fini di evitare l'insorgenza di intossicazioni dovute ai fenomeni putrefattivi della carne), gli animali erbivori possiedono una serie di adattamenti (intestino assai allungato, stomaco compartimentato come in ruminanti e canguri, cecotrofia -ossia assunzione dei propri escrementi per ridigerirli- come nei lagomorfi e in alcuni roditori) volti a estrarre la maggior quantità possibile di energia dal cibo.
Tutti i mammiferi comunicano fra loro: la comunicazione può avvenire tramite segnali chimici, vocali (richiami), tattili (grooming) o visivi (posture e gesti).
Le specie più solitarie tendono ad avere un repertorio vocale e gestuale assai limitato: generalmente, è sempre presente un richiamo e una postura preposti a segnalare la disponibilità all'accoppiamento, così come un richiamo e una postura indicatori di minaccia nei confronti di intrusi.
Nelle specie più sociali sono presenti modelli di comportamento anche molto complessi, volti a stabilire e mantenere una gerarchia all'interno del gruppo e a segnalare ad altri animali sia degli eventi (presenza di cibo o di pericoli) che lo stato d'animo dell'animale che emette il suono (rabbia, paura, eccitazione, gioia).
Visto il grande numero di specie di mammiferi esistenti e considerando la grande variabilità di forme e dimensioni presenti all'interno della classe, si può comprendere l'estrema eterogeneità delle abitudini di vita dei mammiferi: alcune specie sono solitarie, altre vivono in gruppi che contano anche un migliaio di individui. Alcuni mammiferi sono estremamente territoriali, mentre altri tollerano senza problemi la presenza di altri individui nelle vicinanze. Molte specie hanno abitudini notturne, mentre altre preferiscono essere attive durante il giorno: altre ancora presentano catemeria, ossia tendenza ad alternare periodi di veglia e di sonno durante le ventiquattro ore.
Le varie specie di mammifero hanno aspettative di vita anche assai differenti: generalmente, l'aspettativa di vita è direttamente proporzionale alle dimensioni dell'animale in valori assoluti. Mentre i topi marsupiali maschi vivono al massimo un anno, i grandi mammiferi possono vivere fino a un secolo: l'età massima mai riscontrata in un mammifero spetta a una donna, Jeanne Calment, vissuta 122 anni, ma è assai probabile che i grandi cetacei misticeti possano vivere anche più a lungo (l'età stimata di una balena della Groenlandia è di 211 anni).
La maggioranza dei mammiferi praticano la poliginia o la promiscuità, ossia rispettivamente la costruzione di un harem da parte di un maschio oppure l'accoppiamento di ciascun esemplare con il maggior numero possibile di animali del sesso opposto: questo perché la femmina, una volta fecondata, necessita di un certo periodo per la gestazione e l'allattamento dei cuccioli, periodo durante il quale il maschio tenta invece di lasciare quanta più progenie possibile.
Conseguenza della poliginia sono le lotte fra maschi per il diritto all'accoppiamento, che nel tempo hanno dato origine a una serie di cerimoniali legati alla competizione e alla comparsa di caratteristiche anatomiche legate all'evento riproduttivo. In queste specie, è solitamente presente un dimorfismo sessuale spesso molto accentuato, con i maschi più grandi e forti delle femmine e spesso dotati di strutture accessorie a carattere sessuale, come la criniera del leone o le corna di molti artiodattili.
Solo il 3% di tutte le specie di mammifero presenta abitudini Monogame: in questi casi, il maschio e la femmina (che non di rado rimangono insieme anche al di fuori del periodo riproduttivo) sono soliti partecipare assieme alla cura dei cuccioli.
Alcune specie alternano i due comportamenti a seconda delle risorse a disposizione: quando il cibo è scarso viene praticata la monogamia, in modo tale da assicurare la sopravvivenza alla prole, seppure poca in termini numerici, mentre nei periodi di abbondanza viene praticata la promiscuità o la poliginia, sì da mettere al mondo quanta più prole possibile.
Rarissima è invece la poliandria, riscontrabile solo in alcune specie di callitricidi: in questi casi, è il maschio a occuparsi della prole. Altri mammiferi nei quali è il maschio a occuparsi dei cuccioli, delegando alla femmina solo l'allattamento, sono le scimmie platirrine dell'America centro-meridionale.
Un caso particolare è rappresentato dall'eterocefalo glabro, un roditore africano che presenta abitudini sociali simili a quelle di api e formiche: questi animali vivono infatti in grandi colonie sotterranee, costituite da una femmina "regina" attorniata da alcuni maschi "fuchi", i quali sono gli unici a potersi accoppiare con la regina, mentre i rimanenti animali sono sterili e preposti allo svolgimento delle attività necessarie al mantenimento della colonia.
Nei monotremi è presente una cloaca nella quale convergono le due vie dell'apparato escretore (renale e intestinale), oltre che il canale riproduttivo. Il pene del maschio è unicamente proposto all'emissione dello sperma e presenta una biforcazione verso la punta.
Questi animali sono gli unici mammiferi a non presentare viviparità ma oviparità: la femmina emette infatti da uno a tre uova di circa un centimetro e mezzo di diametro, simili a quelle dei rettili, dotate di grande tuorlo. Le uova vengono covate dalla femmina per una decina di giorni, finché non si schiudono e ne fuoriescono i piccoli, che sono paragonabili ai marsupiali neonati in termini di sottosviluppo.
Nei marsupiali le femmine presentano sistema riproduttivo raddoppiato con due vagine e due uteri, mentre i maschi hanno un pene biforcato nella sua parte distale. La gestazione di questi animali dura al massimo un mese anche nelle specie di maggiori dimensioni, mentre in altre specie anche di meno: il record spetta alla specie Sminthopsis macroura, con soli 10-11 giorni di gestazione. La placenta è quasi sempre assente, fatta eccezione per alcune specie (come il koala e i bandicoot) dove si riscontra una sorta di placenta primitiva.
I nuovi nati sono assai piccoli e sottosviluppati, pesando circa l'1% rispetto alla madre: solo le zampe anteriori sono ben sviluppate, in quanto il piccolo le utilizza per farsi strada lungo il ventre della madre, fino a raggiungerne il marsupio e attaccarsi a uno dei capezzoli che ivi si trovano. Il marsupio può essere permanente, ma in alcune specie esso si forma solo durante il periodo dell'allevamento dei piccoli: altre specie, infine, non presentano affatto marsupio, quanto piuttosto delle pliche cutanee. Una volta raggiunto il capezzolo, il piccolo vi si aggrappa saldamente per le prime settimane di vita: lo svezzamento dei marsupiali è più tardivo rispetto a quello dei placentati.
I placentati presentano trofoblasto, che funge da barriera immunologica e consente una lunga permanenza dell'embrione nell'utero materno, la qual cosa risulta impossibile nei marsupiali, i quali sono costretti a partorire prima che le proprie difese immunitarie divengano pienamente efficienti contro l'embrione. La gestazione varia a seconda della specie, ad esempio roditori e carnivori hanno gravidanze veloci e cucciolate abbastanza numerose, mentre animali come i cetartiodattili hanno gravidanze assai lunghe e danno alla luce uno o due cuccioli alla volta. I record di durata spettano ad alcune specie di criceto, la cui femmina ha gestazione di soli 15 giorni, e all'elefante africano, che ha una gestazione lunga due anni. Il maggiore numero di cuccioli (fino a trentadue) spetta al tenrec.
I mammiferi sono stati fondamentali per la storia dell'uomo, mammifero anch'esso: gli uomini primitivi si nutrivano della carne di altri mammiferi e ne utilizzavano le pellicce per difendersi dal freddo, inoltre utilizzavano le loro ossa per farne utensili. In seguito, molti mammiferi vennero addomesticati per utilizzarli come animali da soma o come fonte di carne e latte: altri invece venivano cacciati per ricavarne carne, ossa o zanne, da utilizzare come trofeo o per farne manufatti, o ancora per le presunte proprietà mediche (come il corno del rinoceronte) o per i significati religiosi o scaramantici che alcune parti del corpo potevano avere. Al giorno d'oggi, l'uso di animali da soma è stato quasi ovunque soppiantato dall'utilizzo di macchine, mentre permane l'allevamento di animali a scopo alimentare o come animali da compagnia o da laboratorio.
Allo stesso modo, anche l'uomo ha molto influenzato l'andamento delle popolazioni di mammiferi: in seguito all'espansione umana molte specie opportunistiche hanno esteso il loro areale muovendosi assieme alle navi o venendo introdotte più o meno di proposito in nuove terre, mentre altre sono state decimate dalla caccia o dalla distruzione dell'habitat o sono addirittura andate incontro all'estinzione. Tutta una serie di mammiferi, infine, è stata modificata dall'uomo perché meglio rispondesse alle sue esigenze, fossero esse di carne, latte, lana o lavoro.
In tempi antichi gli animali più forti, grandi o pericolosi sono stati venerati come spiriti totemici e in seguito come stemmi di alcune città o simboli di clan, mentre altri vennero bollati come esseri demoniaci a causa delle loro abitudini notturne o del cattivo aspetto: è il caso del gatto e dei pipistrelli. In fiabe e leggende di tutto il mondo abbondano le immagini stereotipate degli animali, come la volpe furba, il mulo testardo o il maiale ingordo.
Uno dei motivi principali della domesticazione di molte specie di mammiferi è stata la necessità di avere sempre sottomano una riserva di carne fresca, ricca di proteine e grassi, anche quando la selvaggina scarseggiava. I principali animali allevati per la carne sono bovini e suini, in misura assai minore anche conigli, ovini, caprini ed equini.
Anche la pelle e il pelo dei mammiferi tornavano utili all'uomo, che li utilizzava per coprirsi e difendersi dal freddo: animali allevati per la propria lana sono la pecora e l'alpaca, mentre i bovini vengono allevati anche per ricavarne cuoio dalla conciatura della pelle. Altri animali allevati per l'industria conciaria sono cincillà, visoni, zibellini e nutrie.
Dei mammiferi si può utilizzare anche il latte, che nelle altre specie è più ricco di nutrimento rispetto a quello umano, del quale può rappresentare un valido sostituto: i principali animali da latte sono i bovini, con oltre l'85% del totale mondiale, ma viene utilizzato anche il latte di pecora e capra, d'asina o di renna.
Alcuni mammiferi, tuttavia, non sono stati addomesticati per la loro carne, ma per la loro forza od agilità, che consentivano all'uomo di utilizzarli sia come cavalcatura per compiere lunghe distanze, che come animali da soma per compiere lavori troppo faticosi in poco tempo: è il caso di cavalli, asini, cammelli, dromedari, bufali indiani, elefanti asiatici e lama. Attualmente, l'utilizzo di animali da soma è limitato alle regioni più impervie o sottosviluppate, mentre nei Paesi industrializzati essi sono stati largamente sostituiti dalle macchine e sussistono in allevamenti amatoriali od in impieghi puramente rappresentativi (ad esempio le guardie a cavallo).
Per gli stessi motivi, alcuni di questi animali sono stati utilizzati anche come animali da guerra: fino al tardo XIX secolo, l'utilizzo di cavalli nelle operazioni veloci di attacco spesso risultava decisivo nell'esito della battaglia, mentre nell'antichità alcuni popoli (come i persiani e i Cartaginesi) erano soliti schierare fra le proprie file alcuni elefanti da guerra. In tempi recenti, cavalli ed elefanti vennero anch'essi soppiantati dalle macchine da guerra, ma l'utilizzo di animali continuò (ad esempio i muli degli Alpini durante le due Guerre Mondiali, dei cani anticarro sovietici durante la Seconda guerra mondiale, o ancora dei delfini addestrati come cacciamine dall'esercito statunitense)
Altri mammiferi, non forti né apprezzabili dal punto di vista alimentare, vennero invece scelti per le loro potenzialità come aiutanti nella caccia o nella disinfestazione degli accampamenti: è il caso del cane e del gatto, che tuttavia attualmente vengono tenuti perlopiù come animali da compagnia, anche se alcune razze di cane (come i segugi) continuano a venire selezionate appositamente per la caccia. I cani sono anche stati utilizzati, assieme ai maiali, come animali da tartufo, grazie al loro finissimo olfatto, od anche come aiutanti per i non vedenti.
Il processo di domesticazione dei mammiferi è cominciato fra i 15 000 ed i 10 000 anni fa, anche se recenti studi genetici effettuati sul cane domestico hanno retrodatato tale valore addirittura a 100 000 anni fa. Gli eventi di addomesticamento sono stati frutto di iniziative parallele prese in periodi diversi ed in luoghi diversi. Gli animali addomesticati più di recente sono stati il lama, il cavallo ed il coniglio, circa 5 000 anni fa.[senza fonte]
L'uomo ha inoltre tenuto in cattività i mammiferi anche per altri motivi:
L'espansione smisurata dell'attività umana ha fatto sì che si venissero a creare delle zone agricole e dei depositi di cibo, che possono di tanto in tanto essere presi di mira da animali selvatici o comunque che vivono a stretto contatto con l'uomo. Fra le specie più dannose sotto questo punto di vista sono i ratti, sia quello nero che soprattutto quello bruno, mentre nelle aree in cui sono presenti mandrie di bestiame i grossi mammiferi carnivori presenti vengono sempre visti come dannosi e perciò eliminati, con esche avvelenate o con una caccia spietata.
In alcuni casi, gli animali divengono direttamente pericolosi per l'uomo: mentre in tempi remoti non era raro che qualche uomo primitivo venisse divorato dai grandi predatori, attualmente è assai arduo che un carnivoro aggredisca un uomo allo scopo di cibarsene. I mammiferi più temuti per i loro presunti gusti antropofagi sono i grandi felini, come le tigri, i leoni e i leopardi, ai quali tuttavia spettano solo meno di una decina di uccisioni l'anno, assai meno delle migliaia di morti a causa di incidenti con altri animali domestici, come muli, tori ecc. Altri grandi predatori molto temuti sono stati (e sono tuttora) gli orsi (in particolare l'orso bruno) e i lupi, sebbene questi ultimi evitano la vicinanza dell'uomo e mietano pochissime vittime umane all'anno.
Molto più pericolosi sono i mammiferi portatori di malattie: ogni anno più di 50 000 uomini muoiono a causa della rabbia (trasmessa da cani, gatti, pipistrelli e altri animali infetti), mentre nel XIV secolo l'epidemia di peste nera trasmessa dai ratti falciò milioni di persone.
Un albero (dal latino arbor) è una pianta legnosa perenne, capace di svilupparsi in altezza grazie ad un fusto legnoso, detto "tronco", che di solito inizia a ramificarsi a qualche metro dal suolo. L'insieme dei rami e delle foglie determina la chioma che può avere forme diverse a seconda delle specie e delle condizioni ambientali.[1]
L'albero si distingue dall'arbusto non per le sue dimensioni, ma perché allo stato adulto ha un fusto perenne, il tronco, con ramificazioni nella parte superiore. 
Il fusto dev'essere nettamente identificabile e privo per un primo tratto di rami: esistono ad esempio dei salici, alberi a tutti gli effetti, con portamento strisciante e alti solo pochi centimetri.
Questa corretta definizione botanica viene tuttavia a volte disattesa qualora si parli di alberi riferendosi ai loro possibili usi commerciali: in questo caso a volte vengono fissate delle altezze minime per la definizione di albero (es. 5 m di altezza per alcune norme FAO).
Il tronco è formato internamente da più strati: la parte più esterna costituisce la corteccia, il secondo strato è chiamato libro, il terzo è il cambio; infine il cilindro centrale che è formato dal legno.
Ogni albero ha la sua sagoma caratteristica che gli deriva dalla conformazione del tronco (sviluppo in altezza e diametro) e dall'insieme delle ramificazioni. Quest'ultime possono essere monopodiali o simpodiali.
L'albero con la più grande circonferenza del tronco è il baobab: anche oltre 40 m di circonferenza. 
La chioma dell'albero è costituita dalle foglie e dai rami o branche.
Può essere: 
A seconda della forma delle foglie si possono distinguere due categorie di alberi, aghifoglie e latifoglie. A seconda del ciclo vitale delle foglie si possono distinguere altre due categorie di alberi, sempreverdi e caducifoglie.
Gli alberi possono vivere isolati o associati, formando raggruppamenti di un'unica specie (come un querceto da sughero) o di specie diverse (bosco o macchia). Poiché le radici sono molto lontane dalle foglie, gli alberi sono molto esigenti dal punto di vista climatico: non possono vivere nelle zone desertiche, subartiche e sui monti oltre una determinata altitudine, dove sono generalmente sostituiti da arbusti.
Gli alberi possono essere suddivisi in altre due categorie:
Esempi di alberi sono: il carrubo Ceratonia siliqua, il bagolaro celtis australis, il siliquastro Cercis siliquastrum, il sorbo domestico sorbus domestica, il pistacchio pistacia vera, il gelso morus alba, il cotogno Cydonia oblonga, l'azzerruolo Crataegus azarolus o il nespolo comune Mespilus germanica.
Il legno degli alberi è una fonte energetica (combustione diretta e carbone di legna) e un materiale da costruzione (intere abitazioni, travature, navi, mobili, oggetti d'uso comune ed artistici). Sempre dagli alberi, spesso coltivati allo scopo, si ricava cellulosa per la produzione della carta.
Gli esemplari di alberi con caratteristiche storiche, paesaggistiche, e di dimensioni ragguardevoli vengono definiti alberi monumentali, che in alcune nazioni vengono censiti e protetti.[2]
Secondo le stime del Corpo Forestale, sono circa 22 000 gli alberi monumentali d'Italia, da querce millenarie al più antico platano. Tra questi, più di 2 000 sono stati dichiarati di “grande interesse” e 150 di “eccezionale valore storico o monumentale”.[3]
Gli alberi habitat sono invece esemplari con valenze ecologiche particolari soprattutto in funzione della biodiversità.
Sin dall'antichità, gli alberi venivano venerati per la loro funzione di tramite, di collegamento tra la dimensione celeste e quella terrena sublunare, se non adorati come vere e proprie divinità.[5][6][7] Nell'albero poteva infatti dimorare un'entità o uno spirito, conosciuto nella cultura indiana come Deva.
In Occidente alcuni alberi potevano assurgere a simbolo dell'axis mundi, ossia dell'asse portante del mondo.[8] Tali erano ad esempio l'Yggdrasill della mitologia norrena, l'Irminsul presso i Sassoni, o il noce di Benevento presso i Longobardi stanziati in Italia. Nella Bibbia la simbologia dell'albero è presente in quello della vita e della conoscenza del bene e del male a cui attinsero Adamo ed Eva, capace di farli «diventare simili a Dio», a prezzo però della perdita della loro innocenza originaria.[9]
Dall'Albero del Paradiso discenderebbe la tradizione dell'albero di Natale, adornato con i simboli cosmici del Sole, della Luna, dei pianeti e delle stelle,[4] mescolato con la mitologia dell'abete sacro a Odino, potente dio dei Germani.[10]
Alberi di bassa altezza, più precisamente un gruppo di abeti innevati
Un albero di media altezza
Un albero molto caratteristico
Albero di olivo
Gli anelli visibili dopo il taglio
Olivo di Ragusa
Sullo sfondo si vede come gli alberi non superino una certa altitudine
Lo stagno è un elemento chimico nella tavola periodica che ha numero atomico 50 e simbolo Sn, derivante da stannum, il nome latino dell'elemento. È il quarto elemento del gruppo 14 del sistema periodico. Questo metallo di post-transizione argenteo e malleabile, che non si ossida facilmente all'aria e resiste alla corrosione, si usa in molte leghe e per ricoprire altri metalli più vulnerabili alla corrosione. Lo stagno si ottiene soprattutto dalla cassiterite, un minerale in cui è presente sotto forma di ossido, e dalla stannite.
Lo stagno è un metallo molto malleabile e molto duttile [1]  bianco argenteo, con una struttura cristallina particolare che provoca uno stridio caratteristico quando una barra di stagno viene piegata (il rumore è causato dalla rottura dei cristalli): se riscaldato, perde la sua duttilità e diventa fragile. Questo metallo resiste alla corrosione da acqua marina, da acqua distillata e da acqua potabile, ma può essere attaccato da acidi forti, da alcali e da sali acidi. Lo stagno agisce da catalizzatore in presenza di ossigeno disciolto nell'acqua e accelera l'attacco chimico.
Lo stagno solido a temperature normali ha due forme allotropiche. Sotto i 13,2 °C è stabile la forma allotropica alfa, detta stagno grigio, che ha una struttura cristallina cubica molto simile al silicio e al germanio. Sopra la temperatura limite di 13,2 °C invece è stabile la seconda forma allotropica, stagno beta, detto anche stagno bianco con una struttura cristallina tetragonale.
Stagno alfa: densità 5,769 g/cm³; numero di coordinazione 4
Stagno beta: densità 7,265 g/cm³; numero di coordinazione 6
Se raffreddato da solido, lo stagno bianco si riconverte lentamente nella forma allotropica alfa. Questo fenomeno, noto come peste dello stagno, viene sfavorito da impurità di alluminio e zinco presenti nel metallo che ne abbassano la transizione a 0 gradi. Per impedire del tutto questa trasformazione vengono aggiunte allo stagno puro piccole quantità di antimonio e bismuto.
Lo stagno si lega facilmente col ferro ed è stato usato in passato per rivestire piombo, zinco e acciaio per impedirne la corrosione. I contenitori, lattine e scatolette, in banda stagnata (lamierino di acciaio stagnato) sono tuttora largamente usati per conservare i cibi, un uso che copre gran parte del mercato mondiale dello stagno metallico. Oltre alla forma metallica trovano largo impiego industriale diversi dei numerosi composti, organici ed inorganici, dello stagno IV.
Altri usi: 
Lo stagno diventa superconduttore sotto 3,72 K: è stato uno dei primi superconduttori scoperti (il primo è mercurio allo stato solido) e l'effetto Meissner, una delle caratteristiche dello stato di superconduttività, è stato osservato per la prima volta in cristalli superconduttori di stagno. La lega niobio-stagno Nb3Sn è usata commercialmente per fabbricare cavi per magneti superconduttori grazie all'alta temperatura critica (18 K) e l'alto valore critico di campo magnetico (25 T). Un magnete superconduttore di un paio di chilogrammi di massa può generare lo stesso campo di un magnete convenzionale pesante molte tonnellate.
Lo stagno (dal latino stannum) è stato uno dei primi metalli ad essere scoperto, e fin dall'antichità venne intensivamente usato per il suo effetto come legante del rame, di cui aumenta di molto la durezza e le doti meccaniche formando la lega nota come bronzo, in uso fino dal 3500 a.C. L'attività di estrazione mineraria dello stagno iniziò presumibilmente in Cornovaglia e a Dartmoor in età classica: grazie ad esso queste regioni svilupparono un fitto commercio con le aree civilizzate del Mar Mediterraneo. Lo stagno puro non venne usato in metallurgia fino al 600 a.C.
Le attività estrattive ebbero un'impennata verso la metà del XIX secolo dopo la scoperta delle proprietà del metallo nella conservazione dei cibi e la sua conseguente diffusione.[2] Nel 1900 la Malaysia produceva la metà di tutto lo stagno a livello mondiale; le estrazioni erano aumentate dopo che nel 1853 l'Inghilterra aveva soppresso l'imposta su questo metallo.
Nell'epoca moderna l'alluminio ha soppiantato alcuni usi dello stagno, ma il termine stagnola è ancora usato per ogni metallo argenteo in forma di fogli sottili.
Circa 35 paesi nel mondo hanno miniere di stagno in attività e praticamente in ogni continente c'è un importante produttore di stagno. Lo stagno metallico si produce riducendo il minerale con carbone in una fornace a riverbero. L'elemento stagno è relativamente scarso nella crosta terrestre, con un'abbondanza relativa di circa 2 ppm, a paragone con le 94 ppm per lo zinco, le 63 ppm per il rame e le 12 ppm per il piombo. La maggior parte dei giacimenti di stagno del mondo sono di natura alluvionale e metà di essi è nel sudest asiatico. L'unico minerale importante dal punto di vista estrattivo è la cassiterite (SnO2), ma piccole quantità di stagno si possono ottenere anche da solfuri complessi come stannite, cilindrite, franckeite, canfieldite e teallite.
Lo stagno è l'elemento con il maggior numero di isotopi stabili, dieci; questi comprendono tutti quelli con  numeri di massa che vanno da 112 e 124, ad eccezione di 113, 121 e 123. Di questi, quelli più abbondanti sono 120Sn (almeno un terzo di tutto lo stagno), 118Sn e 116Sn, mentre quello meno abbondante è 115Sn. Gli isotopi che possiedono numeri di massa pari non hanno spin nucleare, mentre quelli dispari hanno uno spin di ½+. Lo stagno, insieme ai suoi tre isotopi più comuni 115Sn, 117Sn e 119Sn, è tra gli elementi più facili da rilevare e analizzare mediante la spettroscopia NMR e i suoi spostamenti chimici sono raffrontati rispetto allo SnMe4.[4][5]
Si pensa che questo ampio numero di isotopi sia un risultato diretto dello stagno che ha numero atomico di 50, che nella fisica nucleare è un "numero magico". Ci sono 28 isotopi instabili aggiuntivi che sono noti, che abbracciano tutti quelli rimanenti con numeri di massa compresi tra 99 e 137. A parte lo 126Sn, che ha un'emivita di 230 000 anni, tutti gli isotopi radioattivi hanno un'emivita di meno di un anno. Lo 100Sn radioattivo è uno dei pochi nuclidi che possiedono un nucleo "doppiamente magico" e fu scoperto in tempi relativamente recenti, nel 1994.[6] Altri 30 isomeri metastabili sono stati caratterizzati per gli isotopi tra 111 e 131, il più stabile dei quali è lo 121mSn, con un'emivita di 43,9 anni.
Le piccole quantità di stagno che si possono trovare nei cibi in scatola non sono dannose per gli esseri umani. Però, i composti trialchilici e triarilici dello stagno sono biocidi, e devono essere maneggiati con molta attenzione.
Il tempo atmosferico (o meteorologico), nella meteorologia, indica il complesso delle condizioni dell'atmosfera terrestre (definite da parametri come temperatura, pressione atmosferica, umidità, nuvolosità, precipitazioni, visibilità e vento, e dai fenomeni associati come ad es. pioggia, neve, grandine, ecc.) in un dato momento e in un dato luogo della superficie terrestre o in libera atmosfera[1](quando usato senza specificazioni si parla comunemente del "tempo" atmosferico terrestre).
Distinto dal clima, che rappresenta invece lo stato medio dell'atmosfera terrestre su un arco temporale di mesi[2] o vari anni (per l'Organizzazione meteorologica mondiale almeno trenta), su medesime scale spaziali, studiato dalla climatologia. ciò che caratterizza il tempo atmosferico è la cosiddetta variabilità meteorologica che va a sovrapporsi ai trend di natura climatica sul medio-lungo periodo. La maggior parte dei fenomeni che determinano il tempo si verificano nella troposfera, al di sotto della stratosfera e la disciplina che si occupa di studiare e prevedere il tempo atmosferico è la meteorologia.
Si può parlare di tempo perché vi sono differenze di densità (temperatura e umidità) nei diversi punti della Terra; queste differenze possono derivare dall'angolo d'incidenza della radiazione solare, che presenta un gradiente secondo la latitudine. Poiché l'asse di rotazione terrestre è inclinato rispetto al piano orbitale, l'angolo di incidenza della luce solare in uno stesso luogo varia a seconda del momento dell'anno. Sulla Terra, le temperature generalmente variano annualmente tra i -40 e i +40 °C. (estremi record: -89 °C alla Base Vostok in Antartide e +70.7 nel deserto di Dasht-e Lut in Iran).
La forte disparità della temperatura dell'aria tra zone polari e tropicali dà origine al complesso della circolazione atmosferica e alle correnti a getto: le differenze fra le temperature di superficie causano infatti differenze di pressione. Alte altitudini sono più fresche che basse altitudini a causa del calore dovuto alla compressione. I sistemi meteorologici alle medie latitudini, come i cicloni extratropicali, sono causati dall'instabilità dei flussi delle correnti a getto e dall'instabilità baroclina. Altri sistemi perturbati, coinvolti nel ciclo dell'acqua e nelle dinamiche delle correnti aeree, sono i cicloni tropicali, i temporali e i tornado o trombe d'aria.
La previsione meteorologica è l'applicazione della scienza e tecnologia per predire lo stato dell'atmosfera di un tempo futuro in una determinata località e può essere previsto, con buona accuratezza ed entro certi limiti temporali, a partire dallo "stato atmosferico" attuale attraverso opportune tecniche di previsione meteorologica, che sfruttano a loro volta le conoscenze scientifiche acquisite dalla scienza meteorologica: in particolare l'atmosfera è un sistema caotico, cosicché piccoli cambiamenti in una parte del medesimo possono provocare effetti importanti nel sistema complessivo. I tentativi dell'uomo per controllare il tempo meteorologico sono stati molteplici nella sua storia ed è evidente che le attività umane quali l'agricoltura e l'industria, hanno inavvertitamente modificato gli assetti del tempo atmosferico.
Lo studio su come il tempo opera sugli altri pianeti può essere di aiuto nel comprendere come esso opera sulla Terra. Un famoso punto di riferimento nel Sistema solare, la Grande Macchia Rossa di Giove, è una tempesta anticiclonica, la cui esistenza risale ad almeno 300 anni. Il tempo atmosferico non è comunque limitato ai corpi planetari: una corona di stelle viene costantemente perduta nello spazio, creando ciò che è essenzialmente un'atmosfera molto sottile nel sistema solare. I movimenti delle masse eiettate dal Sole si chiama vento solare.
Quattro elementi interagiscono per produrre il tempo atmosferico:
Questi elementi sono essi stessi influenzati dai seguenti fattori:
In fisica, in particolare nel magnetismo, il campo magnetico è un campo vettoriale solenoidale[1] generato nello spazio dal moto di una carica elettrica o da un campo elettrico variabile nel tempo. Insieme al campo elettrico, il campo magnetico costituisce il campo elettromagnetico, responsabile dell'interazione elettromagnetica nello spazio.
In realtà, le equazioni relative al campo elettrico e quelle relative al campo magnetico sono separate solo in apparenza, poiché sono proprio le cariche elettriche stesse che in movimento (come corrente elettrica) danno luogo al campo magnetico.
Tuttavia, siccome il fatto che le cariche elettriche siano ferme o in movimento è relativo (cioè dipendente dal sistema di riferimento scelto per descrivere il fenomeno), diviene ugualmente relativo anche il fatto che si abbia a che fare con un campo elettrico o con un campo magnetico. Appare dunque naturale interpretare il campo elettrico e il campo magnetico come manifestazioni diverse di una singola entità fisica, detta campo elettromagnetico.[2]
La scoperta della produzione di campi magnetici da parte di conduttori percorsi da corrente elettrica si deve a Ørsted nel 1820: sperimentalmente si verifica che la direzione del campo è la direzione indicata dalla posizione d'equilibrio dell'ago di una bussola immersa nel campo; lo strumento per la misura del campo magnetico è il magnetometro.
Il campo magnetico agisce su un oggetto elettricamente carico con la forza di Lorentz (nel caso di una carica elettrica in movimento) oppure tramite il momento torcente che agisce su un dipolo magnetico. L'evoluzione spaziale e temporale del campo magnetico è governata dalle equazioni di Maxwell, un sistema di quattro equazioni differenziali alle derivate parziali lineari che sta alla base della descrizione formale dell'interazione elettromagnetica.
In fisica, il campo di induzione magnetica (anche detto impropriamente campo magnetico) in un punto di un mezzo, è individuato dal vettore  composto da una prima componente indicata con  e una seconda componente indicata con  dovuta a fenomeni microscopici che avvengono nel mezzo, come tipicamente un determinato allineamento degli spin atomici[3].  si misura in tesla (T) o in Wb/m²[4] ed è anche detto densità di flusso magnetico o induzione magnetica;  è detto "campo magnetizzante"[5] e si misura in A/m (o anche in Oe)[6];  è il "vettore di magnetizzazione", anch'esso in A/m;  è la permeabilità magnetica del vuoto pari a . In definitiva: .[7][8][9]
 tiene conto del fatto che i momenti magnetici intrinseci (spin) degli elettroni legati si allineano mediamente in una certa direzione, spesso quella del campo applicato esternamente, e inoltre compiono dei moti medi di precessione attorno a tale direzione in senso orario o antiorario a seconda del segno della loro carica elettrica. Si tratta di moti rotatori nello stesso senso e con la stessa direzione perpendicolare, che forniscono un contributo alla corrente elettrica macroscopica soltanto sulla superficie del materiale: al suo interno i moti delle cariche affiancate tra di loro si compensano a vicenda in quanto ruotano tutte nello stesso senso e da ciò deriva il fatto che le correnti delle cariche legate agli atomi sono esprimibili come il rotore della magnetizzazione. Il legame tra  e  è generalmente spiegabile con delle trattazioni quantistiche della materia, che caratterizzano le proprietà magnetiche dei materiali come il paramagnetismo, il diamagnetismo, il ferromagnetismo, l'antiferromagnetismo, il ferrimagnetismo e il superparamagnetismo.
 è un campo magnetico che ha quattro possibili contributi: la corrente dovuta a cariche libere nel materiale, un campo magnetico applicato esternamente, la variazione nel tempo del campo elettrico e il campo demagnetizzante  che è sempre opposto in verso alla magnetizzazione infatti esso nasce qualora la magnetizzazione abbia dei punti di non uniformità lungo la propria direzione, ovvero quando  ha divergenza non nulla.[10] L'esempio più caratteristico di necessità del campo demagnetizzante in assenza di campi magnetici applicati esternamente, di correnti elettriche libere e variazioni del campo elettrico è il fatto che in un ferromagnete  può essere comunque presente ma essendo nulla fuori dal materiale ha una discontinuità al bordo che la rende non solenoidale quindi se  fosse nullo anche   sarebbe non solenoidale e ciò contraddirebbe la seconda equazione di Maxwell :.
In ambito ingegneristico viene spesso utilizzata una convenzione diversa: le quantità fondamentali (campo elettrico e campo magnetico) sono rappresentate dalla coppia duale , mentre le induzioni corrispondenti, ovvero la coppia duale , vengono considerate la risposta del mezzo all'eccitazione elettromagnetica. Grazie a questa convenzione esiste una dualità sia a livello di unità di misura (ampere è duale di volt, weber è duale di coulomb), sia a livello di notazione. Difatti, introducendo le quantità fittizie densità di carica magnetica  e densità di corrente magnetica , è possibile scrivere delle equazioni di Maxwell perfettamente simmetriche, e ciò consente di enunciare il teorema di dualità elettromagnetica.
Sia data una carica elettrica puntiforme  in moto con velocità istantanea  in una regione caratterizzata dalla presenza di un campo elettrico  e un campo magnetico . La forza di Lorentz è la forza  esercitata dal campo elettromagnetico sulla carica, ed è proporzionale a  e al prodotto vettoriale tra  e  secondo la relazione:[11]
dove  è la posizione della carica,  la sua velocità e  è il tempo.
Una carica positiva viene accelerata nella direzione di  e viene curvata nella direzione perpendicolare al piano formato da  e .
Si consideri il caso in cui sia presente il solo campo magnetico. La formula può essere applicata al caso di un circuito filiforme di lunghezza  percorso dalla corrente elettrica :
e sapendo che per definizione:
con  la densità di corrente, si può estendere al caso più generale di un volume  percorso da una corrente descritta dalla densità di corrente, per il quale si ha:
Dal momento che la forza di Lorentz è legata al campo magnetico tramite il prodotto vettoriale, la forza e il campo non hanno la stessa direzione, essendo perpendicolari. Come conseguenza di ciò, la forza di Lorentz non compie lavoro, infatti:
L'ultimo integrando è nullo perché è il prodotto misto di tre vettori, di cui due paralleli.
Una serie di evidenze sperimentali, tra le quali l'esperimento di Oersted del 1820, ha portato a concludere che il campo magnetico nel generico punto  generato nel vuoto da un elemento infinitesimo  di un circuito percorso da una corrente  è dato da:[12]
dove  è la distanza tra la posizione  dell'elemento infinitesimo  del circuito e il punto  in cui è calcolato il campo, e  è la permeabilità magnetica nel vuoto.
L'integrazione su tutto il circuito della precedente espressione produce la Legge di Biot-Savart:
che rappresenta il campo magnetico totale generato dal circuito in . Nel caso più generale, in cui l'approssimazione di circuito filiforme non viene applicata, si ricorre alla densità  della corrente che attraversa una sezione di conduttore. L'espressione del campo diventa:[13]
dove  è il volume infinitesimo, di lunghezza  e sezione , del conduttore nel punto .
Calcolando la divergenza del campo generato da un circuito si dimostra che essa è sempre nulla:[14]
Questa proprietà costituisce la seconda equazione di Maxwell:
Applicando il teorema del flusso di Gauss, il flusso  di  attraverso qualsiasi superficie chiusa  che contiene al suo interno il circuito è nullo:
dove  è il volume racchiuso dalla frontiera . Questo fatto implica che il campo magnetico è un campo solenoidale. Inoltre, il campo magnetostatico non è conservativo e quindi non è irrotazionale, cioè il suo rotore non è nullo ovunque. Partendo dalla più generale formulazione del campo magnetico, nella quale si sfrutta la densità di corrente, si dimostra che:
dove  indica il vettore densità di corrente. Questa espressione costituisce la quarta equazione di Maxwell nel caso stazionario.[15] Applicando alla precedente espressione il teorema del rotore si ottiene la Legge di Ampère:[16]
ovvero, la circuitazione lungo una linea chiusa del campo magnetostatico è pari alla somma algebrica delle correnti concatenate con essa.
Il potenziale vettore del campo magnetico, indicato solitamente con , è un campo vettoriale tale che  sia uguale al rotore di :[17]
La definizione non è tuttavia univoca, dal momento che  resta invariato se ad  si somma il gradiente di una qualsiasi funzione scalare:
Il potenziale vettore definito in questo modo risulta soddisfare automaticamente le equazioni di Maxwell nel caso statico.
Nel caso elettrodinamico bisogna modificare le definizioni dei potenziali in modo da ottenere che due equazioni di Maxwell risultino immediatamente soddisfatte. Per quanto riguarda , si verifica ancora che è definito in modo che il suo rotore sia , mentre  è definito in modo che:
L'elettrostatica e la magnetostatica rappresentano due casi particolari di una teoria più generale, l'elettrodinamica, dal momento che trattano i casi in cui i campi elettrico e magnetico non variano nel tempo. In condizioni stazionarie i campi possono essere infatti trattati indipendentemente l'uno dall'altro, tuttavia in condizioni non stazionarie appaiono come le manifestazioni di una stessa entità fisica: il campo elettromagnetico.
Più precisamente, le leggi fisiche che correlano i fenomeni elettrici con quelli magnetici sono la legge di Ampere-Maxwell e la sua simmetrica legge di Faraday.
La legge di Faraday afferma che la forza elettromotrice indotta in un circuito chiuso da un campo magnetico è pari all'opposto della variazione del flusso magnetico del campo concatenato con il circuito nell'unità di tempo, ovvero:[2]
Per la definizione di forza elettromotrice si ha, esplicitando la definizione integrale di flusso:[18]
applicando il teorema di Stokes al primo membro:
e per quanto detto si giunge a:
Uguagliando gli integrandi segue la terza equazione di Maxwell:[19]
Si noti che nel caso non stazionario la circuitazione del campo elettrico non è nulla, dal momento che si genera una forza elettromotrice che si oppone alla variazione del flusso del campo magnetico concatenato col circuito.
L'estensione della legge di Ampère al caso non stazionario mostra come un campo elettrico variabile nel tempo sia sorgente di un campo magnetico. Ponendo di essere nel vuoto, la forma locale della legge di Ampère costituisce la quarta equazione di Maxwell nel caso stazionario:
Tale relazione vale solamente nel caso stazionario poiché implica che la divergenza della densità di corrente sia nulla, contraddicendo in questo modo l'equazione di continuità per la corrente elettrica:[20]
Per estendere la legge di Ampère al caso non stazionario è necessario inserire la prima legge di Maxwell nell'equazione di continuità:
Il termine
è detto corrente di spostamento, e deve essere aggiunto alla densità di corrente nel caso non stazionario.[21]
Inserendo la densità di corrente generalizzata così ottenuta nella legge di Ampère:[22][23]
si ottiene la quarta equazione di Maxwell nel vuoto.[24] Tale espressione mostra come la variazione temporale di un campo elettrico sia sorgente di un campo magnetico.
Per descrivere il comportamento del campo magnetico nella materia è sufficiente introdurre nelle equazioni di Maxwell un termine aggiuntivo , che rappresenta la densità di corrente associata alla magnetizzazione del materiale:
Tuttavia, tale termine non è in generale noto: questo ha portato all'introduzione del vettore intensità di magnetizzazione, anche detto vettore di polarizzazione magnetica e indicato con , una grandezza vettoriale macroscopica che descrive il comportamento globale del materiale soggetto alla presenza del campo magnetico. Il vettore rappresenta il momento di dipolo magnetico per unità di volume posseduto dal materiale. Definito come la media del valore medio del momento magnetico proprio  di N particelle contenute in un volume infinitesimo , è espresso dalla relazione:
Nel Sistema internazionale di unità di misura il vettore di polarizzazione magnetica si misura in Ampere su metro (A/m), e nella definizione il limite vale per un volume che contenga un numero significativo di atomi tale da poterne calcolare una proprietà media.
Nel caso in cui la polarizzazione atomica all'interno del materiale sia uniforme, le correnti di magnetizzazione sono descritte dalla corrente di magnetizzazione superficiale , data da:
ovvero la corrente di magnetizzazione è pari al flusso del vettore densità di corrente di magnetizzazione superficiale  attraverso una superficie . Nel caso in cui la polarizzazione atomica all'interno del materiale non sia uniforme, invece, si introduce la corrente di magnetizzazione volumica , data da:
ovvero la corrente di magnetizzazione volumica è pari al flusso del vettore densità di corrente di magnetizzazione volumica  attraverso una superficie . Le relazioni che legano la densità di corrente di magnetizzazione con il vettore di magnetizzazione sono:
dove nella prima equazione  è il versore che identifica la direzione normale alla superficie del materiale.
La presenza di materia costringe a tenere conto delle correnti amperiane nelle equazioni di Maxwell per il campo magnetico:[25]
e porta a definire il vettore campo magnetico  nella materia come:[8]
L'equazione di Maxwell può essere riscritta in modo equivalente:
La densità di corrente  presente nella precedente equazione si riferisce esclusivamente alle correnti elettriche, date dal moto dei soli elettroni liberi, e non alle correnti atomiche di magnetizzazione. Nel caso non stazionario, inoltre, la quarta equazione ha l'espressione:[26]
La permeabilità magnetica è una grandezza fisica che esprime l'attitudine di una sostanza a polarizzarsi in seguito all'applicazione di un campo magnetico e si misura in henry al metro (H/m), equivalente a newton all'ampere quadrato (N/A2). Nel caso in cui il materiale sia omogeneo e isotropo e la sua risposta sia lineare,  i vettori  e  sono paralleli, e questo implica che la relazione tra di essi è di semplice proporzionalità:[27]
dove  è la permeabilità magnetica del materiale considerato.
Dal momento che non tutti i materiali hanno una reazione lineare tra  e , i materiali magnetici si distinguono in tre categorie:
L'energia magnetica è l'energia associata al campo magnetico, e nel caso di materiali in cui la relazione tra  e  sia lineare l'energia magnetica contenuta in un volume  è data da:[28]
dove l'integrando
è la densità di energia magnetica. Per un circuito percorso da corrente la densità di energia magnetica può essere definita a partire dal potenziale vettore  del campo magnetico e il vettore densità di corrente :
Il campo elettromagnetico è dato dalla combinazione del campo elettrico  e del campo magnetico , solitamente descritti con vettori in uno spazio a tre dimensioni. Il campo elettromagnetico interagisce nello spazio con cariche elettriche e può manifestarsi anche in assenza di esse, trattandosi di un'entità fisica che può essere definita indipendentemente dalle sorgenti che l'hanno generata. In assenza di sorgenti il campo elettromagnetico è detto onda elettromagnetica,[29] essendo un fenomeno ondulatorio che non richiede di alcun supporto materiale per diffondersi nello spazio e che nel vuoto viaggia alla velocità della luce. Secondo il modello standard, il quanto della radiazione elettromagnetica è il fotone, mediatore dell'interazione elettromagnetica.
La variazione temporale di uno dei due campi determina il manifestarsi dell'altro: campo elettrico e campo magnetico sono caratterizzati da una stretta connessione, stabilita dalle quattro equazioni di Maxwell. Le equazioni di Maxwell, insieme alla forza di Lorentz, definiscono formalmente il campo elettromagnetico e ne caratterizzano l'interazione con oggetti carichi. Le prime due equazioni di Maxwell sono omogenee e valgono sia nel vuoto sia nei mezzi materiali, e rappresentano in forma differenziale la legge di Faraday e la legge di Gauss per il campo magnetico. Le altre due equazioni descrivono il modo in cui il materiale, nel quale avviene la propagazione, interagisce polarizzandosi con il campo elettrico e magnetico, che nella materia sono denotati con  e . Esse mostrano in forma locale la legge di Gauss elettrica e la legge di Ampère-Maxwell.
Le equazioni di Maxwell sono formulate anche in elettrodinamica quantistica, dove il campo elettromagnetico viene quantizzato. Nell'ambito della meccanica relativistica, i campi sono descritti dalla teoria dell'elettrodinamica classica in forma covariante, cioè invariante sotto trasformazione di Lorentz. Nell'ambito della teoria della relatività il campo elettromagnetico è rappresentato dal tensore elettromagnetico, un tensore a due indici di cui i vettori campo elettrico e magnetico sono particolari componenti.
Al 2022, il più grande campo magnetico costante al mondo è stato generato allo Steady High Magnetic Field Facility (SHMFF) di Hefei, in Cina, ed ha raggiunto un'intensità di 45.22 Tesla.[30]
In fisica la velocità della luce è la velocità di propagazione di un'onda elettromagnetica e di una particella libera senza massa  nel vuoto. Ha un valore di 299792458 m/s[1]. Viene indicata normalmente con la lettera c (dal latino celeritas), scelta fatta per primo da Paul Drude nel 1894[2].
Secondo la relatività ristretta, la velocità della luce nel vuoto, , è una costante fisica universale indipendente dal sistema di riferimento utilizzato e la velocità massima a cui può viaggiare qualsiasi informazione nell'universo, unendo le grandezze fisiche classiche di spazio e tempo nell'unica entità dello spaziotempo e rappresentando la grandezza di conversione nell'equazione di equivalenza massa-energia. Nella relatività generale è la velocità prevista per le onde gravitazionali. 
Dal 21 ottobre 1983 si considera il valore  come esatto, ovvero senza errore, e a partire da esso si definisce la lunghezza del metro nel Sistema Internazionale.
Galileo Galilei fu il primo a sospettare che la luce non si propagasse istantaneamente e a cercare di misurarne la velocità. Egli scrisse del suo tentativo infruttuoso di usare lanterne per mandare dei lampi di luce tra due colline fuori Firenze. Giovanni Alfonso Borelli (1608-1679), seguace di Galilei, fece il tentativo di misurare la velocità della luce sulla distanza Firenze-Pistoia per mezzo di specchi riflettenti.
La prima misura della velocità della luce fu effettuata nel 1676 dal danese Ole Rømer, che utilizzò un'anomalia nella durata delle eclissi dei satelliti medicei (i satelliti di Giove scoperti da Galileo). Egli registrò le eclissi di Io, un satellite di Giove: ogni giorno o due, Io entrava nell'ombra di Giove per poi riemergerne. Rømer poteva vedere Io "spegnersi" e "riaccendersi", se Giove era visibile. L'orbita di Io sembrava essere una specie di distante orologio, ma Rømer scoprì che il suo "ticchettio" era più veloce quando la Terra si avvicinava a Giove e più lento quando se ne allontanava. Rømer misurò le variazioni in rapporto alla distanza tra Terra e Giove e le spiegò stabilendo una velocità finita per la luce. Egli ottenne un valore di circa 210 800 000 m/s, il cui scostamento rispetto al valore accertato in seguito era dovuto essenzialmente alla scarsa precisione con cui aveva misurato il tempo necessario alla luce per percorrere il diametro dell'orbita terrestre. Una targa all'Osservatorio di Parigi, dove l'astronomo danese lavorava, commemora quella che fu, in effetti, la prima misurazione di una quantità universale. Rømer pubblicò i suoi risultati, che contenevano un errore del 10-25%, nel Journal des savants.
Altre misure, via via più precise, furono effettuate da James Bradley, Hippolyte Fizeau e altri, fino a giungere al valore oggi accettato. In particolare Fizeau misurò la velocità della luce tramite un apparecchio consistente in una ruota dentata fatta girare a grande velocità. Sulla ruota venne proiettato un raggio di luce che ne attraversava le fenditure in maniera intermittente, raggiungendo uno specchio posto a grande distanza che rifletteva la luce nuovamente verso la ruota. Il raggio di ritorno, poiché intanto la ruota era girata, passava attraverso la fenditura successiva. Da ciò, nota la distanza che la luce percorreva, e noto l'intervallo di tempo in cui la ruota compiva la rotazione necessaria, Fizeau calcolò la velocità della luce con un piccolo errore.
Quando si rigettò il modello della luce come un flusso di particelle, proposto da Cartesio e sostenuto da Isaac Newton, il modello ondulatorio, suo successore, pose il problema dell'esistenza di un mezzo che sostenesse le oscillazioni. Tale ipotetico mezzo, detto etere, doveva avere caratteristiche molto peculiari: elastico, privo di massa e resistenza al moto dei corpi, doveva peraltro trascinare la luce come una corrente trascina una barca o il vento le onde sonore. Un vento dell'etere doveva trascinare la luce. Per verificare la presenza dell'etere tramite l'effetto di trascinamento, Albert Abraham Michelson e Edward Morley ripeterono più volte un'esperienza con un interferometro.
Se, a causa del vento dell'etere, la velocità di propagazione della luce nei due bracci dell'interferometro fosse stata diversa, i due fasci di luce avrebbero impiegato un tempo diverso per tornare a incontrarsi e quindi le oscillazioni nei due fasci avrebbero presentato una differenza di fase δ, come nelle funzioni sinusoidali:
Ciò provocava la formazione di frange di interferenza al passare entro una fenditura di circa mezzo millimetro fra due cartoncini posti di fronte a una sorgente di luce a poca distanza dall'occhio. Le frange avrebbero dovuto spostarsi al variare dell'orientamento dello strumento rispetto al vento dell'etere.
La differenza attesa nei tempi impiegati dalla luce per percorrere i bracci dell'interferometro parallelo e perpendicolare al vento dell'etere si calcola facilmente.
Nelle numerose esperienze di Michelson, Morley e altri ancora non si osservò mai lo spostamento di tali frange, indipendentemente dal modo in cui veniva orientato l'interferometro e dalla posizione della Terra lungo la sua orbita. La spiegazione di tale risultato secondo Einstein era che non vi è nessun etere e che l'indipendenza della velocità della luce dalla sua direzione di propagazione è un'ovvia conseguenza dell'isotropia dello spazio. L'etere diventò quindi semplicemente non necessario.
Siccome la luce è un'onda elettromagnetica, è possibile ricavarne la velocità nel vuoto utilizzando le equazioni di Maxwell.
Partendo dalla terza equazione di Maxwell e applicando l'operatore rotore, si ottiene:
Vale inoltre l'equazione
Nel vuoto si ha  in quanto non vi sono cariche, e  in quanto non vi sono correnti. Applicando queste condizioni alle due equazioni precedenti e considerando che l'operatore gradiente è effettuato rispetto alle coordinate spaziali si ottiene:
Sostituendovi la quarta equazione di Maxwell, otteniamo infine la prima equazione delle onde elettromagnetiche:
Applicando lo stesso procedimento a partire dalla quarta equazione di Maxwell, si ottiene la seconda equazione delle onde elettromagnetiche:
Le due equazioni delle onde elettromagnetiche sono analoghe all'equazione delle onde di d'Alembert, la cui espressione generale è
dove  è la velocità dell'onda. Per le onde elettromagnetiche
è la velocità  della luce nel vuoto.
La velocità della luce è legata alle proprietà elettromagnetiche del mezzo in cui si propaga:
Quindi
Nel vuoto  e  assumono il valore minimo:
e la velocità della luce nel vuoto vale quindi
dove  è la costante dielettrica del vuoto e  la permeabilità magnetica del vuoto.
Passando attraverso i materiali la luce subisce degli eventi di dispersione ottica e, in moltissimi casi di interesse, si propaga con una velocità inferiore a , di un fattore chiamato indice di rifrazione del materiale. La velocità della luce nell'aria è solo leggermente inferiore a . Materiali più densi, come l'acqua e il vetro rallentano la luce a frazioni pari a 3/4 e 2/3 di . Esistono poi materiali particolari, detti metamateriali, che hanno indice di rifrazione negativo.
La luce sembra rallentare per effetto di urto anelastico: viene assorbita da un atomo del materiale attraversato che si eccita e restituisce la luce in ritardo e in direzione deviata.
Nel 1999, un gruppo di scienziati guidati da Lene Hau fu in grado di rallentare la velocità di un raggio di luce fino a circa 61 km/h. Nel 2001, furono in grado di fermare momentaneamente un raggio. Si veda: condensato di Bose-Einstein per ulteriori informazioni.
Nel gennaio 2003, Mikhail Lukin, assieme a scienziati della Harvard University e dell'Istituto Lebedev di Mosca, riuscirono a fermare completamente la luce dentro un gas di atomi di rubidio a una temperatura di circa 80 °C: gli atomi, per usare le parole di Lukin, "si comportavano come piccoli specchi" (Dumé, 2003), a causa degli schemi di interferenza di due raggi di "controllo". (Dumé, 2003)
Nel luglio del 2003, all'Università di Rochester Matthew Bigelow, Nick Lepeshkin e Robert Boyd hanno sia rallentato che accelerato la luce a temperatura ambiente, in un cristallo di alessandrite, sfruttando i cambiamenti dell'indice di rifrazione a causa dell'interferenza quantistica. Due raggi laser vengono inviati sul cristallo, in determinate condizioni uno dei due subisce un assorbimento ridotto in un certo intervallo di lunghezze d'onda, mentre l'indice di rifrazione aumenta nello stesso intervallo, o "buco spettrale": la velocità di gruppo è dunque molto ridotta. Usando invece lunghezze d'onda differenti, si è riusciti a produrre un "antibuco spettrale", in cui l'assorbimento è maggiore, e dunque alla propagazione superluminale. Si sono osservate velocità di 91 m/s per un laser con una lunghezza d'onda di 488 nanometri, e di -800 m/s [senza fonte] per lunghezze d'onda di 476 nanometri. La velocità negativa indica una propagazione superluminale, perché gli impulsi sembrano uscire dal cristallo prima di esservi entrati.
Nel settembre 2003, Shanhui Fan e Mehmet Fatih Yanik dell'Università di Stanford hanno proposto un metodo per bloccare la luce all'interno di un dispositivo a stato solido, in cui i fotoni rimbalzano tra pilastri di semiconduttori creando una specie di onda stazionaria. I risultati sono stati pubblicati su Physical Review Letters del febbraio 2004.
La formula che descrive lo spazio-tempo nella teoria della relatività ristretta venne utilizzata da Einstein per il calcolo della velocità della luce:
Nella relatività generale, l'espressione dell'elemento  è data dal tensore fondamentale covariante:
Einstein osservò quindi che se si conosce la direzione, cioè sono noti i rapporti , l'equazione del  restituisce le grandezze
e, in conseguenza, la velocità (definita nel senso della geometria euclidea):
L'ultima formula è quella del calcolo del modulo di un vettore, applicata al vettore velocità della luce.
Lo spazio-tempo ha quattro dimensioni, mentre quello euclideo ne ha tre: per utilizzare la geometria euclidea si è operata una restrizione da quattro a tre dimensioni, eliminando quella temporale.
Esprimendo i tre termini spaziali in unità di tempo (si è diviso per ) si ottengono le componenti del vettore velocità.
Il termine  è ricavato per differenza dalla relatività ristretta, noti gli altri tre termini.
L'intervallo spazio-temporale  può essere riscritto come:
in cui è di importanza secondaria il fatto che  rappresenti la velocità della luce, mentre è rilevante che esiste una costante universale, in tutti i sistemi di riferimento, fattore di conversione fra lo spazio e il tempo.
Spazio e tempo non sono la stessa cosa, ma sono indissolubilmente legati in un continuum a quattro dimensioni (l'equazione è polinomiale e quindi è una funzione continua).
Il termine temporale è espresso in unità della luce per essere sommabile alle distanze spaziali: il segno negativo ha il significato fisico che (dato  costante e tendente a zero) dove il tempo si contrae, lo spazio si dilata, e viceversa, dove lo spazio si contrae, il tempo si dilata. 
Il termine  è un invariante alla rotazione, riflessione e traslazione, cambi di coordinate: 
da cui si vede che  è il valore di una grandezza che non può essere superato.
Nell'esperienza diretta siamo abituati alla regola additiva delle velocità: se due automobili si avvicinano una all'altra a 50 km/h, ci si aspetta che ogni auto percepisca l'altra come se si avvicinasse a 100 km/h (ovvero la somma delle rispettive velocità). Dai dati legati fondamentalmente agli esperimenti con gli acceleratori di particelle, diventa evidente che a velocità prossime a quella della luce la regola additiva non è più valida: due astronavi che viaggiassero al 90% della velocità della luce relativamente a un osservatore posto tra di esse non si percepirebbero l'un l'altra come in avvicinamento al 180% della velocità della luce, ma avrebbero una velocità apparente di circa il 99,4475% di c. Questo non deriva da risultati sperimentali poiché la velocità massima mai raggiunta da un oggetto creato dall'uomo è di 265 000 km/h, ovvero 73 611 m/s, quindi molto inferiore.
Si tratta di un risultato teorico dato dalla formula di Einstein per la composizione delle velocità:
dove  e  sono le velocità delle astronavi relativamente all'osservatore e  è la velocità percepita da ciascuna astronave. Indipendentemente dalla velocità a cui un osservatore si muove relativamente a un altro, entrambi misureranno la velocità di un raggio di luce con lo stesso valore costante c. Gli esperimenti ispirati dalla teoria della relatività confermano direttamente e indirettamente che la velocità della luce ha un valore costante, indipendente dal moto dell'osservatore e della sorgente.
Poiché la velocità della luce nel vuoto è costante, è conveniente misurare le distanze in termini di . Come già detto, nel 1983 il metro venne ridefinito in relazione a . In particolare un metro è la 299 792 458ª parte della distanza coperta dalla luce in un secondo. Le distanze negli esperimenti fisici e in astronomia vengono comunemente misurate in secondi luce, minuti luce e anni luce.
, grandezza fissa indipendente dal sistema di riferimento secondo la relatività ristretta, è la velocità massima cui può viaggiare un ente fisico come energia e informazione nello spaziotempo di Minkowski, modellato sulla base del fatto che per ogni evento sia possibile tracciare un cono di luce e suddividere lo spazio in regioni disgiunte: il futuro, il passato e il presente dell'evento. La materia non può raggiungere c a causa del progressivo aumento dell'inerzia fino a valori tendenti all'infinito.
Questo limite allo spazio fisico si appoggia alla struttura causale e  costituisce una costante su cui si appoggia e articola tutta la teoria relativa alla dimensionalità dell'universo fisico osservabile in cui ci muoviamo.  è quindi la velocità massima di tutte le particelle senza massa e dei relativi campi. Anche particelle di tipo immaginario, come i tachioni, pur viaggiando a velocità superiori a quella della luce, non possono essere rallentate a velocità subluminali, ma si possono solo accelerare. Anche in questo caso, allo stato attuale puramente un costrutto teorico,  rimane un muro invalicabile. Esistono tuttavia situazioni, nell'ambito della meccanica quantistica, che implicano effetti istantanei, come l'entanglement quantistico, dove, benché non si trasmetta informazione, si teletrasporta uno stato quantico; questi effetti sono stati osservati sperimentalmente (vedi Esperimento sulla correlazione quantistica di Aspect).
Allo stato attuale della conoscenza teorica  è una barriera invalicabile e non sono sperimentalmente noti oggetti con velocità maggiore della luce (tachioni). 
L'effetto Cherenkov è un effetto superluminale, ma è dovuto a particelle che si trovano a viaggiare al di sotto di c0 ma al di sopra della c del mezzo in cui si muovono, che "frenano" emettendo radiazione.
Il limite imposto dalla relatività ristretta per la velocità quindi non è un limite sulla velocità di propagazione di oggetti e segnali ma è un limite sulla velocità a cui si può propagare l'informazione. Sebbene queste due cose coincidano quasi sempre questa sottile distinzione permette, in alcuni casi particolari, di ottenere effetti cosiddetti superluminali. In questi casi, si possono vedere brevi impulsi di luce che superano degli ostacoli con una velocità apparentemente maggiore di . Eccedere la velocità di gruppo della luce in questo modo è paragonabile a eccedere la velocità del suono sistemando una fila di persone opportunamente distanziate, e facendogli urlare "Sono qui!", una dopo l'altra a brevi intervalli temporizzati da un orologio, in modo che non debbano sentire la voce della persona precedente prima di poter urlare. In questo tipo di fenomeni, tuttavia, la velocità di fase di un pacchetto (più frequenze) è minore di quella della luce.
Secondo le teorie relatività ristretta e generale non è possibile che l'informazione venga trasmessa più velocemente di  in uno spaziotempo uniforme.
L'esistenza di ponti di Einstein-Rosen, cioè fenomeni che permettano il trasferimento di materia o di energia da un punto all'altro dell'universo, non è supportata da prove sperimentali; e anche se esistessero, non si tratterebbe di un effetto superluminare in quanto lo spazio percorso dall'informazione non sarebbe la distanza da noi misurata, ma la distanza abbreviata dalla "scorciatoia".
Oggetti astrofisici (stelle e galassie) apparentemente superluminali vengono comunemente osservati. Per questo tipo di oggetti il trucco risiede nel moto di avvicinamento di questi oggetti in direzione della Terra. La velocità di un oggetto può essere misurata, banalmente, come la distanza tra due punti attraversati dall'oggetto divisa per il tempo necessario per questo tragitto. Per oggetti astrofisici l'informazione spaziale e temporale sui punti di inizio e fine tragitto è trasmessa all'osservatore tramite la luce. Se il punto di fine tragitto è più vicino all'osservatore del punto di inizio, la luce del punto di inizio tragitto risulta ritardata e quella del punto di fine anticipata nel suo arrivo sulla Terra. Il tragitto risulta, così, iniziato dopo e finito prima, cioè minore. Ne può risultare, dunque, anche una velocità apparente maggiore di quella della luce.
Da tempo vengono ipotizzate alcune generalizzazioni della relatività ristretta. Nel 2007 al MINOS in Minnesota, un esperimento sui neutrini inaugurato nel 2005 che lavora con particelle provenienti dal Fermilab, si svolse un'esperienza in cui, studiando l'oscillazione dei neutrini, vennero misurate velocità anomale di tali particelle, ma la maggiore incertezza sulle posizioni esatte di rivelatore ed emissione rese non significativa la possibilità di un superamento di .[3]
Nel settembre 2011 un gruppo di scienziati dei Laboratori Nazionali del Gran Sasso, nell'ambito dell'esperimento OPERA, ha pubblicato i risultati di  alcune osservazioni collaterali di ricerche volte a definire e verificare l'oscillazione dei neutrini. La prima analisi di queste osservazioni ha indicato, anche tenendo conto delle incertezze di misura, che fasci di neutrini muonici, lanciati dal CERN di Ginevra verso il Gran Sasso, viaggiassero a una velocità superiore a quella della luce di una parte su 40 000, con una differenza percentuale calcolata inizialmente a  ; ciò avrebbe suggerito una revisione ed ampliamento della relatività ristretta, probabilmente con il supporto della teoria delle stringhe.[4] Tuttavia dopo pochi mesi, il 22 febbraio 2012, gli stessi ricercatori responsabili del progetto hanno riconosciuto che gli strumenti erano mal calibrati e che la misura dell'anomalia era solo apparente.[5][6]
Si definisce alimento (dal latino alimentum, da alĕre, 'nutrire', 'alimentare') ogni sostanza o miscela di sostanze in qualsiasi stato della materia e struttura non lavorata, parzialmente lavorata o lavorata, destinata a essere ingerita, o di cui si prevede ragionevolmente l'ingestione da parte dell'essere umano. Sono comprese le bevande, le gomme da masticare e qualsiasi sostanza o miscela, compresa l’acqua, intenzionalmente incorporata negli alimenti nel corso della loro filiera produttiva. Non sono compresi mangimi destinati agli animali, gli animali vivi (eccetto quelli destinati al consumo umano), i vegetali prima della raccolta, medicinali, cosmetici, tabacco, stupefacenti, residui e contaminanti.
«[...] Si intende per «alimento» (o «prodotto alimentare», o «derrata alimentare») qualsiasi sostanza o prodotto trasformato, parzialmente trasformato o non trasformato, destinato ad essere ingerito, o di cui si prevede ragionevolmente che possa essere ingerito, da esseri umani.
Sono comprese le bevande, le gomme da masticare e qualsiasi sostanza, compresa l'acqua, intenzionalmente incorporata negli alimenti nel corso della loro produzione, preparazione o trattamento. [...]
Non sono compresi: i mangimi; gli animali vivi, a meno che siano preparati per l'immissione sul mercato ai fini del consumo umano; i vegetali prima della raccolta; i medicinali; i cosmetici; il tabacco e i prodotti del tabacco; le sostanze stupefacenti o psicotrope; residui e contaminanti.»
(Articolo 2 del regolamento (CE) n. 178/2002[2])Gli alimenti vengono variamente prelevati dall'ambiente esterno. A seconda della natura chimica di queste sostanze e dei tipi di organismi viventi considerati, possono essere principalmente suddivisi in due grosse categorie: autotrofi e eterotrofi. L'alimentazione, considerata nel lessico corrente come specifica degli organismi eterotrofi (una pianta non si alimenta, assume nutrienti) consiste nell'assunzione da parte di un organismo delle sostanze indispensabili per il suo metabolismo e le sue funzioni vitali quotidiane. La dieta di un organismo, è ciò che mangia o assume. Negli organismi eterotrofi superiori, fatta salva la disponibilità degli alimenti, la dieta viene in gran parte determinata dalla percezione dell'appetibilità dei cibi.
Per sostenere il metabolismo, gli alimenti svolgono una funzione:
Le molecole di cui sono composti gli alimenti sono trasformate in energia, tramite la mediazione dell'ATP, di fungere da materiale per la formazione dei tessuti biologici e di catalizzare le reazioni chimiche all'interno dell'organismo, nonché di essere accumulate e/o convertite come riserva in altre sostanze.
Dagli alimenti l'organismo estrae le sostanze utili al suo metabolismo. Sono i principi nutritivi, tutti o in parte, a seconda dell'organismo considerato, indispensabili alla vita:
Per gli esseri umani gli alimenti sono molteplici, selezionati nel corso dei millenni in funzione della loro reperibilità e della loro possibilità di fornire sostentamento biologico. Ogni popolazione attribuisce agli alimenti e al loro consumo anche significati e valori simbolici e culturali.
Per esempio, è provato che una dieta povera possa avere un impatto dannoso sulla salute umana e animale, causando nell'uomo malattie da carenza, come scorbuto, Beri-beri, rachitismo, mentre una dieta eccessiva può creare condizioni sanitarie a rischio come l'obesità e comuni malattie croniche sistemiche come le malattie cardiovascolari, il diabete e l'osteoporosi. La povertà della dieta viene ovviamente collegata alle esigenze alimentari specifiche dell'organismo considerato, che possono variare considerevolmente anche tra specie affini, dove possono essere differenti gli amminoacidi essenziali o le stesse vitamine. Il ratto, ad esempio, è in grado di sintetizzare autonomamente la vitamina C necessaria al proprio organismo, la cavia no[3].
L'esistenza di un legame tra ciò di cui ci si alimenta, lo stato di salute e lo svilupparsi di alcune malattie, è riconosciuta fin dall'antichità. Nel 475 a.C. Anassagora sosteneva che nel cibo esistono dei principi che vengono assorbiti dal corpo umano e usati come componenti "generativi" (una prima intuizione dell'esistenza dei principi nutritivi). Nel 400 a.C. Ippocrate diceva "Lascia che il cibo sia la tua medicina, e la medicina sia il tuo cibo". Nel 1747 il medico inglese James Lind condusse il primo esperimento di nutrizione, scoprendo che il succo di limone era in grado di far guarire dallo scorbuto. Solo negli anni 1930 si scoprì che questa proprietà era dovuta alla vitamina C contenuta nei limoni.
Alcune semplici molecole come il glucosio sono assimilate dalle alte vie digerenti per assorbimento dalle mucose. Grazie al processo digestivo, le molecole più complesse vengono suddivise affinché i loro costituenti semplici possano attraversare la parete intestinale, entrare nel flusso sanguigno, e quindi, raggiungere le singole cellule. Qui saranno utilizzate nei diversi processi metabolici: produzione di energia, costruzione e riparazione dei tessuti, regolazione delle attività cellulari, produzione di ormoni, anticorpi, enzimi e tutto ciò che concorre all'incessante lavoro biochimico necessario al mantenimento della vita.
Variare il cibo è la prima regola per alimentarsi correttamente, garantire il completo apporto degli elementi necessari alla nutrizione e, nello stesso tempo, soddisfare la ricerca del gusto e del piacere.
La sicurezza e la salute alimentare sono monitorate dalle agenzie internazionali, come l'International Association for Food Protection, World Resources Institute, Programma alimentare mondiale, Organizzazione delle Nazioni Unite per l'alimentazione e l'agricoltura, e l'International Food Information Council. Essi affrontano questioni come la sostenibilità, la diversità biologica, i cambiamenti climatici, l'economia alimentare, la crescita della popolazione, l'approvvigionamento idrico e l'accesso al cibo.
il cibo è un diritto umano derivato dal Convenzione internazionale sui diritti economici, sociali e culturali (CIDESC), riconoscendo il "diritto ad un adeguato standard di vita, incluso cibo adeguato", così come il "diritto fondamentale di essere libero dalla fame".
Gli alimenti hanno origine da tutto il mondo naturale e non: animali, piante, funghi, batteri, composti inorganici, alimenti di sintesi.
Alcuni tipi di funghi commestibili e batteri sono utilizzati sia come alimenti veri e propri, che nella preparazione di alimenti fermentati e marinati come pane, vino, birra, formaggio, i sottaceti e lo yogurt. Le alghe in molte culture, soprattutto orientali, rappresentano un cibo importante.[4] Inoltre, il sale è consumato spesso come condimento, il bicarbonato di sodio e qualche altro sale inorganico viene usato nella preparazione. Queste sono sostanze inorganiche, che insieme all'acqua, costituiscono una parte importante della dieta umana. La sintesi di prodotti alimentari è una nuova frontiera, e costituisce un'ulteriore diversificazione dell'origine degli alimenti. Vitamine, supplementi, additivi sono tutt'oggi spesso di origine sintetica.
Vi sono circa 2.000 specie di piante che si coltivano per l'alimentazione.[5] La maggior parte di tutti gli alimenti vegetali consumati dagli esseri umani, per il fatto di servire da riserva per lo sviluppo del vegetale stesso sono semi. Questi includono i cereali (quali mais, frumento e riso) e i legumi (quali i fagioli, i piselli e le lenticchie). Alcuni semi vengono spesso utilizzati, spremendoli, per produrre gli oli, compreso il girasole, la colza ed il sesamo.[6]
I frutti sono un prodotto giunto a maturazione fornito da alcune piante. I frutti attraggono gli animali e compongono una parte significativa delle diete della maggior parte delle culture. Possono contribuire a fornire notevole apporto energetico per la ricchezza di carboidrati (banane, platano). Determinati frutti, quali la zucca e la melanzana, sono utilizzate e mangiate come verdure.[7]
Tra gli alimenti vi sono le verdure: verdure di radice (quali le carote) e i tuberi (patate, manioca), gli ortaggi freschi (quali spinaci e lattuga), le verdure con il gambo (quali i germogli e l'asparago, le verdure dell'inflorescenza (quali i carciofi ed il broccolo), le alghe.[8]
I fiori commestibili per esempio sono la viola del pensiero, calendula, nasturzio, girasole, ecc.
Anche gli animali, dai cnidari come le meduse, ai mammiferi, passando per gli insetti, dai molluschi e crostacei, ai vertebrati, tutti sono usati come alimento umano. La carne è un esempio di un prodotto costituito dai tessuti muscolari o da organi. Il latte, il formaggio, il burro, costituiscono invece un esempio di prodotti animali derivati: uccelli, pesci, e moltissimi altri animali producono le uova, spesso commestibili, mentre le api producono il miele, un dolcificante, popolare in molte culture.[9]
La carne si produce per successive fasi: dai luoghi di allevamento al mattatoio per la macellazione, dove si esegue lo sventramento, l'appenditura, la spartizione e la rappresentazione. Questa preparazione viene eseguita solitamente nei mattatoi. Molti paesi regolano i mattatoi secondo una specifica legge umanitaria. Per esempio gli Stati Uniti hanno stabilito la Legge umanitaria di macello del 1958, che obbliga lo stordimento dell'animale prima della sua uccisione.[10]
Gli alimenti sono ottenuti tradizionalmente attraverso l'agricoltura, l'allevamento la pesca, la caccia, ed altri metodi in funzione dal luogo di origine. Nel corso del tempo vi è stata, attraverso una lenta presa di consapevolezza, di una tendenza crescente verso pratiche agricole più sostenibili.[11]
Alcuni alimenti possono essere utilizzati direttamente, molti altri subiscono specifiche preparazioni, per ottenerne una maggiore digeribilità, per motivi di sicurezza sanitaria, per rendere il loro sapore più gradevole. Per esempio: lavare, tagliare, assettare o aggiungere altri alimenti o ingredienti, quali le spezie, mescolare, riscaldare o raffreddare, sottoporre a fermentazione, o combinare con un altro alimento. Una preparazione può contribuire ad aumentare il gusto o l'estetica, un'altra può contribuire a conservare più a lungo l'alimento.
Con il termine "cucinare" si intende una vasta gamma di metodologie, di attrezzi e di combinazioni degli ingredienti per migliorare il sapore o la digeribilità dell'alimento. Cucinare il cibo, conosciuto come arte culinaria, richiede generalmente la selezione, la misura e la combinazione degli ingredienti rispettando una specifica procedura, necessaria per raggiungere un buon risultato. Per il successo sono necessari: variabilità degli ingredienti, adeguate condizioni ambientali, attrezzi e abilità nella cottura, e una passione per la cucina.[12] Le diversità tra le cotture dipendono da fattori nutrizionali, estetici, agricoli, economici, culturali e religiosi.[13]
La cottura richiede il riscaldamento degli alimenti, i quali subiscono, sia trasformazioni meccaniche che chimiche, così da cambiarne il sapore, la struttura, l'apparenza e le proprietà nutrizionali. La cottura propriamente detta, richiede che l'acqua sia portata al punto di ebollizione attraverso l'uso di un contenitore, metodo usato fin dall'antichità.[14] Ci sono prove archeologiche di alimenti arrostiti 420 000 anni fa.[15]
Per cucinare gli alimenti vi sono molti strumenti. I forni sono fondamentali per la cottura. Offrono un metodo che secca gli alimenti. Esistono diverse tipologie di forni. Gli indiani usano il Tandoor, un forno cilindrico in argilla che funziona a una temperatura elevata, che può raggiungere i 450 °C.[16] mentre le cucine occidentali usano generalmente forni a temperatura variabile, come i forni convenzionali, dal tostapane a forni non radianti calore, come il forno a microonde. I forni per funzionare possono utilizzare legna, carbone, gas, elettrico, o petrolio.[17]
Per cucinare molte culture usano le griglie. Una griglia funziona grazie ad una fonte di calore posizionata sotto di essa, solitamente dotata di copertura. Il barbecue americano ne è un esempio: può usare come fonte di calore, legno, carbone o trucioli.[18] Lo stile messicano del barbecue è denominato barbacoa, solitamente usato per cuocere carne di pecora. In Argentina, si usa una griglia a cielo aperto, o un fuoco in terra, su cui solitamente viene cotto un animale intero.
Determinate culture si cibano di animali o verdure non cucinate. Il sushi nel Giappone è un tipico esempio di pietanza che si compone anche di pesce crudo finemente affettato mediante affilatissimi coltelli, in sashimi, in nigiri, o negli stili del maki.[19]. In Italia, il carpaccio è un piatto crudo fatto di carne affettata in modo molto sottile, solitamente lasciato marinare con un aceto o limone, e con l'olio di oliva.[20]
Il crudismo è un movimento salutista che promuove una dieta principalmente vegetariana basata su frutta e cereali in grani.[21]
Molte culture preparano alimenti all'interno di taverne e ristoranti per poi rivenderli ai clienti per un immediato consumo. Il concetto della preparazione dell'alimento a scopo commerciale nel mondo occidentale, ha probabilmente origine durante l'impero romano nella città di Pompei. In Cina, durante la "Dinastia Song" si ha notizia di vendite urbane di alimenti preparati. È probabile che i primi ristoranti della storia in Europa siano stati i negozi di caffè risalenti al XVII secolo.[22] Nel 2005 negli Stati Uniti si sono spesi in un anno 496 miliardi di dollari per i pranzi fuori sede, che avvengono per il 40% in ristoranti veri e propri, per il 37,2% nei ristoranti a servizio limitato (alimenti a preparazione rapida), per il 4,7% in hotel ed in motel, per il 6,6% in scuole o in università, per il 5,4% in distributori automatici, per il 4,0% nei posti di ricreazione e per il 2,2% in altri luoghi.
Gli alimenti confezionati sono preparati al di fuori delle mura domestiche e destinati all'acquisto. Si va dal caso più semplice del macellaio che prepara la carne, al più complesso, prodotto dalla moderna industria alimentare internazionale. Le prime tecniche erano limitate a conservare, confezionare e trasportare gli alimenti disponibili e riguardavano principalmente al suo trattamento con il sale, con lo zucchero, con l'aceto, con il fumo, fino alla fermentazione e alla caseificazione.[23] L'era moderna vide la nascita dell'industria alimentare.[24] Questo sviluppo crebbe smisuratamente grazie ai nuovi consumi di massa e le emergenti nuova tecnologia, come la molatura, la conservazione, il confezionamento l'etichettatura, e il trasporto. Questo portò al vantaggio di disporre di alimenti già preparati, ma a scapito della loro qualità.[25]
All'inizio del XXI secolo si venne a formare una struttura a due livelli: alcune multinazionali internazionali che controllano una vasta gamma di marche alimentari molto conosciute, e una moltitudine di piccole aziende alimentari locali o nazionali. Avanzate tecnologie sono inoltre intervenute a modificare l'industria alimentare: sistemi di controllo computerizzati, metodi sofisticati di lavorazione ed imballaggio, progressi nella logistica e nella distribuzione, possono ulteriormente aumentare la qualità dei prodotti, migliorare la sicurezza degli alimenti, e ridurre i costi.[25]
La banca mondiale ha segnalato che nel 2005 l'Unione europea era il maggiore importatore di alimenti, seguita dagli U.S.A. e dal Giappone. Gli alimenti sono commercializzati a livello globale. La loro varietà e la loro disponibilità non è più limitata dalla loro diversità o coltivati localmente o dalle limitazioni di crescita locale in un periodo dell'anno particolare. Fra il 1961 e il 1999 vi è stato un aumento del 400% nelle esportazioni in tutto il mondo. Alcuni paesi ora dipendono economicamente dalle loro esportazioni: in alcuni casi ne rappresentano più dell'80%.
Nel 1994 oltre 100 paesi firmarono in Uruguay un accordo generale sulle tariffe e sul commercio per regolare il drammatico aumento della liberalizzazione commerciale. Ciò ha incluso un accordo per ridurre le sovvenzioni pagate ai coltivatori.
La vendita dell'alimento unisce il produttore al consumatore. È una catena di attività che porta l'alimento ... dal cancello dell'azienda agricola alla mensola del supermercato ....[26] Persino la vendita di un singolo prodotto alimentare può essere un processo complicato che coinvolge molti produttori ed aziende. Questi catena di attività include sia le aziende trasportatrici degli ingredienti che le aziende che stampano le etichette.[27] Il sistema di commercializzazione dell'alimento è il più grande datore di lavoro non governativo diretto ed indiretto negli Stati Uniti.
Nel XX secolo i supermercati hanno sviluppato il metodo del self-service e della spesa per mezzo dei carrelli: questo ha potuto offrire un alimento di qualità ad un costo più contenuto, grazie alle economie di massa e ai ridotti costi del personale. Con il passare degli anni i supermercati sono stati ulteriormente rivoluzionati tramite lo sviluppo degli ipermercati: ampi supermercati di solito situati fuori città, con disponibilità di una vasta gamma di alimenti provenienti da tutto il mondo.
La vendita al dettaglio degli alimenti, invece, è un mercato a due stadi, in cui un piccolo numero di aziende molto grandi, generalmente multinazionali, controllano moltissimi supermercati. In questo modo sono in grado di controllare il potere di acquisto dei consumatori, influenzando profondamente i coltivatori e i loro processi di produzione. Solo il dieci per cento della spesa del consumatore va ai coltivatori, mentre percentuali maggiori vanno alla pubblicità, al trasporto ed all'intermediazione.[28]
La malnutrizione è una conseguenza della privazione di alimenti, ed è collegata spesso alla carestia. Questa può avere un effetto devastante e diffuso sulla salute umana e sulla mortalità. Durante periodi di scarsità alimentare vengono utilizzate diverse forme di razionamento. Nel mondo, circa 815 milioni di persone sono sottonutrite, mentre più di 16 000 bambini muoiono ogni giorno per cause relative alla fame.[29]
L'aiuto alimentare può aiutare le comunità che soffrono a causa della loro scarsità. Può essere gestito per migliorare le vite delle persone a breve termine, per consentire un successivo recupero e per riavviare l'autoproduzione locale. Per contro, l'aiuto alimentare mal gestito può generare diversi problemi: interrompe i mercati locali e scoraggia le produzioni alimentari. A volte può svilupparsi un ciclo di dipendenza. La relativa misura, o il minacciato ritiro, a volte è usato come uno strumento politico per influenzare una nazione. Gli sforzi internazionali di distribuire aiuti alimentari ai paesi più bisognosi sono coordinati spesso da un programma mondiale di alimentazione.
I più frequenti problemi causati alla salute dal consumo alimentare sono di origine microbiologica. I batteri della salmonella, per esempio, sono una delle cause più diffuse di malattie, specialmente a causa della scarsa cottura del pollo e delle uova. La cosiddetta "intossicazione alimentare", è generalmente causata da batteri, da tossine, da virus, e da parassiti. Ogni anno, circa 7 milioni di persone soffrono di intossicazione alimentare[senza fonte]. I due fattori più comuni che conducono alla malattia alimentare batterica sono la contaminazione trasversale di alimenti pronti, ed il controllo improprio della temperatura degli alimenti crudi.
Più raramente, può anche accadere che l'alimento sia contaminato chimicamente: per esempio da scorretto immagazzinaggio, o dall'uso di saponi e di disinfettanti non appropriati. L'alimento può anche essere alterato da una vasta gamma di corpi estranei provenienti dalla fabbricazione, a seguito cottura, dall'imballaggio, dalla distribuzione o dalla vendita. Questi corpi estranei possono includere parassiti, capelli, estremità di sigaretta, trucioli e tutti gli altri agenti inquinanti. In ogni caso tutti gli alimenti vanno incontro a una progressiva ed inevitabile trasformazione dal punto di vista chimico, microbiologico, fisico, organolettico e strutturale nel tempo, in accordo alla Prima Legge di Parisi della Degradazione Alimentare.
L'intossicazione alimentare è stata riconosciuta come malattia dell'uomo fin da Ippocrate.[30] L'alimento contaminato o alterato posto in vendita, era un fatto comunemente accettato, fino a quando venne introdotta l'igiene e la refrigerazione. La scoperta delle tecniche per la sterilizzazione batterica usando il calore ed altri studi microbiologici, (Louis Pasteur), hanno contribuito ad ottenere la moderna qualità moderna, oggi presente nelle nazioni sviluppate. Ciò è stato ulteriormente sostenuto tramite il lavoro di Justus von Liebig, che ha contribuito allo sviluppo di tecniche per l'immagazzinaggio dell'alimento e di metodi moderni di conservazione. Durante gli anni più recenti, una miglior comprensione delle malattie causate dagli alimenti ha condotto allo sviluppo sistematico di moderne metodologie quali l'analisi dei rischi e i punti di controllo critici (HACCP), in grado di ridurre il pericolo contaminazioni.
Alcuni individui hanno una particolare sensibilità o allergie ad alimenti innocui per la maggior parte delle persone. Ciò accade quando il sistema immunitario della persona confonde, per esempio, una proteina dell'alimento con un agente estraneo e nocivo, per cui lo attacca. Circa il 2% degli adulti e l'8% dei bambini sono portatori di allergie a qualche alimento. La quantità della sostanza dell'alimento richiesta per provocare una reazione in un individuo varia particolarmente da individuo a individuo, e può essere abbastanza irrisoria. In alcuni casi, le tracce di alimento presente nell'aria, percepite attraverso l'odore, possono provocare reazioni mortali in individui estremamente sensibili. Le allergie alimentari producono frequentemente sintomi quali diarrea, le eruzioni cutanee, il rigonfiamento, il vomito ed il rigurgito. I disturbi digestivi si sviluppano solitamente in mezz'ora dall'ingestione.
Raramente, le allergie da alimento possono condurre ad un'emergenza medica, quali shock anafilattico, ipotensione e perdita di coscienza. Il trattamento iniziale solitamente prevede la somministrazione in emergenza di adrenalina.
Le abitudini dietetiche svolgono un ruolo significativo nella salute e nella mortalità di tutti gli esseri umani. La scarsa assunzione delle vitamine e dei minerali può causare malattie che possono avere effetti gravi sulla salute. Per esempio, il 30% della popolazione mondiale ha problemi di sviluppo, o è a rischio per lo sviluppo, a causa di mancanza dello iodio.[31] Si stima che almeno 3 milioni di bambini siano ciechi a causa della mancanza della vitamina A.[32] I livelli di calcio, vitamina D fosforo nell'organismo sono soggetti ad una regolazione reciproca: il consumo di entrambi può condizionarne l'assorbimento. Il kwashiorkor è una sindrome, più frequente nell'infanzia, causata da carenza di proteine nella dieta.[33]
Molte culture hanno differenziato i loro alimenti per modalità di preparazione, cottura e metodi di produzione. Anche se gli esseri umani sono onnivori, le culture delle varie popolazioni nel mondo hanno privilegiato il consumo di alcuni alimenti e definito altri come tabù. Le scelte dietetiche possono così anche rappresentare le culture e svolgere un ruolo nella religione. Per esempio, soltanto gli alimenti "casher" sono consentiti dall'Ebraismo e soltanto alimenti di "ḥalāl/haram" dall'Islam, nella dieta dei credenti.
I fattori che condizionano le scelte alimentari sono dunque relativi a contesti socio-economici, famigliari, affettivi, religiosi, di salute.
Alcuni esempi
I vegetariani scelgono di rinunciare all'alimento proveniente dalle fonti animali o varianti di essi. Altri scelgono una dieta più sana, priva di grassi animali o di zucchero raffinato, aumentando il consumo di fibra e di antiossidanti dietetici.[34] L'obesità, un problema serio nel mondo occidentale, conduce con maggiori probabilità di contrarre malattie di cuore, il diabete e altre malattie.[35] Più recentemente, le abitudini dietetiche sono state influenzate dalle preoccupazioni che numerose persone hanno circa gli effetti possibili sulla salute o sull'ambiente degli alimenti geneticamente modificati.[36] Ulteriori preoccupazioni causate dall'agricoltura industriale, riguardano la protezione degli animali, la salute umana e l'ambiente. Queste preoccupazioni stanno avendo un effetto sulle abitudini dietetiche umane contemporanee. Ciò ha condotto all'emersione della preferenza per l'alimento organico e locale.
Secondo lo studioso Andrea Braggio[37] la commercializzazione avrebbe trasformato l'uomo in un numero, un indefinito dato statistico, una pedina sulla scacchiera delle forze di mercato e dei profitti aziendali. La commercializzazione dei concetti, dei valori, dei modi di guardare il mondo avrebbe permeato tutti gli aspetti della vita. L'economia commerciale e la necessità dei profitti sarebbero diventati la norma in politica, nella salute, nell'istruzione e nei trasporti.
A suo giudizio, l'uomo vede e valuta ora il mondo attraverso il prisma difettoso dei mercati e in ciò risiederebbe il suo sprofondamento nell'infelicità, nel credere per esempio che la gioia passi attraverso il possesso di oggetti o che tutto abbia un prezzo. Incapace di emergere pienamente, il grande potenziale di ogni uomo sarebbe bloccato dall'attuale sistema economico e dai suoi valori di riferimento. La vita delle persone sarebbe sotto il dominio delle logiche di un mercato che però non avrebbe alcun riguardo né dell'uomo né dell'ambiente in cui l'uomo vive.
Questo avrebbe agevolato una sorta di processo di smarrimento, in cui le persone avrebbero presto ignorato le altre dimensioni dell'essere umano: la spiritualità, la socialità, l'affettività, la gratuità. Tutti questi fattori insieme troverebbero piena espressione e verrebbero riassunti nel principio etico della condivisione, che può esplicarsi sia come accesso comune a un patrimonio di nozioni e conoscenze, com'è per esempio nel web, sia come equa distribuzione di beni materiali come il cibo. La condivisione non è dunque considerata come un vago ideale, ma come un principio guida per la condotta, capace di promuovere e favorire in modo concreto le giuste relazioni fra gli uomini basate sulla cooperazione e sulla condivisione delle risorse mondiali. 
La mancanza della condivisione può generare un senso di insoddisfazione e di vuoto a cui si tenta di reagire attraverso i consumi. 
La filosofia della condivisione ritiene però che un numero sempre maggiore di individui in tutto il mondo si starebbe accorgendo  che il benessere si raggiunge solo in parte con la disponibilità di beni e molto di più organizzando il tempo in modo da lasciare più spazio alle relazioni familiari e sociali. Emerge l'idea di poter vivere una vita più appagante dove per esempio il gusto della bella opera prevali sull'efficienza produttivistica in una società dove sia affermato il primo fondamentale diritto da tutelare: il diritto al cibo.
I filosofi della condivisione ritengono che sia necessario un sistema alimentare sano per affrontare le sfide urgenti del nostro tempo. I costi crescenti dell'energia e del cibo, un clima che cambia, minori riserve di acqua, una popolazione in crescita e il paradosso della fame e dell'obesità diffuse impongono un approccio radicalmente diverso al cibo e all'agricoltura.
Il sistema alimentare deve essere riorganizzato sulla base della salute: per le comunità, per le persone, per gli animali e per il mondo naturale. La qualità del cibo, e non soltanto la sua quantità, dovrebbe orientare l'agricoltura. Il modo in cui l'uomo produce, distribuisce e prepara il cibo deve onorare le diverse culture, fornendo non solo un sostentamento ma anche giustizia, bellezza e piacere.[38]
I filosofi della condivisione ritengono che i governi abbiano il dovere di proteggere la popolazione dalla malnutrizione, dal cibo malsicuro e dallo sfruttamento e di difendere dal degrado la terra e l'acqua da cui l'uomo dipende.[39] Individui, produttori e organizzazioni hanno il dovere di creare sistemi regionali in grado di rispettare e onorare i lavoratori della terra senza i quali nessuno sopravviverebbe.[40]
Il regime controllato delle multinazionali, che domina i sistemi alimentari del pianeta, è distruttivo dal punto di vista ambientale, volatile dal punto di vista finanziario, e ingiusto dal punto di vista sociale.[41]
Per risolvere la crisi alimentare occorre trasformare il sistema alimentare è dunque vista favorevolmente la richiesta di un cambiamento di paradigma locale e globale in direzione di una sovranità alimentare. Essa consiste nel diritto delle persone ad avere cibo sano e culturalmente appropriato prodotto con metodi ecologicamente sani e sostenibili e il loro diritto di delineare i propri sistemi alimentari e agricoli.[42]
La produzione e il consumo del cibo si basano in misura fondamentale su considerazioni locali. Una risposta all'odierna crisi alimentare e a quelle future è possibile soltanto con un cambiamento di paradigma in direzione di una sovranità alimentare generale. Piccoli agricoltori, pastori, pescatori, popolazioni indigene e altri hanno delineato un sistema alimentare fondato sul diritto umano ad avere cibo adeguato e su politiche di produzione alimentare che aumentano la democrazia in sistemi alimentari localizzati e garantiscono la massimizzazione dell'uso sostenibile delle risorse naturali.[43] La sovranità alimentare tiene in considerazione tutti i problemi ricorrenti individuati dalla World Food Conference del 1974. Mette al centro il cibo per le persone; valorizza i fornitori di cibo; localizza i sistemi alimentari; garantisce il controllo della comunità e collettivo sulla terra, l'acqua e la diversità genetica; onora e accresce il sapere e le capacità locali; lavora con la natura. La sovranità alimentare è in netto contrasto con le attuali politiche neoliberiste sul commercio e gli aiuti che pretendono di affrontare la questione della sicurezza alimentare del mondo. Queste politiche escludono alcuni attori; sono indifferenti a coloro che producono il cibo.
Secondo i filosofi della condivisione, i governi e le istituzioni internazionali devono rispettare e adottare la sovranità alimentare. Essi ritengono inoltre che il diritto al cibo prevalga sugli accordi commerciali e altre politiche internazionali. Nell'attuale emergenza alimentare i negoziati commerciali relativi al cibo e all'agricoltura devono cessare e deve iniziare il lavoro per un nuovo dialogo sul commercio sotto gli auspici dell'ONU. Le politiche di aggiustamento strutturale imposte dalla Banca mondiale e dal Fmi, l'accordo sull'agricoltura della Wto e il paradigma del libero mercato hanno minato le economie locali e nazionali, eroso l'ambiente e danneggiato i sistemi alimentari locali provocando l'odierna crisi alimentare.
I filosofi della condivisione approvano in pieno i dodici princìpi della dichiarazione per un cibo e un'agricoltura sani che devono orientare la politica alimentare e agricola per fare sì che contribuisca alla salute e alla ricchezza delle nazioni e del mondo. Una politica alimentare e agricola sana: costituisce il fondamento di società sicure e prospere, comunità sane e persone sane; dà a tutti accesso a cibi acquistabili e nutrienti; impedisce lo sfruttamento degli agricoltori, dei lavoratori e delle risorse naturali, il predominio dei genomi e dei mercati e il trattamento crudele degli animali da parte di qualunque nazione, società o individuo; accresce la dignità, la sicurezza e la qualità della vita di tutti coloro che lavorano per nutrire gli altri; impegna risorse per insegnare ai bambini le tecniche e le conoscenze essenziali per la produzione, la preparazione, la nutrizione e il piacere del cibo; protegge le risorse finite dei suoli produttivi, l'acqua dolce e la diversità biologica; cerca di eliminare i combustibili fossili da ogni anello della catena alimentare e di sostituirli con risorse ed energie rinnovabili; prende spunto da una base biologica anziché industriale; alimenta la diversità in tutte le sue forme: diversità delle specie domestiche e selvatiche, diversità dei cibi, dei sapori e delle tradizioni, diversità della proprietà; richiede un dibattito nazionale sulle tecnologie impiegate nella produzione e permette alle regioni di adottare proprie linee guida in questo campo; impone la trasparenza affinché i cittadini sappiano com'è prodotto il cibo che mangiano, da dove viene e che cosa contiene; promuove strutture economiche e sostiene programmi per agevolare lo sviluppo di reti regionali di fattorie e il cibo giusto e sostenibile.[44]
La dichiarazione universale dei diritti dell'uomo del 1948, la Convenzione internazionale sui diritti economici, sociali e culturali (International Covenant on Economic Social and Cultural Rights, Icescr) e la Convenzione sui diritti dell'infanzia, tra gli altri, propugnano il diritto al cibo. Esso è stato definito legalmente dal Committee for Economic, Social and Cultural Rights degli Stati Uniti (1999) come «il diritto di ogni uomo, donna e bambino soli e in comunione con altri di avere sempre accesso materiale ed economico a cibo sufficiente o ai mezzi per procacciarselo in modo conforme alla dignità umana». Secondo i filosofi della condivisione, poiché la grande maggioranza di coloro che soffrono la fame nel mondo sono piccoli contadini o lavoratori senza terra, il diritto al cibo deve essere inteso come diritto a nutrire sé e la propria famiglia. L'Icescr sottolinea tre responsabilità specifiche dello Stato: rispettare, tutelare e tradurre in pratica il diritto al cibo. Le prime due implicano che i governi devono fare sì che né lo Stato né gli individui facciano alcunché che privi le persone dei mezzi per nutrirsi. Le responsabilità di rispettare e tutelare sono fondamentali per il concetto di diritto legale al cibo, che spesso è interpretato falsamente come il diritto di ricevere cibo o aiuti alimentari.[45] L'obbligo di tradurre in pratica il diritto al cibo significa che i governi devono facilitare l'accesso al cibo e alle risorse per produrre cibo, e quando l'accesso non è possibile con i propri mezzi i governi hanno la responsabilità di fornirlo direttamente.[46]
La geometria (dal latino: geometrĭa e questo dal greco antico: γεωμετρία, composto dal prefisso geo che rimanda alla parola γή = "terra" e μετρία, metria = "misura", tradotto quindi letteralmente come misurazione della terra) è quella parte della scienza matematica che si occupa delle forme nel piano e nello spazio e delle loro mutue relazioni.
La nascita della geometria si fa risalire all'epoca degli antichi Egizi. Erodoto racconta che, a causa dei fenomeni di erosione e di deposito dovuti alle piene del Nilo, l'estensione delle proprietà terriere egiziane variavano ogni anno e dovevano quindi essere ricalcolate a fini fiscali. Nacque così il bisogno di inventare tecniche di misura della terra (geometria, nel significato originario del termine).
Lo sviluppo della geometria pratica è molto antico, per le numerose applicazioni che consente e per le quali è stata sviluppata, e in epoche remote fu a volte riservata a una categoria di sapienti con attribuzioni sacerdotali. Presso l'Antica Grecia, soprattutto per via dell'influenza del filosofo ateniese Platone e, ancor prima di lui, di Anassimandro di Mileto[senza fonte], si diffuse massicciamente l'uso della riga e del compasso (sebbene pare che questi strumenti fossero già stati inventati altrove) e, soprattutto, nacque l'idea nuova di usare tecniche dimostrative. La geometria greca servì da base per lo sviluppo della geografia, dell'astronomia, dell'ottica, della meccanica e di altre scienze, nonché di varie tecniche, come quelle per la navigazione. 
Nella civiltà greca, oltre alla geometria euclidea che si studia ancora a scuola, e alla teoria delle coniche, nacquero anche la geometria sferica e la trigonometria (piana e sferica).
La geometria coincide fino all'inizio del XIX secolo con la geometria euclidea. Questa definisce come concetti primitivi il punto, la retta e il piano, e assume la veridicità di alcuni assiomi, gli assiomi di Euclide. Da questi assiomi vengono quindi dedotti dei teoremi anche complessi, come il teorema di Pitagora ed i teoremi della geometria proiettiva.
La scelta dei concetti primitivi e degli assiomi è motivata dal desiderio di rappresentare la realtà, e in particolare gli oggetti nello spazio tridimensionale in cui viviamo. Concetti primitivi come la retta ed il piano vengono descritti informalmente come "fili e fogli di carta senza spessore", e d'altro canto molti oggetti della vita reale vengono idealizzati tramite enti geometrici come il triangolo o la piramide. In questo modo, i teoremi forniscono fin dall'antichità degli strumenti utili per le discipline che riguardano lo spazio in cui viviamo: meccanica, architettura, geografia, navigazione, astronomia.
La geometria piana si occupa delle figure geometriche nel piano. A partire dal concetto primitivo di retta, vengono costruiti i segmenti, e quindi i poligoni come il triangolo, il quadrato, il pentagono, l'esagono, ecc.
Le quantità numeriche importanti nella geometria piana sono la lunghezza, l'angolo e l'area. Ogni segmento ha una lunghezza, e due segmenti che si incontrano in un estremo formano un angolo. Ogni poligono ha un'area. Molti teoremi della geometria piana mettono in relazione le lunghezze, angoli e aree presenti in alcune figure geometriche. Ad esempio, la somma degli angoli interni di un triangolo risulta essere un angolo piatto, e l'area di un rettangolo si esprime come prodotto delle lunghezze dei segmenti di base e altezza. La trigonometria studia le relazioni fra gli angoli e le lunghezze.
La geometria solida (o stereometria) studia le costruzioni geometriche nello spazio. Con segmenti e poligoni si costruiscono i poliedri, come il tetraedro, il cubo e la piramide.
I poliedri hanno vertici, spigoli e facce. Ogni spigolo ha una lunghezza, ed ogni faccia ha un'area. In più, il poliedro ha un volume. Si parla inoltre di angoli diedrali per esprimere l'angolo formato da due facce adiacenti in uno spigolo. Molti teoremi mettono in relazione queste quantità: ad esempio il volume della piramide può essere espresso tramite l'area della figura di base e la lunghezza dell'altezza.
La geometria euclidea considera anche alcune figure curve. Le figure "base" sono la circonferenza nel piano e la sfera nello spazio, definite come luogo dei punti equidistanti da un punto fissato. Partendo da queste figure, ne vengono definite altre come il cono. A queste figure vengono associate grandezze analoghe ai poliedri: si parla quindi di lunghezza della circonferenza, di area del cerchio e di volume della sfera.
L'intersezione nello spazio di un cono con un piano forma una nuova figura curvilinea: a seconda dell'inclinazione del piano, questa è una ellisse, una parabola, un'iperbole o una circonferenza. Queste sezioni coniche sono le curve più semplici realizzabili nel piano. Ruotando una figura intorno ad una retta, si ottengono altre figure curve. Ad esempio, ruotando un'ellisse o una parabola si ottengono l'ellissoide ed il paraboloide. Anche in questo caso, il volume dell'oggetto può essere messo in relazione con altre quantità. La geometria euclidea non fornisce però sufficienti strumenti per dare una corretta definizione di lunghezza e area per molte figure curve.
La geometria cartesiana (o analitica) ingloba le figure ed i teoremi della geometria euclidea, introducendone di nuovi grazie a due altre importanti discipline della matematica: l'algebra e l'analisi. Lo spazio (ed il piano) sono rappresentati con delle coordinate cartesiane. In questo modo ogni figura geometrica è descrivibile tramite una o più equazioni (o disequazioni).
Rette e piani sono oggetti risultanti da equazioni di primo grado, mentre le coniche sono definite tramite equazioni di secondo grado. Equazioni polinomiali di grado superiore definiscono nuovi oggetti curvi. Il calcolo infinitesimale permette di estendere con precisione i concetti di lunghezza e area a queste nuove figure. L'integrale è un utile strumento analitico per determinare queste quantità. Si parla in generale quindi di curve e superfici nel piano e nello spazio.
Retta (passante per l'origine), piano (contenente l'origine) e spazio sono esempi di spazi vettoriali di dimensione rispettivamente 1, 2 e 3: infatti ogni punto è esprimile rispettivamente con 1, 2 o 3 coordinate. La geometria cartesiana è facilmente estendibile alle dimensioni superiori: in questo modo si definiscono spazi di dimensione 4 e oltre, come insiemi di punti aventi 4 o più coordinate.
Grazie all'algebra lineare, lo studio delle rette e dei piani nello spazio può essere esteso allo studio dei sottospazi di uno spazio vettoriale, di dimensione arbitraria. Lo studio di questi oggetti è strettamente collegato a quello dei sistemi lineari e delle loro soluzioni. In dimensione più alta, alcuni risultati possono contrastare con l'intuizione geometrica tridimensionale a cui siamo abituati. Ad esempio, in uno spazio di dimensione 4, due piani possono intersecarsi in un punto solo.
In uno spazio vettoriale l'origine (cioè il punto da cui partono gli assi, di coordinate tutte nulle) gioca un ruolo fondamentale: per poter usare in modo efficace l'algebra lineare, si considerano infatti solo sottospazi passanti per l'origine. In questo modo si ottengono delle relazioni eleganti fra i sottospazi, come la formula di Grassmann.
Nella geometria affine il ruolo predominante dell'origine è abbandonato. I sottospazi non sono vincolati, e possono quindi essere paralleli: questo crea una quantità considerevole di casistiche in più. In particolare, la formula di Grassmann non è più valida. Lo spazio affine è considerato (fino alla scoperta della relatività ristretta) come lo strumento migliore per creare modelli dell'universo, con 3 dimensioni spaziali ed eventualmente 1 dimensione temporale, senza "origini" o punti privilegiati.
Dal XIX secolo in poi l'algebra diventa uno strumento preponderante per lo studio della geometria. Nel tentativo di "abbellire" il quadro, e di ricondurre molte proprietà e teoremi ad un numero sempre minore di proprietà fondamentali, la geometria analitica viene progressivamente inglobata in un concetto più ampio di geometria: si aggiungono i "punti all'infinito" (creando così la geometria proiettiva), e si fanno variare le coordinate di un punto non solo nei numeri reali, ma anche in quelli complessi.
La geometria proiettiva nasce come strumento legato al disegno in prospettiva, e viene formalizzata nel XIX secolo come un arricchimento della geometria cartesiana. La geometria proiettiva include i "punti all'infinito" ed elimina quindi alcune casistiche considerate fastidiose, come la presenza di rette parallele.
In questa geometria molte situazioni si semplificano: due piani distinti si intersecano sempre in una retta, e oggetti differenti della geometria analitica (come le coniche ellisse, parabola e iperbole) risultano essere equivalenti in questo nuovo contesto. La geometria proiettiva è anche un esempio di compattificazione: similmente a quanto accade con la proiezione stereografica, aggiungendo i punti all'infinito lo spazio diventa compatto, cioè "limitato", "finito".
La geometria algebrica verte essenzialmente sullo studio dei polinomi e delle loro radici: gli oggetti che tratta, chiamati varietà algebriche, sono gli insiemi dello spazio proiettivo, affine o euclideo definiti come luoghi di zeri di polinomi.
Nel XX secolo il concetto di varietà algebrica assume un'importanza sempre maggiore. Rette, piani, coniche, ellissoidi, sono tutti esempi di varietà algebriche. Lo studio di questi oggetti raggiunge risultati impressionanti quando le coordinate dello spazio vengono fatte variare nel campo dei numeri complessi: in questo caso, grazie al teorema fondamentale dell'algebra, un polinomio ha sempre delle radici.
Questo fatto algebrico di grande importanza (esprimibile dicendo che i numeri complessi formano un campo algebricamente chiuso) ha come conseguenza la validità di alcuni teoremi potenti di carattere molto generale. Ad esempio, il teorema di Bézout asserisce che due curve di grado  e  nel piano che non hanno componenti in comune si intersecano sempre in  punti, contanti con un'opportuna molteplicità. Questo risultato necessita che il "piano" sia proiettivo e complesso. In particolare, è certamente falso nell'ambito classico della geometria analitica: due circonferenze non devono intersecarsi necessariamente in 4 punti, possono anche essere disgiunte.
Lo studio della geometria nello spazio proiettivo complesso aiuta anche a capire la geometria analitica classica. Le curve nel piano cartesiano reale possono ad esempio essere viste come "sezioni" di oggetti più grandi, contenuti nel piano proiettivo complesso, ed i teoremi generali validi in questo "mondo più vasto e perfetto" si riflettono nel piano cartesiano, pur in modo meno elegante. Come lo studio della geometria affine fa largo uso dell'algebra lineare, quello delle varietà algebriche attinge a piene mani dall'algebra commutativa.
La geometria differenziale è lo studio di oggetti geometrici tramite l'analisi. Gli oggetti geometrici non sono necessariamente definiti da polinomi (come nella geometria algebrica), ma sono ad esempio curve e superfici, cioè oggetti che, visti localmente con una lente di ingrandimento, sembrano quasi rettilinei o piatti. Oggetti cioè "senza spessore", e magari un po' curvi. Come la superficie terrestre, che all'uomo sembra piatta, benché non lo sia.
Questo concetto di "spazio curvo" è espresso tramite la nozione di varietà differenziabile. La sua definizione non necessita neppure di "vivere" in uno spazio ambiente, ed è quindi usata ad esempio nella relatività generale per descrivere intrinsecamente la forma dell'universo. Una varietà può essere dotata di una proprietà fondamentale, la curvatura, che viene misurata tramite oggetti matematici molto complessi, come il tensore di Riemann. Nel caso in cui lo spazio sia una curva o una superficie, questi oggetti matematici risultano più semplici: si parla ad esempio di curvatura gaussiana per le superfici.
Su una varietà dotata di curvatura, detta varietà riemanniana, sono definite una distanza fra punti, e le geodetiche: queste sono curve che modellizzano i percorsi localmente più brevi, come le rette nel piano, o i meridiani sulla superficie terrestre.
Con la geometria differenziale è possibile costruire un "piano" in cui valgono tutti i postulati di Euclide, tranne il quinto, quello delle parallele. Questo postulato ha avuto un'importanza storica fondamentale, perché ci sono voluti 2000 anni per dimostrare la sua effettiva indipendenza dai precedenti. Asserisce che, fissati una retta  ed un punto  non contenuto in , esiste un'unica retta  parallela a  e passante per .
Una geometria non euclidea è una geometria in cui valgono tutti gli assiomi di Euclide, tranne quello delle parallele. La sfera, con le geodetiche che giocano il ruolo delle rette, fornisce un esempio semplice di geometria non euclidea: due geodetiche si intersecano sempre in due punti antipodali, e quindi non ci sono rette parallele. Un tale esempio di geometria è detta ellittica. Esistono anche esempi opposti, in cui ci sono "così tante" rette parallele, che le rette  parallele a  e passanti per  sono infinite (e non una). Questo tipo di geometria è detta iperbolica, ed è più difficile da descrivere concretamente.
La topologia è infine lo studio delle forme, e di tutte quelle proprietà degli enti geometrici che non cambiano quando questi vengono deformati in modo continuo, senza strappi. La topologia studia tutti gli oggetti geometrici (definiti in modo algebrico, differenziale, o quant'altro) guardando solo la loro forma. Distingue ad esempio la sfera dal toro, perché quest'ultimo ha "un buco in mezzo". Studia le proprietà di connessione (spazi "fatti di un pezzo solo") e di compattezza (spazi "limitati"), e le funzioni continue fra questi.
Le forme degli oggetti vengono codificate tramite oggetti algebrici, come il gruppo fondamentale: un gruppo che codifica in modo raffinato la presenza di "buchi" in uno spazio topologico.
Nel 1872 Felix Klein elaborò un programma di ricerca, l'Erlanger Programm, in grado di produrre una grande sintesi delle conoscenze geometriche e integrarle con altri settori della matematica, quali la teoria dei gruppi.
Nella prospettiva di Klein una geometria consiste nello studio di proprietà di uno spazio che sono invarianti rispetto ad un gruppo di trasformazioni (geometria delle trasformazioni):
La geometria analitica e l'algebra lineare forniscono importanti collegamenti tra l'intuizione geometrica e il calcolo algebrico che sono diventati ormai una parte costitutiva di tutta la matematica moderna e delle sue applicazioni in tutte le scienze. La geometria differenziale ha trovato importanti applicazioni nella costruzione di modelli per la fisica e per la cosmologia. La geometria piana e dello spazio fornisce inoltre degli strumenti per modellizzare, progettare e costruire oggetti reali nello spazio tridimensionale: è quindi di fondamentale importanza in architettura e in ingegneria come anche nel disegno e nella computer grafica.
La geometria descrittiva è una disciplina che permette, attraverso determinate costruzioni grafiche, di rappresentare oggetti tridimensionali già esistenti (rilievo) e/o da costruire (progettazione). L'applicazione informatizzata della geometria descrittiva permette oggi la creazione di superfici e solidi, anche ad alta complessità tridimensionale. Inoltre, e soprattutto, ne permette il controllo in modo inequivocabile di ogni loro forma e dimensione. I maggiori campi d'impiego della geometria descrittiva sono quelli dell'architettura, dell'ingegneria e quelli del design industriale.
Una vite è un organo filettato di forma cilindrica, utilizzata prevalentemente per fissare oggetti tra loro. È una macchina semplice in grado di trasformare il moto circolare in moto rettilineo.
L'invenzione della vite è comunemente attribuita al matematico greco Archita. Proclo scrive che Apollonio di Perga aveva dimostrato che l'elica cilindrica è una curva omeomerica, cioè che la curva può scorrere su sé stessa, ovvero il principio che spiega il funzionamento delle viti cilindriche. Nel I secolo a.C. viti di legno erano già in uso nel mondo mediterraneo, per esempio nei torchi per la produzione di olio e vino. Peraltro Lucio Russo[1] argomenta a favore dell'esistenza di torchi nel II secolo a.C. Erone di Alessandria descrive un procedimento basato su una progettazione scientifica per produrre viti cilindriche con madrevite.
Le viti metalliche apparvero per la prima volta in Europa nel XV secolo, ma non divennero di uso comune fino a quando non fu inventato (o reinventato) un sistema per la loro produzione di massa nel XVIII secolo.
L'ingegnere britannico Henry Maudslay brevettò un tornio per la fabbricazione di viti nel 1797. Un dispositivo simile fu brevettato l'anno successivo negli Stati Uniti da David Wilkinson.
La vite con testa a croce fu inventata dallo statunitense John P. Thompson, che vendette il brevetto a Henry Frank Phillips, che a sua volta lo ne depositò negli anni 1930 e successivamente fondò la Phillips Screw Company. Phillips ebbe notevoli difficoltà a trovare una officina in grado di intagliare il nuovo tipo di testa, fino a quando contattò un'altra società American Screw Company che investì nell'idea, ottenendo un notevole successo, poco dopo i due enti brevettarono una nuovo tipo di vite, la pozidriv. Durante la seconda guerra mondiale la standardizzazione dei filetti ebbe un forte incremento, per permettere alle nazioni alleate di scambiarsi componenti e pezzi di ricambio.
La vite è una applicazione particolare del principio del cuneo o piano inclinato. Il cuneo è costituito dall'elica del filetto, che si avvolge sul cilindro della vite e preme su un piano rappresentato dal filetto contrapposto. Le viti possono essere destrorse (ovvero si avvitano girando in senso orario e si svitano girando in senso antiorario) oppure sinistrorse (si avvitano in senso antiorario e si svitano in senso orario).
L'analisi matematica di base è la stessa del cuneo, e l'inclinazione corrispondente è data dal rapporto tra il passo e la circonferenza del filetto. Per evitare che la vite si sviti spontaneamente, l'inclinazione del piano deve essere tale che la forza risultante in condizione di aderenza agisca con la sua componente parallela al piano nel verso di avvitamento.
Un filetto con passo lungo può allentarsi con più facilità rispetto ad uno con passo breve. Inoltre i coefficienti di attrito dei materiali contribuiscono significativamente alla determinazione del limite di slittamento. Per aumentare la tenuta di una vite si usano a volte prodotti frenafiletti, che agiscono come adesivi aumentando l'attrito tra le parti.
Le viti sono prodotte in un'ampia gamma di materiali, il più usato dei quali è l'acciaio, seguito dall'ottone.
Dove sia richiesta resistenza agli agenti corrosivi si utilizza acciaio inossidabile, titanio o bronzo. Per lo più comunque, per aumentare la resistenza alla corrosione, vengono applicati sulla superficie della vite dei rivestimenti elettrolitici (zincatura, dacrometizzazione, brunitura, nichelatura, ramatura, bronzatura). Questi rivestimenti consentono di aumentare la resistenza in ambienti corrosivi anche a 200/300 ore.
Nella grande maggioranza delle applicazioni industriali, le viti e i dadi sono prodotti in materiale 8.8 EN 20898-1 o dove non sia richiesta una particolare resistenza meccanica si utilizza una classe di resistenza 4.8, mentre nel caso dei tiranti si usa il materiale ASTM A193 grado B7 per il tirante e il materiale ASTM A194 grado 2H per i dadi in acciaio al carbonio, mentre per quelli in acciaio inossidabile (o autopassivante) la codifica ASTM è "A193 grado B8" per i tiranti, mentre per i dadi è "A194 grado 8".
Vengono utilizzati anche materiali plastici quali nylon e teflon dove sia richiesta elevata resistenza alla corrosione e isolamento elettrico senza eccessiva forza di unione. Negli isolatori elettrici sono sagomati a vite anche il vetro e la porcellana per unire diversi elementi.
Uno stesso tipo di vite può essere realizzato con acciai di diversa resistenza. Dove siano richieste tensioni elevate un bullone con vite a bassa resistenza può cedere, provocando danni o incidenti. Per questo motivo sulla testa delle viti è impressa una sigla o comunque simboli, che indicano la classe del materiale usato; per applicazioni particolari, che esulano dai normali acciai, sono previste viti per situazioni estreme per freddo e per il caldo, nel primo caso con particolari resistenza all'infragilimento da bassa temperatura, nel secondo caso con materiali che conservano valori accettabili di resistenza ad alte temperature.
Le normali condizioni di resistenza si intendono infatti a condizioni ambientali, queste non valgono affatto in ambienti sostanzialmente diversi, come il corrosivo, (ad esempio sostanze chimiche particolari), che infragilisca la struttura del metallo (freddo), ne alteri la cristallizzazione (radiazioni ionizzanti), o ne degradi la condizione strutturale (calore, stress a fatica).
Per ovviare a tali problemi sono usati materiali intrinsecamente resistenti, o nel caso che questo non sia possibile, materiali che debbano essere sostituiti, specie nei casi di degrado progressivo, quando il decadimento delle caratteristiche è ancora nel limite di rischio ammissibile.
La misurazione della vite avviene secondo il seguente schema:
La lettera iniziale indica il tipo di filettatura, in questo caso Metrica.
Il primo numero indica il diametro esterno della filettatura in mm.
Il secondo numero indica la lunghezza della vite sempre in mm (da non confondere con quello del passo del filetto).
La vite semplice si avvita nel materiale da fissare per mezzo di un filetto complementare in esso praticato.
Il filetto può essere preparato in precedenza per mezzo di trapano e maschio come avviene di solito con l'acciaio e altri materiali, oppure può essere generato estemporaneamente dalla vite stessa, come nel caso del legno o dell'osso.
Le viti autofilettanti hanno solitamente una estremità appuntita per favorire l'imbocco nel foro e a volte l'intero corpo è conico invece che cilindrico.
Nell'alluminio si usa praticare i fori ma non filettarli, lasciando che il filetto venga realizzato da apposite viti al momento del fissaggio. Queste viti per alluminio presentano di solito una scanalatura longitudinale che ha lo scopo di scaricare il truciolo prodotto dall'incisione del materiale.
Alcune viti, dette autoperforanti hanno una punta particolarmente appuntita e sono in grado di perforare materiali sottili come lamiere e materiali plastici, senza bisogno di praticare precedentemente un foro di invito.
Esistono anche le cosiddette viti "trilobate" o "automaschianti", che possono sostituire le normali viti metriche in molte occasioni, soprattutto laddove i particolari da accoppiare siano costituiti di materiali non troppo duri. Infatti la particolare conformazione del gambo, a sezione trilobata anziché cilindrica, consente loro di costruire un filetto metrico al momento del primo avvitamento, fungendo da veri e propri "maschi a filettare". Quando vengono smontate possono essere sostituite da normali viti metriche.
Grazie alla funzione che compie, ha ispirato la realizzazione di altri tipi di attrezzature come lo spaccalegna a vite e tutte le relative applicazioni.
La vite ad anello è dotata di un occhiello in corrispondenza di un'estremità e di filettatura all'estremità opposta. Generalmente sono utilizzate per mantenere cavi o appendere oggetti a muro.
Oltre ai giravite tradizionali, esistono molti tipi di dispositivi - detti inserti - per poter utilizzare alcuni tipi di giravite (o anche un avvitatore) detti appunto ad inserto su una determinata testa della vite. I più comuni sono quello a taglio e quello a croce anche detto Phillips. Altri attacchi offrono una migliore presa e riducono il rischio di danneggiamento dell'innesto o del giravite. In altri casi sono studiati per agevolare il montaggio automatico nella produzione in serie. Nella componentistica elettrica di consumo, come interruttori e prese elettriche, alcuni costruttori adottano nelle viti serrafilo, una doppia impronta nella testa, taglio e stella, soluzione volta ad agevolare un eventuale intervento di manutenzione di emergenza. In genere per ogni tipo di innesto vi sono diverse dimensioni, a seconda della dimensione della punta del giravite. 
I tipi principali sono:
Altre varianti sono:
Alcuni tipi di attacchi sono studiati per impedire lo smontaggio a persone non autorizzate e non in possesso di un cacciavite speciale. Sono perciò dette antimanomissione. Sono spesso usate negli elettrodomestici e in apparecchi elettronici per impedire che persone non competenti possano aprire gli apparecchi correndo rischi di folgorazione, per evitare manomissioni e/o vandalismi o per impedire la riparazione, costringendo il proprietario a ricorrere a centri specializzati.
Diversi innesti convenzionali possono essere realizzati in forma antimanomissione, per esempio aggiungendo un pernetto centrale in rilievo. Altri tipi sono completamente nuovi.
Il tipo a taglio può essere realizzato in modo da consentire l'avvitamento ma non lo svitamento realizzando dei piani inclinati che non offrano presa al cacciavite nel senso di svitamento.
Alcune viti hanno la porzione di testa con la sede per il cacciavite che può essere spezzata applicando una opportuna torsione. Questo rende impossibile lo svitamento e garantisce che la vite abbia un accoppiamento adeguato.
Gli elementi filettati possono avere i filetti secondo vari tipi di filettature, le quali sono descritte da un proprio profilo unificato. Il profilo più usato e pratico è il profilo metrico triangolare ISO, basato sul sistema internazionale, ma ancora sopravvivono altri sistemi, diffusi in passato o in altri paesi o per utilizzi particolari, quali: il profilo metrico trapezoidale ISO, il profilo Whitworth, il profilo Gas e quello a dente di sega. I filetti vengono designati, oltre che con il tipo del profilo, con le dimensioni del diametro e del passo, infatti da questi valori tutti gli elementi geometrici della filettatura possono essere ricavati.
Le filettature metriche a profilo triangolare sono quelle più impiegate; il profilo base, ottenuto sezionando la superficie filettata con un piano passante per l'asse, è formato da una serie di triangolari equilateri (con smussi) con l'angolo tra i fianchi di 60°. Le viti a profilo metrico sono disponibili con passo grosso e fine, le prime sono quelle più usate e comuni.
Sono designate dalla lettera 'M' e da un numero indicante il valore del diametro nominale in millimetri per la serie a passo grosso. Esempio: M5 designa una vite di diametro nominale di 5 mm e costituita da una filettatura metrica ISO a passo grosso.
La serie a passo fine è invece designata con l'aggiunta dopo la lettera 'x' del valore del passo in mm. Esempio: M5x0,5 designa una vite di diametro nominale di 5 mm e costituita da una filettatura metrica ISO a passo fine pari a 0,5 mm.
Il diametro nominale è il diametro esterno del filetto, di poco inferiore al diametro del perno prima che venga filettato.
Prima dell'adozione del sistema metrico, diverse aziende avevano progettato specifiche proprie per la filettatura.
Il primo a progettare un filetto standard fu l'ingegnere inglese Joseph Whitworth intorno al 1841.
Il sistema Whitworth ha due passi, fine e grosso, e il filetto ha una angolazione di 55°. 
Successivamente in Inghilterra fu sviluppato il sistema BA, dal nome del British Association for Advancement of Science. Le viti erano definite con le sigle 2BA, 4BA ecc (i numeri dispari non erano usati quasi mai). Il sistema è ancora usato in strumenti di misura e macchine fotografiche, ma la serie è definita con valori metrici, con 0BA = 1mm di passo. La vite di fissaggio delle macchine fotografiche al cavalletto è di questo tipo, con passo 1/4"-20.
Gli Stati Uniti adottano un loro sistema, chiamato passo unificato standard e una variante, chiamata SAE da Society of Automotive Engineers, è utilizzata dall'industria automobilistica americana.
Il sistema è ancora basato sul pollici, comunemente usato in USA, anche se l'industria automobilistica ha per il resto aderito al sistema metrico già dagli anni settanta.
Le viti sono descritte con coppie di numeri: 4-40, 6-32, 8-32, 10-32, 10-24 ecc per il sistema nominale (per viti di diametro inferiore a 1/4"), oppure 1/4"-20, 1/4"-28 ecc per il sistema basato sui pollici.
I diametri nominali seguono approssimativamente una scala logaritmica dove una vite di un numero raddoppia approssimativamente la resistenza della vite del numero precedente.
Il diametro è dato da: dia = (#N x .013") + .060". Usando questa formula, una vite #5 ha il diametro di .125" (1/8"), una vite #10 ha il diametro di .190" (in pratica 3/16"), etc.
In entrambi i sistemi, il secondo numero indica il numero di filetti contenuti in un pollice.
Viti di questo tipo si possono trovare in vecchi personal computer costruiti secondo le specifiche IBM.
Ora sempre più prodotti vengono costruiti in oriente, dove è utilizzato il sistema metrico, ed esportati in tutto il mondo, compresi gli Stati Uniti, dove l'uso del sistema non metrico declinerà sempre più.
Altri sistemi non metrici sono il BSP (British Standard Pipe) e il CEI (Cycle Engineers Institute), utilizzato in Inghilterra per le biciclette.
Perché si generi la forza di tenuta, è necessario che le viti siano inizialmente poste in tensione, siano pretensionate o, come più volgarmente detto, tirate.
Il mantenimento della forza è dovuto all'elasticità dei materiali stretti.
La forza di tensione deve essere tale per cui la tenuta allo scorrimento dei due materiali uniti sia offerta dall'attrito tra le parti. Se la tensione è insufficiente, le due parti possono infatti scorrere fino a toccare la vite e agire su questa come cesoie. Inoltre i materiali, sfregando, possono usurarsi e ridursi di spessore, annullando la forza tensiva agente sulla vite.
Nelle applicazioni critiche è spesso precisato la coppia di forze con cui stringere la vite o bullone per preimpostare la giusta forza di tensione. Infatti una coppia agisce per muovere la vite, questa non ne risente fino a quando non viene superata la coppia di tensione, dopodiché la giuntura si allenta.
I bulloni per tensioni elevate hanno solitamente la testa di forma esagonale per permettere un elevato momento torcente quindi l'applicazione di una elevata coppia e sopra di essa è inciso un indice di resistenza. Gli indici di resistenza previsti dalle vigenti norme sono 4.6, 4.8, 5.6 (bulloni leggeri), 6.8 (bulloni a media resistenza), 8.8, 10.9 (bulloni ad alta resistenza) e 12.9 (bulloni ad altissima resistenza).
Significato dei numeri:
Per valori superiori di tali carichi, il bullone rispettivamente si rompe a trazione o si snerva, in particolare sottoposto al carico di snervamento indicato e rilasciato, il bullone subisce un allungamento irreversibile (deformazione plastica) non superiore allo 0,2%.
Le viti sono impiegate anche per applicazioni differenti dal semplice fissaggio. La funzione di conversione del moto circolare in lineare è sfruttata in moltissime applicazioni, dal tornio per l'avanzamento automatico del carrello al cavatappi.
Gli ingranaggi a vite senza fine sfruttano una vite per raggiungere elevati rapporti di riduzione di velocità e aumento di coppia.
La vite di Archimede è un antico strumento che permette di sollevare acqua sfruttando il principio della vite, ed è ancora molto usato per spostare soprattutto materiali granulosi come per esempio i cereali (coclea). La vite di Archimede viene utilizzata anche per effettuare spostamenti di precisione: una barra viene filettata con un particolare filetto calibrato e rettificato e sulla stessa viene fissata una chiocciola a ricircolo di sfere; il moto rotatorio della vite permette alla chiocciola di spostarsi di una distanza precalcolata in base al passo del filetto con precisione maggiore rispetto ad un filetto semplice. Tale dispositivo è spesso utilizzato nello spostamento degli assi delle macchine a controllo numerico.
In un bullone generalmente la vite è a testa esagonale e, più raramente, a testa cilindrica con esagono incassato o quadrata. L'accoppiamento dei pezzi da congiungere avviene forando questi, con un diametro maggiore del diametro esterno della vite, facendo attraversare il foro comune ai due pezzi con una vite e accoppiando questa con un dado situato al lato opposto. La vite ha una testa di dimensioni maggiori del foro. Viene spesso interposta tra pezzo e dado una rondella (o rosetta) per evitare il contatto diretto tra i due.
Il dado ha solitamente forma esagonale e presenta un foro in cui è ricavata una filettatura complementare a quella della vite. I fori praticati negli oggetti da unire non devono essere filettati, e devono consentire il libero scorrimento del bullone.
La filettatura della vite può non essere presente per tutta la sua lunghezza, poiché non ha nessuna utilità nella zona interna allo spessore dei materiali. Spesso, anzi, si preferisce non avere il corpo completamente filettato per dare una maggiore resistenza a taglio della vite.
Una variante è costituita da una barra interamente filettata, tagliata alla lunghezza opportuna (tirante) dotato di due dadi. Questa è la forma quasi universalmente impiegata negli accoppiamenti flangiati, e ha il vantaggio di poter essere smontata indifferentemente dai due lati.
Il transistor (termine inglese, contrazione di trans(fer) "trasferimento [di cariche elettriche]" e (re)sistor "resistore"; pronuncia italianizzata "transìstor"[1]) o transistore è un dispositivo a semiconduttore largamente usato nell'elettronica analogica.
Il dispositivo, consentendo di realizzare circuiti che non richiedevano le elevate tensioni anodiche delle valvole termoioniche, permise la realizzazione di apparecchi radio portatili alimentati a pile. Il termine, sottintendendo "radio a transistor", è stato quindi spesso utilizzato nel linguaggio comune anche per identificare tali apparecchi, che raggiunsero il mercato di massa negli anni cinquanta del XX secolo.
Il fisico e ingegnere Julius Edgar Lilienfeld progettò il primo transistor in Canada nel 1925, descrivendo un dispositivo simile all'attuale transistor ad effetto di campo[2]. Tuttavia, Lilienfeld non pubblicò ricerche a tal proposito e nel 1934 l'inventore tedesco Oskar Heil brevettò un dispositivo simile.[3]
Il primo transistor era realizzato con due elettrodi, le cui punte, molto sottili e distanti tra loro alcuni centesimi di millimetro, per la precisione da 127 a 50 micron, erano premute sulla superficie di una piastrina di un cristallo di germanio molto puro, policristallino e di tipo n. La tecnica del contatto puntiforme era già nota ed utilizzata per la costruzione dei diodi rivelatori. Provvisoriamente, dato che il transistor funzionava in modo analogo ad un triodo, venne chiamato triodo a stato solido: il nome definitivo deriva dall'unione dei termini "TRANSconductance" e "resISTOR". Il primo prototipo funzionante fu realizzato nel mese di dicembre del 1947 da due ricercatori dei laboratori Bell Labs: Walter Brattain e John Bardeen del gruppo di ricerca guidato da William Shockley. 
Era questo il transistor a contatti puntiformi (a punte), mentre si deve a William Shockley l'ideazione, nel gennaio 1948[4], e la formulazione, nella primavera dell'anno successivo, della teoria del transistor a giunzione, chiamato inizialmente dallo stesso Shockley, nel suo diario di laboratorio, "sandwich transistor". Nel 1956, i tre ricercatori furono insigniti del premio Nobel per la Fisica, con la motivazione «per le ricerche sui semiconduttori e per la scoperta dell'effetto transistor». Già verso la fine degli anni '50, la produzione di transistor si orientò verso l'utilizzo del silicio come elemento semiconduttore, e, negli anni '70, il transistor al germanio divenne obsoleto.
I tipi di contenitori del dispositivo si sono moltiplicati e, negli anni, sono stati usati materiali come la ceramica, il metallo, la plastica o assemblaggi misti. Negli anni '60, venne usato anche il vetro: il produttore europeo Philips racchiudeva i suoi dispositivi di piccola potenza, ad esempio quelli siglati OC70 e OC71, in un'ampollina cilindrica in vetro verniciata in nero, riempita di grasso al silicone. Nel caso il dispositivo avesse dissipazione maggiore, come l'OC72, il dispositivo era ricoperto semplicemente da un cappuccio in alluminio; avendo reofori identici, il collettore era contraddistinto da un puntino di vernice rossa scura. Nel tempo, molti tipi di contenitori sono andati in disuso a favore di geometrie più efficienti nello smaltimento del calore prodotto. I dispositivi di potenza attuali per bassa frequenza, compresi alcuni tipi di diodi e di IC, vengono assemblati nel contenitore standard definito TO-3, provvisto di due flange forate adatte al fissaggio sul dissipatore tramite una coppia di viti. Realizzato in acciaio, rame, o alluminio, con temperatura ambiente di 25 °C è in grado di trasferire al dissipatore, 300 watt di potenza termica generata dal die.
Con riguardo al movimento delle cariche elettriche all'interno del dispositivo, i transistor sono indicati come transistor bipolari, in cui sia elettroni sia lacune contribuiscono al passaggio della corrente. Sia il transistor a contatti puntiformi sia quello a giunzione sono transistor di tipo bipolare. Il tipo a contatti puntiformi, d'importanza storica per essere stato il primo realizzato ed a trovare pratica applicazione, seppure limitatamente, diventò presto obsoleto per essere soppiantato da quello a giunzione, più stabile e meno rumoroso. In seguito furono creati altri tipi di transistor, in cui il passaggio di corrente avveniva grazie ad un solo tipo di portatori di carica: questi dispositivi sono i transistor ad effetto di campo. Nel tempo entrambi hanno dato origine a molti tipi diversi di transistor, usati per gli scopi più vari. Lo strumento di misura utilizzato per la verifica e la caratterizzazione dei molteplici parametri dei transistor, nonché dei diodi, è il curve tracer (tracciacurve), termine dato allo strumento in relazione ai segnali elettrici visualizzati sotto forma di grafico somiglianti a molteplici "curve", l'aspetto è simile ad un oscilloscopio: questo tipo di strumento è storicamente prodotto dalla società Tektronix.
Il transistor è composto da un materiale semiconduttore al quale sono applicati tre terminali che lo collegano al circuito esterno. Il funzionamento del transistor è basato sulla giunzione p-n, scoperta casualmente da Russell Ohl il 23 febbraio 1939.
Le principali funzioni che gli vengono affidate all'interno di un circuito elettronico sono:
Esistono principalmente due diversi tipi di transistor: il transistor a giunzione bipolare ed il transistor ad effetto di campo, ed è possibile miniaturizzare i dispositivi di entrambe le categorie all'interno di circuiti integrati, il che li rende componenti fondamentali nell'ambito della microelettronica.Il transistor a giunzione bipolare, anche chiamato con l'acronimo BJT, è un tipo di transistor largamente usato nel campo dell'elettronica analogica principalmente come amplificatore ed interruttore.Si tratta di tre strati di materiale semiconduttore drogato, solitamente il silicio, in cui lo strato centrale ha drogaggio opposto agli altri due, in modo da formare una doppia giunzione p-n, cioè o una giunzione p-n-p o una n-p-n. Ad ogni strato è associato un terminale: quello centrale prende il nome di base, quelli esterni sono detti collettore ed emettitore. Il principio di funzionamento del BJT si fonda sulla possibilità di controllare la conduttività elettrica del dispositivo, e quindi la corrente elettrica che lo attraversa, mediante l'applicazione di una tensione tra i suoi terminali. Tale dispositivo coinvolge sia i portatori di carica maggioritari sia quelli minoritari, e pertanto questo tipo di transistore è detto bipolare.
Un sistema costituito da un singolo transistor può essere rappresentato come un generico quadripolo avente due terminali di ingresso e due di uscita. I tre terminali del transistor saranno uno il terminale di ingresso, un altro quello di uscita ed il terzo in comune, connesso cioè sia all'ingresso sia all'uscita. A seconda di quale sia il terminale comune il transistor può assumere le seguenti configurazioni: a base comune, a collettore comune o a emettitore comune.
Insieme al transistor ad effetto di campo, il BJT è il transistor più diffuso in elettronica, è in grado di offrire una maggiore corrente in uscita rispetto al FET, mentre ha lo svantaggio di non avere il terminale di controllo isolato.
Il transistor ad effetto di campo, anche chiamato con l'acronimo FET, è un tipo di transistor largamente usato nel campo dell'elettronica digitale e diffusa, in maniera minore, anche nell'elettronica analogica.
Si tratta di un substrato di materiale semiconduttore, solitamente il silicio, al quale sono applicati quattro terminali: gate (porta), source (sorgente), drain (pozzo) e bulk (substrato); quest'ultimo, se presente, è generalmente connesso al source. Il principio di funzionamento del transistor a effetto di campo si fonda sulla possibilità di controllare la conduttività elettrica del dispositivo, e quindi la corrente elettrica che lo attraversa, mediante la formazione di un campo elettrico al suo interno. Il processo di conduzione coinvolge solo i portatori di carica maggioritari, pertanto questo tipo di transistore è detto unipolare.
La diversificazione dei metodi e dei materiali usati nella realizzazione del dispositivo ha portato alla distinzione di tre principali famiglie di FET: JFET, MESFET e MOSFET. Il JFET, abbreviazione di Junction FET, è dotato di una giunzione p-n come elettrodo rettificante; il MESFET, abbreviazione di Metal Semiconductor FET, una giunzione Schottky raddrizzante metallo-semiconduttore ed il MOSFET, abbreviazione di Metal Oxide Semiconductor FET, genera il campo elettrico grazie ad una struttura metallica esterna, separata dalla giunzione da uno strato di dielettrico, l'ossido.
Il transistor a effetto di campo è stato inventato da Julius Edgar Lilienfeld nel 1925, ma i primi dispositivi costruiti, i JFET, risalgono al 1952, quando fu tecnologicamente possibile realizzarli. Il FET più diffuso è il MOSFET, introdotto da Kahng nel 1960.[5]Insieme al transistor a giunzione bipolare, il FET è il transistor più diffuso in elettronica: a differenza del BJT esso presenta il vantaggio di avere il terminale gate di controllo isolato dal resto del circuito, nel quale non passa alcuna corrente; mentre ha lo svantaggio di non essere in grado di offrire molta corrente in uscita. In genere i circuiti con transistor FET hanno infatti un'alta impedenza di uscita, erogando quindi correnti molto deboli.
I transistor elettrochimici organici (OECTs) sono una delle applicazioni più proficue del PEDOT:PSS nella sua forma di film sottile e la loro accessibilità è dovuta alla facilità di produzione degli stessi e alla bassa tensione che è necessario applicare per il loro funzionamento.
La struttura dei transistor elettrochimici è composta da due parti fondamentali: canale e gate. Il canale, un film sottile di polimero semiconduttore (in questo caso PEDOT:PSS) depositato su un substrato isolante, presenta ai capi i due contatti di source e drain, esattamente come nei transistor a effetto di campo, con i quali condividono anche le curve caratteristiche. Il gate invece può presentarsi in due forme. La prima è l'elettrodo metallico che, immerso nella soluzione elettrolitica in cui si trova il canale, le fornisce tensione di gate; l'elettrodo e il canale in PEDOT non entrano in contatto tra loro. La seconda forma del gate è il film sottile di PEDOT:PSS che, depositato sullo stesso substrato del canale, è isolato rispetto ad esso in assenza di soluzione elettrolitica.
Con l'evolversi della tecnologia sono stati creati diversi altri tipi di transistor, adatti a usi particolari. Tra i più diffusi vi sono il transistore unigiunzione, un generatore di impulsi che non può amplificare né commutare, e gli Insulated Gate Bipolar Transistor, dispositivi ibridi fra i transistor bipolari e i MOSFET, adatti a gestire correnti elevate. Vi sono inoltre transistor sviluppati per applicazioni di ricerca, capaci di ottenere prestazioni quali sopportare elevate correnti o elevate frequenze di funzionamento: nel 2006 un transistor al silicio-germanio ha raggiunto in laboratorio la frequenza di commutazione di 500 GHz.[6]
I transistor sono impiegati principalmente come amplificatori di segnali elettrici o come interruttori elettronici comandati e hanno quasi ovunque sostituito i tubi termoionici.
I transistor sono l'elemento base dei chip (o circuiti integrati), al punto che la loro presenza numerica all'interno di questi ultimi è dichiarata ufficialmente come ordine di grandezza: ad esempio, i circuiti integrati semplici ne hanno da qualche decina a qualche centinaia, quelli complessi ne hanno qualche migliaio. Le APU Instinct di AMD conta cira 146 miliardi di transistor[7].
Il motore a combustione interna (MCI) o motore endotermico, impropriamente motore a scoppio, è una macchina motrice per convertire l'energia termica, posseduta da un flusso aeriforme aria-combustibile, in lavoro meccanico reso disponibile all'albero motore, ed usato per il movimento o convertito in corrente elettrica con generatore elettrico.
La conversione avviene nella camera di combustione, dove i gas combusti generano alta pressione ed aumento di volume tale che spingono il pistone verso il basso, e il pistone a sua volta fa ruotare l'albero motore e trasmette lavoro all'albero di trasmissione. La miscela consiste in un combustibile (possono essere benzina, gasolio, cherosene, gpl, gas naturale, alcool), mentre l'ossigeno dell'aria funziona come comburente. Il tipo di combustibile determina le caratteristiche del motore e quindi la sua applicazione nei vari ambiti.
L'invenzione è ricondotta ai lucchesi Eugenio Barsanti e Felice Matteucci, nel 1853 dettagliarono il funzionamento e la costruzione in documenti e brevetti depositati in diversi paesi europei quali Gran Bretagna, Francia, Italia e Germania[1].
Nei primi prototipi mancava la fase di compressione, ovvero la fase di aspirazione terminava precocemente con la chiusura della valvola di aspirazione prima che il pistone raggiungesse metà corsa, al che scoccava la scintilla e la combustione spingeva il pistone per la restante corsa, approfittando poi della riduzione di pressione per farlo risalire e questo ciclo era davvero poco efficiente.
Le prime applicazioni pratiche dei motori a combustione interna furono come motori marini fuoribordo. Questo perché il principale impedimento all'applicazione pratica del motore a combustione interna in veicoli terrestri era il fatto che, a differenza del motore a vapore, non poteva partire da fermo. I motori marini non risentono di questo problema, essendo le eliche esenti da un rilevante momento di inerzia. Dopo anni di sperimentazioni, solo nel 1899 apparvero delle vere frizioni in grado di far partire un veicolo terrestre da fermo senza doverlo spingere manualmente: ciò diede l'effettivo impulso allo sviluppo dell'autovettura.
in base alla tipologia i motori a combustione interna si suddividono:
Il motori a movimento alternativo in base al tipo di ciclo termodinamico:
oppure in base a come viene frazionato il ciclo sul moto alterno in motori:
Il motore volumetrico alternativo a quattro tempi è il motore che fornisce l'energia meccanica a quasi tutti i mezzi di trasporto su gomma (escluso taluni motocicli con il due tempi), ma anche barche a motore (escluso le navi con il due tempi sovralimentato) e ad alcuni treni. Viene usato talvolta su un piccolo aeroplano ad elica e per produrre energia elettrica a bassa tensione.
I motori a combustione interna si basano sulla reazione chimica esotermica della combustione: la reazione di un carburante con un comburente, normalmente aria. Vedi anche stechiometria. In alcuni motori venne introdotto un nuovo tipo di sistema che migliorava di netto i consumi, denominato Lean Burn (combustione magra), consisteva nell'iniezione di aria ad alta pressione direttamente nella camera di combustione per ottimizzare l'esplosione della miscela.
I motori a combustione interna sono costituiti da diversi sistemi (impianti) che ne permettono il funzionamento, quali:
I carburanti più utilizzati oggi sono composti da idrocarburi e sono derivati dal petrolio. Recentemente sono stati sviluppati prototipi che possono utilizzare anche idrogeno (sia gassoso, sia liquido). La maggior parte dei motori a combustione interna progettati per funzionare a benzina possono bruciare anche metano o GPL senza modifiche a parte quelle necessarie per l'impianto di alimentazione.
Essi vengono classificati in base al sistema di accensione utilizzato per provocare la combustione in:
L'energia dei prodotti di combustione, i gas combusti, è superiore all'energia originale dell'aria e del carburante (che avevano una maggiore energia chimica) e si manifesta attraverso un'elevata temperatura e pressione che vengono trasformate in lavoro meccanico dal motore. Nei motori alternativi, è la pressione dei gas combusti a spingere i pistoni all'interno dei cilindri del motore.
Recuperata l'energia, i gas combusti vengono eliminati attraverso una o due valvole di scarico. Nei motori a combustione interna attuali, dopo essere stati espulsi dal cilindro, i gas di scarico attraversano una turbina a gas che provvede a recuperare l'energia residua dei prodotti della combustione, al fine di poter azionare un compressore centrifugo (calettato sullo stesso albero della turbina), il quale comprime l'aria comburente (sovralimentazione mediante turbocompressore azionato da gas di scarico). Al termine di questa fase il pistone torna nella posizione di punto morto superiore (pms). Tutto il calore non trasformato in lavoro deve essere eliminato dal motore attraverso un sistema di raffreddamento ad aria o a liquido.
La potenza effettiva o potenza meccanica di un motore è la potenza disponibile sull'albero motore considerate tutte le dispersioni. Una delle sue formule è la potenza «per via termica» esprimibile con la formula:
Dove le variabili della formula rappresentano:
La polvere da sparo (anche detta polvere nera o polvere infume) è il più antico esplosivo utilizzato dall'uomo. È costituito da una miscela di zolfo (S), carbonio (C) e nitrato di potassio (salnitro, KNO3). Lo zolfo e il carbone fungono da combustibile, mentre il salnitro è il comburente. A causa delle sue proprietà incendiarie e della quantità di calore e volume di gas che genera, la polvere da sparo è stata ampiamente utilizzata come propellente in armi da fuoco, artiglieria, razzi e fuochi d'artificio e come polvere esplosiva nelle cave, nelle miniere e nella costruzione di strade.
Presumibilmente, fu inventata nel secolo IX e composta da nitrato di potassio, carbone vegetale e zolfo. Il fatto che autori come Scipione Maffei, Bonaiuto Lorini, Bernardino de Mendoza e altri chiamino il salnitro sale della China fa sostenere che i cinesi siano stati i primi a conoscere ed a fabbricare questa sostanza. Questi storici ritengono che i cinesi adoperassero miscele di polvere parecchi secoli prima di Cristo. Queste miscele sarebbero passate agli altri popoli dell'Asia e agli arabi e ai Greci della tarda antichità nel periodo delle migrazioni mongoliche. Le invasioni degli arabi e le crociate in Medio Oriente e Africa fecero conoscere questi composti agli altri popoli. Non è provato che i cinesi possedessero il cosiddetto fuoco che vola, cioè i cannoni di bambù per lanciare proiettili infiammati. Leggende dicono che la scoperta sia avvenuta accidentalmente da parte di alcuni alchimisti mentre ricercavano l'elisir dell'immortalità e il primo riferimento alla polvere nera sia stato l'avviso nei testi di alchimia a non mescolare insieme certe sostanze. Joseph Needham nel suo Scienza e civiltà in Cina individua in un testo dell'XI secolo varie formule per la preparazione di polvere da sparo.
La polvere nera è stata realizzata in numerose differenti formulazioni, le più diffuse delle quali sono (in percentuali in massa):
A seconda del tipo di carbone utilizzato (prodotto dalla pirolisi della legna a 500 °C e in assenza di ossigeno) si ottiene una diversa velocità di combustione. Ad esempio, con grafite, oppure con carbone di quercia, pioppo e faggio, a parità di dimensione granulometrica (generalmente 80 micrometri), si ha una combustione più lenta. Usando invece carbone di vite (oppure quello ottenuto da altri alberi da frutto) oppure carbone di salice, si ottiene una combustione più rapida. Per ottenere la massima velocità di combustione possibile, si può usare carbone di balsa, salicone (salice delle capre), oppure frangola (alder buckthorn). In questo caso, la combustione diventa istantanea, come un flash. Maggiore è la velocità di combustione e più la polvere da sparo, se confinata in un recipiente chiuso e dotato di miccia, tenderà a detonare facilmente. Può raggiungere una velocità di detonazione di 1500 m/sec. Anticamente, polveri a lenta combustione erano utilizzate per il caricamento di cannoni e bombarde, mentre quelle a rapida combustione erano più utili per armi da fuoco portatili.
La combustione della polvere nera è una reazione di ossidoriduzione complessa. Partendo dal dosaggio inglese, avviene la seguente reazione:
10 KNO3 + 3 S + 8 C → 2 K2CO3 + 3 K2SO4 + 6 CO2 + 5 N2
Se il nitrato di potassio supera la percentuale dell'80%, all'incendiarsi della polvere si ottengono molti residui bianchi composti prevalentemente da carbonato e solfato di potassio, residui che continuerebbero a bruciare per qualche istante emettendo gas incandescenti tra cui biossido di carbonio, di zolfo e azoto; quindi la polvere emetterebbe molti più residui solidi che gas diventando praticamente inservibile. Esistono anche delle particolari polveri nere senza zolfo dette "asulfuree", queste polveri nere sono costituite solamente da nitrato di potassio e carbone, di solito nella proporzione del 75% di nitrato di potassio e del 25% di carbone, e hanno la caratteristica di bruciare molto velocemente se si utilizza un carbone contenente molte particelle volatili, ad esempio di balsa, ma non liberano molto calore. Sono quindi preferite le polveri nere normali con zolfo in quanto, liberando più calore, sviluppano pressioni maggiori rispetto ai gas più freddi delle polveri "asulfuree". Con lo zolfo si ottengono quindi esplosioni leggermente più potenti. Se invece si sostituisce al nitrato di potassio il suo rispettivo clorato alle polveri "asulfuree", si ottiene un tipo di polvere nera chiamata H3, costituita di solito dal 75% di clorato di potassio e dal 25% di carbone, che per molti aspetti assomiglia a una polvere flash in quanto deflagra con enorme velocità. È estremamente importante non mettere mai zolfo o zucchero in polveri a base di clorato di potassio in quanto basta un modesto urto per far deflagrare o addirittura detonare improvvisamente la miscela. Talvolta si aggiunge l'1 o il 2% di bicarbonato di sodio alle polveri H3 per impedire che eventuali acidità nel composto decompongano il clorato di potassio in acido clorico che, essendo un potente ossidante, incendierebbe il carbone facendo così deflagrare o detonare la polvere spontaneamente. Se invece si sostituisce al nitrato di potassio il suo perclorato si ottiene un esplosivo chiamato " Pirodex", costituito di solito dal 75% di perclorato di potassio, dal 15% di carbone e dal 10% di zolfo, che libera più calore e meno residui solidi rispetto alla normale polvere nera a base di nitrato di potassio, ma è anche leggermente più lento nella combustione.
Il perclorato di potassio è ottimo per polveri flash con alluminio e/o magnesio e/o zolfo, mentre per la polvere nera è meglio utilizzare nitrato di potassio o di sodio o al massimo di clorato di potassio, che è utilizzato anche per produrre polveri flash senza zolfo e con piccole percentuali di bicarbonato di sodio come precauzione. Aggiungendo alla polvere piccole percentuali di magnesio e alluminio polverizzati si ottiene un aumento di emissione luminosa, calore e pressione, il che aumenta la spettacolarità del fuoco artificiale. Infine aggiungendo alcuni sali di metalli si ottengono diverse colorazioni più o meno intense: i sali di bario, in particolare il nitrato di bario, danno un colore verde acceso, i sali di stronzio e calcio un colore rosso-arancione, quelli di rame verde-azzurro, quelli di sodio giallo-oro, quelli di potassio violetto ecc.
Al posto di zolfo e carbonella vi sono farine di prodotti plastici e/o fosforo oppure alluminio e/o magnesio, in questo caso la polvere prende il nome di "polvere flash" poiché deflagra molto velocemente liberando anche molto calore: si sviluppano temperature fino a 3000 gradi centigradi.
Dal X secolo l'utilizzo della polvere nera per scopi militari divenne di uso corrente in Cina per fabbricare razzi e bombe esplosive lanciate da catapulte. La prima testimonianza di un cannone risale al 1126 quando vennero usati dei cilindri di bambù per lanciare missili contro il nemico. I cilindri di bambù vennero sostituiti da canne di metallo e il più antico cannone in Cina è datato 1290. Dalla Cina l'utilizzo militare della polvere nera fu assorbito dal conquistatore mongolo Gengis Khan che, a sua volta, usò le prime rudimentali armi da fuoco  a polvere nera. Lo dimostra la descrizione di battaglie e apparecchiature di guerra e accenna alle armi usate da quei popoli ne Il Milione di Marco Polo, che però non fa mai menzione di bocche da fuoco. Attraverso l'espansione mongola la polvere nera si diffuse al Giappone e all'Europa dove, in particolare, i mongoli la impiegarono contro gli ungheresi nel 1241. Verso la metà del XIV secolo i primi cannoni erano diffusamente menzionati sia in Europa che in Cina.
L'uso della polvere nera per la produzione di armi da fuoco e cannoni fu ostacolato dalla difficoltà di creare canne metalliche capaci di sopportare l'esplosione. Questo problema può aver portato alla falsa convinzione che i cinesi usassero la loro scoperta solamente per i fuochi d'artificio. In realtà cannoni e razzi spinti da polvere nera furono impiegati nelle invasioni Mongole del XIII secolo e furono una componente importante dell'arte militare in Estremo Oriente. Per esempio le mura cittadine di Pechino furono appositamente costruite per resistere ad attacchi di artiglieria e la dinastia Ming trasferì la capitale da Nanchino a Pechino perché le colline circostanti Nanchino fornivano una buona postazione di artiglieria per un eventuale esercito assediante.
In Europa il suo utilizzo per scopi bellici è riferito alle gesta del condottiero Pietro Navarro, che alla fine del Quattrocento e soprattutto l'inizio del Cinquecento espugnò con le sue mine numerose fortezze. Un vasto sviluppo della tecnologia legata alla polvere nera si ebbe anche in Estremo Oriente tra il XV e il XVII secolo. Miglioramenti nella metallurgia permisero armi più piccole e portarono alla creazione del moschetto. La tecnologia dei cannoni europea sorpassò gradualmente quella della Cina e questi miglioramenti tecnologici furono reintrodotti in Cina dai missionari gesuiti che furono incaricati di sovraintendere alla costruzione dei cannoni da parte degli ultimi imperatori Ming e dei primi imperatori Qing.
L'utilizzo della polvere nera, come esplosivo a fini bellici, termina praticamente negli anni 1870 con l'invenzione della dinamite, a opera di Alfred Nobel, la cui ricetta originale conteneva il 55% in peso di nitroglicerina e 45% di farina fossile e successivamente con l'introduzione di esplosivi più moderni.
Nel 1884 il chimico francese Paul Marie Eugène Vieille, attraverso la gelatinizzazione della nitrocellulosa con una miscela di etere ed alcool, ottenne un nuovo tipo di polvere da sparo, completamente differente dalla polvere nera, chiamata polvere B (in francese Poudre B). Il nuovo composto era un esplosivo di tipo propellente che sviluppava una energia tre volte superiore a quella dei composti usati fino a quel momento, peraltro con una combustione assai più rapida e una riduzione netta dei fumi di combustione – cui l'appellativo "infume". Al primo tipo di polvere presto ne seguirono altri di caratteristiche simili. Ad esempio nel 1888 Nobel ottenne la balistite gelatinizzando cotone collodio con nitroglicerina; cinque anni più tardi il Regio Polverificio di Fontana Liri ottenne la solenite. Nello stesso periodo, infine, nel Regno Unito fu brevettata la sviluppata la cordite.
A differenza della polvere nera, la polvere infume durante la combustione produce solo scorie gassose. Parlando più correttamente di polveri infumi al plurale, si tratta di composti ottenuti dall'uso di materiali come la nitrocellulosa, con o senza nitroglicerina. Questi composti sono facilmente lavorabili ed è così possibile ottenere dei grani di forma regolare per calandratura, trafilatura o altri mezzi meccanici. La forma e la dimensione dei grani influenzano la modalità e la durata della combustione, in questo modo è possibile ottenere effetti differenti con uno stesso composto prodotto in forme o dimensioni diverse.
Le polveri senza fumo sono il prodotto ottenuto da una miscela omogenea di nitrocellulosa con plastificanti e stabilizzanti e/o con nitroglicerina, e/o nitroguanidina e/o altro. Sono composti abbastanza sensibili al calore, ma non agli urti. Vengono  usate come cariche di propulsione per proiettili da armi individuali, cannoni e per propulsione di razzi. Le polveri senza fumo sono esplosivi propellenti con elevata velocità di combustione e generalmente non possono detonare anche se confinate. Attualmente le polveri senza fumo sono gli esplosivi più usati a scopo bellico.
«Quamdiu stabit Colyseus stabit et Roma;cum cadet Colyseus cadet et Roma;cum cadet Roma cadet et mundus»
«Finché esisterà il Colosseo, esisterà anche Roma;
quando cadrà il Colosseo, cadrà anche Roma;quando cadrà Roma, cadrà anche il mondo»
(Profezia di Beda il Venerabile, VIII secolo)Il Colosseo, originariamente conosciuto come Anfiteatro Flavio (in latino: Amphitheatrum Flavium) o semplicemente Amphitheatrum (in italiano: Anfiteatro)[1], situato nel centro della città di Roma, è il più grande anfiteatro romano del mondo (in grado di contenere un numero di spettatori stimato tra 50 000 e 87 000). È il più importante anfiteatro romano, nonché il più imponente monumento dell'antica Roma che sia giunto fino a noi.[2]
Inserito nel 1980 nella lista dei Patrimoni dell'umanità dell'UNESCO - insieme all'intero Centro storico di Roma, alle Zone extraterritoriali della Santa Sede in Italia e alla Basilica di San Paolo fuori le mura - nel 2007, unico monumento europeo, è stato anche inserito fra le Nuove sette meraviglie del mondo a seguito di un concorso organizzato da New Open World Corporation (NOWC).
L'anfiteatro fu edificato in epoca Flavia su un'area al limite orientale del Foro Romano. La sua costruzione, iniziata da Vespasiano nel 70 d.C., fu conclusa da Tito, che lo inaugurò il 21 aprile nell'80 d.C. Ulteriori modifiche vennero apportate durante l'impero di Domiziano, nel 90 d.C.
L'edificio forma un ovale policentrico di 527 m di perimetro, con assi che misurano 187,5 e 156,5 m. L'arena all'interno misura 86 × 54 m, con una superficie di 3 357 m². L'altezza attuale raggiunge 48 m, ma originariamente arrivava a 52 m. La struttura esprime con chiarezza le concezioni architettoniche e costruttive romane della prima Età imperiale, basate rispettivamente sulla linea curva e avvolgente offerta dalla pianta ellittica e sulla complessità dei sistemi costruttivi. Archi e volte sono concatenati tra loro in un serrato rapporto strutturale.
Il nome "Colosseo" si diffuse solo nel Medioevo, e deriva dalla deformazione popolare dell'aggettivo latino "colosseum" (traducibile in "colossale", come appariva nell'Alto Medioevo tra le casette a uno o due piani)[3] o, più probabilmente, dalla vicinanza della colossale statua acrolitica di Nerone che sorgeva nei pressi.[4]
Presto l'edificio divenne simbolo della città imperiale, espressione di un'ideologia in cui la volontà celebrativa giunge a definire modelli per lo svago e il divertimento del popolo.
Anticamente era usato per gli spettacoli dei gladiatori e altre manifestazioni pubbliche (spettacoli di caccia, battaglie navali, rievocazioni di battaglie famose e drammi basati sulla mitologia classica). La tradizione che lo vuole luogo di martirio di cristiani è infondata[5]. Non più in uso dopo il VI secolo,[6] l'enorme struttura venne riutilizzata nei secoli, anche come cava di materiale. Oggi è un simbolo della città di Roma e una delle maggiori attrazioni turistiche sotto forma di monumento archeologico regolarmente visitabile.
Nel 2012 le condizioni della struttura del Colosseo destarono preoccupazione, in seguito a studi che avevano individuato oltre 3.000 lesioni e un esteso stato fessurativo[7]. Inoltre venne rilevata un'inclinazione di 40 cm della struttura, probabilmente a causa di un cedimento della platea di fondazione su cui poggiava[8].
Nel 2022 il circuito archeologico Colosseo, Foro Romano e Palatino ha ottenuto 7 554 544 visitatori, risultando il secondo sito museale statale italiano più visitato (il primo tra quelli a pagamento), alle spalle del Pantheon[9].
«Taccia la barbara Menfi il prodigio delle piramidi, né il lavoro degli Assiri esalti più Babilonia; né siano celebrati gli effeminati Ioni per il tempio di Diana; l'altare dei molteplici corni faccia dimenticare Delo; né i Cari portino più alle stelle, con lodi sperticate, il Mausoleo proteso nel vuoto. Ogni opera cede dinanzi all'Anfiteatro dei Cesari, la fama parlerà ormai d'una sola opera al posto di tutte»
(Marziale, Liber de spectaculis, 1-7-8)La costruzione iniziò fra il 70 e il 72 sotto l'imperatore Vespasiano, della dinastia flavia. I lavori furono finanziati, come altre opere pubbliche del periodo, con il provento delle tasse provinciali e il bottino del saccheggio del tempio di Gerusalemme (70).[10]
Nel 1813 fu rinvenuto un blocco di marmo reimpiegato in epoca tarda, che recava ancora i fori delle lettere di bronzo dell'iscrizione dedicatoria, in origine posta sopra un ingresso: il testo è stato ricostruito nel modo seguente: 
«I[MP(ERATOR)] CAES(AR)VESPASI[ANUS AUG(USTUS)]AMPHITEATRU[M NOVUM][EX] MANUBI(I)S [FIERI IUSSIT]»
«L’imperatore CesareVespasiano Augustofece erigere il nuovo anfiteatrocon i proventi del bottino.»
(CIL VI, 40454a2.)L'area scelta era una vallata tra la Velia, il colle Oppio e il Celio, in cui si trovava un lago artificiale (lo stagnum citato dal poeta Marziale), fatto scavare da Nerone per la propria Domus Aurea.
Questo specchio d'acqua, alimentato da fonti che sgorgavano dalle fondazioni del Tempio del Divo Claudio sul Celio, venne ricoperto da Vespasiano con un gesto "riparatorio" contro la politica del "tiranno" Nerone, che aveva usurpato il terreno pubblico e lo aveva destinato a uso proprio, rendendo così evidente la differenza tra il vecchio e il nuovo principato[senza fonte]. Vespasiano fece dirottare l'acquedotto per uso civile, bonificò il lago e vi fece gettare delle fondazioni, più resistenti nel punto in cui avrebbe dovuto essere edificata la cavea.
Vespasiano vide la costruzione dei primi due piani e riuscì a dedicare l'edificio prima di morire nel 79[11]. L'edificio era il primo grande anfiteatro stabile di Roma, dopo due strutture minori o provvisorie di epoca giulio-claudia (l'amphiteatrum Tauri e l'amphiteatrum Caligulae) e dopo 150 anni dai primi anfiteatri in Campania.[12]
Tito aggiunse il terzo e quarto ordine di posti e inaugurò l'anfiteatro con cento giorni di giochi nell'80[13]. Poco dopo il secondo figlio di Vespasiano, l'imperatore Domiziano, operò notevoli modifiche, completando l'opera ad clipea (probabilmente scudi decorativi in bronzo dorato)[11], aggiungendo forse il maenianum summum in ligneis[14] e realizzando i sotterranei dell'arena: dopo il completamento dei lavori non fu più possibile tenere nell'anfiteatro le naumachie (rappresentazioni di battaglie navali), che invece le fonti riportano per l'epoca precedente.
Contemporaneamente all'anfiteatro furono innalzati alcuni edifici di servizio per i giochi: i ludi (caserme e luoghi di allenamento per i gladiatori, tra cui sono noti il Magnus, il Gallicus, il Matutinus e il Dacicus), la caserma del distaccamento dei marinai della Classis Misenensis (la flotta romana di base a Miseno) adibiti alla manovra del velarium (castra misenatium), il summum choragium e gli armamentaria (depositi delle armi e delle attrezzature), il sanatorium (luogo di cura per le ferite dei combattimenti) e lo spoliarum, un luogo in cui venivano trattate le spoglie dei gladiatori morti in combattimento.
«Il Colosseo, la più bella rovina di Roma, termina il nobile recinto dove si manifesta tutta la storia. Questo magnifico edificio, di cui esistono solo le pietre spoglie dell'oro e de' marmi, servì di arena ai gladiatori combattenti contro le bestie feroci. Così si soleva divertire e ingannare il popolo romano, con emozioni forti, quando i sentimenti naturali non potevano più avere slancio.»
(Madame de Staël)Nerva e Traiano fecero dei lavori, attestati da alcune iscrizioni[15], ma il primo intervento di restauro si ebbe sotto Antonino Pio[16]. Nel 217 un incendio, innescato presumibilmente da un fulmine, fece crollare le strutture superiori; i lavori di restauro fecero chiudere il Colosseo per cinque anni, dal 217 al 222, e i giochi si trasferirono al Circo Massimo[17]. I lavori di restauro furono iniziati sotto Eliogabalo (218-222) e portati avanti da Alessandro Severo, che rifece il colonnato sulla summa cavea. L'edificio fu riaperto nel 222, ma solo sotto Gordiano III i lavori poterono dirsi conclusi,[18] come sembra anche dimostrare la monetazione di questi due imperatori.[19][20] Un altro incendio causato da un fulmine fu all'origine dei lavori di riparazione ordinati dall'imperatore Decio nel 250.[11]
Dopo il sacco di Roma del 410 per opera dei Visigoti di Alarico, sul podio che circondava l'arena fu incisa un'iscrizione in onore dell'imperatore Onorio, forse in seguito a restauri. Onorio proibì i ludi gladiatori e da allora fu adibito alle venationes. L'iscrizione fu successivamente cancellata e riscritta per ricordare grandi lavori di restauro dopo un terremoto nel 442[21], per opera dei praefecti urbi Flavio Sinesio Gennadio Paolo e Rufio Cecina Felice Lampadio. Costanzo II lo ammirò sommamente[22]. Altri restauri a seguito di terremoti si ebbero ancora nel 470[23], per opera del console Messio Febo Severo. I restauri continuarono anche dopo la caduta dell'impero: dopo un terremoto nel 484 o nel 508 il praefectus urbi Decio Mario Venanzio Basilio curò i restauri a proprie spese[24].
Le venationes proseguirono fino all'epoca di Teodorico. Abbiamo i nomi delle più importanti famiglie senatorie dell'epoca di Odoacre iscritte sui gradus: tale usanza è molto più antica, ma periodicamente i nomi erano cancellati e sostituiti con quelli dei nuovi occupanti (anche a seconda del diverso grado tra clarissimi, spectabilis e illustres), per cui restano solo quelli dell'ultima redazione prima del crollo dell'impero.
Dopo l'abbandono fu adibito nel VI secolo ad area di sepoltura e poco dopo utilizzato come castello. Tra il VI e il VII secolo fu fondata all'interno del Colosseo una cappella oggi nota come chiesa di Santa Maria della Pietà al Colosseo[25]. Sotto papa Leone IV fu gravemente danneggiato da un terremoto (847 circa)[11]. Il grande terremoto del 1349 provocò il crollo dell'esterno lato sud, costruito su un terreno alluvionale instabile. A lungo utilizzato come fonte di materiale edilizio, nel XIII secolo fu occupato da un palazzo dei Frangipane, successivamente demolito, ma il Colosseo continuò a essere occupato da altre abitazioni. I blocchi di travertino furono sistematicamente asportati nel XV e XVI secolo per nuove costruzioni, e blocchi caduti a terra furono ancora utilizzati nel 1634 per la costruzione di Palazzo Barberini e nel 1703, dopo un altro terremoto, per il porto di Ripetta.
Benvenuto Cellini, nella sua Autobiografia, raccontò di una spettrale notte tra demoni evocati nel Colosseo, a testimonianza della fama sinistra del luogo.
Nel corso del Giubileo del 1675 assunse il carattere di luogo sacro in memoria dei molti martiri cristiani qui condannati al supplizio. Nel 1744 papa Benedetto XIV ordinò la fine delle spoliazioni con un editto[26] e vi fece costruire le quattordici edicole della Via Crucis, e nel 1749 dichiarò il Colosseo chiesa consacrata a Cristo e ai martiri cristiani.
Nel 1787 durante il soggiorno di Goethe a Roma lasciò una descrizione enfatica del monumento visto di notte tra le pagine del suo Viaggio in Italia:
«Incantevole è soprattutto la vista del Colosseo, che di notte è chiuso; all'interno, in una cappelletta, vive un eremita e sotto le volte in rovina si riparano i mendicanti. Essi avevano acceso il fuoco sul terreno del fondo, e un venticello spingeva il fumo sopra tutta l'arena, coprendo la parte bassa dei ruderi, mentre le mura gigantesche torreggiavano fosche in alto; noi, fermi davanti all'inferriata, contemplavamo quel prodigio, e in cielo la luna splendeva alta e serena. A poco a poco il fumo si diffondeva attraverso le pareti, i vani, le aperture, e nella luce lunare sembrava nebbia. Era uno spettacolo senza l'uguale. Così si dovrebbero vedere illuminati il Pantheon e il Campidoglio, il colonnato di S. Pietro e altre grandi vie e piazze. E così il sole e la luna, non dissimilmente dallo spirito umano, hanno qui tutt'altra funzione che in altri luoghi: qui, dove il loro sguardo è fronteggiato da masse enormi, eppure formalmente perfette.»
(Johann Wolfgang von Goethe, Viaggio in Italia)Liberato in due grandi riprese, con gli scavi diretti da Carlo Fea, Commissario per le Antichità, nel 1811 e 1812 e con quelli di Pietro Rosa (1874-1875), agli inizi dell'Ottocento, oltre a essere oggetto dei più fantasiosi progetti di riuso fino alla metà del Settecento, il Colosseo era staticamente compromesso, dopo esser stato per secoli abitato, adibito a luogo di culto cristiano e utilizzato come cava di travertino. Uno dei principali e più evidenti problemi era l'interruzione brusca dell'anello più esterno nei lati in corrispondenza delle attuali via di San Giovanni in Laterano e via dei Fori Imperiali che furono non a caso oggetto dei restauri più importanti. Il Fea descrisse pure le possibili motivazioni della presenza di fori sulle pietre del monumento interpretandoli come sistema per rimuovere le grappe metalliche che tenevano unite le pietre.[27]
Dopo l'istituzione di una commissione straordinaria da parte di papa Pio VII, i primi restauri iniziarono dopo il 1806, anno in cui un violento terremoto compromise la statica dei due lati liberi dell'anello più esterno. Il terremoto aveva particolarmente aggravato la situazione del terzo anello sul lato occidentale dove, a causa di conci ormai pericolanti, era richiesto un intervento di emergenza.
Dopo il puntellamento dei conci, furono immediatamente montati i ponteggi per la creazione di uno sperone che facesse da contrafforte. Raffaele Stern escogitò due modalità di intervento da sottoporre al vaglio dell'Accademia di San Luca: "per via di togliere", che consisteva nell'eliminazione della parte di attico e delle arcate del terz'ordine danneggiate, soluzione scartata, e "per via d'aggiungere", poi effettivamente realizzata con l'aggiunta di uno sperone in laterizio.
Le prime due arcate di ogni ordine furono tamponate e lo sperone rustico fu realizzato privo delle forme architettoniche delle arcate esistenti a causa dell'emergenza e della necessità di praticare l'intervento in economia e rapidità. Anche i conci puntellati, caricati successivamente di significato romantico e descritti come bloccati nell'atto della caduta, non sono in realtà che il frutto di un intervento d'emergenza. Stern aveva inizialmente pensato di tinteggiare lo sperone, poi ironicamente chiamato “stampella”, con un intonaco color travertino per evitare l'eccessivo contrasto con le parti autentiche, ma la tinteggiatura non fu mai realizzata.
Giuseppe Valadier, che si era già interessato del Colosseo nel 1815 con un Progetto per chiudere decentemente l'Anfiteatro Flavio mediante cancellate, si occupò nel 1823 del recupero dell'anello perimetrale nel lato verso i fori. La differenza sostanziale fra l'impostazione del restauro di Stern e quello di Valadier è che, mentre il primo fu realizzato sotto il pericolo di un crollo imminente, l'altro poté essere praticato in tutta calma.
Dal punto di vista statico l'intervento consistette in un nuovo sperone, realizzato con arcate identiche alle originali. L'aggiunta, interamente in mattoni, fu costruita utilizzando materiale diverso rispetto all'originale per motivi economici, e non per una volontà di differenziazione, con l'eccezione delle basi e dei capitelli in travertino, messi in opera in maniera identica agli originali e con lo stesso livello di definizione. Anche in questo caso, per non guastare esteticamente la preesistenza, si progettò una scialbatura color travertino, mai realizzata.
A dieci anni dall'inizio dei lavori, l'opera fu celebrata da Giuseppe Valadier al pari di una nuova architettura in Opere di Architettura ed Ornamento, ove descrisse e illustrò minuziosamente il cantiere dalla costruzione delle impalcature alla fine del restauro, esaltandolo come una delle sue più grandi realizzazioni.
Dagli anni trenta fino alla conclusione dei lavori avvenuta a metà del secolo, i lavori passarono sotto la direzione di Gaspare Salvi e Luigi Canina.
Il primo intervento di Salvi riguardò la parte più gravemente compromessa dell'intera costruzione rimasta in piedi: il terzo anello sul lato dell'attuale via San Gregorio. Su delle basi in travertino Salvi costruì un completamento con archi in laterizio su imposte di travertino; dagli archi fece partire dagli speroni per ricollegare la parte di nuova costruzione alla parte antica, che fu così staticamente assicurata. I nuovi archi sono segnalati da mattoni bipedali disposti radialmente. I riempimenti dei muri radiali sono realizzati in travertino al primo ordine e in laterizio negli ordini superiori, mentre i pilastri di restauro sono interamente in mattoni. Alla morte di Salvi, Canina assunse la direzione dei lavori, risolvendo sullo stesso lato un problema di strapiombo verso l'interno della parte più alta della costruzione, che fu assicurata con tiranti in ferro ai contrafforti in mattoni di nuova costruzione.
L'ultimo grande intervento fu operato sul lato a nord, verso l'attuale via degli Annibaldi, il più conservato con l'eccezione dell'attico, che presentava uno strapiombo di oltre 60 centimetri fuori dall'asse. Era dunque necessario costruire un sostegno per la parte più esterna strapiombante. Fu così costruito verso l'interno un abbozzo di quart'ordine nel secondo anello, in cui furono affondate catene binate per assicurare la parte d'attico non più in asse.
I resti della Meta Sudans, la fontana flavia, furono demoliti definitivamente tra il 1933 e il 1936, insieme ai resti della base del Colosso di Nerone durante i lavori per la costruzione di via dell'Impero, attuale via dei Fori Imperiali, voluta da Mussolini.
Fra il 1938 e il 1939 furono completamente scavate le strutture sotterranee dell'arena, in parte alterate dalle ricostruzioni.
Dal 2002 il Colosseo è raffigurato sul rovescio della moneta da 5 centesimi di euro coniata dalla Repubblica Italiana.
Nel 2007 il complesso è stato inserito fra le "Sette meraviglie del mondo moderno".[28] Il Colosseo al giorno d'oggi è la maggiore fonte turistica ed è il simbolo di Roma.[29]
Nelle vicinanze era presente una statua colossale di Nerone in bronzo, dalla quale si dice derivi il nome Colosseo, attestato a partire dal Medioevo e legato anche alle dimensioni colossali dell'edificio.[30]
Dopo l'uccisione di Nerone, la statua fu rimodellata per raffigurare Sol Invictus, il dio Sole, aggiungendo intorno alla testa i raggi della corona solare.[31] Il Colosso fu quindi spostato dalla sua originale collocazione, l'atrio della Domus Aurea, per far posto al tempio di Venere e Roma sotto Adriano, nel 126.[32] Il sito del basamento della statua colossale dopo lo spostamento è segnato da un moderno basamento in tufo.
La colossale statua di Nerone fu abbattuta in età imperiale ed è difficile che se ne serbasse il ricordo nel VI secolo. Il notaio e giudice Armannino da Bologna, nel XIV secolo, sosteneva che il Colosseo fosse il principale luogo pagano del mondo. Secondo la sua interpretazione «il Colosseo era diventato la sede di alcune sette di maghi ed adoratori del demonio. A chi si avvicinava era chiesto: "Colis Eum?" (cioè "adori lui?", intendendo il diavolo) a cui bisognava rispondere "Ego Colo"»[33]. Papa Benedetto XIV fece esorcizzare il Colosseo e lo consacrò alla memoria della passione di Cristo e di tutti i santi.
«Vedo una gran cerchia d'archi, e tutt'intorno giacciono pietre infrante che furono parte un tempo di una solida muraglia. Nelle fessure e sopra le volte cresce una foresta di arbusti, olivi selvatici, e mirti, e rovi intricati, e malerbe confuse... Le pietre sono massicce, immense, e sporgono l'una sull'altra. Vi sono terribili fenditure nelle mura, e ampie aperture da cui si vede il cielo azzurro ...»
(Percy Bysshe Shelley)L'edificio poggia su una piattaforma in travertino sopraelevata rispetto all'area circostante. Le fondazioni sono costituite da una grande platea in tufo[2] di circa 13 m di spessore, foderata all'esterno da un muro in laterizio.
La struttura portante è costituita da pilastri in blocchi di travertino, collegati da perni: dopo l'abbandono dell'edificio si cercarono questi elementi metallici per fonderli e riutilizzarli, scavando i blocchi in corrispondenza dei giunti: a questa attività si devono i numerosi fori ben visibili sulla facciata esterna. I pilastri erano collegati da setti murari in blocchi di tufo nell'ordine inferiore e in laterizio superiormente. La cavea era sostenuta da volte a botte trapezoidali volte a crociera e archi che poggiavano sui pilastri di travertino e sui setti radiali di tufi o mattoni. All'esterno è usato il travertino, come nella serie di anelli concentrici di sostegno alla cavea. In queste pareti anulari si aprono vari archi, decorati da paraste che li inquadrano. Le volte a crociera (tra le più antiche del mondo romano) sono in opus caementicium e spesso sono costolonate tramite archi incrociati in laterizio, usato anche nei paramenti. I muri radiali, oltre i due ambulacri esterni, sono rafforzati da blocchi di tufo. 
Un complesso sistema di adduzione e smaltimento idrico consentiva la manutenzione dell'edificio e alimentava le fontane poste nella cavea per gli spettatori.
La facciata esterna (alta fino a 48,50 m) è in travertino e si articola in quattro ordini, secondo uno schema tipico di tutti gli edifici da spettacolo del mondo romano: i tre registri inferiori con 80 arcate numerate, rette da pilastri ai quali si addossano semicolonne, mentre il quarto livello (attico) è costituito da una parete piena, scandita da lesene in corrispondenza dei pilastri delle arcate. Gli ordini per ogni piano sono dorico, ionico e corinzio. L'ultimo piano è pure definito in stile corinzio.
Nei tratti di parete tra le lesene si aprono 40 piccole finestre quadrangolari, una ogni due riquadri (nei riquadri pieni dovevano trovarsi i clipei bronzei), e immediatamente sopra il livello delle finestre vi sono collocate tre mensole sporgenti per ogni riquadro, nelle quali erano alloggiati i pali di legno che venivano utilizzati per aprire e chiudere il velarium, probabilmente ancorato a terra alla serie di cippi inclinati di pietra che ancora oggi sono in parte visibili esternamente, al limite della pedana in travertino su cui poggia il Colosseo (visibili quelli sul lato verso il Celio). Nel primo ordine sono presenti 80 ingressi di cui 4 particolari, posti sugli assi dell’ellisse.
Sull’asse corto vi erano gli ingressi per le tribune d’onore (l’ingresso per l’imperatore); sull’asse lungo gli ingressi che conducevano direttamente all’arena. Inoltre i diversi piani erano riservati per ogni classe sociale.
L’imperatore sedeva la mattina nel podio verso l’Arco di Costantino e il pomeriggio in quello verso l'odierna Metropolitana.
Al secondo e terzo livello gli archi sono bordati da una parapetto continuo, in corrispondenza del quale le semicolonne presentano un dado come base.
Le semicolonne e le lesene dei quattro ordini hanno a partire dal basso capitelli tuscanici, ionici, corinzi e corinzi a foglie lisce. I primi tre ordini ripetono la medesima successione visibile sulla facciata esterna del teatro di Marcello.
Le raffigurazioni monetarie ci tramandano la presenza di quattro archi alle terminazioni delle assi dell'ovale della pianta, ornati da un piccolo protiro marmoreo.
Il Colosseo aveva una copertura in tessuto (velarium in latino) formata da molti teli che coprivano gli spalti degli spettatori ma lasciavano scoperta l'arena centrale. Il velarium era usato per proteggere le persone dal sole ed era manovrato da un distaccamento di marinai della flotta di Miseno, stanziata accanto al Colosseo. I teli erano fissati con un complesso sistema di funi e guidati da pulegge e contemporaneamente l'intera struttura era fissata a terra con funi legate a cippi di pietra posti all'esterno del Colosseo, e in parte visibili ancora oggi.
All'interno si trova la cavea con i gradini per i posti degli spettatori; era interamente in marmo e suddivisa, tramite praecinctiones o baltea (fasce divisorie in muratura), in cinque settori orizzontali (maeniana), riservati a categorie diverse di pubblico, il cui grado decresceva con l'aumentare dell'altezza. Il settore inferiore, riservato ai senatori e alle loro famiglie, aveva gradini ampi e bassi che ospitavano seggi di legno (subsellia); sulla balaustra del podio venivano iscritti i nomi dei senatori a cui i posti inferiori erano riservati.
Seguivano il maenianum primum, con una ventina di gradini di marmo, il maenianum secundum, suddiviso in imum (inferiore) e summum (superiore), ancora con circa sedici gradini in marmo, e infine il maenianum summum, con circa undici gradini lignei all'interno del portico colonnato che coronava la cavea (porticus in summa cavea): i resti architettonici di quest'ultimo appartengono ai rifacimenti di epoca severiana o di Gordiano III. Sui gradini sotto il colonnato prendevano posto le donne, alle quali, da Augusto in poi, fu sempre vietato di mescolarsi ad altri spettatori. Il posto peggiore era sul terrazzo sopra il colonnato, solo con posti in piedi, destinato alle classi infime della plebe.
Verticalmente i settori erano scanditi da scalette e dagli accessi alla cavea (vomitoria), ed erano protetti da transenne in marmo (risalenti ai restauri del II secolo).
Alle due estremità in corrispondenza dell'asse minore, precedute esternamente da un avancorpo, si trovavano due palchi riservati agli alti personaggi ospitati nei due palchi oggi scomparsi. Uno, a forma di "S", era destinato all'imperatore, ai consoli e alle vestali; l'altro al praefectus urbi e ad altri dignitari.
Gli spettatori raggiungevano il loro posto entrando dalle arcate loro riservate. Gli imperatori e le autorità raggiungevano i loro posti fruendo del privilegio di entrare da ingressi riservati, posti sull'asse minore dell'ovale, mentre gli ingressi collocati al centro dell'asse maggiore erano riservati agli attori e ai protagonisti degli spettacoli. Ma il resto del pubblico doveva mettersi in coda sotto l'arcata che mostrava il numero corrispondente alla tessera assegnata. Ciascuna delle arcate per il pubblico era quindi contraddistinta da un numerale, inciso sulla chiave di volta, per consentire agli spettatori di raggiungere rapidamente e ordinatamente il proprio posto. I numeri incisi sulle arcate del Colosseo erano colorati di rosso per essere visibili anche da lontano. Lo hanno rivelato i restauri sponsorizzati dal gruppo Tod's e durante i quali, agendo con la nebulizzazione d'acqua per rimuovere lo sporco e lo smog depositati sul prospetto dell'edificio, sono venute alla luce tracce di colore piccole, ma inequivocabili.[34] Da qui si accedeva a scale incrociate che portavano a una serie simmetrica di corridoi anulari coperti a volta. Immettono ciascuna in un ampio settore comprendente tre cunei, scompartito da pilastri. Il percorso aveva le pareti rivestite in marmo e presentava una decorazione a stucco sulla volta, ancora quella originale di epoca flavia. Il palco meridionale, che ospitava l'imperatore, aveva anche un altro accesso più diretto, attraverso un criptoportico che dava direttamente all'esterno.
Dodici arcate erano riservate ai senatori e immettevano in corridoi che raggiungevano l'anello più interno: da qui con una breve scala si raggiungeva il settore inferiore della cavea. Anche questi passaggi erano rivestiti di marmo.
Le altre arcate davano accesso alle numerose scale a una o due rampe che portavano ai settori superiori. Le pareti erano qui rivestite di intonaco, anche sulle volte.
L'arena ellittica (86 × 54 m) presentava una pavimentazione parte in muratura e parte in tavolato di legno, e veniva ricoperta da sabbia, costantemente pulita, per assorbire il sangue delle uccisioni. Era separata dalla cavea tramite un alto podium di circa 4 m, decorato da nicchie e marmi e protetto da una balaustra bronzea, oltre la quale erano situati i sedili di rango. L'arena aveva varie trappole e montacarichi che comunicavano con i sotterranei e che potevano essere utilizzati durante lo spettacolo.
Sotto l'arena erano stati realizzati ambienti di servizio (ipogeo), articolati in un ampio passaggio centrale lungo l'asse maggiore e in dodici corridoi curvilinei, disposti simmetricamente sui due lati. Qui si trovavano i montacarichi che permettevano di far salire nell'arena i macchinari o gli animali impiegati nei giochi e che, in numero di 80, si distribuivano su quattro dei corridoi: i resti conservati si riferiscono a un rifacimento del III o IV secolo. Tuttavia è ancora possibile fare un confronto con i sotterranei dell'Anfiteatro Flavio di Pozzuoli, realizzato dagli stessi architetti del Colosseo, in modo da avere un'idea di come potevano essere in epoca romana i sotterranei del Colosseo: a Pozzuoli infatti sono tuttora visibili gli ingranaggi che i Romani utilizzavano per sollevare le gabbie contenenti belve feroci sull'arena. Il tetto dei sotterranei non è più conservato, quindi gli ambienti sottostanti l'arena sono oggi visibili all'aperto.
Le strutture di servizio sottostanti all'arena erano fornite di ingressi separati:
All'interno del Colosseo è situata la chiesa di Santa Maria della Pietà al Colosseo, luogo di culto cattolico. La piccola chiesa è inserita in uno dei fornici dell'anfiteatro Flavio. Venne probabilmente fondata tra il VI e il VII secolo, sebbene le prime notizie certe riguardo la sua esistenza risalgono al XIV secolo[25][35].
La chiesa ha rappresentato da sempre un luogo di culto in memoria dei martiri cristiani che persero la vita all'interno del Colosseo, e fu frequentata da numerosi santi tra cui San Ignazio di Loyola, San Filippo Neri e San Camillo de Lellis. L'archeologo romano Mariano Armellini racconta che la cappella: " … era destinata in origine a guardaroba della compagnia che soleva rappresentare nell'arena dell'anfiteatro il gran dramma della Passione di Gesù Cristo, uso che si mantenne fino ai tempi di Paolo IV"[25][35]. In seguito, nel 1622, l'edicola fu acquistata dalla Confraternita del Gonfalone che la trasformò in un oratorio, e la affidò a un monaco come custode del luogo.
Nel 1936 il Vicariato di Roma affidò al Circolo San Pietro l'incarico di provvedere all'officiatura della chiesa.[25][35]
Il Colosseo ospitava i giochi dell'anfiteatro, che comprendevano: lotte tra animali (venationes), l'uccisione di condannati da parte di animali feroci o altri tipi di esecuzioni (noxii) e i combattimenti tra gladiatori (munera).
Le attività seguivano un programma codificato: la mattina c'erano i combattimenti fra gli animali o fra un gladiatore e un animale, all'ora di pranzo si eseguivano le condanne a morte e solo nel pomeriggio si svolgevano i combattimenti fra gladiatori.
Per l'inaugurazione dell'edificio, l'imperatore Tito diede dei giochi che durarono tre mesi, durante i quali morirono circa 2 000 gladiatori e 9 000 animali. Per celebrare il trionfo di Traiano sui Daci vi combatterono 10 000 gladiatori.
Gli ultimi combattimenti tra gladiatori sono testimoniati nel 437, ma l'anfiteatro fu ancora utilizzato per le venationes (uccisione di animali) fino al regno di Teodorico il Grande: le ultime vennero organizzate nel 519, in occasione del consolato di Eutarico (genero di Teodorico), e nel 523, per il consolato di Anicio Massimo.
Gli scavi dei collettori fognari del Colosseo hanno restituito resti di scheletri di numerosi animali domestici e selvatici, tra cui orsi, leoni, cavalli, struzzi.
Il Colosseo è un bene in consegna al Parco archeologico del Colosseo e da esso è direttamente gestito e tutelato[36].
Nel 2016 il circuito di Colosseo, Foro romano e Palatino è stato visitato da 6 408 852 persone, confermandosi il sito più visitato in Italia.[37][38] Nel 2018 è stato visitato da oltre 7,6 milioni di visitatori[39]. Nella tabella che segue è riportato l'andamento complessivo del "Circuito archeologico Colosseo, Foro romano e Palatino" negli ultimi anni, sulla base dei dati dell'ufficio statistico dei beni culturali italiani:[40]
L'opera è il termine italiano di utilizzo internazionale per un genere teatrale e musicale in cui l'azione scenica è abbinata alla musica e al canto. La denominazione "opera" è la forma abbreviata di opera lirica[1] o anche della locuzione sostantivale opera in musica. Non è un caso che la parola "opera" sia usata invariabilmente in quasi tutte le lingue del mondo: anche se pure altre nazioni posseggono tradizioni operistiche di innegabile importanza e valore, il genere è nato e si è sviluppato in Italia, paese che per questo possiede il maggior numero di teatri d'opera al mondo e ha tra i suoi maggiori vanti l'essere universalmente considerata la patria dell'opera.
Tra i numerosi sinonimi, più o meno appropriati, basta ricordare melodramma, opera in musica, teatro musicale e opera lirica, espressione largamente impiegata dal linguaggio comune e mediatico. Il termine è fortemente contestualizzato nel suo impiego, in quanto il vocabolo opera, in italiano, è un termine di origine latina che indica un lavoro in generale, particolarmente in ambito artistico[2].
Dall'agosto 2013, l'Associazione Cantori Professionisti d'Italia ha depositato presso il MIBACT il dossier per la Candidatura UNESCO per l'opera italiana, con l'intento di iscrivere l'opera all'interno del Patrimonio dell'Umanità protetto da UNESCO.
Il teatro di prosa opera per mezzo di scenografie e costumi e attraverso la recitazione. Il testo letterario appositamente composto, che contiene le battute pronunciate dai personaggi e le didascalie, è denominato libretto. I cantanti sono accompagnati da un complesso strumentale di dimensioni variabili, anche di una grande orchestra sinfonica. Fin dal suo primo apparire, l'opera accese appassionate dispute tra gli intellettuali, tese a stabilire se l'elemento più importante fosse la musica o il testo poetico.
I soggetti rappresentati sono vari e possono corrispondere a taluni sottogeneri: serio, buffo, giocoso, semiserio, farsesco.
L'opera si articola convenzionalmente in vari numeri musicali, che includono sia momenti d'assieme (duetti, terzetti, concertati, cori, balletti) sia assoli (arie, ariosi, romanze, cavatine, cabalette).
In realtà oggi il successo di un'opera deriva da un insieme di fattori alla cui base, oltre alla qualità della musica (che dovrebbe andare incontro al gusto prevalente, ma che talvolta presenta tratti di forte innovazione), vi è l'efficacia drammaturgica del libretto e di tutti gli elementi di cui si compone lo spettacolo teatrale.
Un'importanza fondamentale rivestono dunque anche la messinscena (scenografia, regia, costumi ed eventuali coreografie), la recitazione ma, soprattutto, la qualità vocale dei cantanti. Se le risorse per una produzione scenica sono insufficienti, soprattutto se il lavoro richiede una messa in scena particolarmente elaborata, l'opera può essere eseguita in forma di concerto.
La storia dell'opera abbraccia un arco temporale di oltre quattro secoli, dalla fine del XVI al presente. Dopo la metà del secolo XX la produzione di nuove opere si è ridotta sensibilmente, anche a causa dell'affermarsi di nuove forme di spettacolo e intrattenimento, non più legate alla dimensione del teatro, quali la cinematografia, la radiofonia e la televisione.
Fino a quasi tutto l'Ottocento l'opera italiana è suddivisa in numeri musicali: arie, duetti, terzetti, concertati, cori, balletti, ecc.
Nel XVIII secolo singoli numeri sono raccordati da recitativi accompagnati solo dal basso continuo, noti come recitativi secchi, nei quali si era evoluto il "recitar cantando" del melodramma della fine del XVI secolo. Nel teatro musicale comico francese e tedesco (vale a dire nei generi dell'opéra-comique e del singspiel) i recitativi secchi sono sostituiti da dialoghi parlati.
Aria e recitativo hanno convissuto a lungo nel secondo Settecento e nei primi anni dell'Ottocento, finché il recitativo secco non cadde in disuso, venendo sostituito completamente da quello accompagnato dall'intera orchestra, ma sopravvivendo un po' più a lungo nell'ambito del teatro comico. Il recitativo accompagnato sarà invece inglobato nel numero insieme all'aria con la denominazione di scena. 
I cantanti, e i ruoli che essi interpretano, sono distinti in rapporto al registro vocale.
Le voci maschili sono denominate, dalla più grave alla più acuta, basso, baritono, tenore. A essi si possono aggiungere le voci di controtenore (o contraltista) e di sopranista, che utilizzano un'impostazione in falsetto a imitazione della voce femminile. Esse eseguono ruoli un tempo affidati ai castrati.
Le voci femminili sono classificate, dalla più grave alla più acuta, come contralto, mezzosoprano e soprano. Anch'esse eseguono oggi, molto più di frequente delle corrispondenti voci maschili, i ruoli sopranili e/o contraltili scritti per le voci dei castrati.
La storia dell'opera abbraccia un arco cronologico-temporale di oltre quattro secoli, dalla fine del XVI al presente. Le origini dell'opera si fanno risalire al passaggio tra il XVI e il XVII secolo, quando un gruppo di intellettuali fiorentini, noto come Camerata de' Bardi, dal nome del mecenate che li ospitava, decide di formalizzare il nuovo genere. Le sue radici storiche risalgono per altro al teatro medievale e ad artisti come Guido d'Arezzo, un religioso italiano emulato in seguito anche all'estero, tipico esempio è dato dalla religiosa benedettina Ildegarda di Bingen, quest'ultima nota per l'opera drammatica Ordo Virtutum composta nel 1151 circa, mentre le radici ideali affondano nel teatro antico e in particolare nella tragedia classica. D'altronde già la commedia dell'arte cinquecentesca prevedeva al suo interno l'uso delle canzoni, così come il ballet de court francese ed il masque inglese mescolavano voci, strumenti, scene, mentre i drammi pastorali comprendevano ampi spazi musicali.
L'opera ha poi enorme diffusione in età barocca, affermandosi soprattutto a Roma e Venezia. Spettacolo inizialmente riservato alle corti, e dunque destinato a una élite di intellettuali e aristocratici, acquista carattere di intrattenimento a partire dall'apertura dei primi teatri pubblici, nel 1637 il Teatro San Cassiano a Venezia, il primo teatro moderno per struttura, per organizzazione, per gestione (basti pensare al palcoscenico con fondali dipinti intercambiabili, la platea e i palchetti da affittare) e nel 1639 il Teatro Santi Giovanni e Paolo di Venezia.
Tra i soggetti preferiti ci sono, nel corso del XVII secolo, i poemi omerici e virgiliani e le vicende cavalleresche, in particolare quelle narrate da Ludovico Ariosto e Torquato Tasso, con l'aggiunta di spunti comici, erotici, fantasiosi. La musica è caratterizzata dall'onnipresente basso continuo, arricchito dalla presenza di strumenti a fiato e ad arco.
Alla severità dell'opera degli esordi, ancora permeata dell'estetica tardo-rinascimentale e che trova l'espressione più alta e originale nella figura di Claudio Monteverdi, subentra allora un gusto per la varietà delle musiche, delle situazioni, dei personaggi, degli intrecci; mentre la forma dell'aria, dalla melodia accattivante e occasione di esibizione canora, ruba sempre più spazio al recitativo dei dialoghi e, di riflesso, all'aspetto letterario, mentre il canto si fa sempre più fiorito.
Nel frattempo, il compositore italiano naturalizzato francese Jean-Baptiste Lully dà vita all'opera francese, Henry Purcell fa nascere l'opera inglese e Heinrich Schütz dà origine all'opera tedesca.
In quest'ultima la frequente cantabilità che riscontriamo nelle opere italiane, poco adatta per la musica francese, viene abbandonata e si lascia spazio a una interpretazione musicale del testo.
Lo stile di canto, più severo e declamatorio, è prevalentemente sillabico. Ulteriori elementi di differenziazione rispetto al modello italiano sono costituiti dall'importanza assegnata alle coreografie e dalla struttura in cinque atti, che l'opera seria francese conserverà fino a tutto il XIX secolo. Nacquero così la tragédie lyrique e l'opéra-ballet.
Dalla fine del Seicento, le arie dell'opera italiana si compongono di due strofe poetiche intonate col "da capo", ossia ripetendo, con qualche variazione di stile, la prima strofa. Una forma impiegata fino alla fine del XVIII secolo. È questo il secolo nel quale l'opera italiana è riformata dai poeti Apostolo Zeno e Pietro Metastasio, i quali stabiliscono una serie di canoni formali, relativi sia all'impianto drammaturgico che alla struttura metrica delle arie, applicando le cosiddette unità aristoteliche e dedicandosi esclusivamente al genere serio.La scelta di Zeno e Metastasio di escludere ogni elemento comico dal teatro musicale serio determina la nascita dell'opera comica, dapprima in forma di intermezzo, poi come opera buffa.
Georg Friedrich Händel fu uno dei maggiori compositori del Settecento ed oggi molte sue opere sono eseguite frequentemente; tra queste, soprattutto Giulio Cesare, Rinaldo, Ariodante e Tamerlano.
La seconda metà del XVIII secolo registra anche l'azione riformatrice di Gluck e Mozart, in qualche misura anticipata, in Italia, da quella di Niccolò Jommelli e Tommaso Traetta. La riforma consiste in una riduzione dell'ampollosità e della retorica canora a vantaggio di un chiaro svolgimento dell'azione e di una maggiore aderenza della musica a situazioni e personaggi. La struttura del melodramma italiano, in particolare, col passare dei decenni, si era infatti cristallizzata in una meccanica successione di recitativi e arie. Gluck realizza la sua riforma nell'ambito dell'opera seria, mantenendosi entro il filone di una classicità espressivamente austera, entro i generi dell'opera italiana prima e dell'opera francese poi; Mozart sviluppando liberamente il genere di ascendenza goldoniana del dramma giocoso, nelle sue opere italiane più famose, nonché dando impulso alla nascente opera tedesca.
Ancora oggi Don Giovanni, Le nozze di Figaro, Die Zauberflöte e Il ratto dal serraglio di Mozart sono tra le opere maggiormente eseguite nel mondo. Intanto in Francia divampa la querelle des bouffons, un'accesa polemica tra i sostenitori dell'opera buffa italiana (tra cui gli enciclopedisti e in particolare Jean-Jacques Rousseau) e i seguaci dell'opera francese, scatenata dalla rappresentazione di un intermezzo di Pergolesi, La serva padrona.
Nella seconda metà del Settecento alcuni dei più importanti maestri italiani, quali Piccinni e Sacchini e, più tardi, Cherubini e Spontini, si stabiliscono a Parigi, ma lo scontro fra le tradizioni e le scuole operistiche italiana e francese non cessa, traducendosi nell'ennesima disputa parigina, che vede contrapposti i seguaci di Piccinni e quelli di Gluck.
Gli anni che vanno dal 1810 al 1823 sono dominati in Italia dalla figura di Gioachino Rossini, che da un lato porta a compimento l'esperienza dell'opera buffa, abbandonando la commedia realistica in favore di una comicità assoluta, con punte di moderno surrealismo, dall'altro ingloba nel genere serio elementi di importazione francese. Lo stesso Rossini, trasferitosi a Parigi, inaugura con Guillaume Tell il genere del grand opéra, destinato a un'enorme fortuna nei decenni seguenti.
Dopo di lui, in Italia, la distinzione tra i generi si attenua progressivamente. Situazioni e personaggi di commedia sono integrati sempre più spesso nel teatro drammatico, proseguendo di fatto il breve esperimento dell'opera semiseria. Più in generale, nel periodo post-rossiniano la componente aulica e moraleggiante lascia spazio all'elemento propriamente lirico, e in queste opere, che si collocano in una posizione sospesa fra l'estetica classica e quella romantica, assistiamo al trionfo del belcanto, liberato da ogni retorica.
Una sterzata verso un romanticismo di gusto francese o al più inglese, carico di contrasti drammatici ma anche caratterizzato da esplicite incursioni nel realismo, viene dal teatro di Giovanni Pacini, Saverio Mercadante, Vincenzo Bellini e Gaetano Donizetti. Sulla loro scia, ma con una maggiore attenzione alla rappresentazione, diretta o metaforica, della realtà storica dell'Italia contemporanea e con una ben più organica visione drammaturgica, si colloca la figura di Giuseppe Verdi, autore di alcune delle opere più famose ed eseguite di sempre, quali Nabucco, Rigoletto, Il trovatore, La traviata, Aida, Otello e Falstaff.
In questa fase, che termina all'incirca con gli anni sessanta del XIX secolo, si assiste a una progressiva dilatazione delle forme chiuse, in particolare del numero, in favore di una nuova continuità drammaturgica.
Nel frattempo, l'opera francese sviluppa i generi contrapposti del grand opéra (con messe in scena sfarzose e balli) e dell'opéra-comique (con i dialoghi parlati), ciascuno legato a un teatro parigino. Con la seconda metà del secolo si impone però un nuovo genere intermedio, l'opéra-lyrique, elaborato da Charles Gounod a partire dal Faust.
Il modello francese ha un impatto decisivo anche sulla produzione operistica italiana degli anni settanta e ottanta dell'Ottocento, nella fase storica nota come "transizione", durante la quale, mentre decadono le vecchie forme convenzionali, si afferma il genere della Grande opera, rivisitazione italiana del vecchio grand opéra francese.
Assai meno fortunato rispetto al precedente, ma destinato a incidere ben più a lungo e ben più in profondità sull'evoluzione del teatro musicale europeo è il modello alternativo di Richard Wagner. Muovendo da una debole tradizione operistica tedesca - i cui maggiori esponenti erano stati finora Mozart, Beethoven (Fidelio) e Weber (Der Freischütz) - Wagner rivoluzionò dalle fondamenta il genere operistico, eliminando le forme chiuse e il protagonismo dei cantanti e strutturando le sue partiture in chiave sinfonica intorno ai leitmotiv (temi conduttori). Il suo nuovo linguaggio, estremamente ardito, è alle radici della musica moderna e nei decenni seguenti fu assorbito anche dalle scuole operistiche italiana e francese. Più indipendente si mantenne la nascente scuola russa, con Michail Glinka prima e il Gruppo dei Cinque poi, che muoveva da premesse nazionalistiche.
In Italia il modello musicale wagneriano e quello teatrale-drammaturgico (e, in minor misura, lirico-musicale) dell'ultimo Verdi furono assorbiti e rielaborati in modo originale dai compositori della Giovane Scuola, affermatasi a partire dall'ultimo decennio del secolo, fra cui Pietro Mascagni, Ruggero Leoncavallo, Umberto Giordano, Francesco Cilea e soprattutto Giacomo Puccini autore di opere divenute celebri quali Manon Lescaut, La bohème, Tosca, Madama Butterfly. Vanno infine segnalati gli apporti alla poetica della giovane scuola da parte di musicisti di "transizione", come Amilcare Ponchielli, Arrigo Boito e Alfredo Catalani, e del francese Georges Bizet, che con Carmen aveva aperto nuove strade alla lirica europea del tempo.
In questo periodo gli operisti italiani, accantonati i soggetti storici della grande opera, si orientarono tuttavia verso drammaturgie di tipo realista o addirittura verista (con la nascita del genere vero e proprio dell'opera verista), ben più affini a quelle del teatro musicale francese del secondo Ottocento, in particolare al genere dell'opéra-lyrique.
Dopo la metà del XX secolo la produzione di nuove opere si è ridotta sensibilmente, anche a causa dell'affermarsi di nuove forme di spettacolo e intrattenimento quali la cinematografia, la radiofonia e la televisione.
Nel corso della storia si sono formati vari generi di opera lirica, con una continua contaminazione e derivazione di una dall'altra categoria, per seguire i gusti del pubblico o per creare da parte degli artisti soggetti e lavori originali. 
L'opera seria è un genere tipico dell'opera italiana. Si contrappone storicamente al genere dell'opera buffa, al punto tale che la decadenza di quest'ultima, nel corso del XIX secolo, finì per renderne prima incerti, poi irriconoscibili i contorni. I temi portanti dell'opera seria sono il dramma e le passioni umane.
Si sviluppò a Napoli nella prima metà del XVIII secolo come opera comica e da lì migrò a Roma e nel nord Italia. Compositori famosi, compreso Mozart, Rossini, Donizetti e altri ancora, diedero un largo contributo allo sviluppo di questo genere operistico.
Il melodramma giocoso o dramma giocoso è un genere operistico che ebbe origine in Italia verso la metà del XVIII secolo. Il termine venne per la prima volta usato da Giovanni Cosimo Villifranchi come prefazione al suo lavoro comico L'Ipocondriaco, però fu Carlo Goldoni che iniziò ad impiegarlo regolarmente dal 1748. Un dramma giocoso ha un intreccio sentimentale o patetico concluso da un lieto fine e si colloca quindi a metà strada tra l'opera seria e l'opera buffa.
L'opera semiseria è un genere operistico in cui convivono personaggi, forme e stili tratti dall'opera seria e dall'opera buffa. Storicamente il genere semiserio si affermò in Italia negli ultimi decenni del Settecento, sul modello della pièce au sauvatage francese. 
La farsa è genere operistico diffuso tra l'ultima decade del XVIII secolo e le prime tre del XIX secolo principalmente a Venezia e a Napoli e in misura minore nel resto d'Italia. Si trattava normalmente di un'opera di carattere buffo con un solo atto, a volte rappresentata insieme a dei balletti.
Il Singspiel (termine che significa letteralmente "recita cantata") è un genere operistico in voga tra il XVIII e il XIX secolo, sorto e sviluppatosi in area tedesco-austriaca, caratterizzato dall'alternanza di parti recitate e parti cantate. A differenza dell'opera italiana, che prevede recitativi cantati, nel Singspiel i recitativi sono perciò recitati, in lingua tedesca, come nel teatro di prosa.
L'opéra-comique è un genere operistico francese che conteneva dialoghi parlati. Essa derivò dal vaudeville dei Theatres di St Germain e St Laurent (ed in misura minore dal teatro della Comédie-Italienne). Il genere ebbe inizio con l'opera Télémaque di Alain-René Lesage del 1715 ed ebbe termine soltanto nel XX secolo.
Il grand opéra è un genere operistico che ha dominato la scena francese fra gli anni venti e gli anni ottanta dell'Ottocento, sostituendosi alla tragédie lyrique molto in voga nel XVII e XVIII secolo. I primi esempi compiuti di grand opéra sono: La muta di Portici (La muette de Portici) di Auber (1828) e Guglielmo Tell (Guillaume Tell) di Rossini (1829).
Musikdrama, in italiano dramma musicale, è un termine tedesco usato per indicare l'unità di prosa e musica. Coniato da Theodor Mundt nel 1833, è stato adottato dal compositore Richard Wagner, assieme al neologismo Gesamtkunstwerk (opera d'arte totale), per definire le proprie opere, come L'olandese volante, Tannhäuser e Lohengrin, la Tetralogia, Tristano e Isotta, I maestri cantori di Norimberga e Parsifal.
Il karate-dō (空手道? lett. "via della mano vuota"), anche noto semplicemente come karate o anche adattato in caratè, è un'arte marziale originaria dell'isola di Okinawa, nel Regno delle Ryūkyū, le cui isole nel 1879 vennero annesse al Giappone[1][2] con il nome di "Prefettura di Okinawa". Venne sviluppato dall'unione tra i metodi di combattimento indigeni, chiamati te (手? lett. "mano"), e il quanfa cinese[3][4] a seguito degli stretti contatti culturali e commerciali tra gli abitanti dell'arcipelago e i navigatori cinesi.
Nel corso del diciottesimo secolo ci si riferiva a tale arte marziale con il nome di tōde o tō-te (唐手? mano cinese), ma con il passare del tempo si è privilegiato il nome karate[5], dato da una differente lettura del kanji '唐'. Negli anni '30 del novecento, a causa del crescente militarismo giapponese,[6] il primo carattere venne sostituito con '空', mantenendo così la lettura karate ma assumendo un nuovo significato, ovvero sia che i nipponici avevano sviluppato una forma di combattimento originale, sia che si trattava di un metodo di combattimento a mani nude.[7] Secondo Gichin Funakoshi, l'aggiunta del carattere dō (道? lett. "via") si deve far risalire al 1929/1930, anni nei quali i membri del club di karate dell'Università Keio decisero di cambiare nuovamente il nome per differenziarlo dalle arti cinesi.[8]
La diffusione del karate al di fuori dell'isola di Okinawa iniziò nel 1922, quando il Ministero dell'Educazione Giapponese invitò Gichin Funakoshi a Tokyo per una dimostrazione di karate, la National Athletic Exhibition,[9] e successivamente nel 1924 l'Università Keio istituì in Giappone il primo club universitario di karate, al punto che nel 1932 tutti i maggiori atenei nipponici avevano il proprio circolo.[10] Dopo la seconda guerra mondiale Okinawa divenne un importante sito militare statunitense, e il karate divenne popolare tra i soldati stanziati sulle isole.[11]
Questa arte marziale prevede soprattutto il combattimento a mani nude, senza l'ausilio di armi, anche se la pratica del kobudō di Okinawa, che prevede l'uso delle armi tradizionali (Bo, Tonfa, Sai, Nunchaku, Kama), è strettamente collegata alla pratica del karate, e alcune scuole e stili integrano la pratica del karate con lo studio delle armi. Attualmente viene praticato nel mondo in due differenti versioni, quella sportiva (nella quale è privato della sua componente marziale e finalizzato ai risultati competitivi tipici dell'agonismo occidentale) e quella tradizionale più legata ai precetti originali e alla difesa personale. In passato era studiato e praticato solo da uomini, ma con il passare degli anni anche le donne si sono avvicinate a questa disciplina.
Originariamente, quest'arte marziale aveva il nome di tōde o tō-te (唐手? mano della dinastia Tang) o, semplicemente, te (手? mano). Il primo utilizzo scritto della parola karate è da attribuirsi ad Itosu Ankō, che utilizzò il carattere 唐?, mentre il primo utilizzo documentato della grafia 空手? risale al 1905 ed è da attribuirsi a Chōmo Hanashiro in Karate Shoshu Hen.[12] Riguardo a quale delle due grafie fosse quella originale per la parola karate, Gichin Funakoshi scrive:Poiché non esiste materiale scritto, non sappiamo se il kara fosse originariamente scritto con il carattere 唐?, che significa "Cina" o con il carattere 空?, che significa "vuoto". Nel periodo in cui la Cina, e tutto ciò che poteva essere definito cinese, godeva della massima popolarità nelle Ryūkyū, il primo carattere veniva impiegato come sinonimo di alta qualità. Sotto questa influenza, il karate ha cominciato ad essere scritto con questo carattere perché gli fosse conferita una nota di classe o di eleganza. — Gichin Funakoshi[13]Lo stesso Gichin Funakoshi utilizzò nomi diversi nei titoli dei suoi libri: nel 1922 utilizzerà la dicitura tō-te o karate (唐手?), nel 1925 il termine karate-jutsu (唐手術?) e, nel 1935 e in tutte le pubblicazioni successive utilizzerà karate-dō (空手道?). Questi ultimi due sono dei chiari calchi dei nomi delle arti marziali giapponesi che utilizzavano gli affissi jutsu edō per descrivere, rispettivamente, una tecnica marziale concentrata sull'esecuzione e una via marziale che aggiunge un importante fattore di sviluppo dell'individuo.
Riguardo all'adozione del termine karate (空手?) Morio Higaonna scrive:Nel 1933 l'arte del karate di Okinawa fu riconosciuta come un'arte marziale giapponese dal Comitato di arti marziali giapponesi noto come "Butoku Kai". Fino al 1935, "karate" era scritto come "唐手?" (mano cinese), ma, nel 1935, i maestri dei vari stili di karate di Okinawa si sono riuniti per decidere un nuovo nome per la loro arte. Decisero di chiamare la loro arte "karate" scritta in caratteri giapponesi come "空手?" (mano vuota). — Morio HigaonnaDescrivere in modo dettagliato l'evoluzione del karate risulta difficile per mancanza di fonti storiografiche certe.
Si possono solo formulare ipotesi riguardo alla nascita e alla diffusione iniziale di quest'arte marziale, utilizzando rare fonti costituite perlopiù da racconti e leggende trasmessi oralmente. Dal XIX secolo in poi, la storia risulta più chiaramente documentata.
La storia del karate parte da un arcipelago a sud del Giappone, le isole Ryūkyū, e in particolare da una di queste, l'isola più grande: Okinawa, dove già esistevano alcune forme di combattimento note come te.
L'isola di Okinawa era divisa in tre principati: Hokuzan (北山 Montagna settentrionale), Chūzan (中山 Montagna centrale) e Nanzan (南山 Montagna meridionale). Per molti secoli Okinawa – nell'arcipelago dei tre regni delle Ryu-kyu, che allora erano stati a sé, indipendenti dal Giappone – aveva mantenuto rapporti commerciali con la provincia cinese del Fujian e fu così, probabilmente, che conobbe alcune arti marziali cinesi come il kenpo o quanfa («metodo del pugno») – nato secondo la tradizione nel monastero di Shàolín-sì – modificandolo col passare degli anni secondo metodi locali.
Shō Hashi (soprannominato Shang Bazhi), re di Chuzan, nel 1429 unificò i tre regni di Okinawa e in seguito anche tutti i regni delle Ryu-kyu. Poco più tardi, Sho Shin (che regnò dal 1478 al 1526), per mantenere la pace, intorno al 1500 vietò il possesso di armi, che furono raccolte e chiuse in un magazzino del castello di Shuri.
Dopo la battaglia di Sekigahara, il clan vittorioso dello shogunato Tokugawa concesse al clan Shimazu, che governava il bellicoso feudo di Satsuma nell'isola di Kyūshū, di occupare le Ryu-kyu: 3000 samurai compirono l'invasione senza incontrare valida resistenza (1609).
Poiché fu rinnovato il divieto di possedere armi e persino gli utensili di uso quotidiano come bastoni e falcetti dovevano essere chiusi nei magazzini durante la notte, i membri della classe nobiliare si dedicarono in segreto allo studio di una forma di autodifesa da usare contro gli invasori.
Nacque così la scuola Okinawa-te («mano di Okinawa»), detta anche tōde («mano cinese», dove l'ideogramma to caratterizza la dinastia Tang), che si differenziava in tre stili: Naha-te, sul modello del kung-fu della Cina meridionale, Shuri-te e Tomari-te, sul modello del kung-fu della Cina settentrionale. Va precisato che Naha era la capitale dell'isola di Okinawa, Shuri la sede del castello reale e Tomari la zona del porto (oggi Shuri e Tomari sono quartieri di Naha)[14].
L'ideogramma te (手) letteralmente indica la parola "mano", ma per estensione può anche indicare "arte" o "tecnica"; il significato di Okinawa-te, quindi, è "arte marziale di Okinawa".
Essa era praticata esclusivamente dai nobili, che la tramandavano di generazione in generazione. Secondo le credenze popolari, come detto sopra, la nascita del karate è dovuta alla proibizione dell'uso delle armi nell'arcipelago delle isole Ryūkyū. La conoscenza del te restava uno dei pochissimi segni di appartenenza passata a un'elevata posizione sociale. Per questo motivo i nobili, ormai divenuti contadini, tramandavano quest'arte a una cerchia ristrettissima di persone, quasi in modo esoterico.
Così facendo si è avuta una dispersione dell'arte originale e furono gettate le basi per i vari stili di karate. Per la nascita del tode furono fondamentali anche le arti marziali cinesi: le persone che si recavano in Cina, anche per due o tre anni, avevano modo di studiare le arti marziali del luogo e, in molti casi, cercarono di apprenderle; però le arti marziali cinesi si basavano su concetti filosofici e su un'elaborata concezione del corpo umano, pertanto era impossibile imparare le arti cinesi nello spazio di un solo viaggio, e con ciò i viaggiatori giapponesi appresero quel che potevano.
Si pensa quindi che sia stata possibile una sorta di fusione tra le arti arrivate dalla Cina, che comunque costituivano uno stile non metodico, e il te okinawense. Una prova di questo importante scambio culturale tra Okinawa e Cina è fornita da un maestro vissuto in epoca successiva, Ankō Itosu. In uno scritto di suo pugno vede le origini del karate nelle arti cinesi e sottolinea come non abbiano influito né il Buddhismo né il Confucianesimo.
Il primo maestro delle Ryu-kyu fu Sakugawa Kanga di Shuri (1733-1815), nobile di Okinawa ed esperto di te; era soprannominato “Tode” perché combinò il kempo, da lui studiato in Cina, con le arti marziali di Okinawa. Egli fu il primo maestro che provò una razionalizzazione e una codificazione delle arti diffuse a Okinawa. Tuttavia trascorse ancora qualche decennio prima dello sviluppo di una vera e propria scuola di tode.
Il fondatore di questa scuola fu il suo allievo Matsumura Sōkon (1809-1901); egli fu maestro di Asato Ankō (o Azato 1827-1906), a sua volta maestro di Funakoshi Gichin (1868-1957), e Itosu Ankō (1830-1915), anch'egli maestro di Funakoshi e di altri importanti maestri come Motobu Chōki (1870-1944), Motobu Chōyū (1865-1928), Chibana Chōshin (1885-1969), Mabuni Kenwa (1889-1952) e Tōyama Kanken (1888-1966).
Il suo stile di tode era chiamato Shuri-te (arte marziale di Shuri) in quanto Matsumura era residente proprio nella città di Shuri. Egli basò il proprio insegnamento su tre punti fondamentali: la pratica dell'arte autoctona di Okinawa, l'arte giapponese della spada (Jigen-ryū) e la pratica delle arti cinesi. Nacque così il vero e proprio tode.
Anko Itosu introdusse il to-de nelle scuole di Okinawa e mise a punto i cinque kata detti Pinan (presenti nel karate degli stili come il Wado-Ryu e Shito-Ryu; questi kata cambiarono poi il nome in Heian[15]).
Il primo maestro di Okinawa a recarsi in Giappone fu Motobu Chōki di Shuri (1871-1944), straordinario combattente, ma illetterato, che perciò non ottenne grande successo come insegnante. Solo più tardi, con l'arrivo di Funakoshi, divenuto poi maestro, l'Okinawa-te poté diffondersi nel paese del Sol Levante.
Si dice che il primo maestro di Naha-te fosse Higaonna Kanryō, noto anche come Higashionna (1853-1915; secondo alcune fonti la nascita sarebbe nel 1840). Kanryio Higaonna aiutò molto Funakoshi nella diffusione del karate in Giappone. Con questa diffusione, l'Okinawa-te divenne così il karate.
Gichin Funakoshi nacque a Shuri.
Bambino gracile e introverso, si appassionò alle arti di combattimento: studiò con Azato, padre di un suo compagno di scuola e maestro di svariate arti marziali, poi con Itosu, quindi con Matsumura. Era non solo un abile calligrafo, ma conosceva anche i classici cinesi; pertanto nel 1888 cominciò a insegnare in una scuola elementare.
Nel 1921 passò per Okinawa il principe Hirohito, diretto in Europa, e nel castello di Shuri, Funakoshi organizzò un'esibizione che fu molto apprezzata. Lasciato l'insegnamento, nella primavera del 1922 Funakoshi fu scelto per eseguire una dimostrazione di karate alla Scuola Normale Superiore Femminile di Tokyo, ove si stabilì[9].
Nel 1922 scrisse "Ryu-kyu kempo": karate (karate significava ancora «mano cinese» e i nomi dei kata erano quelli originari di Okinawa).
Nel 1935 pubblicò "Karate-do kyohan", molti anni dopo tradotto dal maestro Tsutomu Ōshima.
I primi anni furono difficili soprattutto sotto l'aspetto economico. Nel 1931 il karate fu ufficialmente riconosciuto dal Dai Nippon Butoku Kai, l'organizzazione imperiale per l'educazione della gioventù. Dopo aver utilizzato un'aula del Meisei Juku (un ostello per studenti di Okinawa nel quartiere Suidobata), per qualche tempo Funakoshi fu ospite nella palestra del maestro di scherma Hiromichi Nakayama.
Nel 1936, grazie al comitato nazionale di sostenitori del karate, venne costruito il dojo Shotokan («casa delle onde di pino») a Zoshigaya, sobborgo del quartiere speciale di Toshima a Tokyo. “Shoto” era lo pseudonimo che Funakoshi usava da giovane nel firmare i suoi poemi cinesi, "kan" invece vuol dire "sala".
Per facilitare la diffusione del karate in Giappone, gli ideogrammi tode e te, vennero assemblati. Si ottenne così la parola tote, ma l'ideogramma to, che si leggeva anche "kara" (ma col significato di «vuoto» sia nel senso di «disarmato», sia in riferimento allo stato mentale del praticante, concetto Zen di mu-shin), fu cambiato con questa lettura.
Pertanto l'ideogramma finale risultò karate. Vennero inoltre cambiati in giapponese i nomi originali delle tecniche e dei kata per renderli più comprensibili.
Nel dopoguerra il generale Douglas MacArthur proibì la pratica delle arti marziali, ritenute l'anima dello spirito militarista nipponico, ma a poco a poco l'interesse per il karate crebbe anche in Occidente e Funakoshi fu ripetutamente invitato a dare dimostrazioni.
Funakoshi lasciò la direzione dello stile Shotokan al figlio Yoshitaka, che trasformò profondamente lo stile elaborato dal padre, inserendovi attacchi lunghi e potenti, che facevano uso di nuove tecniche di calci. Yoshitaka morì di tubercolosi nel 1945.
Ricordiamo che la diffusione del karate nel Giappone si deve ai maestri Funakoshi e Higaonna, ma la diffusione di esso in tutto il mondo occidentale, si deve a un allievo di Chōjun Miyagi (che era un allievo di Higaonna): Jitsumi Gōgen Yamaguchi.
Dal karate nacquero poi diverse correnti di pensiero e il karate si divise così in vari stili.
Funakoshi divide le scuole e i kata del karate di Okinawa in due stili principali: shōrin-ryū (a cui attribuisce caratteristiche simili a quelle degli stili settentrionali di kung-fu) e shōrei-ryū (più simile al kung-fu meridionale). L'altra principale divisione degli stili di karate di Okinawa si basa sulla città di origine: Tomari, Naha e Shuri.
In generale, lo shōrin-ryū era associato allo Shuri-te e al Tomari-te, mentre lo shōrei-ryu era associato al Naha-te. Il Naha-te, ideato da Kanryō Higaonna diede vita ad alcuni stili di karate, il cui principale è il Gōjū-ryū, la cosiddetta "scuola dura e morbida" sviluppata dal maestro Chōjun Myiagi.
Lo Shuri-te e il Tomari-te videro una fusione sempre più profonda e diedero vita ad alcuni stili come il Wado-Ryu e lo Shotokan-ryu.
A Okinawa esiste una tradizione dove entrambi gli approcci shōrin e shōrei sono mescolati in uno stile unico, la cui maggiore scuola è quella di Kenwa Mabuni che insegna lo Shitō-ryū, anche se l'influenza maggiore di questo stile deriva dall'area shōrei.
I principali stili del karate sono:
Nel karate si sono formati molti altri stili, e talvolta all'interno di un Paese, ci sono dei maestri che si ritengono creatori di stili che non sono altro che copie di stili antichi o, comunque, già preesistenti. La World Karate Federation, che è l'unica organizzazione mondiale, che raggruppa le federazioni nazionali riconosciute dai rispettivi comitati olimpici, ed essa stessa riconosciuta dal CIO, riconosce solo I seguenti 4 stili di karate della lista:[17]
Anko Itosu ebbe il grande merito di introdurre il karate nelle scuole dell'epoca; a seguito delle prestigiose esibizioni del Maestro Gichin Funakoshi a Tokyo nel 1922, il karate venne conosciuto al di fuori dell'isola di Okinawa. Questi sono stati i quattro maestri che hanno determinato nel karate svolte di fondamentale importanza.
Funakoshi fu anche fondatore dello Stile Shotokan, che basa l'efficacia delle proprie tecniche su agili spostamenti e attacchi penetranti. Egli intese e insegnò il karate come "sistema di disciplina interiore" capace di condizionare tutti gli aspetti della vita dei praticanti, denominato più precisamente karate-dō.
Da allora il karate si è diffuso in gran parte del mondo, subendo anche cambiamenti discutibili che - secondo alcuni - lo hanno allontanato dallo spirito originale voluto dai suoi fondatori.
Il più grande ringraziamento che il praticante possa elevare è diretto ai maestri che insegnano a comprendere quest'arte e svelano, passo dopo passo, il Dō, la "via" è molto più della tecnica, è un lento e misterioso cammino dell'essere verso la propria perfezione, il proprio compimento.
Ogni scuola di karate tradizionale sintetizza per i propri allievi i principi morali che devono guidare la pratica e che ne costituiscono i fondamenti. Essi sono chiaramente enunciati nel dōjō kun, regole variabili da scuola a scuola, e nei nijū kun, unici per lo stile shotokan.
Dōjō kun indica le regole del dōjō, che variano a seconda della scuola. Quelli sotto riportati si riferiscono allo shotokan.
Il karate è fondamentalmente rispetto reciproco, sul quale si basa e il dōjō kun dovrebbe venire applicato anche al di fuori del dōjō. Infatti un esempio di questo principio è che nel kumite, praticato da certe palestre, non si può toccare l'avversario, mentre prima di salire sul tatami bisogna fare il saluto al Maestro.
I quattro lati del dōjō hanno particolari nomi: la Sede Superiore, ovvero dove sta il ritratto del Maestro fondatore dello stile che viene praticato è chiamato Kami-za, mentre il lato dove stanno gli allievi, per fare il saluto, è chiamato Shimo-za, ovvero sede inferiore. Nel saluto gli allievi sono sistemati in ordine di cintura, incominciando dalle nere con grado maggiore fino ad arrivare alle bianche. Il lato verso gli allievi di grado più alto è chiamato Jo-seki, mentre invece quello verso le bianche, quindi verso coloro con meno esperienza è chiamato Shimo-seki.
I venti principi fondamentali dello spirito del karate (松濤二十訓 Shōtō nijū kun?) insegnati dal maestro Gichin Funakoshi sono:[18]
In quasi tutte le arti marziali è uso allenarsi indossando un abito adeguato, chiamato gi (pronuncia: ghi); nel karate, quest'abito è il karate-gi, composto da una giacca (uwagi), da un paio di pantaloni (zubon) di cotone bianco e da una cintura (obi) il cui colore designa il grado raggiunto dal praticante non dal punto di vista fisico ma dal punto di vista della preparazione mentale e dell'esperienza.
Oltre al termine specifico "karate-gi", l'abito per la pratica del karate può essere chiamato genericamente "keikogi" o "dogi"; mentre molto in voga è il termine "kimono". Questa antica parola della lingua giapponese, che originariamente significava semplicemente "abito", ai nostri giorni viene usata per indicare uno specifico tipo di vestito tradizionale che nulla ha a che vedere con la pratica delle arti marziali.
Fu il maestro Gichin Funakoshi ad adottare per primo l'uso del "karate-gi".
Infatti, in occasione della prima dimostrazione al Budokan di Tokyo, lui e un suo allievo indossarono un abito fatto da Funakoshi stesso la notte precedente, ispirandosi al modello del judo-gi e utilizzando, però, una tela più leggera e comoda. Il colore bianco è quello naturale del cotone non tinto, essendo questo un abito semplice e umile.
In genere esistono tre tipi di karategi:
In molte arti del Budō (Kendō, Kyudo, Aikidō), per esercitarsi si indossa, invece, una gonna-pantalone (hakama) tipica giapponese ma mai utilizzata a Okinawa.
Si pratica a piedi scalzi.
La cintura nel karate è un riferimento che indica l'abilità, attestata dal superamento di appositi esami, nella pratica della disciplina di chi la indossa.
Nel 1924 Gichin Funakoshi, fondatore del Karate Shotokan, adottò il sistema dei "dan" dal fondatore del judo, Kanō Jigorō. Egli usò un sistema di gradi con un set limitato di colori di cintura. Anche gli altri insegnanti di Okinawa adottarono questa pratica. In precedenza gli allievi incominciavano la pratica con la cintura bianca; però non esistevano le cinture colorate: la cintura nera fu adottata da Kanō soltanto tre anni dopo l'invenzione del sistema di dan, prendendola dalla fascia nera indossata, nel nuoto, dagli atleti migliori. Quando Funakoshi adottò il sistema, comunque, le cinture erano già tre: bianca, marrone e nera, a cui si aggiunse, in seguito, la cintura verde (o blu, a seconda della testimonianza). Tuttavia il sistema di gradazione delle cinture può variare a seconda dello stile. Nel sistema kyū/dan i gradi per principianti cominciano con un kyū numerato in maniera crescente (ad esempio 9 kyū), e avanza in maniera decrescente fino al kyū di numero più basso. Il dan incomincia col 1 dan (Shodan, o "cominciando a dan") sino a giungere ai dan di grado più elevati. I gradi sono assegnati come una "cintura di colore" o mudansha ("uni senza dan"). I karateka con grado di dan sono assegnati come yudansha ("possessori del rango di dan"). Il yudansha porta tipicamente una cintura nera. I requisiti dei ranghi differiscono fra stili, organizzazioni e scuole. La minima età e il tempo nei gradi sono fattori promozione importanti.
L'esame consiste nel dimostrare le tecniche di fronte a una commissione di esaminatori. Questa varia da scuola a scuola, ma l'esame può includere tutto ciò che si è imparato fino a quel punto oppure nozioni nuove. La dimostrazione è una domanda per grado nuovo (shinsa) e può includere: kata, bunkai, l'autodifesa, routine, tameshiwari ("rompendo"), e/o kumite (combattimento). L'esame di cintura nera può includere anche una parte scritta.
Le cinture colorate vengono dette Kyū, mentre le cinture nere vengono dette Dan. Entrambe le parole significano "grado", "livello", ma la prima è comunemente utilizzata. Il primo livello di dan non è chiamato "ichi dan", che vorrebbe dire "primo grado", ma "sho dan", cioè "inizio del grado", a testimonianza del fatto che il raggiungimento della prima cintura nera è solo l'inizio di un lungo e severo apprendimento dell'Arte Marziale, in cui i livelli di kyū hanno il solo scopo di dare le basi necessarie a un apprendimento più approfondito.
CINTURE COLORATE, che si ottengono per esame:
CINTURE NERE, che si ottengono per esame:
CINTURE NERE, che si ottengono ad honorem per meriti od onorificenze:
Le classificazioni per i kyū variano da federazione a federazione, ed esistono, presso alcune scuole, ulteriori cinture intermedie (bianca, bianco-gialla, gialla, gialla-arancione, arancione, arancione-verde, verde, verde-blu, blu, blu-marrone, marrone, marrone-nera).
Dopo la cintura marrone si passa a cintura nera che rimane tale al raggiungimento di gradi superiori (dan), dal 1º in poi, anche se è possibile trovare federazioni che utilizzano la cintura bianco-rossa per il 6°, 7°, 8° dan e rossa per i 9º e 10º dan.
L'ideogramma dan si trova anche nella parola shodan, che significa "principiante", per dimostrare come l'aver impiegato alcuni anni per diventare cintura nera sia davvero poca cosa in confronto a tutti gli anni di allenamento che aspettano. Generalmente, le cinture si ottengono per esami fino al 5º dan, mentre dal 6º dan in poi, il grado viene assegnato solo per meriti speciali e non più in seguito a esami, anche se il modo in cui vengono rilasciati i più alti gradi dan può variare da federazione a federazione. Per i gradi più elevati non viene valutata solamente la mera capacità tecnica raggiunta ma soprattutto le doti di esperienza, didattica, organizzazione, sviluppo e dedizione a quest'arte marziale.
Bisogna però sottolineare come il formalismo relativo al vestiario e alle cinture incominciò solamente con lo sviluppo di massa del karate e quindi con la sua commercializzazione, soprattutto in occidente. Alle origini, il karate era praticato con i vestiti quotidiani, spesso solamente con la biancheria intima e non esistevano le graduatorie per cinture. Da molti praticanti di karate tradizionale, la cintura è considerata un simbolo di un certo livello di conoscenza e di percorso ma non possiede certo un valore meramente di grado.
Gichin Funakoshi interpretò il "kara" del karate-dō con il significato di "purificare sé stessi da pensieri egoisti e malvagi, perché solo con una mente e coscienza limpida il praticante può comprendere la conoscenza che riceve". Riteneva che il karateka doveva essere "interiormente umile ed esternamente gentile". Solamente comportandosi umilmente si può essere aperti alle molte lezioni del karate. Questo può essere fatto solamente attraverso l'ascolto e attraverso la ricezione delle critiche. Egli considerava la cortesia di primaria importanza. Diceva che "il karate viene propriamente applicato solo in quelle rare situazioni in cui uno deve davvero atterrare qualcuno o essere da lui atterrato". Funakoshi ha ritenuto insolito per un appassionato l'utilizzo del karate in uno scontro fisico reale più di una volta nella vita. Egli disse che i praticanti di karate "non devono mai essere facilmente trascinati in una lotta". Resta inteso che un colpo scagliato da un vero esperto potrebbe significare la morte. Risulta chiaro che coloro i quali fanno un uso distorto di ciò che hanno imparato portano disonore a sé stessi.[19]
Una peculiarità del karate è il fatto di stare a piedi nudi nello svolgere la lezione, questo ha motivazioni tecniche e formali, risponde a esigenze pratiche ed è volto al conseguimento della massima efficacia.
Ragioni fisiche: il piede è ricco di ricettori tattili che permettono di conoscere la conformazione del suolo senza interventi della vista; la struttura ossea del piede è arcuata così da restare parzialmente sospesa sul piano di appoggio. L'adattamento alle caratteristiche del suolo viene avvertito dai recettori di tensione dei tendini e delle articolazioni: il corpo risponde così alla percezione dell'inclinazione e della direzione di pendenza, adeguandosi alle mutevoli necessità dello stare eretti. Fare karate significa anche imparare a flettere, estendere e ruotare il piede, adattandolo al fine di ottenere un impatto efficace sul bersaglio.
Un'altra delle ragioni che chiariscono perché i praticanti di karate tradizionale non usino protezioni ai piedi affonda le sue radici nel passato, quando i samurai divennero imbattibili nell'uso della spada, si chiesero cosa sarebbe stato di loro se fossero stati sorpresi disarmati. Di qui la necessità di imparare a usare il corpo come un'arma e vennero sviluppate le prime tecniche a mano nuda: la loro evoluzione e quella delle forme di lotta che in esse si fusero, portò alla codificazione di sistemi di combattimento a mano disarmata sempre più articolati.
Lo stare a piedi nudi è un segno di umiltà, rispetto e di volontà di affrontare l'allenamento con la mente vuota dalle preoccupazioni quotidiane.
A seconda dei vari stili di karate, il karate si compone di numerosissime tecniche: tecniche di pugno, di mano aperta, di gomito, calci, parate, cadute, spostamenti, posizioni e guardie.
Il karate prevede lo studio approfondito di tecniche di colpo dette "atemi waza", parola derivata dalla contrazione del verbo "ateru-colpire" e "mi-corpo". Si utilizzano pugni, calci (principalmente alle gambe e al tronco), gomitate, ginocchiate e colpi di percussione a mano aperta nelle zone sensibili del corpo umano (femore, articolazioni, fegato, gola, costole fluttuanti) al fine di provocare un trauma anatomico che neutralizzi l'avversario nel modo più veloce ed efficace possibile seguendo la regola del "minimo sforzo, massimo risultato".
Da segnalare che nello studio più avanzato dell'arte vengono esaminati anche gli "tsubo" o "punti di pressione" e particolarmente rilevante è il fatto che nel primo testo redatto dal maestro Funakoshi ("Karate-do Kyohan") un intero capitolo fosse dedicato all'anatomia umana a dimostrazione che non solo si deve imparare "come" colpire ma anche, e soprattutto, "dove".
Tutte queste tecniche sono corredate da un insieme di parate, schivate, spostamenti e scivolate atte a deflettere e intercettare gli attacchi oltre a proiezioni, spazzate, bloccaggi e leve articolari.
Non si deve però pensare al Judo o all'Aikido. Le proiezioni e le spazzate del karate non prevedono di "lanciare" l'avversario in lontananza (come nell'Aikido) ma di "sgretolarlo" sul suo centro, a terra, per impedirgli di contrattaccare e quindi finirlo con tecniche di colpo. Il karate, del resto, è primariamente un'arte di percussione sebbene il suo studio comprenda tutte le possibilità di combattimento.
Il Kihon è un termine che indica le tecniche di allenamento base, di parata o di attacco, su cui si basa il karate. In pratica, si tratta di esercizi propedeutici all'esecuzione tecnica nel karate.
Il kihon, nel karate, è l'insieme delle tecniche fondamentali.
In italiano potremmo tradurlo con le parole "basilare" o "rudimenti". La parola kihon è composta da due sezioni: Ki (fondamenta o radici) e Hon (base). Visualizzando gli ideogrammi delle due sezioni si nota che Ki è formato da due parti, una che simboleggia la terra e l'altra rappresenta l'inizio; Hon, invece, mostra un albero le cui radici sono rivolte verso il basso.
La parola Kihon ha dunque il significato della necessità di porre delle solide fondamenta, delle profonde radici per poter costruire qualche cosa di duraturo. Nella cultura giapponese viene data molta importanza alla preparazione prima di mettere mano a qualunque progetto ed è importante essere padroni delle basi di qualunque disciplina, prima di progredire in essa.
Come in qualsiasi altra disciplina, anche nel karate, senza una perfetta padronanza degli esercizi di base, non è possibile progredire e raggiungere notevoli livelli di pratica. Le basi del karate, i primi esercizi insegnati all'allievo, portano a imparare il corretto uso del proprio corpo, sia esso in movimento o statico.
Nella pratica del kihon si impara a migliorare la propria resistenza e a ottenere una maggiore rapidità nell'esecuzione; aiuta anche a rafforzare lo spirito combattivo e l'allievo apprende come gestire le "armi" del nostro corpo.
Il kime, nella pratica del Karate, può essere definito come "focalizzazione della massima potenza esplosiva del colpo" in un punto stabilito. Lo studio e la corretta comprensione di ogni singola tecnica, da parte dell'allievo, dovranno trovare quindi il loro naturale coronamento nello sviluppo del kime, conferendo ad ogni attacco e ad ogni parata la massima incisività, potenza e pulizia. Nessun praticante di Karate, dunque, può aspirare a progredire verso i gradi superiori della disciplina se non è in grado di applicare un buon kime durante l'esecuzione delle tecniche. Lo stesso principio si applica, a maggior ragione, nelle manifestazioni agonistiche, nelle quali il kime è uno degli elementi fondamentali di valutazione dell'atleta.
Il kata è un combattimento contro più avversari immaginari. Si tratta di una serie di movimenti codificati che rappresentano varie tecniche di combattimento, in modo da evidenziarne i principi fondanti e le opportunità di esecuzione ottimali (spazio, tempo e velocità).
Nel Kata, che significa "forma", si racchiudono le tecniche diffuse dalle varie scuole. Il karate ha una vasta gamma di kata che si differenziano nei diversi stili e per i diversi kyū. I kata possono essere visti come delle tecniche marziali prestabilite, per la maggior parte, nelle otto direzioni dello spazio. Il kata non viene considerato come un combattimento simbolico eseguito a vuoto, ma come un combattimento contro uno o più avversari.
Il numero dei kata, ma anche i loro nomi e i kata stessi, cambiano in base alla scuola ("stile") che si pratica.
Gli elementi fondamentali per eseguire un buon kata sono[20]:
E da un punto di vista atletico:
La maggior parte delle volte, un kata (nelle gare a squadre) è seguito dal bunkai, cioè la messa in pratica delle tecniche e la dimostrazione dell'efficacia delle tecniche e dei movimenti;
solitamente le squadre sono formate da tre persone e, solo in Italia, vige la regola per cui il Torei (colui che si difende) deve essere unico.
Bunkai letteralmente significa "smontare" e indica lo studio per l'applicazione pratica delle tecniche contenute nei kata. Lo studio di esse permette di estrapolare dai kata efficaci tecniche di difesa, molto spesso proiezioni, tecniche combinate, leve articolari e spazzate che sono nascoste magari all'interno di una tecnica di pugno o parata. Lo studio dei Bunkai Kata è uno dei più complessi dell'arte poiché richiede una chiave di lettura che si deve dedurre dallo stile del fondatore. È altresì uno degli argomenti più delicati per i teorici e gli studiosi dell'arte marziale poiché non possediamo documenti scritti sulla pratica del bunkai sebbene essa sia importantissima per la comprensione del karate.
Da ricordare, inoltre, come le tecniche dei kata derivino da tecniche di combattimento codificate e non il contrario. Ciò significa che le tecniche contenute nelle forme sono funzionali e non mera tradizione scolastica.
Il termine bunkai (分解? "caratteri Han") è utilizzato nelle arti marziali giapponesi per indicare la spiegazione testuale e palese di un gesto simbolico contenuto in un esercizio formale (kata). La parola è formata da due kanji che significano rispettivamente “porzione” e "slegare" e uniti servono a indicare l'atto di ricondurre qualcosa di complesso alle sue parti essenziali.
Kata bunkai significa letteralmente "kata smontato", cioè applicato. Mentre i kata vengono svolti con un avversario (o più) immaginario, il kata bunkai viene svolto con avversario (o più) vero, pertanto si ha bisogno di un partner.
I bunkai sono normalmente eseguiti nel dojo o in esami per passaggi di grado, nello specifico per esami inerenti ai passaggi da secondo dan o superiori, con un partner o un gruppo di partner che danno una dimostrazione del significato delle tecniche eseguite in un kata oppure mettono in pratica un attacco predefinito cui occorre rispondere con un determinato kata. In questo modo l'allievo comprende i vari movimenti di cui è composto il kata e migliora la propria tecnica imparando a valutare i tempi, aggiustare le distanze e adattare la tecnica alle dimensioni dell'avversario.
Gichin Funakoshi (船越 義珍), disse: "Non ci sono dispute nel Karate". Prima della seconda guerra mondiale, in Okinawa, il kumite non era parte integrante dell'insegnamento. Shigeru Egami riferisce che, nel 1940, alcuni karateka furono cacciati dal dojo perché usavano il karate nelle risse in strada. Tra le caratteristiche del Kumite del Karate si nota che i colpi, con l'eccezione del Kyokushinkai (e degli stili a contatto pieno da esso derivati), non vengono affondati alla ricerca del knockout dell'avversario, ma vengono arrestati per ovvi motivi di incolumità. Le tecniche tuttavia devono dimostrare il loro potenziale ed essere eseguite, arrestandole con controllo per non arrecare eccessivi danni. Ciò è possibile grazie a un adeguato allenamento e a un opportuno regolamento di gara. Quest'ultimo infatti prevede, in linea di massima, un lieve contatto a livello addominale, nessun contatto con tecniche di braccio al volto e un lievissimo contatto con tecniche di calcio al volto (anche se esistono vari regolamenti e, per esempio, in alcune federazioni e in determinati stili il contatto è consentito). L'eventuale ausilio di protezioni preventive (conchiglia, paradenti, corpetto, paratibia-piede, guantini e maschera per il naso, abolita nel 2015/16 perché sembrava arrecare più danni che senza) e l'adozione di sanzioni adeguate e di opportune norme completano il regolamento nella massima tutela dei praticanti. Negli anni cinquanta, il maestro Mas Oyama creò il Kyokushinkai (Full Contact Karate) e da esso, successivamente, si svilupparono molti altri stili che facevano del contatto pieno il loro punto di forza.
Il karate di Okinawa usa un addestramento supplementare noto come Hojo undō (補助運動). Questo utilizza una semplice attrezzatura fatta di legno e pietra. Il makiwara è uno degli attrezzi più usati (allenamento all'impatto dei colpi).
Il "nigiri game" è un grande vaso usato per rinforzare la presa di mani e dita. Questi esercizi supplementari sono progettati per aumentare forza, capacità di resistenza, velocità e coordinazione muscolare.
Il karate sportivo enfatizza esercizio aerobico, anaerobico, potenza, agilità, flessibilità e gestione dello stress. Tutte le pratiche variano a seconda delle scuole e degli insegnanti.
Il karate sportivo è la forma sportiva del karate, modellata tra diversi stili, privata in gran parte della sua componente marziale e finalizzata alla sola competizione agonistica.[21]
La federazione mondiale del karate (WKF) è riconosciuta dal comitato olimpico internazionale (CIO) come responsabile per le competizioni di karate. La WKF ha sviluppato regole comuni che governano tutti gli stili. I WKF organisations nazionali coordinano coi loro rispettivi comitati olimpici nazionali.
Il karate è una disciplina olimpica. Ha raggiunto il numero di voti sufficiente nelle decisioni del Comitato Olimpico Internazionale nel 2016 e nel 2021 è stata presente alle olimpiadi di Tokyo.
Sul fronte karate sportivo va precisato che, oltre alla WKF, ci sono realtà diverse che enfatizzano il combattimento, nelle cui competizioni si può vincere anche per KO. Famoso è il Sabaki Challenge, dove ogni anno si sfidano atleti provenienti da ogni parte del mondo. Da menzionare, poi, i campionati mondiali di Kyokushinkai e Ashihara; entrambi caratterizzati da un numero rilevante di atleti internazionali.
Con il termine antica Grecia (o anche I Greci) si indica la civiltà sviluppatasi nella attuale Grecia, in Albania, nelle isole del Mar Egeo, sulle coste del Mar Nero (Turchia occidentale), nella Sicilia orientale e meridionale, sulle zone costiere dell'Italia meridionale (complessivamente denominate poi Magna Grecia), in Nordafrica, in Corsica, in Sardegna, sulle coste orientali della Spagna e quelle meridionali della Francia.
La cultura greca, nonostante la conformazione geografica del continente favorisse l'insorgere di molteplici unità politiche a sé stanti (le poleis), fu un fenomeno omogeneo, che interessò tutte le genti elleniche, accomunate dalla stessa lingua; attribuiva molta importanza alla conoscenza e alla ricerca della verità: per i greci avvicinarsi alla verità significava avvicinarsi alla divinità, pertanto attribuivano un carattere quasi religioso alla conoscenza e alle scienze; in questo contesto gli antichi greci avevano intuito l'importanza della matematica nella ricerca di una conoscenza più vicina alla verità e questo spiegherebbe come la civiltà greca sia riuscita, nel giro di pochi secoli e con una popolazione limitata in numero, a raggiungere notevoli traguardi nella filosofia, nella matematica e nelle scienze.
Le prime civiltà di cui si ha notizia per la Grecia antica sono la cicladica e quella elladica, influenzata dalla civiltà minoica, che sorse a Creta nell'età del bronzo. Forse provenienti da oriente, si sviluppò a Creta l'omonima civiltà che fu fautrice di grandissime opere e che sviluppò la talassocrazia (letteralmente "dominio sul mare"), commerciando con tutto il mediterraneo orientale e creando una società molto evoluta chiamata minoica. Intorno al XVI secolo a.C. nell'attuale Grecia continentale si affermò la civiltà micenea, che si espanse nel bacino egeo, andando a includere i territori che erano stati interessati dalla presenza minoica. Successivamente l'espansione micenea interessò anche le coste dell'Anatolia, come testimoniato dall'epopea omerica della Guerra di Troia. La fine della civiltà micenea (XI secolo a.C.), che si verificò in contemporanea con la caduta o la profonda crisi dei grandi imperi del Vicino Oriente, coincide con la fine dell'età del bronzo e l'inizio della prima età del ferro, che si conclude al sorgere delle prime città-stato greche, quando convenzionalmente inizia l'età classica in Grecia (IX secolo a.C.).
Questa fase è stata recepita da una tradizione storiografica che ha le sue radici nel XIX secolo come un periodo di stagnazione chiamato medioevo ellenico, facendo un parallelo con i secoli considerati "bui" del Medioevo dell'era volgare. L'inizio di quest'epoca sarebbe stato causato dalla presunta invasione dorica e dei cosiddetti Popoli del Mare, i quali maneggiavano armi di ferro, che avrebbero disperso facilmente così i già indeboliti Micenei. Questa fase sarebbe terminata quando la civiltà greca sarebbe stata incanalata in un rinascimento che fece espandere il mondo greco dal Mar Nero fino alla Spagna.
Verso la fine del IX secolo a.C. il mondo greco fu interessato da una progressiva trasformazione politica ed economica, caratterizzata dall'incremento demografico, dal contatto con le popolazioni ricche e progredite delle isole orientali dell'Egeo e delle coste dell'Asia Minore e da una ripresa degli scambi commerciali. Lentamente l'istituto monarchico perse il proprio potere a favore dell'aristocrazia, che nell'VIII secolo a.C. prese il potere in tutta l'area egea.
Sorsero così le poleis, delle città-stato, che divennero veri e propri centri politici, economici e militari, retti da governi autonomi e indipendenti. Tra l'VIII ed il VII secolo a.C. vi fu un fenomeno migratorio che ebbe notevoli ripercussioni sull'assetto sociale, politico ed economico della Grecia arcaica.
La colonizzazione greca, causata dai gravi contrasti di classe, dalle guerre tra città e dall'aumento della popolazione, che fece crescere il fabbisogno di terre e materie prime, interessò sia l'area orientale (Tracia e Mar Nero), sia quella occidentale (Italia meridionale, Francia e Spagna).
Tra le conseguenze socio-economiche di questa colonizzazione vi furono l'espansione e l'incremento degli scambi commerciali e delle attività artigianali ed industriali e l'introduzione della moneta, favorendo la formazione di una nuova classe di commercianti ed industriali, che progressivamente misero in crisi il predominio dell'aristocrazia.
Il periodo classico, a volte chiamato periodo ellenico, si estende grossomodo tra il V e il IV secolo a.C., convenzionalmente terminando con la morte di Alessandro Magno nel 323 a.C. Il periodo classico in questo senso segue l'epoca arcaica ed è a sua volta seguito dall'epoca ellenistica.
All'inizio del V secolo a.C. le guerre persiane opposero i Greci ai Persiani dell'Impero achemenide. Esse furono caratterizzate dalla rivolta delle città greche asiatiche contro la dominazione persiana e l'intervento di Atene in loro favore. Le due spedizioni militari dei sovrani Dario I e Serse costituirono i due principali episodi militari del conflitto, che si concluse con la vittoria delle città greche condotte da Atene e Sparta.
Dopo la vittoria sui Persiani, nel 477, Atene, consolidata la propria supremazia navale, si fece promotrice dell'istituzione della Lega di Delo o Lega delio-attica. Intorno al 460 comparve sulla scena ateniese Pericle, capo del "partito" popolare.
La crescita della potenza ateniese entrò presto in conflitto con la Lega peloponnesiaca, guidata da Sparta. Un primo scontro tra le due città si concluse nel 445 con una pace trentennale, di poco posteriore alla pace di Callia, stipulata tra Atene e la Persia.
La guerra fu combattuta tra il 431 a.C. ed il 404 a.C., con protagoniste Sparta e Atene e le rispettive coalizioni, e fu caratterizzata da tre fasi: nella prima, la fase Archidamica, Sparta effettuò continui attacchi contro l'Attica, mentre Atene utilizzava la propria potente flotta per colpire le coste del Peloponneso. Questo periodo di scontri si concluse nel 421 a.C. con la firma della pace di Nicia; al 415 a.C. risale infatti la spedizione ateniese in Sicilia; nel 413 a.C. si apre la fase Deceleica, caratterizzata dall'intenzione spartana di fomentare moti di ribellione tra le forze sottoposte ad Atene; questa strategia, unita agli aiuti economici provenienti dalla Persia e all'incapacità ateniese di difendersi, portò nel 404 a.C. alla vittoria della Lega del Peloponneso.
La guerra del Peloponneso cambiò il volto della Grecia antica: Atene, che dalle guerre persiane aveva visto crescere enormemente il proprio potere, dovette sopportare alla fine dello scontro con Sparta un gravissimo crollo in favore della forza egemone del Peloponneso. Tutta la Grecia interessata dalla guerra risentì fortemente del lungo periodo di devastazione, sia dal punto di vista della perdita di vite umane sia da quello economico.
Nel 401 Sparta inviò in Asia un corpo di 13.000 mercenari per sostenere Ciro il Giovane nel suo tentativo di rovesciare il fratello Artaserse II e salire così sul trono dell'impero persiano.
Nell'estate del 395 a.C. scoppiò la guerra in Grecia e Tebe, Atene, Argo e Corinto si allearono in funzione antispartana, dando vita alla guerra corinzia. Questa si concluse nel 387, con la "pace del re" o trattato di Antalcida, le cui clausole sancivano il dominio persiano sulle città dell'Asia minore e l'autonomia delle città greche della madrepatria. Seguirono altri conflitti tra Sparta e Tebe, fino alla sconfitta spartana nella battaglia di Leuttra (luglio 371).
Il risultato della battaglia sancì la fine della supremazia di Sparta, costretta a sciogliere la Lega peloponnesiaca, e l'affermazione di Tebe come potenza egemone in Grecia.
L'esasperazione dei cittadini nei confronti delle interminabili guerre tra le città portò alla convinzione che la pace e l'unità potessero essere raggiunte solo attraverso l'intervento di un principe straniero. Così Filippo II di Macedonia, la cui casa reale si era ellenizzata dai tempi delle guerre persiane, riuscì ad entrare nelle discordie tra i greci e ad imporre la sua talassocrazia.
Con le imprese del figlio di Filippo, Alessandro Magno, cessarono tutte le libertà delle polis greche. I successi del principe macedone furono visti però come il coronamento di un sogno: la grande vittoria della Grecia unita contro il popolo persiano. A rafforzare il sostegno verso Alessandro, fu l'ambizione stessa del giovane condottiero, che intendeva varcare l'Ellesponto, per conquistare il mondo e creare un regno universale, coeso dalla cultura greca. La spedizione di Alessandro Magno (334-323 a.C.) può, per importanza e conseguenze, essere considerata uno degli eventi epocali nella storia del mondo antico. La portata di quella che è stata chiamata la rivoluzione alessandrina fu talmente rilevante, per le implicazioni politiche e per i mutamenti culturali che ingenerò, da determinare la fine dell'era classica e l'inizio dell'era cosiddetta ellenistica.
Dopo le vittorie del Granico e di Isso, Alessandro occupò l'Egitto, fondando la città di Alessandria. Nell'autunno del 331 Alessandro sconfisse Dario III a Gaugamela ed occupò Babilonia, Susa e Persepoli, decretando la fine dell'impero persiano. Ormai in fuga, Dario III fu assassinato dai suoi stessi generali nel luglio del 330. Alessandro intraprese la conquista dell'India, ma, dopo aver attraversato l'Indo e vinto il rajah Poro nella battaglia dell'Idaspe, fece ritorno a Babilonia. Nel giugno del 323 il grande re macedone morì a Babilonia per una febbre malarica; tramontò così il suo sogno della realizzazione di un impero universale.
Grazie alle sue conquiste, la civiltà greca si diffuse nel mondo mediterraneo e orientale, ingenerando tali mutamenti culturali da determinare la fine dell'era classica e l'inizio dell'era cosiddetta ellenistica.
Dopo la morte di Alessandro, ci fu un'accesa lotta fra i suoi successori, i Diadochi. Nel 323 a.C. il generale Perdicca regge l'Impero in nome del figlio di Alessandro; Antipatro ottiene il controllo della Macedonia e della Grecia, mentre Antigono controlla la Frigia e la Lidia, Tolomeo I l'Egitto e Lisimaco la Tracia.
Ma dopo la morte di Antipatro (319 a.C.) e l'assassinio dei familiari di Alessandro, cominciano le dispute; infatti Antigono condanna a morte Eumene di Cardia e mira a diventare unico signore ma gli altri non vogliono lasciare i loro domini, si arriva così alla Guerra dei Diadochi (315 a.C.-301 a.C.). La battaglia di Ipso decreta la sconfitta di Antigono e la creazione di quattro regni:, alla fine della quale, nel 281 a.C., il suo enorme impero fu smembrato in tre grandi regni.
A partire dal 215 a.C., Roma intervenne in Grecia più volte in occasione delle guerre macedoniche a causa dell'alleanza stretta da Annibale con Filippo V di Macedonia. Dopo aver ottenuto l'alleanza di Atene, del regno di Pergamo e della Lega etolica, i Romani sbarcarono in Grecia e nel 197 a.C. il console Tito Quinzio Flaminino sconfisse Filippo nella battaglia di Cinocefale. La pace che seguì stabilì l'alleanza tra Roma e la Macedonia e il ritiro di ogni guarnigione macedone dalla Grecia. La libertà della Grecia fu proclamata da Flaminino durante i Giochi istmici di Corinto, mandando la folla in delirio. L'anno dopo i Romani evacuarono la Grecia, ma gli Etoli, delusi dalle clausole della pace che giudicavano penalizzanti per se stessi, assunsero un atteggiamento ostile verso Roma.
Nel 193 a.C. il re seleucide Antioco III il Grande sbarcò in Grecia, deciso a porla sotto la propria egemonia. I Romani sconfissero Antioco nella battaglia delle Termopili, costringendolo ad evacuare la Grecia e tornare in Asia.
Alla morte di Filippo V, nel 179 a.C., salì sul trono di Macedonia il figlio Perseo, il quale desiderava ripristinare l'egemonia macedone sulla Grecia. In seguito alla sua sconfitta nella battaglia di Pidna, la Macedonia fu suddivisa in quattro repubbliche che non dovevano avere alcun rapporto tra loro.
Successivamente, nel 146 a.C. gli Achei furono sconfitti nella battaglia di Corinto, che fu poi rasa al suolo; la Grecia e la Macedonia divennero, così, province della Repubblica romana.
La religione greca è l'insieme di credenze, miti, rituali, culti misterici, teologie e pratiche teurgiche e spirituali professate nella Grecia antica, sotto forma di religione pubblica, filosofica o iniziatica.
Le origini di questa religione vanno individuate nella preistoria dei primi popoli abitanti l'Europa, nelle credenze e nelle tradizioni di differenti popoli indoeuropei che, a partire dal XXVI secolo a.C., migrarono in quelle regioni, nelle civiltà minoica e micenea e nelle influenze delle civiltà del Vicino Oriente antico occorse lungo i secoli[1].
La "religione greca" cessò di essere con gli editti promulgati dall'imperatore romano di fede cristiana Teodosio I, il quale proibì tutti i culti non cristiani, ivi compresi i misteri eleusini, e con le devastazioni operate dai Goti lungo il IV e il V secolo d.C.
La mitologia greca è la raccolta di tutti i miti e le leggende appartenenti alla cultura degli antichi greci ed elleni che riguardano i loro dei ed eroi, la loro concezione del mondo, i loro culti e le pratiche religiose. Essa si compone di un vasto repertorio di racconti (λόγοι) che spiegano l'origine del mondo ed espongono dettagliatamente la vita e le vicende di un gran numero di divinità, eroi ed eroine, mostri e altre creature mitologiche. Questi racconti furono inizialmente composti e diffusi in una forma poetica e compositiva orale, mentre sono invece giunti fino a noi principalmente attraverso i testi scritti della tradizione letteraria greca. La mitologia greca ha avuto una grandissima influenza sulla cultura, le arti e la letteratura della civiltà occidentale e la sua eredità resta tuttora ben viva nei linguaggi e nelle culture europee.
Ogni aspetto della vita dell'uomo greco aveva sempre e comunque una valenza religiosa, tanto che è estremamente difficile distinguere nella società greca l'ambito "sacro" da quello "profano". Esempi di questa commistione socio-religiosa sono i giochi e le festività greche. Gli agoni e in particolar modo i giochi olimpici rappresentavano per il mondo greco un'occasione eccezionale, nel corso della quale le città interrompevano le proprie dispute e riuscivano a riconoscersi reciprocamente come sorelle. In un certo modo rappresentarono il punto più alto della cultura ellenica, riuscendo a rappresentare concretamente gli ideali di aretè (ἀρετή) cui tendevano i racconti mitici.
Tra le festività greche si ricordano le panatenee, le dionisie e le tesmoforie.
Grande importanza ricoprivano i santuari panellenici, fra cui i più importanti erano il santuario di Zeus di Olimpia e quello di Apollo a Delfi, sede dell'oracolo di Delfi.
La letteratura greca  , espressione dell'antica Grecia e della sua ricchissima cultura, è tra gli elementi fondanti dell'idea moderna di Occidente. Elevatasi fin dalle origini grazie ai capolavori di Omero ed Esiodo, la letteratura greca ha permeato la storia della letteratura con contributi fondamentali in ogni genere letterario, come la poesia, con i versi di Alceo, Saffo, Anacreonte, Pindaro, Callimaco e Teocrito, la tragedia, con i drammi di Eschilo, Sofocle ed Euripide, le commedie di Aristofane, l'oratoria di Isocrate, Lisia e Demostene, e i grandi storici, da Erodoto a Tucidide, a Senofonte, fino a Plutarco.
Importante anche il teatro greco. Gli Ateniesi organizzavano alcuni giorni l'anno grandi festività durante le quali i maggiori autori teatrali dell'epoca gareggiavano per conquistare la vittoria. Gli attori, esclusivamente uomini anche nelle parti femminili, indossavano maschere che li rendevano riconoscibili anche a grande distanza. La recitazione era rigorosamente in versi, e alle parti soliste si accompagnava un coro, gruppo di attori che assolveva la funzione di collegamento delle scene, commento e narrazione della trama. La forma d'arte di ispirazione più elevata era considerata la tragedia, i cui temi ricorrenti erano derivati dai miti e dai racconti eroici. Le commedie, di carattere più leggero e divertente, prendevano spesso di mira la politica, i personaggi pubblici e gli usi del tempo.
La filosofia greca rappresenta, nell'ambito della storia della filosofia occidentale, il primo momento dell'evoluzione del pensiero filosofico. Dal punto di vista cronologico, si identifica questa fase con il periodo che va dal VII secolo a.C. alla chiusura dell'Accademia di Atene, avvenuta nel 529 d.C. con l'editto di Giustiniano.
Attraverso i secoli i grandi pensatori greci da Talete a Pitagora, dai Presocratici a Socrate, da Platone ad Aristotele, fino ad arrivare alle scuole di pensiero del Cinismo, dello Scetticismo, dell'Epicureismo e dello Stoicismo, hanno costruito i capisaldi del pensiero della civiltà occidentale.
L'arte greca ha esercitato un'enorme influenza culturale in molte aree geografiche dal mondo antico fino ai nostri giorni, soprattutto nel campo della scultura e dell'architettura. In Occidente ebbe un forte influsso sull'arte romana imperiale, al punto che quest'ultima ne fu a volte considerata una mera derivazione. In Oriente le conquiste di Alessandro Magno avviarono un lungo periodo di scambi tra le culture della Grecia, dell'Asia centrale e dell'India (arte greco-buddhista del Gandhāra), con propaggini addirittura in Giappone. A partire dal Rinascimento, in Europa l'estetica e l'alta capacità tecnica dell'arte greca ispirarono generazioni di artisti e fino al XIX secolo; la tradizione classica derivata dalla Grecia ha dominato l'arte all'interno della cultura occidentale.
L'architettura greca riveste particolare importanza per tutta la storia dell'architettura occidentale. La codificazione che, nel periodo arcaico, verrà sviluppata per l'architettura templare nei tre ordini dorico, ionico e corinzio diventerà con l'ellenismo il linguaggio universale del mondo mediterraneo.
L'architettura romana rielaborerà questo linguaggio, mantenendolo invariato nelle sue componenti essenziali grammaticali, e verrà di nuovo riscoperto (senza in realtà essere mai stato dimenticato) nel rinascimento e nei secoli successivi fino al XIX secolo.
La scultura è probabilmente l'aspetto più conosciuto dell'arte greca, quello che per un contemporaneo meglio esprime il bello ideale e la perfezione plastica.
Solo una piccola parte della produzione scultorea greca è giunta fino a noi. Molti dei capolavori descritti dalla letteratura antica sono ormai perduti o gravemente mutilati, e la stragrande maggioranza e in particolare le statue in bronzo, il cui materiale era più facilmente riutilizzabile, ci è conosciuta solo da copie di epoca romana, più o meno fedelmente riprodotte. Infine la nostra visione della scultura antica è distorta, poiché ritrovamenti e studi scientifici hanno dimostrato come la policromia di statue e architetture fosse una caratteristica imprescindibile delle opere, ma solo in rarissimi casi essa si è preservata fino a noi.
Tradizionalmente si distinguono nella scultura greca cinque periodi: il periodo dedalico (VII secolo a.C.), il periodo arcaico (VI secolo a.C., fino al 480 a.C., distruzione da parte dei Persiani delle mura dell'Acropoli di Atene), il primo periodo classico (V secolo a.C.), rappresentato da scultori quali Fidia, Mirone e Policleto, il periodo tardo classico (IV secolo a.C., fino al 323 a.C., morte di Alessandro Magno), rappresentato da Prassitele, Skopas e Lisippo ed il periodo ellenistico (dalla morte di Alessandro Magno nel 323 a.C. alla conquista romana del 146 a.C.).
L'arte della ceramica e della pittura vascolare raggiunse nella Grecia antica un alto livello di qualità artistica ed è anche una testimonianza privilegiata della vita e cultura degli antichi Greci.
I vasi greci sono pervenuti ai giorni nostri in gran numero, ma la quantità dei ritrovamenti ceramici rappresenta probabilmente solo un'infima parte della produzione dell'epoca, anche in considerazione del fatto che esistono oggi più di 50.000 vasi provenienti dalla sola Atene.
La ceramica greca è caratterizzata dalla grande varietà di forme vascolari e dall'evoluzione degli stili decorativi, dallo stile geometrico alla ceramica a figure nere e a quella a figure rosse.
Nell'antica Grecia la musica occupava un ruolo di grande rilievo nella vita sociale e religiosa. Per i greci la musica era un'arte che comprendeva, oltre alla musica stessa, anche la poesia, la danza, la medicina e le pratiche magiche. L'importanza della musica nel mondo greco è testimoniata da numerosi miti che la riguardano, come quello di Orfeo, considerato l'inventore della musica.
Durante il periodo arcaico (dalle origini al VI secolo a.C.) la musica era praticata solamente da professionisti: gli aedi e i rapsodi. Questi declamavano i miti accompagnandosi con uno strumento musicale e tramandavano la musica oralmente. In seguito nel periodo classico (dal VI secolo a.C. al IV secolo a.C.) la musica entrò a far parte del sistema educativo e così venne divulgata. A questo periodo risalgono pochissime fonti di scrittura musicale che erano soltanto di aiuto ai professionisti, perciò la musica veniva ancora tramandata oralmente. Sempre nel periodo classico si sviluppò la tragedia. I soggetti della tragedia erano presi dai miti letterari e consistevano in dialoghi tra due o tre personaggi alternati da canti corali. Gli attori erano tutti uomini, indossavano maschere e recitavano con l'accompagnamento della musica. La struttura architettonica del teatro era costituita da una gradinata a semicerchio per il pubblico, di fronte c'era il palco dove si esibivano gli attori e tra gradinata e palco c'era l'orchestra dove si trovava il coro.
I greci usavano diversi strumenti. I più comuni erano la lira o cetra, sacra al dio Apollo, e l'aulos sacro al dio Dioniso. Erano in uso anche strumenti a percussione tra cui i tamburi e i cimbali, meglio noti come piatti.
Le acquisizioni scientifiche delle civiltà preesistenti, soprattutto egiziane e babilonesi per le conoscenze matematiche, geometriche e astronomiche, ma anche mediche, chimiche e relative a varie tecnologie, vennero non solo elaborate e integrate dalla speculazione scientifica greca in una organica costruzione sistematica, ma anche ampliate ed arricchite di nuove teorie. Queste, soprattutto a partire dalla metà del II secolo a.C., andarono in gran parte perdute e misconosciute e solo con gli arabi e in seguito con il Rinascimento furono in parte riprese e diedero impulso alla rinascita scientifica del mondo occidentale.
Ad un periodo delle origini, contraddistinto dalle speculazioni filosofiche dei presocratici, come Anassimandro, Anassimene ed Eraclito, seguì quello caratterizzato da una vasta elaborazione teorica, parzialmente presentata in alcune opere di Platone ed Aristotele. La vera fioritura scientifica, caratterizzata dalla distinzione tra filosofia e scienza, avvenne solamente con l'età ellenistica, grazie all'incontro tra tecnologie delle millenarie civiltà mesopotamica ed egizia con lo spirito critico e le capacità logiche sviluppati nelle città greche. Un ruolo importante ebbe Alessandria d'Egitto, il più importante centro degli studi scientifici e dell'elaborazione culturale dell'epoca sviluppatosi anche grazie all'impulso dei primi sovrani della dinastia tolemaica (v. a. Biblioteca di Alessandria). Questo periodo culturale può vantare lo sviluppo di metodologie di indagine razionali e rigorose, accurate specializzazioni in varie discipline particolari e realizzazioni tecnologiche che resteranno ineguagliate per molti secoli.
Le donne nell'antica Grecia non godevano di molti diritti, essendo escluse dalla cittadinanza, e, ad Atene, dal possedere medie e grandi proprietà.
Le città greche sono le prime di cui abbiamo notizia ad aver concentrato l'attenzione sul processo decisionale, invece che sui requisiti di un governo efficiente e sulle modalità di attuazione delle delibere. Essi crearono e perfezionarono le tecniche per l'esercizio del potere deliberativo in ambito pubblico, il cui principale strumento era la persuasione ottenuta con argomentazioni razionali. I Greci svilupparono anche quel particolare metodo di affrontare i problemi e le procedure politiche per cui, partendo dalla situazione particolare, si arriva ai principi generali: in questo senso possiamo dire che i Greci inventarono la politica e il pensiero politico. Il loro primato nella storia del pensiero politico e sociale occidentale si evince dal fatto che tutte le parole e i concetti più importanti della teoria politica derivano dal linguaggio greco.
Tuttavia parole di origine greca come "politica", "democrazia" e "tirannide" avevano per loro significati assai diversi da quelli attuali: per i Greci le questioni del potere e del controllo erano marginali, lo scopo della politica era far emergere la volontà generale dell'azione, non elaborando una teoria della sovranità. La comunità (koinonia) era tutto, i sistemi politici greci avevano il compito di subordinare il gruppo alla comunità, con il risultato che i gruppi che riuscivano ad acquisire importanza politica non erano gruppi marginali.
Lo scopo ultimo della politica era di conseguire "il bel vivere", che aveva a che fare con il riposo o l'attività. È proprio questo il salto di qualità che è attribuibile tutt'oggi ai Greci: sperimentarono di rado quel conflitto fra società ed individuo che è causato dalla distanza fra chi governa e chi è governato, ed era evidente che gli interessi dell'individuo fossero quelli della comunità.
Nella polis i diritti e i doveri del cittadino comprendevano l'attività politica, il servizio militare e la partecipazione alla vita religiosa della comunità. Il godimento dei pieni diritti politici spettava solo ai figli maschi adulti di status libero che erano considerati politai, ossia in possesso del diritto di cittadinanza in base a diversi criteri. Dal godimento dei pieni diritti erano escluse le donne, gli stranieri residenti liberi e gli schiavi.
Sul piano politico i diritti fondamentali consistevano nell'esercitare la sovranità e le magistrature (archein), praticare l'attività giudiziaria (dikazein), partecipare alle assemblee (ekklesiazein). Essere cittadini comportava una serie di vantaggi di carattere puramente economico, dalla retribuzione delle cariche pubbliche, al possesso di beni immobili, all'accesso ai sussidi statali e alle distribuzioni di denaro, grano e carne.
Per quanto riguarda il ruolo militare, la guerra costituisce una delle attività principali del mestiere di cittadino. Ad Atene si era tenuti a prestare il servizio militare dai 20 ai 40 anni di età, mentre fino al compimento dei 59 anni si entrava a far parte della riserva, e dopo i 60 anni si usciva definitivamente dalle liste agli abili.
L'inquadramento del cittadino nelle strutture della città era regolato da strumenti quali le tribù, un tipo di organizzazione della popolazione ampiamente diffuso nelle città greche. Tutti i cittadini al compimento dei 18 anni giuravano sulla Costituzione, impegnandosi a difendere la patria ed a obbedire alle leggi. I cittadini erano inseriti in strutture preesistenti alla realtà delle polis e risalenti alle antiche tradizioni di carattere genetico, organismi paralleli a quelli statali.
L'economia della Grecia antica era caratterizzata da una forte predominanza del settore agricolo, mentre le materie prime venivano fornite soprattutto mediante la creazione di colonie. Più di una fonte di sostentamento, l'agricoltura era alla base dei rapporti sociali: la maggioranza della popolazione del mondo greco era rurale e la proprietà fondiaria rappresentava un ideale.
L'artigianato e il commercio (principalmente marittimo) si svilupparono a partire dal VI secolo a.C. In ogni caso i greci provavano una certa ripugnanza per il lavoro retribuito, in particolare il lavoro manuale: la politica era l'unica attività considerata degna per un cittadino, il resto del lavoro era svolto principalmente da schiavi.
La schiavitù nell'antica Grecia si espanse, nel corso dei secoli, dai pochi schiavi di proprietà dei sovrani ad un vero e proprio mercato. La maggior parte degli schiavi erano prigionieri di guerra.
In epoca omerica, infatti, i pochi schiavi a servizio del re e dei nobili erano soprattutto donne impiegate come domestiche, ma anche come concubine. Gli uomini si occupavano del pascolo e dell'agricoltura. Tra l'800 e il 600 a.C. con la colonizzazione dalle sponde del Mar Nero a quelle del Mediterraneo, il commercio di schiavi si sviluppò notevolmente. Nei secoli seguenti con lo sviluppo dell'industria l'utilizzo degli schiavi si estese anche in questo settore, prevalendo sull'impiego di uomini liberi e estendendosi anche alle miniere, ai lavori pubblici e alle case private.
L'educazione svolse un ruolo significativo nella vita greca dalla fondazione delle poleis fino al periodo ellenistico e romano. Dalle sue origini nell'età omerica nella tradizione aristocratica, la formazione greca si è gradualmente "democratizzata" nel V secolo a.C., grazie anche all'influenza dei sofisti, di Platone e di Isocrate. Nel periodo ellenistico, l'istruzione in una palestra era considerata un presupposto imprescindibile per la partecipazione alla vita greca.
C'erano due forme di educazione nella Grecia antica: quella formale, attraverso la frequenza di una scuola pubblica o fornita da un precettore assunto, e quella informale, fornita da un insegnante non pagato in un contesto privato. L'istruzione era una componente essenziale dell'identità di un cittadino greco e il tipo di educazione impartita era basata sulla classe sociale di appartenenza e sulla cultura della propria polis.
L'apartheid (italiana: /apar'tajd/; afrikaans: [aˈpartɦɛit]; letteralmente "separazione", "partizione") era la politica di segregazione razziale istituita nel 1948 dal governo di etnia bianca del Sudafrica, e rimasta in vigore fino al 1991. Il suo "iniziatore" è stato Daniel François Malan, che dal 1948 al 1954 fu anche primo ministro.
Fu applicato dal governo sudafricano anche alla Namibia, fino al 1996 amministrata dal Sudafrica. Per estensione il termine è oggi utilizzato per rimarcare qualunque forma di segregazione civile e politica a danno di minoranze, ad opera del governo di uno stato sovrano, sulla base di pregiudizi etnici e sociali.
L'anniversario della fine è il 27 aprile, giorno festivo in Sudafrica, quando si festeggia la Festa della libertà.
Il termine apartheid fu utilizzato, in senso politico, per la prima volta nel 1915 dal primo ministro sudafricano Jan Smuts; con le elezioni del 1928 vennero introdotti nel paese i primi elementi di segregazione razziale. Nel 1939 Smuts tornò al potere e il nazionalismo afrikaner non poté proseguire il suo progetto politico.
Durante la seconda guerra mondiale un gruppo di intellettuali afrikaner influenzati dal nazismo completò la teorizzazione del progetto dell'apartheid.
L'apartheid viene ufficialmente introdotta nel 1948, dopo la vittoria alle elezioni del Partito Nazionale[1]. I principali ideologi dell'apartheid furono i primi ministri Daniel François Malan (in carica dal 1948 al 1954), Johannes Gerhardus Strijdom (dal 1954 al 1958) e Hendrik Frensch Verwoerd (vero e proprio "architetto dell'apartheid"[senza fonte]), in carica dal 1958 fino al suo accoltellamento nel 1966 da parte di Dimitri Tsafendas, un semplice uomo eletto al parlamento sudafricano di origini greco-mozambicane. Verwoerd definiva l'apartheid come "una politica di buon vicinato".[2] Nel 1956 la politica di apartheid fu estesa a tutti i cittadini di colore, compresi gli asiatici.
Negli anni '60, 3,5 milioni di uomini e donne nere di etnia bantu furono sfrattati con la forza dalle loro case e deportati nei "bantustan". Furono privati di ogni diritto politico e civile, e poterono frequentare per acquisire un’istruzione esclusivamente scuole agricole e commerciali speciali. I negozi erano obbligati a servire tutti i clienti di etnia bianca prima di quelli di etnia nera. Questi ultimi, inoltre, dovevano avere speciali passaporti interni per muoversi nelle zone riservate alle etnie bianche, pena l'arresto.
In un primo tempo sia neri che bianchi organizzarono proteste contro l'apartheid, in genere brutalmente soffocate dalle forze di sicurezza governative. Nei primi anni sessanta l'Umkhonto we Sizwe, organizzazione armata facente capo all'African National Congress, iniziò a usare la ribellione armata, limitandosi però ad azioni di sabotaggio contro obiettivi strategici come centrali elettriche e altre infrastrutture. Nel 1975, il governo sudafricano decise di imporre la redazione di ogni norma giuridica in lingua afrikaans. La legge fu estesa a tutte le scuole, imponendo che le lezioni fossero tenute metà in inglese e metà in afrikaans.[3]
La comunità internazionale varò una serie di sanzioni al regime segregazionista sudafricano.  L'apartheid fu dichiarato crimine internazionale da una convenzione delle Nazioni Unite, votata dall'assemblea generale nel 1973 ed entrata in vigore nel 1976 (International Convention on the Suppression and Punishment of the Crime of Apartheid), e quindi successivamente inserito nella lista dei crimini contro l'umanità. Inoltre ci fu il boicottaggio di 33 nazioni africane alle Olimpiadi del 1976, in segno di protesta contro la nazionale di rugby neozelandese che aveva accettato di giocare alcune partite contro la squadra sudafricana. Anche gli Stati inizialmente ostili a tali misure, come il Regno Unito e gli Stati Uniti (questi ultimi preferirono una politica conciliante nota come constructive engagement), a metà degli anni ottanta si allinearono agli altri Stati. Forti furono anche le pressioni internazionali nel mondo dello sport, con il boicottaggio sportivo del Sudafrica dalle partecipazioni alle olimpiadi a causa dell'apartheid.
Diverse personalità si batterono contro il regime di segregazione, come Stephen Biko e Nelson Mandela; la prima iniziativa ufficiale volta all'isolamento sportivo venne adottata con l'accordo di Gleneagles ratificato dal Commonwealth delle nazioni nel 1977.
La liberazione di Nelson Mandela, massimo leader dell'ANC, avvenuta nel 1990 dopo 27 anni di prigionia (dovuti al rinnegamento dei "crimini" da lui commessi e al suo abbracciare la nonviolenza negli anni '80), e la sua successiva elezione a capo dello Stato decretarono la fine dell'apartheid e l'inizio di una nuova era.
Il referendum del 1992 e le elezioni generali in Sudafrica del 1994 videro il superamento della segregazione, nelle elezioni si registrò la vittoria del Congresso Nazionale Africano[4][5] con il 62,65% dei voti, al di sotto però della soglia dei due terzi necessaria per modificare la costituzione, permettendo comunque ai neri di ricominciare una vita normale. Da allora l'ANC governa ininterrottamente il paese, prima con Nelson Mandela (ridisegnando la bandiera simboleggiando la pace nel mondo), poi con Thabo Mbeki e successivamente con Kgalema Motlanthe, Jacob Zuma e Cyril Ramaphosa. La Commissione per la verità e la riconciliazione, istituita nel 1995, si è occupata di raccogliere testimonianze sulle violazioni dei diritti umani e ha concesso l'amnistia a chi confessasse spontaneamente e pienamente i crimini commessi contro i neri agli ordini del governo, amnistiando anche gli atti di terrorismo commessi dallo Umkhonto we Sizwe.
Il Sudafrica post-apartheid, aggiungendo nove lingue africane come ndebele, sesotho del nord, sesotho, swati, tsonga, tswana, xhosa e zulu, ha portato il totale degli idiomi ufficiali a undici. Tuttavia permasero diverse situazioni di disuguaglianza, e vi sono ancora piccoli gruppi di nostalgici bianchi di estrema destra che supportano il ritorno dell'apartheid o l'indipendentismo afrikaner, ad esempio il Partito Nazionale Rifondato del Sudafrica e il Movimento di Resistenza Afrikaner. Nel 2006, il 70% delle proprietà terriere era posseduta da bianchi.[6]
La filosofia dell'apartheid affermava di voler dare ai vari gruppi razziali la possibilità di condurre il proprio sviluppo sociale in armonia con le proprie tradizioni (teoria dello "sviluppo separato", in teoria un'applicazione dell'autodeterminazione dei popoli, di fatto eufemismo per separatismo e segregazione razziale).
Oltre che sul razzismo scientifico importato dal colonialismo britannico vi era una componente razzista religiosa di origine calvinista-olandese su cui si basava la giustificazione teologica della separazione delle razze.[7][8]
In Sudafrica, mentre i neri e i meticci coloured (termine spesso usato per definire tutti i neri) costituivano l'80% circa della popolazione, i bianchi si dividevano in coloni di origine britannica ed afrikaner. Gli afrikaner, che costituivano la maggioranza della popolazione bianca, erano da sempre favorevoli ad una politica razzista, mentre i sudafricani di origine inglese, malgrado il sostanziale appoggio dell'apartheid, erano più concilianti nei confronti dei connazionali neri.
Le principali leggi che costituivano il sistema erano[9]:
Era prevista la separazione dei bianchi dai neri nelle zone abitate da entrambi (per esempio rispetto all'uso di mezzi e strutture pubbliche) e l'istituzione dei bantustan, i territori semi-indipendenti in cui molti neri furono costretti a trasferirsi. L'apartheid divideva i cittadini in quattro categorie:
A questo venne aggiunto lo status di bianchi onorari, concesso a etnie e nazionalità per particolari motivi e che non rientravano tra i bianchi.
Il termine polo nord indica generalmente il punto più a nord (o più a settentrione) di un qualsiasi corpo celeste (es. un pianeta o una stella) e per convenzione viene usato come sistema di riferimento primario rispetto al polo sud.
Facendo riferimento alla Terra, il termine può indicare diversi punti geografici posti sulla superficie terrestre, la maggior parte dei quali sono situati nel Mar Glaciale Artico, ed è utilizzato anche per riferirsi in maniera generica a quella regione del mondo denominata Artide o in alcuni casi al territorio compreso all'interno del circolo polare artico. Con "polo nord" si può anche intendere il polo magnetico positivo (P) di un magnete.
Il Polo Nord del nostro pianeta può essere definito in diversi modi, tuttavia le definizioni a cui più spesso si fa riferimento sono le prime due:
Il Polo Nord geografico, chiamato anche vero nord, rappresenta il punto immaginario dell'emisfero boreale in cui l'asse di rotazione terrestre incontra la superficie terrestre o per meglio dire la superficie del geoide. Un altro modo per definirlo è dire che è il punto in cui la latitudine è un angolo retto, ossia è di 90° nord. Il Polo Nord geografico è uno dei due punti della superficie terrestre in cui si incontrano i meridiani: questo significa che se ci si trova esattamente sul polo nord geografico, in qualunque direzione si decida di andare, procedendo in linea retta si andrà sempre verso il sud geografico ossia verso il Polo Sud geografico.
Fino al XIX secolo si è ritenuto che il Polo Nord geografico fosse un punto fisso, tuttavia questa convinzione è stata smentita grazie a misurazioni molto accurate basate sull'osservazione delle stelle e agli studi effettuati dall'astronomo americano Seth Carlo Chandler (1846-1913).
Chandler nel 1891 scoprì che il Polo Nord geografico, visto dall'alto, non sia immobile ma si muove, descrivendo un cerchio approssimativo, attorno a un punto chiamato "polo medio di rotazione"; questo moto fu successivamente chiamato oscillazione di Chandler in suo onore. L'oscillazione di Chandler ha un periodo di circa 435 giorni e il cerchio imperfetto che descrive intorno al polo medio di rotazione (che ha un'ampiezza media di circa 6 m), è dovuto alla forma irregolare della Terra e al non perfetto allineamento dell'asse di rotazione terrestre con l'asse di inerzia terrestre. Questo mancato allineamento fa sì che la Terra oltre a ruotare sul proprio asse oscilli leggermente, in modo analogo al moto di una trottola leggermente sbilanciata. Sulle cause di questo mancato allineamento ci sono diverse teorie: inizialmente si riteneva che fossero da ricercare nei terremoti ma studi recenti effettuati da Richard Gross del Jet Propulsion Laboratory avrebbero dimostrato che la causa principale siano le variazioni di pressione dell'acqua marina sui fondali oceanici dovute a modifiche della percentuale di sali disciolti nell'acqua.
Sarebbe desiderabile che il sistema di coordinate terrestri (latitudine e longitudine) e l'orografia facessero riferimento a punti morfologici fissi, tuttavia a causa di fenomeni naturali come la deriva dei continenti, il vulcanesimo, l'erosione e altri fattori, non esistono sistemi in cui tutte le caratteristiche geografiche siano fisse. Per ovviare ai problemi che la mancanza di punti di riferimento fissi possono generare, l'International Earth Rotation and Reference Systems Service (IERS) e l'Unione astronomica internazionale (UAI) hanno elaborato un modello matematico chiamato Sistema internazionale di riferimento terrestre (ITRS). Il Polo Nord geografico di questo modello è un punto convenzionale che non giace sull'asse di rotazione terrestre.
Il polo nord magnetico è il punto della superficie terrestre dove le linee di flusso del campo geomagnetico sono perpendicolari al suolo e dirette verso il terreno. Questa definizione fu proposta nel 1600 da William Gilbert, un gentiluomo che faceva parte della corte di Elisabetta I d'Inghilterra, ed è ancora oggi in uso.
Visto che il polo nord magnetico della Terra attrae il polo magnetico nord dei magneti, dal punto di vista fisico si tratta di un polo magnetico di tipo sud. Nonostante questo fu chiamato polo nord magnetico perché in prossimità del polo nord geografico. Al tempo delle prime misurazioni, nel 1830, si trova al largo delle coste del Canada.[5]
.[ quantificare le dimensioni].[ e localizzarle]Il polo nord magnetico non è in realtà un punto ben preciso ma una zona di discrete dimensioni, infatti varia (nella scala dei tempi storici) nell'ordine di gradi e decine di gradi la propria longitudine e latitudine, e può addirittura invertirsi col polo sud magnetico (nella scala dei tempi geologici) come testimoniato dalla disciplina del geomagnetismo.[senza fonte][6][7]
I poli geografici e magnetici della Terra non sono situati nello stesso luogo; questo crea delle difficoltà se si deve stabilire una direzione perché normalmente le carte geografiche fanno riferimento al polo nord geografico, mentre le bussole indicano il polo nord magnetico. A causa di queste differenza di posizione i meridiani geografici non sono paralleli ai meridiani magnetici o, detto in altri termini, i meridiani geografici non sono paralleli alle linee di forza del campo magnetico della Terra. L'angolo formato da meridiani geografici e magnetici varia a seconda del punto sulla superficie terrestre in cui ci si trova e prende il nome di declinazione magnetica. La declinazione magnetica varia non solo a seconda del luogo sulla superficie terrestre in cui viene misurata ma anche a seconda del tempo in cui la misurazione è stata fatta, perché i poli magnetici e geografici non sono punti fissi ma variano nel corso degli anni. La declinazione magnetica è un valore molto importante di cui bisogna tenere conto quando si deve stabilire una rotta con un grado di precisione abbastanza elevato e quando la distanza da percorrere è relativamente lunga.
Il governo canadese ha effettuato numerose misurazioni, che mostrano come il polo nord magnetico si muova in direzione nord-ovest. La sua posizione nel 2003 era 78°18' nord, 104° ovest, vicino all'Isola di Ellef Ringnes, una delle isole Regina Elisabetta, in Canada. Durante il XX secolo si è mosso di 1100 km, e dal 1970 la sua velocità è cresciuta da 9 km all'anno a 41 km all'anno (media del 2001-2003) fino a 64 km nel 2009. Se dovesse mantenere velocità e direzione attuali, potrebbe raggiungere la Siberia entro il 2050[8].
Questo lento movimento è sovrapposto a un movimento giornaliero in cui il nord magnetico descrive un'ellisse, con uno spostamento massimo dalla sua posizione media di 80 km. Questo effetto è dovuto al disturbo causato dal Sole al campo geomagnetico. Inoltre una linea tirata tra i due poli magnetici non passa per il centro della terra, ma lo manca di circa 530 km.
In passato però quello che oggi viene chiamato Polo Nord Magnetico è stato anche il Polo Sud Magnetico del globo. Questo fenomeno di inversione del campo magnetico terrestre, chiamato inversione geomagnetica, si è ripetuto diverse volte durante la storia della Terra, l'ultima delle quali, secondo le ricerche condotte dagli esperti di paleomagnetismo, risale a circa 780 000 anni fa, durante l'epoca geologica chiamata pleistocene. Queste periodiche inversioni si ritiene che avvengano a causa di particolari fenomeni che accadono nella parte più esterna del nucleo terrestre. Questa parte esterna composta da ferro e nichel allo stato liquido è normalmente in continuo movimento ma periodicamente, per ragioni non ancora del tutto chiarite, a volte rallenta fino a interrompersi per poi continuare nella direzione opposta. Siccome gran parte del campo magnetico terrestre è prodotto proprio dal movimento della parte esterna del nucleo all'invertirsi di questo movimento si ha anche una inversione di polarità.
La prima spedizione ad aver raggiunto il polo nord magnetico fu diretta da James Clark Ross che lo individuò il 1º giugno 1831 a Capo Adelaide nella Boothia, penisola settentrionale del Canada. Successivamente nel 1903 Roald Amundsen lo individuò in una posizione leggermente diversa.
La terza spedizione fu promossa dal governo canadese e vi parteciparono gli scienziati Paul Serson e Jack Clark del Dominion Astrophysical Observatory che individuarono il polo nord magnetico sul lago di Allen nell'isola Principe di Galles.
Nel 2007 i giornalisti inglesi della trasmissione Top Gear Jeremy Clarkson e James May lo raggiunsero a bordo di un'autovettura.
Il polo nord geomagnetico della terra è definito come il punto a nord dove termina l'asse della magnetosfera terrestre. Contrariamente al polo nord magnetico non si tratta di un punto reale ma di una astrazione basata su un modello matematico chiamato modello del dipolo che spiega solo in parte (circa il 90%) il reale comportamento del campo magnetico terrestre. Nel modello del dipolo il campo magnetico generato dalla Terra può essere visto come generato da un'enorme barra magnetica che passando per il centro della Terra attraversa tutto il pianeta. Rispetto all'asse di rotazione terrestre questa enorme barra immaginaria è inclinata di circa 11,5° e il punto in cui interseca la superficie terrestre prende appunto il nome di polo nord geomagnetico.
Poiché questo punto immaginario è basato su un'approssimazione della realtà il polo nord geomagnetico non coincide col polo nord magnetico che è situato attualmente a una distanza media di circa 30° di longitudine. Come il polo nord magnetico anche il polo nord geomagnetico è in realtà un polo magnetico sud.
La zona circostante il polo nord geomagnetico è molto importante per gli scienziati che si occupano dello studio dell'aurora boreale questo perché la zona che circonda il polo nord geomagnetico fino a una distanza di circa 23° è quella in cui questi fenomeni avvengono più spesso del mondo.
La prima spedizione verso il polo nord geomagnetico è stata effettuata da David Hempleman-Adams nel 1992.
Il polo nord dell'inaccessibilità è uno dei poli dell'inaccessibilità che possono essere individuati sulla superficie della Terra. Questi poli pur potendo essere individuati con precisione su una carta geografica non hanno caratteristiche fisiche particolari ma sono rilevanti unicamente perché si trovano in corrispondenza di punti geografici che rispondono a una caratteristica predefinita.
Il polo nord dell'inaccessibilità è, per definizione, il punto del mar Glaciale Artico più distante da ogni linea costiera. È situato circa 1100 km dalla costa più vicina alle seguenti coordinate geografiche: 84°03′N 174°51′W﻿ / ﻿84.05°N 174.85°W84.05; -174.85.
Il primo sorvolo di questo particolare luogo geografico fu fatto nel 1927 da Hubert Wilkins; successivamente, nel 1958 fu raggiunto per la prima volta da una rompighiaccio sovietica.
In astronomia l'intersezione fra l'asse di rotazione di un qualsiasi corpo celeste e la sua superficie crea due punti distinti detti poli nord e sud.
L'Unione Astronomica Internazionale definisce il polo nord di un oggetto del sistema solare come: quel polo che si affaccia verso il polo nord del piano invariante del sistema solare. Il piano invariante del sistema solare è il piano che forma un angolo di 90° rispetto al vettore del momento angolare totale del sistema solare. Siccome le orbite dei pianeti sono poco inclinate rispetto all'eclittica il piano invariante e il piano dell'eclittica sono quasi coincidenti e fa sì che il polo nord di un pianeta sia quello che si affaccia verso il polo nord del piano dell'eclittica.
Un'altra definizione di polo nord frequentemente usata in astronomia fa uso di una regola chiamata "regola della mano destra". Il polo nord secondo questa regola "è quel polo intorno a cui il corpo celeste ruota in senso antiorario".
Se si fa riferimento alla definizione proposta dallo IAU l'inclinazione assiale dell'oggetto celeste sarà sempre di 90° o inferiore e il suo periodo di rotazione sarà negativo (moto retrogrado) mentre riferendosi alla regola della mano destra l'inclinazione assiale sarà sempre uguale o superiore a 90° e il periodo di rotazione sarà sempre positivo.
Molto usati in astronomia sono anche i termini polo nord celeste e polo nord dell'eclittica. Per polo nord celeste si intende la proiezione del polo nord geografico di un pianeta sulla sfera celeste. Per poli dell'eclittica si intende invece i due punti
rispetto ai quali tutti i punti dell'eclittica sono equidistanti. Il polo nord dell'eclittica è quello nell'emisfero nord.
Molte leggende legate alla figura di Babbo Natale prevedono che la sua casa sia situata al polo nord. Qui viene  aiutato dai suoi folletti e  riceve le lettere dei bambini con le richieste dei regali che poi costruisce
Due città degli USA sono chiamate polo nord: North Pole nello stato dell'Alaska e North Pole nello Stato di New York.
Il Canada (AFI: /ˈkanada/)[6] o Canadà (AFI: /kanaˈda/)[7] è uno Stato dell'America Settentrionale che si affaccia dall'Atlantico a est, dal Mar Glaciale Artico a nord e dall'Oceano Pacifico a ovest. Con una superficie di 9985000 km² è il secondo paese del mondo per superficie totale dopo la Russia. Confina con la Groenlandia (Regno di Danimarca) e con gli Stati Uniti d'America: quelli continentali a sud, in buona parte lungo la linea del 49º parallelo Nord, e con lo Stato dell'Alaska a nord-ovest quasi interamente lungo il 141º meridiano Ovest:[8] si tratta del confine terrestre tra due Stati più lungo del mondo (8891 km).
Era abitato, prima dell'arrivo europeo sul continente, da popolazioni indigene, il territorio dell'attuale Canada fu colonizzato da Francia e Regno Unito a inizio XVII secolo[8], a partire dalla costa atlantica.
I francesi persero in seguito i loro territori progressivamente a favore del Regno Unito: dapprima (1713) con il trattato di Utrecht alla fine della guerra di successione spagnola, con cui Terranova e la baia di Hudson furono cedute da Luigi XIV; a seguire nel 1763 dopo la sconfitta nella guerra franco-indiana, teatro nordamericano della guerra dei sette anni, e, infine, con la vendita di Napoleone (1803) della Louisiana francese agli Stati Uniti d'America e delle sue ultime rimanenze oltre il confine canadese al Regno Unito.
Il 1º luglio 1867 nacque la federazione canadese con l'unione delle tre colonie del Nord America Britannico di Nuova Scozia, Nuovo Brunswick e Canada[9], che in seguito divennero quattro per la scissione della provincia del Canada in Ontario e Québec.
Nel corso del tempo si aggiunsero sempre più province, che avrebbero poi formato l'odierno Stato nordamericano.
Costituitosi in Stato unitario il 1º luglio 1867 come Confederazione canadese per iniziativa della Corona britannica, divenne formalmente coeguale con il Regno Unito l'11 dicembre 1931, data di promulgazione dello statuto di Westminster cui affrancò molti dei suoi ex dominion.
Infine, con la nuova legge sul Canada del 1982 (il cosiddetto patriation o "rimpatrio"), il Regno Unito abdicò anche al potere formale di modifica della costituzione canadese, garantitogli dallo Statuto del 1931.
Il Canada è uno Stato membro del Commonwealth britannico, del quale è uno dei quindici reami: di conseguenza, benché indipendente,[8] ha come capo di Stato il sovrano del Regno Unito, al 2023 il re Carlo III.
In rappresentanza del sovrano agisce localmente il governatore generale del Canada, il quale è capo di Stato de facto, avendo le prerogative di accreditare il corpo diplomatico, assegnare l'incarico di primo ministro e nominare i giudici della Corte suprema, convocare le elezioni generali federali e, in talune occasioni, rappresentare il Paese a livello internazionale.
Dal 1959 esiste la prassi non ufficiale di nominare alternativamente un governatore generale anglofono e uno francofono per rispetto dei due maggiori gruppi linguistici del Paese.
Il sistema politico è parlamentare e il primo ministro è in genere il leader del partito che vince le elezioni generali federali, che si tengono normalmente ogni quattro anni, salvo consultazioni anticipate (le più recenti risalgono al 20 settembre 2021).
Al 2021 il governatore generale in carica è l'ex funzionaria pubblica e diplomatica Inuit Mary Simon  (1947-) mentre il primo ministro è il leader liberale Justin Trudeau (1971-), in ufficio dal 4 novembre 2015.
In Canada si parlano diverse lingue sia native sia europee, ma quelle ufficiali sono il francese e l'inglese[8], che hanno status paritetico in tutti gli atti pubblici della federazione: su circa 35-37 milioni d'abitanti (stima 2019), quasi il 57% di essi è di madrelingua inglese e poco più del 21% francese; tuttavia, molti canadesi sono bilingue e al 2011 l'85% della popolazione dichiarava padronanza dell'inglese e il 30,1% del francese.[10]
Dal 2006 la provincia del Québec, ufficialmente francofona, è riconosciuta come «nazione in seno a un Canada unito».
Tra le lingue non ufficiali con più di 300 000 parlanti figurano lo spagnolo, il tagalog, l'arabo, il tedesco e l'italiano, grazie alla presenza di fenomeni migratori nel Paese.
Il PIL nominale del Canada è il 8 al mondo[la pagina nel wikilink una posizione diversa, così come l'infobox e il link nello stesso. Serve aggiornare allo stesso anno]: esso si basa prevalentemente sulle ingenti risorse naturali e sulle sue ben sviluppate reti commerciali, specialmente con gli Stati Uniti, con cui il Canada intrattiene complesse relazioni di lunga data.
Il Canada è uno dei Paesi più avanzati del mondo con il ventesimo PIL pro-capite e il sedicesimo indice di sviluppo umano.
Il Canada fa parte dell'ONU fin dalla sua prima assemblea generale del 1945 e, come media potenza, è membro di numerosi organismi internazionali militari, politici e commerciali quali il G7, il G20, la NATO, il NAFTA, l'OCSE, il OMC, l'OAC, l'APEC.
Il demotico di una persona originaria del Canada è canadese (plurale canadesi), invariato al femminile.
In inglese è Canadian (plurale Canadians) e in francese è canadien se maschile o canadienne se femminile (al plurale rispettivamente canadiens e canadiennes).
Nel corso della storia sono state formulate diverse teorie sulle origini etimologiche del nome Canada. Al giorno d'oggi il nome è comunemente accettato come proveniente dalla parola irochese kanata, che significa "villaggio" o "insediamento". Nel 1535, gli abitanti indigeni dell'attuale regione di Quebec City usarono la parola kanata per indirizzare l'esploratore francese Jacques Cartier al villaggio di Stadacona. Cartier in seguito usò la parola Canada per riferirsi non solo a quello specifico villaggio ma all'intera area soggetta al potere di Capo Donnacona (il capo di Stadacona). Nel 1545, i libri e le mappe europee avevano iniziato a riferirsi a questa piccola regione lungo il fiume San Lorenzo come Canada.
Dal XVI all'inizio del XVIII secolo, la parola "Canada " si riferiva alla parte della Nuova Francia che si trovava lungo il corso del fiume San Lorenzo. Nel 1791, l'area divenne parte dell'Impero Britannico venendo suddivisa in due colonie chiamate Alto Canada (Upper Canada) e Basso Canada (Lower Canada). Queste due colonie furono chiamate collettivamente Canadas (al plurale) fino alla loro unione come Provincia britannica del Canada nel 1841.
Al momento della Confederazione nel 1867, il nome Canada fu adottato come nome legale per il nuovo paese alla Conferenza di Londra. Al Canada fu poi conferito lo status di Dominion, divenendo così il Dominion of Canada. Negli anni '50, il termine Dominion of Canada non era più utilizzato dal Regno Unito, che considerava il Canada un "Reame del Commonwealth". Il termine Dominion era usato più che altro per distinguere il governo federale dalle province, anche se dopo la seconda guerra mondiale il termine federale aveva sostituito la dicitura dominion. Nel 1951 il governo di Louis St. Laurent pose fine alla pratica di utilizzare il titolo Dominion negli statuti del Canada.
Il Canada Act 1982, che ha portato la costituzione del Canada completamente sotto il controllo canadese, si riferiva alla nazione solo con il nome Canada. Nello stesso anno, il nome della festa nazionale fu cambiato da Dominion Day a Canada Day.
Gli archeologi stimano che i primi uomini a giungere nella regione geografica del Canada siano arrivati dall'Asia, attraverso lo Stretto di Bering, già oltre 40 000 anni fa. Queste e ondate successive diedero origine ai discendenti degli attuali indiani canadesi e alle popolazioni Inuit.
I primi europei a giungere sulle coste canadesi presso L'Anse aux Meadows furono i componenti della famiglia vichinga Erikson (proprietari della Groenlandia): intorno all'anno Mille si stabilirono nella zona settentrionale dell'isola di Terranova, che chiamarono Vinland (terra del vino). Dopo vari conflitti con i nativi abbandonarono definitivamente il territorio, ma ci tornarono periodicamente per rifornirsi di legname.
Nel 1497, su incarico degli inglesi, l'italiano Giovanni Caboto raggiunse l'isola di Terranova. Nel 1509 Sebastiano Caboto esplorò tutte le coste nordamericane, dall'isola di Baffin alla Florida.
Al 1535 si deve l'origine del nome del Canada: durante le esplorazioni lungo il fiume San Lorenzo compiute da Jacques Cartier alcuni irochesi si riferirono al villaggio di Stadacona, la futura Québec, con il termine kanata (che nella loro lingua vuol dire "comunità", "villaggio").
Jacques Cartier utilizzò così il nome Canada per tutto il territorio in cui si trovava il villaggio di Stadacona. Negli anni seguenti il nome indicava sulle carte geografiche tutti i territori a nord del fiume San Lorenzo.[11] Nei secoli XVII e XVIII il nome Canada venne utilizzato per indicare i territori della Nuova Francia, estendendone via via l'uso fino a ricomprendervi le sponde settentrionali dei Grandi Laghi.
Il Canada divenne possedimento della Francia nel 1534, quando l'esploratore francese Jacques Cartier prese possesso della zona circostante il fiume San Lorenzo in nome del re Francesco I. Per oltre cento anni il Canada rimase una colonia francese. Samuel de Champlain, nel 1604, stabilì la prima colonia permanente nel Nord America a Port Royal, Acadia (poi diventata Annapolis Royal, Nuova Scozia). Quattro anni dopo fondò la colonia del Québec. Nel 1615 scoprì i laghi Huron e Ontario. Dal 1615 furono accolti i primi missionari che tentarono di convertire gli Irochesi e gli Uroni, nativi del luogo.
Il progetto di un impero americano francese, suffragato dalla Nuova Francia che nel 1608 aveva come capitale la città di Québec, inevitabilmente fece scoppiare un conflitto tra Francia e Gran Bretagna. Le guerre per il dominio coloniale del Nord America e che vedono schierate queste due potenze passano sotto il nome di guerre franco-indiane. Nel 1763, dopo la guerra dei sette anni, in cui rilevante fu la vittoria schiacciante di James Wolfe durante la battaglia di Québec, tutto quello che rimaneva della Nuova Francia passò sotto il dominio della Gran Bretagna.
Durante la guerra anglo-americana la colonia canadese fu una pedina della Gran Bretagna nella guerra contro gli Stati Uniti.[12] Con l'Atto di Unione del 1840 vennero fuse in una sola le allora due colonie dell'Alto e Basso Canada. La prima ha prevalente cultura britannica, la seconda di spiccata cultura francofona. Obiettivo non ultimo era quello di convertire il Basso Canada alla cultura e alla lingua inglese.
Nel 1867 alcune colonie britanniche del Nord America Provincia del Canada, Nuovo Brunswick e Nuova Scozia si unirono nella Confederazione canadese. Il dominio del Canada ottenne la piena indipendenza nel 1931. Dalla nascita del Canada, le sue frontiere esterne sono cambiate sei volte, e internamente si è passati da quattro province a dieci province e tre territori.
I Nativi furono una popolazione indigena abitante in Canada, discriminata dal resto della popolazione. Il governo, per evitare questa discriminazione dalla parte degli abitanti bianchi del Canada, pubblicò una legge: l'assimilazione forzata ovvero insegnare e obbligare i Nativi a rispettare la cultura canadese e abbandonare quindi la propria. Questa legge è a doppio senso: in questo i Nativi non erano più discriminati ma allo stesso tempo erano obbligati a seguire la cultura (quindi anche la religione) facendo perciò emergere un nuovo problema.
Il termine Prime nazioni si riferisce alle popolazioni aborigene del Canada che non sono Métis o Inuit. Nel 2011, questa popolazione contava circa 1,3 milioni di persone.
Le migrazioni degli aborigeni risalgono a circa 15.000 anni fa , all'ultima era glaciale, che abbassò il livello del mare e creò un ponte terrestre dall'Eurasia all'America, permettendo loro di insediarsi.[13]
Nell'ottobre 2019, il Canada viene segnalato dalle Nazioni Unite per le condizioni abitative delle popolazioni indigene. La commissione d'inchiesta sottolinea che gli aborigeni hanno "maggiori probabilità di essere alloggiati male e di avere di conseguenza problemi di salute". Inoltre, "la percentuale di senzatetto tra loro è sproporzionatamente alta e sono estremamente vulnerabili agli sfratti forzati, all'accaparramento delle terre e agli effetti del cambiamento climatico. Quando difendono i loro diritti, sono spesso bersaglio di violenze estreme". Anche le comunità aborigene sono pesantemente colpite dalla carenza di alloggi nel Canada settentrionale: comunità che dormono alternativamente. "Quindici persone vivono in una casa grande come una roulotte. [...] Devono fare i turni per dormire quando non c'è molto spazio.[14]
Il Canada ha una superficie di 9984670 km², perciò risulta essere il secondo Stato per estensione dopo la Russia. La differenza di fuso orario fra le coste orientale e occidentale è di 6 ore.
A parte l'Arcipelago artico canadese, il territorio può essere suddiviso in cinque grandi aree: lo scudo canadese, il sistema montuoso degli Appalachi, i Grandi Laghi e il bacino del San Lorenzo, le pianure centrali e la catena costiera.
La morfologia del territorio canadese ha un'importanza minore rispetto al clima, per quanto riguarda gli insediamenti umani. Il Canada è, infatti, un territorio per gran parte pianeggiante, con rilevanti catene montuose solo a occidente e nel senso dei meridiani, per cui le condizioni di abitabilità sono essenzialmente in diretta funzione del clima: dove esso è meno polare si ha la parte più densamente popolata del Paese. Questa corrisponde alla fascia più meridionale, che si appoggia al confine degli Stati Uniti fino alla costa del Pacifico. Seguono il "Canada medio" e il "Canada alto", dove la nordicità è già molto accentuata; infine c'è l'estremo nord, che ha un clima polare. Importanti catene montuose sono le Montagne Rocciose Canadesi, poste a occidente, e la Cordigliera Artica nelle terre estreme del Nord. La montagna più alta del Canada è il Monte Logan nello Yukon con i suoi 5 959 metri.
Il Canada possiede più laghi e acque interne di qualsiasi altro paese al mondo. Oltre ai Grandi Laghi, che si estendono in gran parte negli Stati Uniti, i più estesi del paese sono il Grande Lago degli Orsi e il Grande Lago degli Schiavi nei Territori del Nord-Ovest; il lago Athabasca nelle province di Alberta e Saskatchewan; il lago Winnipeg e il lago Manitoba nella provincia di Manitoba e il lago Mistassini nella provincia di Québec.
I principali fiumi canadesi sono il San Lorenzo, emissario dei Grandi Laghi, che sfocia nel golfo omonimo (vedi Golfo di San Lorenzo); l'Ottawa e il Saguenay, principali affluenti del San Lorenzo; il Saint John, che confluisce nella Baia di Fundy, tra la Nuova Scozia e il Nuovo Brunswick; il Saskatchewan, che forma il lago Winnipeg, e il Nelson, che da questo lago raggiunge la baia di Hudson; il sistema formato dai fiumi Athabasca, Peace, Slave e Mackenzie, che sfociano nel Mar Glaciale Artico; l'alto corso dello Yukon, che attraversa l'Alaska e raggiunge il mare di Bering; il Fraser e il corso alto del Columbia, che sfociano nell'Oceano Pacifico.
Le temperature medie estive e invernali del Canada variano a seconda della porzione di territorio cui si fa riferimento. Gli inverni sono molto rigidi nella maggior parte delle regioni del Paese, particolarmente nell'entroterra dove le temperature medie durante tale periodo oscillano intorno ai −15 °C, con picchi sotto i −40 °C.[15] Nello Yukon le medie di gennaio arrivano a −34 °C con un record di −59 °C (2ª temperatura minima in Nord America dopo Prospect Creek in Alaska con i suoi −62,1 °C[16]). Nell'entroterra il suolo è coperto dalla neve da 3 a 5 mesi l'anno per le regioni meridionali; il manto nevoso copre il suolo per 6 mesi nelle zone centrali e 7 o 8 mesi al nord. Nei punti più settentrionali la neve è perenne.
La costa occidentale del Canada gode di inverni meno rigidi dell'interno e piovosi, con temperature medie in gennaio anche superiori a 0 °C. Le precipitazioni nevose sono discontinue e non durano più di due settimane. La costa orientale fino al 50º parallelo ha un clima continentale (circa −7 °C a gennaio e 22 °C a luglio), dal 50º al 58º parallelo ha un clima subartico, con inverni freddi (medie di gennaio da −10 °C a −21 °C) ed estati fresche (medie di luglio tra i 12 °C e i 20 °C). A nord del 58º parallelo il clima è artico a causa della corrente fredda del Labrador: nessun mese ha medie superiori a 10 °C, quelle di gennaio arrivano a −24 °C, vi sono gli orsi polari, vi crescono solo muschi e licheni, le medie sono sotto zero per otto mesi. Nell'interno del Labrador il clima è circa dello stesso tipo per la latitudine ma gli inverni sono un po' più freddi e le estati un po' più calde (Kuujiiaq, circa 58° N, di gennaio ha temperature estreme di −19 °C/−28 °C e di luglio di 5 °C/17 °C; in altre località a gennaio si arriva a −28 °C di media).
D'estate nelle regioni costiere le temperature più alte si aggirano intorno ai 20 °C, mentre all'interno le temperature medie estive variano tra i 25 e i 30 °C con punte di 40 °C.[17]
Secondo un rapporto commissionato dal governo, il riscaldamento climatico in Canada è due volte più veloce che nel resto del mondo. Secondo gli esperti che hanno scritto il rapporto, il riscaldamento globale "aumenterà la gravità delle ondate di calore e contribuirà ad aumentare il rischio di siccità e incendi boschivi. Sebbene le inondazioni interne siano il risultato di molteplici fattori, precipitazioni più intense aumenteranno il rischio di inondazioni nelle aree urbane.[18]
Il 75% del popolo canadese abita a meno di 330 chilometri dalla frontiera con gli Stati Uniti, un confine non presidiato militarmente e la più lunga tra le frontiere nel mondo, estesa per oltre 8000 km.
Della popolazione nata nel Canada (84% del totale che ammonta nel 2011 a 33 400 000 unità), poco più della metà (circa 17 milioni) è di origini britanniche, il 34% è di origini francesi (11,5 milioni). Si sono inoltre insediate una ventina di popolazioni diverse, tra cui tedeschi (900 000), italiani (700 000), ucraini (420 000), olandesi (352 000), polacchi (222 000). Per quanto riguarda la popolazione immigrata, oltre un milione proviene dalla Gran Bretagna e circa 280 000 dagli Stati Uniti. La maggioranza dei canadesi parlanti francese abita nella provincia del Québec, costituendone circa l'80% della popolazione.
La popolazione indigena canadese è costituita da algonchini, irochesi, cayuga, inuit, che costituiscono circa il 3% della popolazione totale. Le popolazioni di origine africana sono presenti in minima parte (circa l'1%). Tra gli anni settanta e ottanta del Novecento si verificò un notevole aumento di popolazione asiatica (circa l'8% della popolazione totale), che per due terzi vive in Ontario e nella Columbia Britannica. Oggi il Paese ha uno dei più alti tassi di immigrazione al mondo, soprattutto di rifugiati; molti immigrati si trovano nelle città maggiori.
Dopo la sua prima colonizzazione il Canada ha ricevuto varie ondate migratorie, che hanno contribuito a renderlo un paese fortemente multiculturale, con importanti e significative minoranze.
Tra il XVII e XVIII secolo a insediarsi furono prevalentemente i coloni francesi con Samuel de Champlain,[8] soprattutto lungo le sponde atlantiche (Acadia) o la valle del fiume San Lorenzo (nell'odierno Quebec). La regione rimase tuttavia fortemente disabitata e in gran parte inesplorata. Nel XIX secolo, con la cessione della Nuova Francia al Regno Unito e l'inizio del dominio britannico, iniziò l'afflusso di coloni di lingua inglese,[8] prevalentemente verso le regioni dei Grandi Laghi, nell'odierno Ontario. Il governo dell'epoca favorì l'insediamento di popolazioni di madrelingua inglese, anche per contrastare e riequilibrare l'influenza del francofono Basso Canada (Quebec).
Importanti ondate migratorie provenienti dall'Europa si ebbero poi nei primi del Novecento e negli anni cinquanta.
La modifica della legge sull'immigrazione (l'Immigration Act del 1976) ha nella sostanza aperto le porte a nuovi flussi provenienti dai paesi non europei. Negli anni ottanta prima, e dall'inizio del nuovo millennio poi, si stimano tra i 225 000 e i 275 000 il numero dei nuovi ingressi annui.[19]
Le varie immigrazioni succedutesi nel corso della storia del paese (e in parte in corso) hanno reso il Canada un paese fortemente variegato dal punto di vista etnico e culturale. Diversamente da altri Paesi (in particolare i vicini Stati Uniti d'America), dove si è affermata nel tempo una forte tendenza all'assimilazione delle varie culture a quella anglosassone, che dovrebbero essere superate per dare vita a un'identità nazionale il più omogenea possibile, in Canada si è invece affermato un modello multiculturale in senso stretto, che tende cioè a offrire maggiori spazi e tutele alle singole culture d'origine, come è esplicitamente sancito nell'Immigration Act. Per descrivere questa realtà multiculturale canadese si usa spesso l'espressione "mosaico culturale", in opposizione al modello statunitense del melting pot (letteralmente: "crogiolo"). Va tuttavia osservato come nel lungo periodo, e di loro spontanea volontà, gli immigrati si riconoscano e si inseriscano in uno dei due modelli culturali storici, ovvero quello francofono e quello anglosassone.
Questo grafico non è al momento disponibile a causa di un problema tecnico temporaneo. Si prega quindi di non rimuoverlo.
██ Europei (76,7%)██ Asiatici (14,2%)██ Aborigeni (4,3%)██ Neri (2,9%)██ Latino-americani (1,2%)██ Multirazziali (0,5%)██ Altro (0,3%)     Canadese     Inglese     Francese     Scozzese     Tedesca     Italiana     Indigena     Ucraina     Indiana     InuitContando sia le risposte singole sia quelle multiple, le origini etniche in cui i canadesi si identificano più comunemente nel 2016 sono:[21]
Gli abitanti originari del Canada appartengono a molti gruppi diversi. Essi fino a poco tempo fa venivano chiamati "Eschimesi", mentre oggi il loro nome è "Inuit" (Inuk o Inuq al singolare): nella loro lingua, l'inuktitut, vuol dire "gente". Sopravvivono basandosi sulle risorse offerte dal mare e con la caccia, praticata mediante tecniche molto avanzate. Talvolta, questi popoli visitavano anche le aree della tundra per sfruttare anche questi territori. Tuttavia, durante la seconda guerra mondiale e la guerra fredda l'Artico assunse un'importanza strategica e ciò portò pesanti modifiche nel loro stile di vita, con il forte impatto con altre culture che portò anche dei salari per gli Inuit. Oggi, vivono quasi tutti in insediamenti, molti dei quali sono sorti durante o dopo la guerra, oppure sono ex-edifici commerciali o scientifici, sebbene molti prediligano ancora il nomadismo. Tuttavia, la tecnologia ha raggiunto anche gli Inuit, che grazie a TV, satelliti e telefoni possono usufruire anche di molte delle comodità della vita moderna. Le città maggiori sono servite da voli frequenti da e per i centri più esterni.
Gli altri nativi del Canada sono i cosiddetti "primi popoli", una volta noti come "Indiani d'America". Essi, pur appartenendo a etnie diverse con lingue e culture altrettanto diverse, hanno in comune alcuni obiettivi, come quello di strappare al sistema federale il controllo sul sistema scolastico, al fine di istituire scuole gestite dai popoli locali a salvaguardia delle loro lingue e culture. Molti esponenti indigeni vedono nell'azione politica l'unico modo per riscattare alcune ingiustizie subite nel passato.
L'assemblea dei primi popoli è presieduta da un Grande Capo eletto e fa da portavoce alle istanze di tutte le popolazioni indigene. Essa ha portato all'attenzione dei dibattiti politici problemi come l'alcolismo, la tossicodipendenza e la violenza che sono autentiche piaghe in queste popolazioni.
Secondo il censimento della popolazione del 2007, l'orientamento religioso dei canadesi è così suddiviso:
Fra i protestanti la Chiesa unita del Canada, costituitasi nel 1925, con circa 2 800 000 fedeli (censimento 2001), è la più numerosa.
Il 60% circa dei canadesi è di lingua madre inglese e circa il 24% di madrelingua francese. Gli altri hanno come madrilingue altri idiomi europei (tedesco e italiano soprattutto) e solo il 2% circa delle lingue parlate sono autoctone (inuit e native americane). In Canada sono riconosciute due lingue ufficiali: l'inglese e il francese. Nel Territorio del Nunavut sono riconosciute undici lingue ufficiali: oltre all'inglese e al francese,[8] nove lingue indigene. L'inglese è la lingua più parlata mentre il francese è parlato diffusamente nelle province del Québec, del Nuovo Brunswick e nella parte nord-orientale della provincia dell'Ontario (Canada francese); inoltre comunità francofone minori sono disseminate nel territorio delle altre province. L'inglese è parlato nel resto del Canada, ma vi sono comunità anglofone anche nelle province francofone. I cittadini canadesi imparano entrambe le lingue a scuola, sebbene molti di loro parlino abitualmente una sola delle due lingue.
Il Canada è uno Stato federale,[8] istituito come dominio nel 1867, e dal 1926 appartenente al Commonwealth.
Possiede una nuova Costituzione: la Costituzione del Canada, dal 17 aprile 1982.
Il Canada è una federazione composta da dieci province e tre territori. A loro volta, queste possono essere raggruppate in tre regioni principali: Canada occidentale, Canada centrale e Canada orientale, quest'ultima suddivisibile in Canada atlantico e Canada settentrionale. Le province hanno maggiore autonomia rispetto ai territori, con responsabilità per i programmi sociali come l'assistenza sanitaria, l'istruzione e il welfare.[38] Nel loro complesso le province ricevono una quota di entrate fiscali maggiore rispetto al governo federale, un'organizzazione quasi unica tra le federazioni di tutto il mondo. Utilizzando i suoi poteri di spesa, il governo federale può avviare politiche nazionali in aree provinciali, come ad esempio il Canada Health Act. Pagamenti di equalizzazione sono attuati dal governo federale per garantire una ragionevole uniformità negli standard di servizi e fiscalità tra le province più ricche e quelle più povere.[39]
La capitale Ottawa (Ontario) è soltanto la quarta città per numero di abitanti dopo Toronto (Ontario), Montréal (Quebec) e Vancouver (Columbia Britannica). Di seguito sono elencate le 20 aree metropolitane più popolose.[40]
Secondo l'impostazione federalista, in Canada non esiste un sistema di istruzione nazionale uniforme; tuttavia, le scuole terziarie sono soggette a un controllo di qualità attuato dallo Stato unitario e la maggior parte delle università canadesi sono membri dell'Association of Universities and Colleges of Canada (AUCC): in questo modo, il loro livello è generalmente considerato equilibrato.[42]
Le province e i territori sono esclusivamente responsabili per l'istruzione e non vi è alcun ministero. Pertanto, a seconda della provincia, vi è una differente età per l'entrata nel sistema scolastico (quinto o sesto anno di età) e una differente durata della scuola primaria (fino alla 6ª o 7ª classe). La scuola secondaria (nota come École polyvalente) comprende, in un'unica soluzione, la scuola media di tre anni (istruzione secondaria) e la scuola superiore. Il 2% degli istituti scolastici è privato, di cui la maggior parte è di proprietà degli enti ecclesiastici. Circa il 10% degli studenti frequenta una scuola privata. Il livello di prestazioni delle scuole private è stato stimato nel 2006 come molto alto.
Mentre la frequenza scolastica è gratuita, l'università prevede il pagamento di tasse variabili.[43] Tra le più di 80 università, l'Università di Toronto e l'Università di Montréal sono tra le più grandi. La più antica, l'Università Laval, a Québec, è un istituto gesuita ed è stato fondato nel 1663: effettivamente l'Università Laval venne istituita nel 1852, ma ha le sue radici come Seminario del Québec nel 1663 fondato dal vescovo francese François de Montmorency-Laval. Solo nel 1818 è stata fondata la prima università laica in Canada: l'Università Dalhousie di Halifax, seguita dalla McGill University di Montréal (1821) e dall'Università di Toronto (1827).
È un servizio sanitario nazionale universalistico, con integrazioni private chiamato single-payer health care, un tipo di assistenza sanitaria che copre i costi essenziali per tutti i residenti, ma inferiori ai sistemi sanitari completi del tipo italiano o nordico di welfare.[44]
Al 2015 il Canada contava una forza militare composta da 68 250 persone, tra professionisti e volontari, e circa 51 000 riservisti.[45] Le Forze Canadesi unificate (CF) comprendono l'esercito (Canadian Army), la marina (Royal Canadian Navy) e l'aeronautica (Royal Canadian Air Force). Nel 2013, la spesa militare del Canada è stata pari a circa 19 miliardi di dollari canadesi, pari a circa l'1% del PIL del paese.[46][47]
Il Canada e gli Stati Uniti condividono la più lunga frontiera indifesa del mondo, co-operando su campagne militari e sulle esercitazioni e sono reciprocamente i più grandi partner commerciali.[48][49] Tuttavia, il Canada ha una politica estera indipendente, in particolare ha mantenuto rapporti completi con Cuba dal 1961 al 2014 e non ha partecipato all'invasione dell'Iraq nel 2003. Il Canada mantiene anche storici legami verso il Regno Unito e la Francia e ad altre ex colonie britanniche e francesi, attraverso l'adesione al Commonwealth delle nazioni e all'Organizzazione internazionale della francofonia.[50] È noto che il Canada intrattenga buoni rapporti con i Paesi Bassi, in parte per via del suo contributo alla liberazione olandese durante la seconda guerra mondiale.
Il forte attaccamento del Canada all'Impero britannico e al Commonwealth ha portato a una consistente partecipazione agli sforzi militari britannici durante la seconda guerra boera, la prima guerra mondiale e la seconda guerra mondiale. Da allora, il Canada è stato un sostenitore del multilateralismo, compiendo sforzi per risolvere i problemi globali in collaborazione con le altre nazioni.[51][52] Il Canada è stato un membro fondatore delle Nazioni Unite nel 1945 e della NATO nel 1949. Durante la guerra fredda, ha contribuito fortemente nelle forze ONU nella guerra di Corea e, in collaborazione con gli Stati Uniti d'America, ha fondato il Comando di Difesa Aerospaziale del Nord America (NORAD), per la difesa contro potenziali attacchi aerei da parte dell'Unione Sovietica.[53]
Durante la crisi di Suez del 1956 il futuro primo ministro Lester B. Pearson ha alleviato le tensioni proponendo l'intervento di una forza di pace delle Nazioni Unite, per la quale è stato insignito del premio Nobel per la pace nel 1957.[54] Per quanto questa sia stata la prima missione di peacekeeping delle Nazioni Unite, Pearson è spesso accreditato come l'inventore del concetto. Il Canada ha partecipato a oltre 50 missioni di pace, tra cui tutti gli interventi delle Nazioni Unite fino al 1989, e mantiene forze in missioni internazionali, come in Ruanda e nell'ex Jugoslavia.
Nel 1990 il Canada si è unito all'Organizzazione degli Stati americani (OAS) e nel giugno del 2000 ha ospitato l'Assemblea Generale dell'OAS a Windsor, in Ontario, mentre nel mese di aprile 2001 è stata sede del terzo Vertice delle Americhe a Québec.[55] Il Canada cerca, inoltre, di espandere i suoi legami con le economie delle isole del Pacifico attraverso l'appartenenza al forum Asia-Pacific Economic Cooperation.[56]
Nel 2001 il Canada ha schierato truppe in Afghanistan nel quadro della forza di stabilizzazione degli Stati Uniti e secondo l'autorizzazione delle Nazioni Unite, guidando la NATO International Security Assistance Force. In 10 anni di missione, il Canada ha perso 158 soldati, un diplomatico, due operatori umanitari e un giornalista,[57] spendendo una cifra di circa 11,3 miliardi di dollari canadesi[senza fonte].
Nel febbraio 2007 il Canada, l'Italia, il Regno Unito, la Norvegia e la Russia hanno annunciato il loro impegno comune a un progetto da 1,5 miliardi di dollari per aiutare a sviluppare vaccini per i paesi in via di sviluppo, e ha invitato altri paesi a unirsi a loro.[58] Nel mese di agosto 2007, rivendicazioni territoriali del Canada nell'Artico sono state contestate dopo una spedizione sottomarina russa al Polo nord; il Canada ha ritenuto che tale area fosse territorio sovrano dal 1925.[59] Tra marzo e ottobre 2011, le forze canadesi hanno partecipato a un intervento della NATO mandato ONU nella guerra civile libica del 2011.[60] A partire dal 2014, le unità terrestri e aeree canadesi si sono unite agli sforzi internazionali per sconfiggere l'insurrezione dello Stato Islamico in Iraq.[61]
Il Canada è una monarchia costituzionale con Carlo III Re del Canada come capo di Stato. Il paese è una democrazia parlamentare con un sistema federale[8] di forti tradizioni democratiche. La Costituzione è la legge suprema del paese, e consta di un testo scritto e di convenzioni non scritte[62] La Constitution Act del 1867 (in linea di principio creata su modello di quella del Regno Unito), sanciva una divisione di poteri tra il governo federale (centrale) e il governo provinciale; lo statuto di Westminster del 1931 dava la piena autonomia al Canada; e la Constitution Act del 1982, in aggiunta alla Carta Canadese dei Diritti e delle Libertà, garantisce i diritti e le libertà fondamentali, che non possono essere ignorati da qualsiasi livello del Governo.
Come in tutti i sistemi parlamentari, il potere esecutivo pur essendo costituzionalmente attribuito al monarca,[63] in pratica è esercitato dal Consiglio dei ministri (Cabinet) presieduto dal Primo Ministro. Formalmente, il Consiglio è retto dal rappresentante del Re, il Governatore Generale, che assume le prerogative regali quando il Re non si trova sul suolo del Canada. Il Governatore è altresì Comandante in capo delle Forze armate canadesi. È nominato dal Re su consiglio del Primo Ministro. Rideau Hall è la residenza principale a Ottawa, e la Citadelle de Québec è la sua residenza nella città di Québec.
Il vero detentore del potere esecutivo è il Primo Ministro, solitamente il leader del partito politico che ottiene la fiducia della Camera dei Comuni, è nominato dal Governatore Generale, sulla base del risultato elettorale. Il leader del secondo partito più rappresentato diviene il leader dell'opposizione. Mary May Simon è l'attuale Governatore Generale, ed è in carica dal 26 luglio 2021; Justin Trudeau, leader del Partito Liberale del Canada è entrato in carica come Primo Ministro il 4 novembre 2015.
Il potere legislativo è esercitato dal parlamento federale, composto da due camere (houses): la Camera dei Comuni (eletta) e il Senato (nominato). Il Re ha il potere di firma delle leggi (promulgazione), che teoricamente potrebbe rifiutare, potere in realtà mai usato. Formalmente essa partecipa al procedimento di formazione legislativa. Ogni membro della Camera dei Comuni è eletto con la maggioranza dei voti all'interno del proprio distretto elettorale; le elezioni generali sono indette dal Governatore Generale, su consiglio del Primo Ministro o quando il Governo perde la fiducia del Parlamento. Non vi è alcun termine minimo per la durata del Parlamento, mentre una nuova elezione deve essere indetta entro cinque anni delle ultime elezioni generali. I membri del Senato, i cui seggi sono attribuiti su base regionale, sono scelti dal Primo Ministro e sono formalmente nominati dal Governatore Generale, fino all'età di 75 anni. L'organo legislativo ha la sua sede sulla Collina del Parlamento, dove si trovano gli edifici parlamentari.
Il Canada ha avuto un'alternanza tra governi formati da due partiti nel corso del XX secolo: il Partito Conservatore Progressista, di centro-destra, e il Partito Liberale, di centro-sinistra. Fino agli anni ottanta, entrambi i partiti sono stati favorevoli a un significativo intervento dello Stato nell'economia, finché l'elezione di Brian Mulroney, a Primo Ministro ha sancito la svolta dei Conservatori Progressisti a favore di privatizzazioni, meno regolamentazione e meno tasse per le imprese e per i più abbienti. Con il ritiro di Mulroney nel 1993, il suo partito ha però subito un tracollo di voti e di seggi alla Camera dei Comuni, consentendo ai Liberali di tornare al governo, contando soprattutto sulla propria supremazia in Ontario.
Il terzo partito è stato tradizionalmente il Nuovo Partito Democratico, collocato a sinistra dello spettro politico. Negli anni novanta questo partito, così come i conservatori progressisti, hanno subito un'emorragia di voti e seggi a favore dei partiti regionali nati in quel periodo: il Blocco del Québec, favorevole all'indipendenza del Canada francese e collegato al Partito del Québec presente solo nel Parlamento provinciale; e il Partito Riformatore del Canada, con base nel Canada occidentale, conservatore e ostile a concessioni a favore del Québec, che nel 2000 ha assunto il nome di Alleanza Canadese, rispecchiando l'intento di unificare tutto l'elettorato di destra. L'Alleanza Canadese nel 2003 si è fusa con i conservatori progressisti, dando vita al Partito Conservatore del Canada (al governo dal 2006). Il Partito Verde del Canada non ha ottenuto rappresentanza in Parlamento, ma ha comunque raccolto una quota significativa dei voti alle elezioni nazionali.
L'economia del Canada, membro del G8, dell'OCSE e della NAFTA, è una delle più forti nel mondo, ed è tuttora in forte espansione, avendo subito solo marginalmente la crisi del 2008, che invece ha colpito duramente i vicini Stati Uniti. Secondo un rapporto dell'FMI il Canada, trainato dall'export di materie prime, ha aggirato l'ostacolo crisi mantenendo intatto e robusto il settore immobiliare e continuando a crescere a ritmi molto sostenuti sin dal principio. Anche il tasso di disoccupazione si mantiene basso.
Il paese è tra i primi per prodotto interno lordo,[64] e storicamente il suo indice di sviluppo umano è uno dei più alti in assoluto, costantemente superiore a quello degli stessi Stati Uniti. È per eccellenza, insieme alla Russia, la superpotenza estrattiva del pianeta; infatti nel sottosuolo sono presenti in grandi quantità praticamente tutti i metalli della crosta terrestre, oltre a enormi giacimenti di petrolio (con le sabbie bituminose dell'Alberta il Canada è da considerarsi tra i primissimi produttori petroliferi mondiali, subito dopo l'Arabia Saudita), gas naturale, fosfati, carbone e uranio (primo produttore al mondo). Conseguentemente Il paese è sede di alcune delle maggiori industrie minerarie mondiali come la Barrick Gold (maggior estrattore mondiale di oro), la Cameco (maggior estrattore mondiale di uranio), la Rio Tinto Alcan (numero 1 al mondo nella estrazione e produzione di alluminio), la Potash One (maggior produttore mondiale di potassio) e altre numerose compagnie minerarie e petrolifere tra le prime al mondo.
La superpotenza mineraria canadese negli ultimi tempi ha attirato il fortissimo interesse asiatico e soprattutto della Cina,[65] che con lo sviluppo economico degli ultimi anni sta ripetutamente tentando di abbattere la supremazia delle mining corps canadesi, per destabilizzare pesantemente il mercato dei minerali e del petrolio (soprattutto sabbie dell'Alberta), in attesa di prenderne possesso come dominatore. Tuttavia per ora le majors canadesi mantengono la loro supremazia.
Inoltre a seguito della crisi delle terre rare (chiusura delle esportazioni da parte della Cina), il Canada, grazie ai giacimenti intorno alla baia di Hudson sembra l'unico paese a poter far fronte al blocco cinese. Il settore primario ha nella cerealicoltura e nello sfruttamento delle risorse forestali i suoi punti di forza. L'industria e le attività terziarie sono molto sviluppate.
Nel settore agricolo, si coltivano in particolare orzo, mais, frumento, patate, avena, colza, girasole e soia. Importante è anche l'allevamento, specie di bovini. I pescosi mari attorno a Terranova sostengono un settore ittico attivo ed efficiente.
Il Canada è al primo posto, a livello mondiale, anche nella produzione di energia idroelettrica e ne esporta circa il 14% negli Stati Uniti. Dei 566,3 miliardi di kWh prodotti nel 2003, il 67% è generato da centrali idroelettriche, il 7% da centrali a combustione, il 14% dalle centrali nucleari (attive 19 centrali) e poco più del 12% dalle centrali a fonti alternative (solare o eolico).
Discorso a parte va fatto per la provincia del Quebec dove il sistema di dighe costruito sul fiume San Lorenzo assicura una produzione di energia da fonti idriche pari al 61%, mentre la quota delle energie rinnovabili garantisce oltre il 38% dell'energia, rendendo la provincia francofona una delle più virtuose basi di sviluppo delle energie verdi a livello mondiale.
Le industrie principali sono quelle meccaniche (in particolare aeronautica, aerospaziale e automobilistica), quelle tessili e alimentari, la produzione di carta, la lavorazione del ferro e dell'acciaio, la fabbricazione di macchinari ad alta tecnologia e di macchine utensili. Importante è anche l'industria elettronica, legata ai settori militari, aerospaziale, dei trasporti e delle telecomunicazioni (polo di Montréal). Come in tutti i paesi sviluppati, il settore che più contribuisce al reddito nazionale è il terziario (banche, commercio, comunicazione, turismo).
Le esportazioni principali del Canada sono i prodotti di alta tecnologia, le automobili, il petrolio, il gas naturale, il carbone, i metalli in genere, i prodotti agricoli e forestali. I maggiori partner commerciali del Paese sono gli USA, la Gran Bretagna, la Cina e il Giappone.
La principale borsa valori del paese è il Toronto Stock Exchange, con sede a Toronto, ma importante è anche il Montréal Stock Exchange.
L'industria mineraria è fortemente sostenuta dal governo. Il Paese ospita le sedi e le principali filiali della maggior parte delle società minerarie mondiali. La legislazione federale e provinciale incoraggia lo sviluppo del mercato azionario, consentendo forme di divulgazione dei depositi più flessibili che altrove, e la tassazione è favorevole alle imprese. Inoltre, la rete diplomatica canadese fornisce sostegno politico all'estero a qualsiasi società mineraria registrata nel Paese. Il Primo Ministro Stephen Harper (2006-2015) ha dichiarato di voler rendere il Canada uno dei maggiori esportatori di risorse naturali al mondo. È stato criticato per aver deliberatamente indebolito le protezioni ambientali esistenti al fine di favorire l'industria, compresa quella mineraria.[66]
Nel 2018, gli scienziati avvertono dello scioglimento dei ghiacciai dello Yukon, che è due volte più veloce del previsto e potrebbe avere "conseguenze drammatiche" nella regione. Questa accelerazione ha già provocato cambiamenti nella regione: nel 2016, per mancanza d'acqua, il fiume Slims che alimenta il Kluane Lake è stato completamente prosciugato. Da allora, il livello del lago è sceso, causando la scomparsa di migliaia di pesci.[67]
Il Canada ha una vegetazione molto ricca. La tundra ricopre quasi completamente tutte le regioni Artiche, mentre i rilievi degli Appalachi e della Catena Costiera sono ricoperti da foreste di conifere. Nelle Pianure si estendono enormi praterie, dove crescono quasi esclusivamente graminacee. La vegetazione dei versanti orientali delle Montagne Rocciose è molto rada, mentre i versanti occidentali sono coperti da fitte foreste e da lunghe distese di conifere.
La fauna canadese è simile a quella europea e dell'Asia settentrionale. Tra i carnivori ci sono numerose specie di mustelidi (la donnola, l'ermellino, lo zibellino canadese, la martora e il visone). Nelle regioni artiche sono presenti l'orso grizzly, l'orso polare, la volpe, il coyote, la lince, il lupo, il puma e la capra delle nevi. Tra i roditori c'è il castoro che è famoso per le sue dighe, mentre sono diffusi: il riccio, il topo muschiato e la lepre. A sud vivono diverse specie di cervidi: l'antilocapra, il caribù/Renna, wapiti, l'alce. È inoltre presente il bisonte. Le specie di uccelli sono numerose, come: il gheppio, la gru e la poiana. Molto ricca è anche la fauna ittica lungo i litorali e nei laghi e non solo.
Tra i simboli nazionali del Canada, cioè quei simboli che vengono utilizzati in patria e all'estero per rappresentare il paese e la sua gente, posizione preminente ha l'uso della foglia d'acero il cui utilizzo risale già ai primi anni del XVII secolo.[68] Compare ad esempio nella bandiera, nello stemma, in alcune monete e come logo di numerose compagnie e società.
Da sempre noto come paese molto attento all'ecologia (nonostante alcuni impianti industriali estremamente inquinanti posti a nord della provincia dell'Alberta), il Canada porta con sé una cultura ecologista molto presente nelle coscienze civiche della popolazione.
Oltre ai simboli nazionali posti sugli stendardi rappresentativi, quasi sempre indicanti animali, piante o luoghi naturali, il Canada può fregiarsi di due simboli ecologisti molto importanti:
E ancora sono da ricordare tra i più rappresentativi simboli nazionali del Canada:
Fra gli architetti canadesi maggiormente noti si ricordano Hossein Amanat, Louis Bourgeois, James Bradburne, James K. M. Cheng, Arthur Erickson, Frank Gehry, Phyllis Lambert, Moshe Safdie, Fariborz Sahba
Ben 20 siti del Canada sono stati iscritti nella Lista dei patrimoni dell'umanità dell'UNESCO.
In campo artistico nel XX secolo si distinse la figura della pittrice Emily Carr, dallo stile pittorico modernista e post- impressionista, mentre tra il XX e il XXI secolo si distinse Kenojuak Ashevak, importante esponente della moderna arte inuit.
Nell'ambito di una letteratura canadese bisogna distinguere essenzialmente una letteratura franco-canadese da quella anglo- canadese: tra gli autori più affermati del XX secolo ricordiamo Marie-Claire Blais e Margaret Atwood.
Importante affermazione anche nel romanzo riguardante la letteratura per ragazzi con Lucy Maud Montgomery, nota autrice di Anna dai capelli rossi (1908), da cui sono stati prodotti diversi adattamenti in film, serie tv e fumetti.
Toronto, grande centro urbano del Canada, è la città natale di Glenn Gould (1932-1982), grande pianista e clavicembalista, celebre per le interpretazioni della musica di J. S. Bach.[69]
L'Orchestra Sinfonica di Montréal (Orchestre symphonique de Montréal) è tradizionalmente considerata la migliore del paese, e una delle più premiate del Nord America.[70]
Nel campo della musica barocca l'ensemble Tafelmusik di Toronto è fra i più rinomati al mondo per le sue esecuzioni su strumenti d'epoca delle musiche di J. S. Bach e Antonio Vivaldi,[71] mentre nel jazz lo è il pianista Oscar Peterson.[72]
Canadese è Loreena McKennitt, musicista e cantautrice considerata un'icona della musica eclettico-celtica.[73] Mentre i suoi primi dischi sono prettamente di musica celtica l'artista, grazie anche a una serie di viaggi in Europa e in Oriente, ha successivamente contaminato la musica celtica con nuove suggestioni seguendo il tema delle peregrinazioni delle popolazioni celtiche.[74]
Bryan Adams, rockstar nata a Kingston, nell'Ontario,[75] ha raggiunto popolarità in tutto il mondo agli inizi degli anni 80 con i dischi Cuts Like a Knife e Reckless, in cui è contenuta la hit Summer of '69, e soprattutto nei primi anni 90 con il disco Waking Up the Neighbours, di cui sono state vendute oltre 16 milioni di copie.[76][77] Adams ha ricevuto un Grammy Award per la hit Everything I Do[78] e tre candidature all'Oscar, e ha collaborato con molti dei più grandi artisti della storia musicale.[79]
Canadese è il paroliere Luc Plamondon, produttore del musical Notre-Dame de Paris. Quattro dei protagonisti originali dello spettacolo sono canadesi: uno del Manitoba (Daniel Lavoie) e tre del Québec (Garou, Luck Mervil e Bruno Pelletier).
È originario di Toronto il cantautore Neil Young che vi nacque nel 1945. Considerato da molti il padre dello stile grunge, è da più di 40 anni sulle scene mondiali.[80] La cantautrice Joni Mitchell nacque invece a Fort Macleod, nella provincia di Alberta. Altro gigante della musica canadese è Leonard Cohen, poeta e romanziere di successo oltre che cantautore colto e amatissimo in tutto il mondo, nato a Montréal.[81][82]
Nella musica pop hanno ottenuto fama mondiale, tra i tanti, Sarah McLachlan, Nelly Furtado, Carly Rae Jepsen, il cantante Michael Bublé, vincitore di quattro Grammy Awards,[83] Alanis Morissette, vincitrice di numerosi Grammy Awards e Juno Awards,[84] e Céline Dion, vincitrice di un Eurovision Song Contest, dieci Grammy Awards e due premi Oscar[85][86] ed è ritenuta l'artista canadese di maggior successo della storia della musica.[87] Canadesi sono anche la cantante punk rock Avril Lavigne, diventata famosa negli anni 2000 con album come Under My Skin (2004), il rapper Drake, il giovane Shawn Mendes, oltre a Justin Bieber, uno degli artisti più giovani ad aver raggiunto ll numero 1 nella classifica Hot 100 di Billboard, nominato a due Grammy Awards nel 2015. Per il genere country pop da ricordare in particolare Shania Twain.
Tra i gruppi musicali i più famosi e influenti sono considerati gli Arcade Fire, i Rush, i Nickelback, i Simple Plan, i Sum 41, i The Guess Who, i The Band, i The Tragically Hip, i Gorguts, gli Annihilator e i D.O.A..[84]
Nel campo cinematografico, tra il XIX e il XX secolo, durante l'epoca del vaudeville, si afferma l'attrice Marie Dressler, vincitrice del Premio Oscar come migliore attrice nel 1931. Nel XX secolo un'altra importante attrice del cinema canadese fu Mary Pickford, Oscar alla miglior attrice, nel 1930. È da ricordare, inoltre, la figura del regista James Cameron il cui film Avatar (2009) è l'attuale film con maggiori incassi nella storia del cinema.
Nel 2012, il Canada ha speso circa 31,3 miliardi di dollari canadesi in ricerca e sviluppo, di cui circa 7 miliardi sono stati stanziati dai governi federali e provinciali.[88] Al 2015, il Paese vantava tredici premi Nobel per la fisica, la chimica e la medicina,[89][90] e nel 2012 si è classificato quarto in tutto il mondo per la qualità della ricerca scientifica in un ampio sondaggio rivolto a scienziati internazionali.[91] Il paese, inoltre, ospita la sede principale di diverse aziende tecnologiche riconosciute a livello mondiale.[92] I canadesi possono disporre di uno dei più alti livelli di accesso a Internet di tutto il mondo, con oltre 33 milioni di utenti, pari a circa il 94% per cento della sua popolazione totale.[93]
L'Agenzia spaziale canadese gestisce un programma spaziale molto attivo che varia dall'esplorazione planetaria, alla ricerca aeronautica, allo sviluppo di razzi e satelliti. Il Canada è stato il terzo paese in grado di lanciare un satellite nello spazio, dopo l'Unione Sovietica e gli Stati Uniti, grazie ad Alouette 1 lanciato nel 1962.[94] Nel 1984, Marc Garneau divenne primo astronauta canadese. Al 2015, nove canadesi hanno volato nello spazio, nel corso di diciassette missioni con equipaggio.[95]
Il Canada è un partecipante al progetto della Stazione Spaziale Internazionale (ISS) ed è un pioniere nel campo della robotica spaziale, grazie allo sviluppo dei manipolatori robotici Canadarm, Canadarm 2 e Dextre, utilizzati per lo Space Shuttle della NASA e per la ISS. Dal 1960, l'industria aerospaziale canadese ha progettato e costruito numerosi satelliti, tra cui Radarsat-1 e Radarsat-2, ISIS e MOST.[96] Il Canada ha anche prodotto uno dei razzi sonda di maggior successo e ampiamente utilizzato a livello mondiale: i Black Bran; oltre 1 000 di essi sono stati lanciati dopo il loro primo sviluppo avvenuto nel 1961.[97]
Tra le personalità che si sono maggiormente distinte in campo scientifico, ricordiamo quella del fisiologo Frederick Grant Banting (1891-1941), scopritore dell'insulina, nel 1921: Premio Nobel per la medicina, nel 1923, oggi la sua data di nascita, il 14 novembre, è celebrata nel mondo con la Giornata mondiale del diabete
Il Canada ha due sport nazionali: l'hockey su ghiaccio e il Lacrosse.
L'hockey su ghiaccio, che vi è nato ed è anche lo sport più popolare: infatti il paese è tra i dominatori delle competizioni internazionali di tale sport (ricordiamo che la nazionale di hockey su ghiaccio maschile del Canada ha vinto 26 mondiali e 9 Giochi olimpici invernali) assieme al lacrosse, questi sport vengono praticati prevalentemente, in inverno il primo, e in estate il secondo. La Lega nazionale d'hockey fu fondata a Montréal e rimane il massimo campionato professionale nel mondo.
Tra gli hockeisti su ghiaccio ricordiamo Jacques Plante, di ruolo portiere, inventore, tra l'altro, della maschera da protezione, nell'hockey, per i portieri, Bobby Orr, Don Cherry e ancora, tra i più importanti giocatori di hockey su ghiaccio spicca soprattutto Wayne Gretzky.
Si può dire, in conclusione, che l'hockey su ghiaccio è lo sport nazionale canadese.
Il lacrosse è invece praticato su manto erboso, e ha come scopo segnare con una pallina in una porta, usando mazze con all'estremità una rete. In tale disciplina il Canada vanta la vittoria in due campionati mondiali.
Il Canada inoltre ospita dal 1967 il Gran Premio di Formula 1, che si disputa sul circuito Gilles Villeneuve sull'Ile de Notre Dame a Montréal dal 1978. Il figlio di Gilles Villeneuve, Jacques, è stato campione del mondo di Formula 1 nel 1997.
Il Canada è la patria anche di due velocisti che hanno fatto la storia dell'atletica leggera: Ben Johnson e Donovan Bailey.
Nel 2012 il ciclista Ryder Hesjedal diventa il primo canadese della storia a vincere il Giro d'Italia.
Di rilievo è anche la disciplina del wrestling, dato che la famosa Famiglia Hart è originaria proprio del Canada. Oltre alla Famiglia Hart, sono originari del Canada wrestler come Edge, Christian, Chris Jericho, Bobby Roode, Kevin Steen, Petey Williams, Eric Young, El Generico, Trish Stratus e Chris Benoit
La Nazionale di calcio del Canada ha partecipato a due edizioni della Coppa del Mondo (Messico 1986 e Qatar 2022), uscendo in entrambi i casi al primo turno.[98] Tuttavia nel 2007 il Canada ha iscritto nella Major League Soccer (MLS) americana la squadra di club Toronto FC, trasformando così il campionato degli Stati Uniti in una lega in parte canadese e in parte statunitense; con l'espansione del 2011 anche il Whitecaps Football Club, squadra con sede a Vancouver, è entrato a far parte della MLS. Infine, l'ingresso nella MLS del Montréal Impact nel 2012 ha portato a tre le franchigie canadesi iscritte alle competizioni. Il canadese Joey Saputo, presidente del Montréal Impact, dal 2014 è anche azionista di maggioranza della squadra italiana del Bologna.
Inoltre la Nazionale canadese è stata due volte Campione (1985-2000) nella CONCACAF Gold Cup.
Il 21 dicembre 1891 viene disputata la prima partita di pallacanestro, di cui il canadese James Naismith è considerato l'inventore.[99]
La nazionale di pallacanestro del Canada ha vinto, tra l'altro, una medaglia d'argento nel torneo olimpico del 1936.
La prima medaglia d'oro olimpica  (e prima medaglia olimpica) canadese fu vinta da George Orton, nell'atletica leggera, ai Giochi olimpici di Parigi 1900.
Tra gli altri sport più seguiti, ci sono il football canadese, (simile al football americano, ma con regole diverse), il rugby a 15, il calcio (lo sport più popolare a livello di partecipazione nazionale), il curling (molto popolare d'inverno), nonché football americano e baseball, data la vicinanza con gli Stati Uniti d'America, grandi appassionati di questi due ultimi sport. I Toronto Blue Jays ad esempio, rappresentano la città di Toronto nel massimo campionato statunitense di baseball, la Major League Baseball.
Altro sport che non è nazionale in Canada, ma dove trova origini, è la canoa canadese, praticata agonisticamente in ginocchio e amatorialmente da seduti.
Nel 2019 la franchigia dei Toronto Raptors ha vinto le Finals Nba, laureandosi campioni del mondo.
Molto popolare anche il broomball, sport simile all'hockey ma senza pattini.
Nelle province del Québec e del Nuovo Brunswick è molto praticata la pallamano.
Nel sud dell'Alberta sono praticati sport riguardanti l'equitazione americana.
Le franchigie canadesi delle grandi leghe sportive fanno parte delle leghe sportive insieme alle squadre di club degli Stati Uniti. Con il passare degli anni le leghe statunitense del baseball e della pallacanestro si sono aperte anche a squadre di club canadesi, e la lega canadese dell'hockey su ghiaccio si è aperta a squadre di club statunitensi. Ecco un elenco con le squadre canadesi che partecipano alle leghe considerate in Canada "nordamericane":
La cucina canadese, le cui origini sono legate al dominio degli inglesi e dei francesi rispettivamente nella parte anglofona e francofona del Canada, risentono spesso, in particolare nell'ovest del paese, della cucina italiana, polacca e ucraina.
6 dicembre: giornata nazionale del Ricordo e dell'azione contro la violenza alle donne, in memoria al Massacro del Politecnico di Montréal, nel 1989.
La Russia (in russo: Росси́я?, traslitterato: Rossíja, ascolta[?·info]), ufficialmente Federazione Russa (in russo: Росси́йская Федера́ция?, traslitterato: Rossíjskaja Federácija, ascolta[?·info]), è uno Stato transcontinentale che si estende per un quarto in Europa e per tutto il resto in Asia. È il più vasto Stato del mondo, con una superficie di 17864345 km²,[6] e a inizio 2023 conta 146 099 728 abitanti.[3] La capitale è Mosca. La lingua ufficiale è il russo ma le repubbliche autonome possono avere altre lingue ufficiali. L'attuale presidente della federazione è Vladimir Putin.
Confina con Norvegia, Finlandia, Estonia, Lettonia, Lituania, Polonia, Bielorussia, Ucraina, Georgia, Azerbaigian, Kazakistan, Cina, Corea del Nord, Mongolia; assieme alla Cina, è lo Stato con il maggior numero di Stati limitrofi (quattordici).[7] Essa possiede, inoltre, confini marittimi con il Giappone (attraverso il mare di Ochotsk) e gli Stati Uniti (attraverso lo stretto di Bering). È bagnata a nord-ovest dal mar Baltico nel golfo di Finlandia, a nord dal mar Glaciale Artico, a est dall'Oceano Pacifico e a sud dal mar Nero e dal mar Caspio. Comprende anche l'exclave dell'oblast' di Kaliningrad. È tradizionalmente suddivisa tra Russia europea e Russia asiatica dalla catena montuosa degli Urali, dal corso del Fiume Ural, dalla costa settentrionale del mar Caspio e dalla depressione del Kuma-Manyč.
È stato tra i protagonisti della storia del XX secolo, per il ruolo svolto nella seconda guerra mondiale e in seguito per essere stata una delle maggiori forze coinvolte nella cosiddetta guerra fredda. È il successore legale dell'Unione Sovietica (e in quanto tale ha ereditato il seggio di membro permanente nel Consiglio di sicurezza delle Nazioni Unite) ed è fra le quindici ex repubbliche sovietiche ad aver raccolto la maggior parte dell'eredità politica e militare sovietica. È uno Stato con una forte influenza politica all'interno della Comunità degli Stati Indipendenti, composta da nove ex repubbliche dell'Unione Sovietica; è inoltre uno degli Stati fondatori dell'Unione eurasiatica.
Nei primi anni del XXI secolo l'economia ha presentato tassi di crescita tra i più elevati a livello globale, tanto che la Russia è considerata uno dei cinque Paesi cui ci si riferisce con l'acronimo BRICS.[8] La crisi finanziaria internazionale si è fatta però sentire duramente a partire dall'autunno 2008, mettendo in dubbio molte delle certezze acquisite in un decennio di espansione.[9]
Dopo il referendum sull'autodeterminazione della Crimea del 2014, la Russia ha annesso quest'area, sebbene l'occupazione non sia riconosciuta dalla quasi totalità della comunità internazionale.
Nei secoli precedenti l'era volgare le vaste terre della Russia meridionale erano abitate da popoli indoeuropei (dei quali era probabilmente la terra d'origine) come gli sciti, cui si avvicendarono i sarmati e, nell'Alto Medioevo, gli slavi; nell'area che poi divenne il centro del futuro stato russo, vale a dire il bacino di Mosca, per lungo tempo prima del X secolo dimorarono genti di ceppo finnico o lituano.[10]
Tra il III e il VI secolo le steppe subirono, a ondate successive, l'ascesa di popoli nomadi guidati da tribù bellicose che si dirigevano verso l'Europa occidentale. Fu il caso, ad esempio, degli unni e degli avari. Un popolo turco, i cazari, governò la Russia meridionale durante l'VIII secolo; essi furono preziosi alleati dell'Impero Romano d'Oriente (Impero bizantino) e condussero diverse guerre contro i califfati arabi.
Dal VII secolo gli slavi costituirono la maggioranza della popolazione nella Russia occidentale, e pian piano assimilarono le preesistenti tribù finniche, come i merja, i muromi e i mesceri. A metà del IX secolo un gruppo originario della Scandinavia, i variaghi, assunse il ruolo di élite dominante nella capitale slava di Novgorod. Anche se l'elemento etnico dei variaghi (vichinghi orientali) si confuse abbastanza presto nella maggioritaria popolazione slava, la dinastia da loro espressa (Rjurikidi) rimase al potere diversi secoli, durante i quali si affiliò alla Chiesa ortodossa di Costantinopoli (Bisanzio). La capitale venne trasferita a Kiev nell'882.
In questo periodo il termine Rhos o Rus' cominciò a essere riferito ai variaghi e in seguito anche agli slavi che popolavano la regione. Tra il X e l'XI secolo la Rus' di Kiev divenne lo Stato più grande d'Europa e uno dei più prosperi, grazie alla sua posizione commerciale tra Europa e Asia. L'apertura di nuove vie commerciali con l'Oriente al tempo delle crociate contribuì al declino e alla frammentazione dello Stato di Kiev nel corso del XII secolo, aggravatasi dopo la morte, nel 1132, del figlio di Vladimiro II Monomaco.
Nei secoli XI e XII le sempre più frequenti incursioni di popolazioni turche, come i kipciak e i peceneghi, portarono le popolazioni slave del sud a spostarsi verso le regioni del nord, note come Zales'. Gli Stati di Novgorod e Vladimir-Suzdal emersero come eredi della Rus' di Kiev nei territori settentrionali, mentre il medio corso del Volga finì sotto il controllo dello stato islamico della Bulgaria del Volga.
Come molte altre regioni dell'Europa orientale, questi territori vennero invasi dai mongoli, i quali nel 1240 piegarono la Rus' di Kiev. Conosciuti più tardi anche con il nome indeterminato e generico di tartari, i mongoli avrebbero governato le zone meridionali e centrali dell'odierna Russia per circa tre secoli, tempo durante il quale i vari potentati locali sarebbero Stati dipendenti del loro Khanato dell'Orda d'Oro. I territori delle odierne Ucraina e Bielorussia furono inclusi nel Granducato di Lituania e poi nella confederazione polacco lituana o, per rapidità, Polonia, fattore che differenziò ucraini e bielorussi dalle altre popolazioni russe.
Come nei Balcani e in Asia Minore, il lungo governo dei nomadi avrebbe ritardato lo sviluppo economico e sociale del Paese. Novgorod e Pskov riuscirono peraltro a ritagliarsi un certo grado di autonomia, che li preservò da molti problemi e molte atrocità del periodo. Nel XIII secolo il signore di Novgorod Aleksandr Nevskij respinse gli svedesi e i cavalieri teutonici che cercavano di colonizzare la regione.
Con Ivan I (1332-1341), il Granducato di Mosca si avviò a divenire il più importante principato russo. Lo Stato russo incentrato su Mosca, contrariamente all'Impero bizantino, sua fonte d'ispirazione politica e religiosa, fu in grado di sopravvivere e di organizzare una propria riscossa, riuscendo infine a sottomettere i suoi nemici e a occupare i loro territori.
Il Ducato di Mosca ancora sotto il dominio indiretto dei mongoli cui pagava un tributo annuale (avendo l'obbligo di riscuotere detto tributo da tutti gli altri stati-città feudali russi) all'inizio del XIV secolo cominciò ad affermare la sua influenza sulla Russia occidentale. Una parte di questo tributo veniva trattenuta e questo permise la crescita economica, sociale e militare del Ducato moscovita e la sua capacità di guidare la liberazione dalla supremazia del Kanato tartaro. Assistita dalla Chiesa ortodossa russa e dalla rinascita spirituale portata da San Sergio di Radonež, nel 1380 la Moscovia sconfisse i tartari nella battaglia di Kulikovo.
Dopo la Caduta di Costantinopoli nel 1453, il Granducato moscovita rimase l'unico Stato cristiano sulla frontiera orientale dell'Europa, ed Ivan III di Russia rivendicò l'eredità dell'Impero Romano d'Oriente paragonando Mosca ad una Terza Roma,
All'inizio del XVI secolo, il granducato moscovita era riuscito ad annettersi tutti i territori della Rus' di Kiev che erano stati oggetti delle invasioni dei tartari. Nel contempo, riuscì a proteggere le regioni ai confini meridionali dagli attacchi portati dai tartari della Crimea e dalle altre popolazioni turche. I nobili, a cui era concessa una tenuta dai sovrani, furono obbligati a servire nell'esercito. Il sistema delle concessioni diventò una delle basi dell'esercito nobiliare a cavallo.
Il matrimonio di Sophia Paleologa (anche conosciuta con l'originale nome greco e ortodosso di Zoe), figlia di Tommaso Paleologo, despota di Morea, il quale rivendicava il trono di Costantinopoli in quanto fratello di Costantino XI, ultimo imperatore bizantino, con Ivan III "il Grande" condusse a Mosca quanto restava della Corte di Costantinopoli con il suo cerimoniale e tutto il suo apparato (così come l'aquila bicipite). Ivan III fu il primo a fregiarsi del titolo di Zar (la parola zar deriva dal latino Caesar, cognomen di Gaio Giulio Cesare), cioè Imperatore Romano d'Oriente (mantenne una regolare corrispondenza con l'Imperatore del Sacro Romano Impero Massimiliano I d'Asburgo che era solito chiamarlo "fratello") ed assieme alla moglie decise che la sua capitale doveva succedere a Costantinopoli e diventare la Terza Roma, per questo invitò a Mosca un gran numero di artisti e iniziò la costruzione del Cremlino con la direzione di Ridolfo (Aristotele) Fioravanti da Bologna.
Fu sotto il regno di Ivan III che il nuovo Sudebnik russo, o codice di leggi, fu redatto da Vladimir Gusev. Fu sotto il regno di Ivan III che la Russia si liberò definitivamente dal giogo tartaro e cessò di pagare l'ordinario tributo richiesto dal Khan. Durante il regno di Ivan III il tipo di governo nella Moscovia cambiò radicalmente mutando in autocrazia. Suo nipote Ivan IV (detto dai russi "Grosnj" cioè il "temibile o il tonante" e dagli occidentali il "Terribile",[11] 1533-1584) proseguì con determinazione la politica dell'avo di rafforzare la monarchia assoluta a detrimento dell'alta nobilità dei boiardi (analogamente a quanto faceva con gli stessi mezzi e metodi Elisabetta I Tudor in Gran Bretagna o Enrico IV in Francia). Venne incoronato ufficialmente come primo Zar di Russia nel 1547. Lo zar promulgò un nuovo codice di leggi (Sudebnik del 1550) istituendo il primo organo di rappresentanza russo su base feudale (zemskij sobor) e introducendo un'autogestione locale nelle zone rurali.[12][13]
Durante il proprio lungo regno Ivan IV raddoppiò il già vasto territorio russo annettendo i tre khanati tatari (parti della dissolta Orda d'Oro): Kazan' e Astrachan' lungo il Volga, e il Khanato di Sibir nel sud-ovest della Siberia. Entro la fine del XVI secolo la Russia aveva consolidato e cementato la natura dello stato coerentemente "romano" in quanto Stato multiconfessionale, multietnico e transcontinentale.
Tuttavia lo zarato fu indebolito dalla lunga e infruttuosa guerra di Livonia contro la coalizione di Polonia, Lituania e Svezia per l'accesso alla costa del mar Baltico e al commercio marittimo.[14] Allo stesso tempo i tatari del Khanato di Crimea, il solo successore rimasto dell'Orda d'Oro, continuarono a razziare la Russia meridionale. Nel tentativo di ripristinare i khanati del Volga, i crimeani e i loro alleati ottomani invasero la Russia centrale e furono anche in grado di dare alle fiamme parti di Mosca nel 1571.[15] Tuttavia l'anno successivo il grande esercito degli invasori venne completamente sconfitto dai russi nella battaglia di Molodi, ponendo per sempre fine alla minaccia dell'espansione ottomana-crimeana in Russia. Le razzie di schiavi da parte dei crimeani tuttavia non cessarono fino alla fine del XVII secolo, anche se la costruzione di nuove linee fortificate in tutta la Russia meridionale, come la Zasečnaja Čerta, ridussero costantemente la zona soggetta alle incursioni.[16]
I primi anni del XVII secolo in Russia furono molto tumultuosi e per questo vengono chiamati Periodo dei torbidi.[17] La morte dei figli di Ivan, che segnò la fine dell'antica dinastia dei Rjurikidi nel 1598, in congiuntura con la carestia del 1601-1603,[18] portò il paese alla guerra civile, dovuta ai tentativi dei boiardi di recuperare il potere perduto, e anche ai conflitti con gli stati confinanti europei. La Confederazione polacco-lituana occupò varie zone della Russia, tra cui Mosca. Nel 1612 i polacchi furono però costretti alla ritirata da milizie di volontari russi capeggiate da due eroi nazionali, il mercante Kuz'ma Minin e il principe Dmitrij Požarskij.
Nel 1613 lo Zemskij Sobor elesse Zar il diciassettenne Michele Romanov primo membro della dinastia Romanov a salire al trono (era figlio del patriarca della Chiesa ortodossa russa, Filarete Romanov, che dal 1619, appena rientrato in patria dopo essere stato per nove anni ostaggio del re di Polonia, divenne di fatto il vero governante della Russia, dirigendo la politica del figlio e occupandosi personalmente dell'amministrazione dello Stato fino al 1633, anno in cui Filarete muore) e il Paese cominciò così la sua graduale ripresa dalla crisi.
La Russia proseguì la sua espansione territoriale per tutto il XVII secolo, l'epoca d'oro dei cosacchi. I cosacchi erano dei guerrieri organizzati in comunità militari, simili ai pirati e ai pionieri del Nuovo Mondo. Nel 1648 i contadini dell'Ucraina si unirono ai cosacchi zaporoghi contro la Polonia-Lituania durante la rivolta di Chmel'nyc'kij, a causa dell'oppressione sociale e religiosa sofferta sotto il dominio polacco. Nel 1654 il leader ucraino Bohdan Chmel'nyc'kij offrì allo zar di Russia Alessio I la protezione dell'Ucraina. L'accettazione di questa offerta da parte di Alessio portò a un'altra guerra russo-polacca (1654-1667). Alla fine l'Ucraina venne divisa lungo il Dnepr, lasciando la parte occidentale (la riva destra ucraina) sotto il dominio polacco e la parte orientale (la riva sinistra ucraina e Kiev) alla Russia. Più tardi nel 1670-1671 i cosacchi del Don guidati da Sten'ka Razin diedero il via a una grande rivolta nella regione del Volga, ma le truppe dello zar riuscirono a sconfiggere i ribelli.
A est la rapida esplorazione e colonizzazione russa dei grandi territori della Siberia fu condotta per lo più dai cosacchi, a caccia di pelli di animale pregiate e avorio. Gli esploratori russi si spinsero a est soprattutto lungo le strade dei fiumi siberiani e dalla metà del XVII secolo vi furono insediamenti russi nella Siberia orientale, nella penisola dei Ciukci, lungo l'Amur e sulla costa del Pacifico. Nel 1648 lo stretto di Bering tra America settentrionale e Asia fu forse attraversato per la prima volta da Fedot Popov e Semën Dežnëv, ma la notizia non giunse in Europa. Ufficialmente fu Vitus Bering, un esploratore danese al servizio degli zar, a scoprirlo e a dargli il proprio nome nel 1728.
Nel 1667 il movimento religioso dei Vecchi credenti si oppose ad alcune riforme della chiesa ortodossa, creando uno scisma, che ebbe numerosi seguaci nella Russia settentrionale, zona degli Urali e Siberia [19].
Sotto Pietro il Grande la Russia venne proclamata impero nel 1721 e riconosciuta come una potenza mondiale. Governando dal 1682 al 1725 Pietro sconfisse la Svezia nella grande guerra del Nord, costringendola a cedere la Carelia occidentale e l'Ingria (due regioni perse dalla Russia nel Periodo dei torbidi),[20] nonché l'Estonia e la Livonia, assicurando alla Russia l'accesso al mare e al commercio marittimo.[21] Sul mar Baltico Pietro fondò una nuova capitale chiamata San Pietroburgo, più tardi conosciuta come la "finestra sull'Europa". Pietro riuscì a importare cultura e nuove idee dall'Europa occidentale, modernizzando un Paese seriamente arretrato, in cui l'istituto feudale della servitù della gleba era ancora vivo e vitale.
Il regno di Elisabetta, figlia di Pietro I, dal 1741 al 1762 vide la partecipazione della Russia nella guerra dei sette anni (1756-1763). Durante questo conflitto la Russia annesse la Prussia Orientale per un breve periodo e prese anche Berlino. Tuttavia, dopo la morte di Elisabetta tutte queste conquiste furono restituite al Regno di Prussia dal filo-prussiano Pietro III di Russia.
Caterina II ("la Grande"), che regnò dal 1762 al 1796, presiedette l'età dell'illuminismo russo. Estese il controllo politico russo sulla confederazione polacco-lituana e incorporò la maggior parte dei suoi territori nella Russia durante le spartizioni della Polonia, spingendo la frontiera russa in direzione ovest verso l'Europa centrale. Nel sud, dopo i successi delle guerre russo-turche contro l'Impero ottomano, Caterina fece avanzare il confine della Russia fino al mar Nero, sconfiggendo il Khanato di Crimea. Come risultato delle vittorie contro gli ottomani dall'inizio del XIX secolo la Russia fece anche importanti conquiste territoriali nella Transcaucasia. Tutto ciò venne proseguito da Alessandro I (1801-1825) il quale strappò la Finlandia all'indebolito regno di Svezia nel 1809 e la Bessarabia agli ottomani nel 1812. Allo stesso tempo i russi colonizzarono l'Alaska e si insediarono in California, come a Fort Ross.
Fra il 1803 e il 1806 venne compiuta la prima circumnavigazione russa della Terra, seguita poi da altri importanti viaggi russi d'esplorazione marittima. Nel 1820 una spedizione russa scoprì il continente dell'Antartide.
In alleanza con altri Paesi europei, la Russia combatté contro la Francia di Napoleone. La campagna di Russia, all'apice del potere di Napoleone, nel 1812 fallì completamente contro un'ostinata resistenza combinata con le difficoltà climatiche ed ambientali, portando gli invasori ad una disastrosa sconfitta in cui perì più del 95% della Grande Armata napoleonica.[22] Guidato da Michail Kutuzov e da Barclay de Tolly, l'esercito russo cacciò Napoleone dal Paese ed avanzò attraverso l'Europa nella guerra della sesta coalizione, entrando infine a Parigi. Alessandro I guidò la delegazione della Russia al congresso di Vienna, che stabilì la carta politica dell'Europa post-napoleonica.
Gli ufficiali delle guerre napoleoniche portarono indietro con loro le idee del liberalismo in Russia e tentarono di limitare il potere dello zar durante l'abortito moto decabrista del 1825. Alla fine del regno conservatore di Nicola I (1825-1855), il periodo culmine di potere e influenza della Russia sull'Europa venne interrotto dalla sconfitta nella guerra di Crimea. Tra il 1847 e il 1851 una massiccia epidemia di colera proveniente dall'Asia travolse la Russia, causando circa un milione di vittime.[23]
Il successore di Nicola, Alessandro II (1855-1881), apportò notevoli cambiamenti nel Paese, tra cui l'abolizione della servitù della gleba nel 1861. Queste grandi riforme spronarono l'industrializzazione e modernizzarono l'esercito russo, che aveva liberato con successo la Bulgaria dal dominio ottomano nella guerra russo-turca (1877-1878).
La fine del XIX secolo vide la nascita di vari movimenti socialisti in Russia: Alessandro II fu ucciso nel 1881 da terroristi rivoluzionari e il regno di suo figlio Alessandro III (1881-1894) fu meno liberale, ma più stabile. L'ultimo imperatore russo, Nicola II (1894-1917), non fu in grado di prevenire gli eventi della rivoluzione russa del 1905, innescata dall'infruttuosa guerra russo-giapponese e dalla violenta repressione dei manifestanti nella cosiddetta domenica di sangue. La rivolta venne soppressa, ma il governo fu costretto a concedere importanti riforme, tra cui la concessione della libertà di stampa e di associazione, la legalizzazione dei partiti politici e la creazione di un organo legislativo di natura elettiva, la Duma di Stato. La migrazione verso la Siberia aumentò rapidamente nel XX secolo, in particolare durante la riforma agraria di Stolypin. Tra il 1906 e il 1914 più di quattro milioni di coloni giunsero in quella regione.[24]
Nel 1914 la Russia prese parte alla prima guerra mondiale in risposta alla dichiarazione di guerra dell'Impero austro-ungarico al Regno di Serbia, alleata della Russia, e combatté su più fronti mentre si trovava isolata dai suoi alleati della Triplice intesa. Nel 1916 l'offensiva Brusilov dell'esercito russo distrusse quasi completamente la forza militare dell'Austria-Ungheria. Tuttavia, la sfiducia già esistente nell'opinione pubblica nei confronti del regime si accrebbe a causa dei crescenti costi della guerra, dell'alto numero di vittime e delle voci circolanti di tradimento e corruzione. Tutto ciò creò il clima per la rivoluzione del 1917, compiutasi in due principali tappe.
La rivoluzione di febbraio, di ispirazione borghese, costrinse lo zar Nicola II ad abdicare; insieme con la sua famiglia fu imprigionato a Casa Ipat'ev e poi giustiziato durante la guerra civile russa. La monarchia venne sostituita da una traballante coalizione di partiti politici, i quali si erano auto-dichiarati Governo provvisorio. Parallelamente ad esso esisteva un establishment socialista, il soviet di Pietrogrado, che esercitava il potere attraverso consigli democraticamente eletti di operai e di contadini, chiamati appunto soviet. Il governo delle nuove autorità aggravò soltanto la crisi nel Paese, invece di risolverla. Infine, la rivoluzione d'ottobre, guidata dal leader del partito bolscevico Vladimir Il'ič Ul'janov, detto Lenin, rovesciò il Governo provvisorio e diede pieni poteri al governo dei soviet, facendo così nascere il primo Stato socialista del mondo.
Subito dopo la rivoluzione d'ottobre scoppiò una guerra civile tra l'esercito sovietico, la cosiddetta Armata Rossa, organizzato e comandato da Lev Trockij, e i vari eserciti che si rifacevano al potere zarista, le Armate Bianche. La Russia dei bolscevichi perse i suoi territori ucraini, polacchi, baltici e finnici con la firma del trattato di Brest-Litovsk, con il quale usciva dalla prima guerra mondiale e poneva fine alle ostilità con gli Imperi centrali. Le potenze alleate dell'Intesa lanciarono quindi, senza successo, un intervento militare a sostegno delle forze anticomuniste. Nel frattempo, sia i bolscevichi che l'Armata Bianca effettuarono campagne di deportazioni, arresti di massa ed esecuzioni contro i propri avversari, denominate rispettivamente Terrore rosso e Terrore bianco. Entro la fine della guerra civile l'economia russa e le sue infrastrutture furono pesantemente danneggiate. Milioni di persone divennero rifugiati bianchi e si stima che la carestia russa del 1921-1923 causò fino ad un massimo di cinque milioni di vittime.
Il 30 dicembre 1922 la Repubblica Socialista Federativa Sovietica Russa, insieme con le repubbliche socialiste sovietiche di Ucraina, Bielorussia e Transcaucasia, fondò l'Unione delle Repubbliche Socialiste Sovietiche, comunemente conosciuta come Unione Sovietica o in forma ancora più abbreviata "URSS". Successivi eventi portarono il paese a contenere quindici repubbliche federate e la più grande per dimensioni, con più della metà della popolazione totale dell'Unione Sovietica e più potente economicamente era proprio quella della Russia, che si trovò a dominare per tutti i sessantanove anni della sua storia le restanti quattordici repubbliche.
Dopo la morte di Lenin nel 1924, che aveva sofferto per una serie di infarti, venne designata una troika per governare l'Unione Sovietica. Tuttavia Iosif Džugašvili, detto Stalin, che era stato eletto segretario generale del Partito Comunista, riuscì a sopprimere tutti i gruppi d'opposizione all'interno del partito e a concentrare il potere nelle sue mani. Lev Trockij, il principale sostenitore della rivoluzione mondiale, fu esiliato dall'Unione Sovietica nel 1929 e l'idea di Stalin del "socialismo in un solo Paese" divenne la linea di pensiero dominante. La continua lotta interna al partito bolscevico culminò con le grandi purghe, una brutale repressione di massa avvenuta tra il 1937 e il 1938, in cui centinaia di migliaia di persone furono giustiziate, compresi membri originari del partito e capi militari accusati di tramare un colpo di Stato.
Sotto il controllo di Stalin il governo lanciò un'economia pianificata, l'industrializzazione di un paese in gran parte rurale e la collettivizzazione dell'agricoltura. Durante questo periodo di rapido cambiamento economico e sociale, milioni di persone furono mandate nei campi di lavoro forzato (gulag), tra cui molti detenuti politici per la loro opposizione alla dittatura di Stalin; milioni furono deportati ed esiliati in zone remote dell'Unione Sovietica. La disorganizzazione nella transizione del settore agricolo, combinata alle dure politiche statali e ad un periodo di siccità, portò alla carestia del 1932-1933. In un breve lasso di tempo l'Unione Sovietica, anche se a carissimo prezzo, venne trasformata da un'economia basata quasi soltanto sull'agricoltura in una grande potenza industrializzata.
La politica dell'Appeasement, adottata da Gran Bretagna e Francia nei confronti dell'annessione di Austria e Cecoslovacchia da parte di Adolf Hitler, non arginò l'aumento di potenza della Germania nazista, la quale poneva una seria minaccia per l'Unione Sovietica. Nello stesso periodo, la Germania nazista si alleò con l'Impero giapponese, rivale dell'Unione Sovietica in Estremo Oriente e suo nemico nelle guerre di confine sovietico-giapponesi del 1938-1939.
Nel mese di agosto del 1939, dopo un altro fallito tentativo di stabilire un'alleanza anti-nazista con la Gran Bretagna e la Francia, il governo sovietico decise di migliorare le relazioni con la Germania, concludendo il patto Molotov-Ribbentrop, una promessa di non aggressione tra i due Paesi e una spartizione delle reciproche sfere d'influenza nell'Europa orientale. Con lo scoppio della seconda guerra mondiale, mentre Hitler conquistava la Polonia e la Francia e altri Paesi agivano su un solo fronte, l'Unione Sovietica fu in grado di radunare il suo esercito e rivendicare alcuni ex territori dell'Impero russo a seguito dell'invasione sovietica della Polonia, della guerra d'inverno e dell'occupazione degli Stati Baltici.
Il 22 giugno 1941 la Germania nazista ruppe il patto di non aggressione e invase l'Unione Sovietica con la più grande e potente operazione militare terrestre della storia umana[25] e l'apertura del più grande teatro di guerra della seconda guerra mondiale. Anche se l'esercito tedesco ebbe all'inizio un notevole successo, il suo attacco fu arrestato nella battaglia di Mosca e successivamente i tedeschi subirono dure sconfitte, prima nella battaglia di Stalingrado nell'inverno del 1942-1943[26] e poi nella battaglia di Kursk nell'estate del 1943. Un altro fallimento tedesco fu l'assedio di Leningrado, in cui la città rimase completamente accerchiata da terra tra il 1941 e il 1944 dalle forze tedesche e finlandesi, sofferse la fame e la morte di un milione di civili, ma non si arrese mai.[27] Sotto l'amministrazione di Stalin e la guida di comandanti come Georgij Žukov e Konstantin Rokossovskij, le forze sovietiche conquistarono l'Europa orientale nel 1944-1945 e presero Berlino nel maggio 1945. Nel mese di agosto del 1945 l'esercito sovietico cacciò i giapponesi dalla Manciuria cinese e della Corea del Nord, contribuendo alla vittoria degli Alleati sul Giappone.
Il periodo dal 1941 al 1945 della seconda guerra mondiale è conosciuto in Russia come la "grande guerra patriottica". Durante questo conflitto, in cui avvennero le più letali operazioni di guerra della storia umana, le morti tra soldati e civili sovietici furono rispettivamente di undici milioni e sedici milioni, che rappresentano circa un terzo di tutte le vittime della seconda guerra mondiale. La complessiva perdita demografica per la popolazione sovietica fu ancora maggiore: l'economia e le infrastrutture sovietiche subirono massicce devastazioni, ma l'Unione Sovietica emerse lo stesso alla fine del conflitto come una superpotenza, riconosciuta a livello mondiale.
L'Armata Rossa occupò l'Europa dell'est dopo la guerra, compresa la Germania orientale, e governi non indipendenti di stampo socialista furono insediati negli Stati satellite del blocco orientale. Divenendo la seconda potenza nucleare del mondo, l'Unione Sovietica istituì l'alleanza del patto di Varsavia ed entrò in conflitto per il dominio globale, conosciuto come guerra fredda, contro gli Stati Uniti e la NATO. Le due nazioni ingaggiarono una lunga lotta geopolitica per il controllo dei cuori e delle menti del Terzo Mondo a partire dalla crisi di Suez del 1956. L'Unione Sovietica sostenne i movimenti rivoluzionari di tutto il mondo, tra cui le neonate Repubblica Popolare Cinese, Repubblica Popolare Democratica di Corea e in seguito la Repubblica di Cuba. Quantità significative di risorse sovietiche furono assegnate in aiuto agli altri Paesi socialisti.
Dopo la morte di Stalin e un breve periodo di governo comune, il nuovo leader Nikita Khruščёv denunciò il culto della personalità di Stalin e lanciò la politica di "destalinizzazione". Il sistema penale dei campi di lavoro forzato fu riformato e molti prigionieri furono liberati e riabilitati (molti dei quali nel frattempo erano già morti). Il generale allentamento delle politiche repressive divenne noto in seguito come il "disgelo di Khruščёv". Allo stesso tempo le tensioni con gli Stati Uniti si intensificarono quando i due rivali si scontrarono sul dispiegamento da parte degli statunitensi dei missili Jupiter in Turchia e da parte dei sovietici dei missili a Cuba. Le due parti si erano appunto imbarcate in una lunga e costosa corsa per accumulare il maggior numero possibile di armi nucleari. Nel 1962 con la crisi dei missili di Cuba il leader sovietico Nikita Khruščёv e il presidente statunitense John Fitzgerald Kennedy raggiunsero l'acme della crisi fra i blocchi sovietico e statunitense, con il posizionamento di basi missilistiche a Cuba in seguito all'embargo inferto alla stessa da parte degli Stati Uniti e in un più ampio ambito di conflitto ideologico ed economico fra i due schieramenti.
Nel 1957 l'Unione Sovietica lanciò il primo satellite artificiale del mondo, lo Sputnik 1, dando così il via alla corsa allo spazio. Il cosmonauta russo Jurij Gagarin fu il primo umano a orbitare nello spazio attorno alla Terra a bordo della navicella Vostok 1 il 12 aprile 1961.
Dopo l'estromissione di Khruščёv nel 1964, seguì un altro periodo di governo comune fino a quando Leonid Brežnev non divenne il leader incontrastato dell'Unione Sovietica. Gli anni settanta e i primi anni ottanta furono in seguito denominati la "stagnazione brezneviana", un periodo in cui la crescita economica si arrestò e le politiche sociali furono paralizzate. La riforma Kosygin del 1965 puntò a una parziale decentralizzazione nel controllo dell'economia sovietica e a spostare l'enfasi dall'industria pesante e della produzione militare all'industria leggera e dei beni di consumo, ma tutto ciò venne soffocato dalla leadership comunista, su posizioni fortemente conservatrici.
Nel 1979, dopo una rivoluzione guidata dai comunisti in Afghanistan, le forze armate sovietiche entrarono nel Paese su richiesta del nuovo regime. L'occupazione militare prosciugò le risorse economiche e si trascinò senza raggiungere risultati politici significativi. Alla fine l'esercito sovietico si dovette ritirare dall'Afghanistan nel 1989, a causa dell'opposizione internazionale, della persistente guerriglia anti-sovietica e della mancanza di sostegno da parte dei cittadini sovietici al conflitto.
Dal 1985 in poi l'ultimo leader sovietico, Michail Gorbačëv, cercò di introdurre alcune riforme nel sistema sovietico, tra cui la glasnost' ("trasparenza") e la perestrojka ("ricostruzione"), nel tentativo di porre fine al periodo di stagnazione economica e di democratizzare il governo. Tuttavia ciò condusse alla nascita di forti movimenti nazionalisti e separatisti. Prima del 1991 l'economia sovietica era la seconda più grande del mondo,[senza fonte] ma durante i suoi ultimi anni venne afflitta dalla carenza di merci nei negozi di alimentari, da enormi deficit di bilancio e dall'inflazione causata dalla crescita eccessiva dell'offerta di moneta.
Nel 1991 la crisi economica e il subbuglio politico cominciarono a straripare e le repubbliche baltiche scelsero di separarsi dall'Unione. Il 17 marzo si tenne un referendum, in cui la maggioranza dei votanti si espresse a favore del mantenimento dell'Unione Sovietica in una federazione riformata. Nell'agosto del 1991 un tentato colpo di Stato militare per deporre Gorbačëv e preservare l'Unione Sovietica portò invece alla fine del Partito Comunista dell'Unione Sovietica e il 26 dicembre 1991 l'Unione Sovietica si dissolse in quindici Stati post-sovietici.
Boris El'cin fu eletto presidente della Russia nel giugno 1991 nelle prime elezioni presidenziali dirette della storia russa. Durante e dopo la dissoluzione sovietica furono intraprese riforme tra cui la privatizzazione del settore pubblico e l'apertura al libero mercato, comprese trasformazioni radicali sulla falsariga della "terapia shock", raccomandata dagli Stati Uniti e dal Fondo Monetario Internazionale. Tutto ciò determinò una grave crisi economica, caratterizzata dal calo del 50% del PIL e della produzione industriale tra il 1990 e il 1995.
Le privatizzazioni spostarono per lo più il controllo delle imprese dagli enti statali a individui con legami governativi. Molti dei nuovi ricchi trasferirono poi miliardi di dollari in contanti e in beni fuori dal Paese, generando un'enorme fuga di capitali. La recessione economica portò al collasso dei servizi sociali; il tasso di natalità crollò, mentre quello di mortalità salì alle stelle. Milioni di persone furono ridotte in miseria, da un tasso di povertà dell'1,5% in epoca tardo sovietica, si passò al 39-49% entro la metà del 1993. Gli anni novanta videro una corruzione estrema e il dilagare di un'illegalità senza freni, l'aumento di bande criminali e dei crimini violenti.
Gli anni novanta furono anche segnati da conflitti armati nel Caucaso del nord, sia scontri etnici locali sia insurrezioni di islamisti separatisti. Da quando i separatisti ceceni avevano dichiarato l'indipendenza nei primi anni novanta, un'intermittente guerriglia fu combattuta tra gruppi di ribelli ed esercito russo. Gli attacchi terroristici contro i civili, compiuti dai separatisti, in particolare la crisi del teatro Dubrovka e la strage di Beslan, causarono centinaia di morti e suscitarono l'attenzione mondiale.
La Russia fu costretta ad assumersi la responsabilità della liquidazione dei debiti esteri dell'Unione Sovietica, anche se la sua popolazione attuale comprendeva soltanto la metà degli abitanti dello Stato sovietico al momento del suo scioglimento, non riuscendo comunque a pagare tali debiti sino alla riforma indetta da Putin nel 2017. Elevati disavanzi di bilancio impedirono il pagamento della liquidazione dei debiti contratti dall'Unione Sovietica e causarono la crisi finanziaria russa del 1998, che sfociò in un ulteriore calo del PIL.
Il 31 dicembre 1999 il presidente El'cin si dimise a sorpresa in favore del Primo ministro, nominato da poco, Vladimir Putin, il quale vinse poi le elezioni presidenziali del 2000. Putin soffocò l'insurrezione cecena, anche se sporadici atti di violenza si verificano ancora in ogni parte del Caucaso del nord. Agli alti prezzi del petrolio e ad una moneta inizialmente debole seguirono aumenti della domanda interna e dei consumi e gli investimenti aiutarono l'economia russa a crescere per nove anni consecutivi, migliorando il tenore di vita e aumentando l'influenza della Russia nel panorama mondiale. Nonostante molte riforme compiute sotto la presidenza di Putin vengano generalmente criticate e definite antidemocratiche dalle nazioni occidentali, si è lo stesso guadagnato un diffusissimo consenso in Russia per aver fatto ritornare l'ordine, la stabilità e il progresso nel Paese.
Nel 2014, in seguito alla rimozione del presidente ucraino filorusso Viktor Janukovyč in seguito alla rivoluzione di Euromaidan, si è tenuto un referendum sull'autodeterminazione della Crimea, indetto dalle forze politiche della penisola di Crimea, a maggioranza russofona, che si era proclamata unilateralmente indipendente dall'Ucraina nello stesso anno. L'esito del referendum è stata una schiacciante vittoria dei favorevoli all'annessione. È dunque cominciato l'iter amministrativo di annessione di quest'area, nonostante l'occupazione non sia riconosciuta dalla maggioranza della comunità internazionale. L'annessione ha avuto come conseguenza la nascita di due nuovi soggetti amministrativi della Federazione Russa: la Repubblica di Crimea e la città federale di Sebastopoli. Nello stesso periodo è iniziato il lungo scontro di confine per il Donbass, sede di altre due repubbliche separatiste.
Il 24 febbraio 2022, dopo un discorso alla nazione, il presidente Vladimir Putin ha ordinato l'invasione dell'Ucraina, secondo i media russi per garantire la pace alle repubbliche secessioniste di Luhansk e Donetsk.[28][29] La guerra risulta essere la più grande mai avvenuta in Europa dopo la seconda guerra mondiale.[30] L'invasione è stata condannata dalla quasi totalità dei paesi occidentali,[31] che hanno reagito ponendo delle pesanti sanzioni economiche contro il Cremlino[32], e alleati storici come la Repubblica Popolare Cinese, pur non varando sanzioni e rimanendo neutrali, hanno espresso preoccupazioni riguardo al conflitto. Il 30 settembre 2022 le repubbliche popolari di Luhansk e Donetsk e le oblast' occupate durante l'invasione vengono annesse alla Federazione russa come nuovi soggetti federali, motivando questa azione come il risultato di un referendum promosso e avvenuto durante l'occupazione e non riconosciuto valido da nessuna nazione, ad eccezione della Corea del Nord.[33][34][35][36]
Il 23 novembre 2022 il Parlamento europeo vota a favore la risoluzione riguardo al definire la Russia uno Stato promotore del terrorismo.[37][38][39]
La Federazione Russa si estende su gran parte dell'Europa orientale e sull'intera area settentrionale del continente asiatico, per questo motivo conosce una grande varietà di paesaggi e climi. Il territorio, diviso solitamente in Russia europea e Russia asiatica, appartiene alla regione biogeografica boreale.
Il confine tra Russia europea e Russia asiatica è convenzionale. La linea di demarcazione più seguita parte dal Mar Glaciale Artico,[40] segue poi il margine orientale dei monti Urali, prosegue lungo il corso del fiume Ural, la costa nord-occidentale del mar Caspio, la depressione del Kuma-Manyč e arriva infine alla foce del fiume Don, nel Mar d'Azov.[41]
Il territorio russo è costituito per la quasi totalità da vastissime pianure e da rilievi molto deboli; zone montuose accidentate si estendono solo ai confini dello spazio russo, presso i confini meridionali (catena del Caucaso, monti dell'Altaj) e nell'estremo oriente, che è anzi una zona molto accidentata dal punto di vista geologico. Ovunque, escluse le estreme zone meridionali, sono ben visibili i segni del glacialismo, che è stato uno dei più potenti fattori di costruzione del territorio russo attuale. La massima elevazione è raggiunta nella catena del Caucaso dal monte Elbrus (5642 m).
La quasi totalità della parte europea, così come la Siberia occidentale, è costituita da pianure; sono separate, come se fossero degli assi di simmetria, dalla catena montuosa degli Urali. Mentre la parte europea (chiamata Bassopiano Sarmatico) è spesso interrotta da modestissimi rilievi (Rialto centrale russo, Alture di Mosca, Alture del Volga fra i maggiori), la pianura della Siberia occidentale è una zona estremamente piatta, fatto questo che origina enormi problemi di drenaggio delle acque (che pure, per le caratteristiche climatiche, non sono abbondanti).
La Siberia centrale coincide praticamente con lo sterminato altopiano omonimo, che, pur con quote modeste (culmina a 1700 m al suo estremo nord) si estende su quasi quattro milioni di chilometri quadrati. La Siberia orientale è una zona invece prevalentemente montuosa, generalmente molto accidentata, che può raggiungere quote notevoli (si sfiorano i 5000 m nelle massime cime della Kamčatka). L'Estremo Oriente russo, si trova sul confine fra la placca eurasiatica e quella nordamericana (nella zona dei monti Čerskij e dei monti di Verchojansk) e fra quella eurasiatica e quella pacifica, che va in subduzione al di sotto della prima originando catene montuose (Catena Centrale e Orientale della Kamčatka, monti dei Coriacchi) e archi insulari (isole Curili).
Le coste si estendono per varie decine di migliaia di chilometri e sono prevalentemente basse tranne in alcune zone rivolte all'oceano Pacifico. Numerosi sono i bacini marini che bagnano le coste: a ovest la Russia si affaccia per un breve tratto sul mar Baltico, mentre a est il Pacifico forma i vasti bacini del mare di Ochotsk e del mare di Bering; la lunga fascia costiera artica si articola in grosse penisole piuttosto tozze (fra le maggiori quella del Tajmyr, di Gyda e di Jamal) che formano i bacini del mar Bianco, mare di Kara, mare di Laptev, mare della Siberia Orientale.
Le principali isole sono la Novaja Zemlja, la Terra di Francesco Giuseppe, le Isole della Nuova Siberia, l'Isola di Wrangel e, sul lato pacifico, le isole Curili e Sachalin.
Le rilevanti dimensioni territoriali russe e la ridotta frammentazione degli spazi si riflettono nella presenza di fiumi fra i maggiori del mondo, come lunghezza, portata d'acqua e vastità del bacino idrografico.
I maggiori fiumi russi sono il Volga (3531 km), che drena una grossa fetta della parte europea del territorio, e i tre grandi fiumi siberiani: l'Ob' (3680 km), lo Enisej o Jenisej (4287 km) e la Lena, ai quali si aggiungono, seppure con dimensioni lievemente minori, l'Amur e la Kolyma. Al di fuori di questi fiumi, di rilevanza mondiale, esistono altre decine di fiumi di lunghezza superiori ai 1000 km: in Europa si estendono i bacini del Dnepr, del Don, della Pečora, della Dvina Settentrionale e Occidentale e, fra gli affluenti del Volga, la Oka e la Kama; nella parte asiatica fra i maggiori sono la Tunguska Pietrosa e Inferiore, l'Angara, il Vitim, la Indigirka, l'Olenëk, il Taz.
Riguardo ai laghi, eccetto i due maggiori, situati ai confini meridionali (mar Caspio e Bajkal), i maggiori sono situati nella parte europea; sono mediamente poco profondi, vista la debole ondulazione del territorio (Ladoga, Onega, Il'men', lago dei Ciudi). Nelle vaste pianure siberiane sono invece molto estese le zone paludose. Molto importanti, nel panorama russo, sono i bacini artificiali, alcuni dei quali di rilevanza mondiale, originati dallo sbarramento dei maggiori fiumi a scopi energetici.
La Russia è essenzialmente divisa da nord a sud tra i seguenti climi:
La fauna della Russia è molto variegata e basata sui vari ambienti presenti nel paese. I carnivori principali sono linci, orsi bruni europei, lupi, volpi, ghiottoni, volpi artiche, orsi polari e zibellini. Come grandi erbivori in Russia si trovano renne, alci, buoi muschiati, wapiti, caprioli e saiga. Sulle coste sono presenti vari tipi di mammiferi marini come la foca della Groenlandia, il tricheco e vari tipi di balene. Molti animali vivono in zone uniche come il leopardo dell'Amur lungo il fiume Amur, la gru della Manciuria in Manciuria e la rara tigre siberiana, presente esclusivamente sulle montagne della Siberia sud-orientale.
In base al censimento russo del 2010 la Russia aveva 142,8 milioni di abitanti,[42] saliti a 146,2 milioni nel 2021 in seguito all'annessione russa della Crimea del 2014.[43] È, pertanto, il nono Paese più popoloso del mondo prima del Giappone e del Messico.Nel 1815 la popolazione russa era composta da 45 milioni di abitanti e gran parte di essa (80%) era composta da servi della gleba o contadini di terre direttamente di proprietà dello Zar. Sebbene la Russia sia stata segnata da vere e proprie catastrofi demografiche (circa 3,5 milioni di morti nella prima guerra mondiale, circa 8-10 milioni nel 1917-1922 nella guerra civile russa, tra i 7 e i 14 milioni nel 1928-1940 per la carestia provocata dalla collettivizzazione forzata delle terre,[44] 25 milioni di morti nel 1941-1945 a causa della seconda guerra mondiale[45]), la crescita della popolazione nel periodo sovietico è proceduta a ritmo sostenuto, soprattutto per l'immigrazione forzata dalle altre repubbliche sovietiche. Gli abitanti passarono dai 91 milioni del 1914 ai 102 milioni del 1950, fino a raggiungere il massimo storico di 148,538 milioni nel 1992.
Tuttavia, dall'inizio degli anni novanta, la popolazione è fortemente diminuita, fino a sfiorare i 142 milioni (stima 2008). La causa della diminuzione della popolazione è da ricercarsi nel crollo delle nascite e nel contemporaneo aumento della mortalità che si sono verificate dopo la caduta dell'URSS. Ancora oggi, sebbene in via di diminuzione, il tasso di mortalità (13,5‰) è ancora molto alto rispetto alla media dei paesi sviluppati, mentre la speranza di vita degli uomini (64 anni) è assai bassa e risulta di ben 13 anni inferiore a quella femminile.Tali fattori hanno determinato un tasso di crescita naturale fortemente negativo (passato dal +6,9‰ del 1986, ad un picco negativo di -6,5‰ nel 2000). I consistenti flussi migratori in uscita (tedeschi di Russia verso la Germania, ebrei verso Israele, russi in cerca di lavoro verso l'Europa occidentale) sono stati invece più che compensati negli ultimi anni dal ritorno di russi o russofoni dalle repubbliche ex-sovietiche: si calcola che in Russia vivano circa 10 milioni di immigrati clandestini (stima 2007).[46]
Per arrestare il declino demografico l'amministrazione Putin ha avviato un ambizioso programma di politica demografica, teso ad aumentare le nascite. Si tratta di una serie di provvedimenti che vanno da un taglio di alcune imposte per le coppie che abbiano più di due figli, a un aiuto statale, comprendente sia una somma di denaro sia una serie di bonus per i primi tre anni di vita del figlio, diretto alle giovani coppie per invogliarle a procreare più figli. Dal 2012 si è assistito a un parziale successo della politica perseguita dal governo, che secondo le fonti ufficiali, sarebbe riuscita a invertire il saldo negativo della popolazione per due anni di fila, tanto che nel 2013 si sarebbe registrato un incremento naturale pari a circa 24 000 unità. Nel 2017 il Paese ha registrato un decremento naturale pari a circa 135 000 unità. Tuttavia l'attendibilità delle statistiche ufficiali è oggetto di dibattito tra gli studiosi.[47][48]
La Russia è scarsamente popolata in rapporto alla sua enorme estensione; la densità della popolazione è di 9 ab./km2, maggiore nella parte europea della Russia, nella zona delle montagne degli Urali, e nella parte sud-orientale della Siberia. La Federazione Russa ospita molti differenti gruppi etnici e popolazioni indigene. L'80% della popolazione è composta da Russi etnici, il resto comprende Baschiri, Ceceni, Ciuvasci, Cosacchi, Evenchi, Tedeschi, Ingusci, Yupik, Calmucchi, Careliani, Coreani, Mordvini, Osseti, Taimyri, Tatari, Tuvani, Jakuti, Ucraini e molti altri.
Il governo non conduce censimenti ufficiali delle religioni professate in Russia e pertanto le stime si basano solo su sondaggi. Nel mese di agosto 2012, l'istituto Sreda ha pubblicato i rilevamenti statistici di un sondaggio ad ampio campione condotto su tutto il territorio nazionale come complemento del censimento del 2010.[49] Da questi risulta che il 46,8% dei russi (circa 58 milioni) siano cristiani (tra cui 41% ortodossi, meno dell'1% cattolici, protestanti, e il resto cristiani non confessionali). Il 6,5% della popolazione (9.4 milioni) segue l'Islam (ma il sondaggio non raccolse dati in due regioni a maggioranza islamica, Cecenia e Inguscezia, la cui popolazione complessiva raggiungeva i 2 milioni), mentre l'1,5% (1.7 milioni) varie forme di paganesimo e lo 0,5% (circa 800 000) il buddismo.[49] Il cristianesimo ortodosso, l'Islam, il buddismo e l'ebraismo sono religioni tradizionali della Russia e legalmente fanno parte del "patrimonio storico" del Paese.[50]
La cristianizzazione della Russia risale al X secolo e la Chiesa ortodossa russa è il più grande corpo religioso nel paese; sono attive anche piccole confessioni cristiane: cattolici, armeni gregoriani e varie chiese protestanti. La Chiesa ortodossa russa era la religione di Stato del Paese prima della Rivoluzione e si stima che circa il 95% delle parrocchie appartengano a questa confessione.[51] Tuttavia la stragrande maggioranza dei credenti ortodossi non frequentano la chiesa regolarmente. Pasqua è la festa religiosa più popolare nel Paese, celebrata da circa i tre quarti della popolazione russa, inclusi coloro che non appartengono ad alcun credo. In occasione di questa festa la tradizione vuole che si producano dolci caratteristici, uova colorate e pascha.[52]
L'Islam è la seconda religione della Russia[53] e a Mosca si trova la più grande moschea d'Europa, inaugurata nel 2015.[54] È la religione predominante o tradizionale tra alcune etnie caucasiche (in particolare tra i Ceceni, tra gli Ingusci e i Circassi) e tra i popoli turchi (in particolare i Tartari e i Baschiri). Complessivamente, come detto sopra, vi sarebbero 9,4 milioni di musulmani nel Paese. Tuttavia questo dato è probabilmente più alto perché l'indagine non comprende i dati dettagliati per due stati tradizionalmente islamici: la Cecenia e l'Inguscezia. Secondo questa indagine la maggior parte dei musulmani sono "non affiliati" a eventuali scuole islamiche o a organizzazioni islamiche; ciò è tipico dell'Islam, in cui non è indispensabile per un credente far parte di un'organizzazione o gruppo. Tra coloro che sono affiliati, perlopiù sono sunniti, mentre gli sciiti e gli ahmadiyya sono in netta minoranza.[49]
Il buddismo è una religione tradizionale in tre regioni della Federazione Russa: Buriazia, Tuva e Calmucchia. Alcune popolazioni turco-mongoliche e altaiche della Siberia e delle regioni dell'Estremo Oriente, Jakuzia e Čukotka, praticano il Tengrismo e altre religioni incentrate sullo sciamanesimo locale. Tra i russi etnici (slavi) vi è una forte ripresa della religione slava pre-cristiana (chiamata rodnoveria = "religione nativa").
La confessione religiosa segue principalmente l'etnia d'origine, dove gli slavi sono tendenzialmente cristiani ortodossi, i turchi musulmani e in generale le popolazioni mongoliche professano il buddismo.[55]
Diverse stime ritengono che tra il 16% e il 48% della popolazione russa non segua alcuna religione.[56] Il numero di atei è comunque sceso notevolmente: recenti statistiche affermano infatti che solo il 7% si dichiara ateo, un calo del 5% in tre anni.[57]
Riguardo alla libertà di professare la propria religione, bisogna sottolineare che recentemente la Corte Suprema Russa (su richiesta del Ministero della Giustizia), dopo diverse udienze, ha deliberato contro la Congregazione dei Testimoni di Geova, ordinando di chiudere il centro amministrativo nazionale, sito a San Pietroburgo, e di liquidare le 395 associazioni religiose locali dei Testimoni in Russia. Questa sentenza, che di fatto mette al bando l'associazione dei Testimoni di Geova in Russia, è stata presa accogliendo l'argomentazione esposta dal Ministero della Giustizia il 15 marzo 2017, che identificava come "estremista" l'associazione dei Testimoni, decisione presa nonostante il fatto che gli avvocati del Ministero non siano stati in grado di fornire alla Corte alcuna prova concreta riguardo alle accuse in oggetto. Di conseguenza, dal 20 aprile, i Testimoni di Geova che decidono di proseguire le loro attività di pacifiche riunioni e preghiera, rischiano seriamente di essere pesantemente perseguitati dallo Stato come veri e propri "terroristi".[58]
I 160 gruppi etnici russi parlano circa 100 lingue.[59] Secondo il censimento del 2002, 142,6 milioni di persone parlano russo, seguite da 5,3 milioni di lingua tartara e 1,8 milioni di lingua ucraina.[60] La lingua russa è l'unica lingua ufficiale di Stato, ma la Costituzione conferisce alle singole repubbliche il diritto di stabilire le proprie lingue ufficiali, oltre al russo.[61]
Il russo appartiene alla famiglia delle lingue indo-europee e delle lingue slave orientali. I primi esempi di scritti in russo antico sono attestati a partire dal X secolo.[62]
Il russo è la seconda lingua più usata su internet dopo l'inglese[63] e una delle due lingue ufficiali a bordo della Stazione Spaziale Internazionale[64] ed è una delle sei lingue ufficiali delle Nazioni Unite.[65]
La libertà dei media in Russia riguarda sia la capacità dei direttori dei mezzi di comunicazione di massa di attuare politiche indipendenti sia la capacità dei giornalisti di accedere a fonti di informazione e di lavorare senza pressioni esterne. I media russi includono canali televisivi e radiofonici, periodici e media su Internet, che secondo le leggi della Federazione Russa possono essere proprietà statale o privata.
Nel 2013 la Russia si è classificata al 148º posto su 179 paesi nell'indice della libertà di stampa di Reporters Without Borders. Nel 2015 Freedom House riporta che la Russia ha ottenuto un punteggio di 8,93 (su 100), soprattutto a causa delle nuove leggi introdotte nel 2014 che hanno ulteriormente esteso il controllo statale sui mass media.[66] La situazione è ancora peggiore in Crimea dove, dopo l'annessione della Russia, sia la giurisdizione russa che i mezzi extra-giudiziali sono applicati di routine per limitare la libertà di espressione.[67]
Vari aspetti della libertà di stampa sono criticati da molteplici organizzazioni internazionali.[68][69][70][71][72][73][74][75] Mentre molta attenzione viene prestata alle influenze politiche, l'esperto di media William Dunkerley della American University di Mosca, sostiene che la genesi della libertà di stampa della Russia risiede nella disfunzione economica che caratterizza il settore.[76]
Secondo la Costituzione il Paese è composto da ottantatré soggetti federali.[77] Nel 1993, quando la Costituzione è entrata in vigore, vi erano ottantanove soggetti federali, ma in seguito alcuni di loro sono stati accorpati.[78]
I soggetti federali sono, dal 2000 (legge del 13 maggio-n. 849), raggruppati in otto circondari federali, ognuno amministrato da un inviato nominato dal Presidente della Federazione Russa.[79] A differenza dei soggetti federali, i distretti federali non sono un livello subnazionale di governo, ma sono un livello di amministrazione del governo federale. Gli inviati ai distretti federali fungono da collegamento tra i soggetti federali e il governo federale e sono i primi responsabili della supervisione della conformità dei soggetti federali con le leggi federali.
L'attuale Costituzione della Federazione Russa venne adottata tramite referendum nazionale il 12 dicembre 1993.
La Russia vanta la percentuale più alta di diplomati di livello superiore, rispetto a qualsiasi altro Stato del mondo.[82] Il Paese offre un sistema gratuito di istruzione garantito, costituzionalmente, a tutti i cittadini,[83] tuttavia per accedere all'istruzione superiore sovvenzionata vi è una forte competizione.[84] In seguito alla grande enfasi posta sulla scienza e sulla tecnologia, l'istruzione nel campo medico, matematico, scientifico e aerospaziale è in generale di qualità elevata.[85]
Dal 1990 il ciclo di studi obbligatori è di undici anni. L'istruzione nelle scuole secondarie statali è gratuita, come anche nelle università, anche se con eccezioni. Infatti, anche se una parte consistente degli studenti frequenta gratuitamente, molti istituti stanno cominciando a proporre posti a pagamento.[86]
La scuola dell'obbligo dura 9 anni, al termine dei quali è necessario passare l'OGE (Esame Principale di Stato). Gli studenti scelgono le materie nelle quali vogliono essere esaminati, tranne la lingua russa e la matematica, che sono materie che prevedono esaminazione obbligatoria. Se si vuole continuare il percorso di studi dopo l'OGE, si deve scegliere un percorso di studio scolastico individuale della durata di due anni, un liceo della durata di tre anni o un college della durata di quattro anni. Al termine dell'istruzione secondaria di secondo grado bisogna passare l'EGE (Esame di Stato Unificato), il quale prevede due materie obbligatorie, ovvero la lingua russa e la matematica, e delle materie a scelta.[87] 
Nel 2004 la spesa statale per l'istruzione è stata pari al 3,6% del PIL, corrispondenti al 13% del bilancio statale consolidato.[88] Il governo stanzia fondi per pagare le tasse universitarie entro un bilancio di previsione stabilito o secondo il numero di studenti per ogni istituto statale. Gli studenti che frequentano gli istituti di istruzione superiore ricevono un piccolo stipendio e alloggiano gratuitamente se provengono da fuori città.[89]
Le più antiche e grandi università russe sono l'Università statale di Mosca e l'Università statale di San Pietroburgo. 
L'Università statale di Mosca, la più antica di Russia, venne fondata nel 1755 dall'imperatrice Elisabetta di Russia, che con decreto del 25 gennaio 1755 accolse le istanze di Ivan Šuvalov e Michail Lomonosov, a cui è intitolata. Negli anni duemila, al fine di creare istituti di istruzione superiore e di ricerca di scala paragonabile alle regioni russe, il governo ha lanciato un programma per istituire le "università federali", per lo più grazie alla fusione di grandi università regionali già esistenti e gli istituti di ricerca, fornendo loro un finanziamento speciale. Queste nuove istituzioni sono l'Università Federale Meridionale, l'Università Federale Siberiana, l'Università Federale di Kazan', l'Università Federale nord-orientale e l'Università Federale dell'Estremo Oriente.
La Costituzione russa garantisce il libero accesso all'assistenza sanitaria per tutti i cittadini.[90] Tuttavia tale gratuità appare parzialmente limitata a causa della registrazione obbligatoria.[91] Mentre il Paese gode di un numero di medici, ospedali e operatori sanitari tra i più alti rispetto a quasi qualsiasi altro paese al mondo su base pro capite,[92] a seguito della dissoluzione dell'Unione Sovietica la salute della popolazione russa ha subito un peggioramento per via dei cambiamenti sociali, economici e degli stili di vita.[93] Tuttavia questa tendenza è stata invertita a partire dal 2006, con un'aspettativa di vita media che ha visto un incremento di 5,2 anni per i maschi e di 3,1 anni per le femmine, nel periodo tra il 2006 e il 2014.[94]
Al 2014 l'aspettativa di vita media in Russia era di 65,29 anni per i maschi e di 76,49 anni per le femmine.[94] Il più grande fattore che contribuisce alla relativamente bassa aspettativa di vita maschile è l'alto tasso di mortalità che si registra in età lavorativa. I decessi per lo più si verificano a causa di cause prevenibili (ad esempio, alcolismo, tabagismo, incidenti stradali, crimini violenti). A seguito della grande differenza nella speranza di vita e anche per l'effetto duraturo successivo alle alte perdite umane avvenute durante la seconda guerra mondiale, vi è uno squilibrio tra i sessi, con un rapporto di 0,859 maschi per ogni femmina.[95]
L'esercito russo è composto da Esercito, Marina e Aeronautica. Vi sono inoltre tre ulteriori bracci indipendenti che sono le forze missilistiche strategiche, le truppe aviotrasportate e le Forze spaziali. Nel 2006, l'esercito contava 1 037 000 persone in servizio attivo.[96] Il servizio militare, della durata di un anno, è obbligatorio per tutti i cittadini di sesso maschile di età compresa tra 18 e i 27 anni.[95]
La Russia possiede la più grande riserva di armi nucleari nel mondo e la seconda più grande flotta di sottomarini lanciamissili balistici ed è l'unico Paese, insieme agli Stati Uniti, con una moderna forza di bombardieri strategici.[97][98] La sua componente di carri armati è la più grande del mondo.
Il Paese vanta un'industria di grandi dimensioni ed è in grado di produrre autonomamente la maggior parte del suo equipaggiamento militare e solo pochi tipi di armi devono essere importate. Ciò rende la Russia uno dei più importanti fornitori al mondo di armi e da sola copre circa il 30% del mercato mondiale con esportazioni in circa 80 Paesi.[99] Lo Stockholm International Peace Research Institute, SIPRI, ha rilevato che la Russia è stato il secondo più grande esportatore di armi nel 2010-2014, aumentando le sue esportazioni del 37% rispetto al periodo 2005-2009. Nel 2010-2014 la Russia ha consegnato armamenti a 56 Stati e alle forze ribelli dell'Ucraina orientale.[100]
Il bilancio 2014 delle spese militari del governo russo è stato di circa 2 490 miliardi di rubli (circa 69,3 miliardi di dollari statunitensi), il terzo più grande al mondo dopo gli Stati Uniti e la Cina. Il bilancio è destinato a salire a 3 030 miliardi di rubli (circa 83,7 miliardi di dollari) nel 2015 e a 3 360 miliardi di rubli (circa 93,9 miliardi di dollari) nel 2016.[101] Tuttavia stime non ufficiali considerano in realtà un bilancio significativamente più alto, ad esempio il SIPRI stima che la spesa militare del 2013 sia stata di 18 miliardi di dollari superiore ai dati ufficiali.[102][103] Al 2014 il bilancio militare della Russia era superiore a qualsiasi altra nazione europea.
Secondo il Global Peace Index del 2012 la Russia è il sesto Paese meno pacifico su 162 Paesi considerati, principalmente a causa della sua industria bellica. La Russia è storicamente classificata in bassa posizione fin dalla nascita dell'indice nel 2007.[104]
La sicurezza dei cittadini è garantita da diverse strutture governative quali l'MVD[105] (il Ministero dell'Interno - МВД РФ), l'MCHS[106] (il Ministero per le Situazioni anomale. - МЧС РФ), l'FSB[107] (il Servizio Federale di Sicurezza - ФСБ РФ), il FSO[108] (il Servizio Federale di Protezione - ФСО РФ), l'SVR[109] (il Servizio di Controspionaggio - СВР РФ), il GFS[110] (il Servizio delle Comunicazioni Speciali - ГФС РФ),lo FSTEK[111] (il Servizio Federale per il controllo tecnico e per il controllo dell'export - ФСТЭК РФ), il FSVNG[112] (la Guardia Nazionale - ФСВНГ РФ), lo FSIN[113] (il Servizio Federale per i detenuti - ФСИН РФ), il GRU (il Comando Generale per lo Spionaggio - ГРУ РФ), dal FSSP[114] (il Servizio Federale degli Ufficiali Giudiziari - ФССП РФ) e dal SKR[115] (il Comitato Investigativo - СК РФ).
In accordo con la Costituzione della Federazione Russa la forma di governo è semipresidenziale;[116][117] il Presidente della Federazione Russa è il capo di Stato ed è eletto a suffragio universale diretto con un sistema a doppio turno (con secondo turno di ballottaggio tra i due candidati con più voti, nel caso nessuno ottenga al primo turno la maggioranza assoluta dei voti validi). Il mandato presidenziale, originariamente previsto in quattro anni, è stato elevato nel dicembre 2008 a sei anni a decorrere dalla successiva elezione, per non più di due mandati consecutivi. Il presidente nomina il primo ministro e, su sua proposta, nomina e revoca i ministri, così come può far dimettere l'intero governo.[118][119]
La Federazione Russa è fondamentalmente strutturata come una democrazia rappresentativa, con il governo federale composto da tre rami:
La Russia possiede un parlamento bicamerale. L'Assemblea Federale (Federalnoe Sobranie) consiste in una camera alta conosciuta come Consiglio Federale (Sovet Federacii), composta da 170 delegati che prestano un servizio quadriennale (ognuna delle 85 suddivisioni amministrative ne nomina due), e in una camera bassa conosciuta, appunto, come Duma di Stato (Gosudarstvennaja Duma), che comprende 450 deputati, in carica per cinque (dal 2011) anni.
La nuova legge elettorale prevede la distribuzione dei seggi tra le liste che hanno superato su scala nazionale lo sbarramento del 7%. I principali partiti politici, disciplinati da un'apposita legge,[121] sono Russia Unita, il Partito Comunista della Federazione Russa, il Partito Liberal-Democratico di Russia, Russia Giusta e Russia del Futuro (non registrata). Nel 2012 la Russia si è classificata 122ª su 167 nazioni esaminate dal Democracy Index,[122] mentre il World Justice Project la classifica all'80° su 99 Paesi in termini di stato di diritto.[123]
La Russia possiede un'economia di mercato molto sviluppata e che vanta enormi risorse naturali, in particolare petrolio e gas naturale. In termini di PIL nominale si classifica al 12º posto mondiale e al 6º posto come potere d'acquisto. A partire dall'inizio del XXI secolo l'alto consumo interno e una maggiore stabilità politica hanno sostenuto la crescita economica e nel 2008 il Paese ha chiuso il suo nono anno consecutivo di crescita, sperimentando però subito dopo un rallentamento dovuto al calo del prezzo del petrolio e del gas. Il PIL pro capite reale registrato nel 2010 era di 19 840 dollari statunitensi.[124] La crescita è stata trainata principalmente dai servizi non commerciabili e dal mercato interno, a differenza delle esportazioni di petrolio o dall'estrazione di minerali.[95] La media nominale dello stipendio per i russi è stata di 967 dollari al mese nei primi del 2013, rispetto agli 80 dollari che si potevano guadagnare nel 2000.[125][126] Nel marzo 2014 il salario mensile nominale medio aveva raggiunto i 30 000 rubli (980 dollari),[127][128] mentre l'imposta sul reddito delle persone fisiche era fissata al tasso del 13% sulla maggior parte dei redditi.[129] Nel 2011 circa il 12,8% dei russi viveva sotto la soglia di povertà nazionale[130] con un significativo calo dal 40% rispetto al 1998, il momento peggiore dopo il crollo dell'Unione Sovietica.[131] Nel 2014 la disoccupazione in Russia era al 5,4%, in netto calo dal 12,4% dal 1999.[131] La classe media è cresciuta dai soli 8 milioni di persone del 2000 ai 104 milioni di individui nel 2013.[132][133] Le importazioni di zucchero sono scese dell'82% tra il 2012 e il 2013 a seguito dell'aumento della produzione interna.[134] A fine 2014, visto il calo del rublo, il reddito medio netto era pari a 360 € secondo l'istituto nazionale di statistica ROSSTAT.[135]
Petrolio, gas naturale, metalli e legname rappresentano oltre l'80% delle esportazioni russe all'estero.[95] A partire dal 2003 le esportazioni di risorse naturali hanno cominciato a diminuire con il mercato interno che si è rafforzato considerevolmente. Nonostante i prezzi alti dell'energia, il petrolio e il gas contribuiscono solo al 5,7% del PIL del Paese.[136] I proventi delle esportazioni hanno permesso alla Russia di aumentare le sue riserve di valuta estera dai 12 miliardi di dollari del 1999 ai 597,3 miliardi di dollari posseduti al 1º agosto 2008, andando a costituire la terza più grande riserva di valuta estera del mondo.[137] Nel 2006 la Russia aveva rimborsato la maggior parte dei suoi enormi debiti[138] garantendosi uno dei più bassi debiti esteri tra le principali economie.[139] Il fondo di stabilizzazione ha aiutato la Russia a uscire dalla crisi finanziaria globale in un modo migliore rispetto a come molti esperti si aspettavano.[140]
Un semplice e snello sistema di tassazione, adottato a partire dal 2001, ha ridotto la pressione fiscale sulle persone e aumentato enormemente le entrate dello Stato.[141] La Russia ha una flat tax del 13% che la classifica come il paese con il secondo sistema fiscale personale più attraente per singoli manager del mondo dopo gli Emirati Arabi Uniti.[142] Secondo Bloomberg la Russia gode di maggior considerazione rispetto alla maggior parte dei paesi ricchi di risorse nel suo sviluppo economico, grazie alla sua lunga tradizione nell'istruzione, nella scienza e nell'industria.[143] In Eurasia è il paese che ha la maggiore percentuale di laureati.[144]
Lo sviluppo economico in Russia non è stato tuttavia geograficamente uniforme, con la regione di Mosca che ha contribuito a una quota molto ampia del PIL complessivo.[145] La disuguaglianza del reddito familiare e della ricchezza è stata ampiamente sottolineata e Credit Suisse ha rilevato che la non uniforme distribuzione della ricchezza russa è molto più accentuata rispetto a molti altri Paesi considerati e che "merita di essere posta in una categoria a parte".[146][147] Un altro problema riguarda la modernizzazione delle infrastrutture; a tal proposito il governo ha garantito che circa 1 000 miliardi di dollari sarebbero stati investiti nello sviluppo infrastrutturale entro il 2020.[148] Nel dicembre 2011 la Russia ha aderito all'Organizzazione mondiale del commercio, garantendosi così un maggiore accesso ai mercati esteri. Alcuni analisti stimano che l'adesione all'OMC potrebbe portare all'economia russa un rimbalzo fino al 3% annuo.[149] Secondo l'indice di percezione della corruzione, la Russia si classifica come il primo Paese più corrotto in Europa dal 2016. La Camera di Commercio russo-norvegese afferma anche che «la corruzione è uno dei più grandi problemi con cui le aziende russe e internazionali hanno a che fare».[150] Si stima che la corruzione costi all'economia russa circa 2 miliardi di dollari (80 miliardi di rubli) per anno.[151]
Secondo uno stress test condotto dalla banca centrale russa sul sistema finanziario l'economia del Paese sarebbe in grado di gestire una svalutazione del 25% -30% senza grosse interferenze da parte della stessa banca centrale. Tuttavia l'economia russa alla fine del 2013 ha cominciato un periodo di stagnazione in concomitanza con la guerra dell'Ucraina orientale ed è in pericolo di entrare in stagflazione, cioè una crescita lenta e alta inflazione. Da ottobre 2013 a ottobre 2014 il rublo russo è crollato del 24% entrando nel livello in cui la banca centrale potrebbe valutare un intervento per rafforzare la moneta. Inoltre, dopo aver portato l'inflazione al 3,6% nel 2012, il tasso più basso dall'indipendenza dall'Unione Sovietica, l'inflazione in Russia è salita a quasi il 7,5% nel 2014, portando la banca centrale ad aumentare il tasso di interesse dal 5,5% all'8%.[152][153][154] In un articolo dell'ottobre 2014 apparso su Bloomberg Business Week si riferiva che il Paese aveva cominciato a spostare significativamente la sua economia verso la Cina, in risposta alla crescente tensione finanziaria a seguito della sua annessione della Crimea e le successive sanzioni economiche occidentali.[155]
A seguito delle sanzioni occidentali per l'invasione dell'Ucraina, i depositi privati nelle banche russe sono diminuiti di 1 300 miliardi di rubli (21,6 miliardi di dollari), pari al 3,8%. Il Fondo Monetario Internazionale prevede per il 2022 un aumento dei disoccupati pari a 3.8 milioni di unità. Ad aprile è stata varata una legge che vieta alle banche russe di divulgare i bilanci intermedi e annuali, mentre il Cremlino ha ottenuto la facoltà di non divulgare i dati relativi alle riserve in valuta estera.[156]
In Russia la superficie totale della terra coltivata è stata stimata nel 2005 in 1237294 km², la quarta più ampia al mondo.[157] Dal 1999 al 2009 l'agricoltura ha mostrato una crescita costante[158] e il Paese si è trasformato da grande importatore di grano al primo esportatore. La produzione di carne è cresciuta dalle 6 813 000 tonnellate del 1999 alle 9 331 000 tonnellate del 2008 e continua a crescere.[159] Questa crescita del settore agricolo è stata sostenuta dalla politica di credito del governo che ha aiutato sia i singoli agricoltori, sia le grandi aziende agricole private che derivano dai kolchoz sovietici e che ancora possiedono una quota significativa dei terreni agricoli.[160] Mentre le grandi aziende si concentrano principalmente sulla produzione di grano e sull'allevamento, nei piccoli appezzamenti delle famiglie si concentrano soprattutto la coltivazioni di patate, verdure e frutta.[161]
Grazie all'accesso a un oceano e a diversi mari la pesca è uno dei settori di produzione più importanti e contribuisce all'approvvigionamento di pesce a livello mondiale. Nel 2016 la sola Russia aveva realizzato 491 700 068 tonnellate di pescato.[162] Sia le esportazioni sia le importazioni di pesce e prodotti del mare sono cresciute significativamente negli ultimi anni.[163]
La Russia possiede più di un quinto delle foreste di tutto il mondo.[164][165] Tuttavia, secondo uno studio del 2012 dalla Food and Agriculture Organization delle Nazioni Unite,[166] questo notevole potenziale è sottoutilizzato e la quota russa nel commercio mondiale dei prodotti forestali è inferiore al quattro per cento.[167][168]
Negli ultimi anni la Russia è stata spesso descritta dai media come una superpotenza energetica.[169][170] Il Paese possiede le maggiori riserve mondiali di gas naturale dopo il Qatar,[171] le ottave più grandi riserve di petrolio,[172] e la seconda più grande di carbone.[173] La Russia è il principale esportatore mondiale di gas naturale[174] e il secondo più grande produttore.[175][176]
La Russia è il terzo più grande produttore di energia elettrica di tutto il mondo[177] e il quinto più grande da fonti rinnovabili, il secondo per la produzione idroelettrica.[173] I più grandi impianti idroelettrici si trovano nella Russia europea, lungo grandi fiumi come il Volga. La parte asiatica della Russia dispone anche di una serie di importanti centrali idroelettriche, ma il gigantesco potenziale idroelettrico della Siberia e dell'estremo oriente russo rimane in gran parte non sfruttato.
La Russia è stata il primo Paese a sviluppare energia nucleare per scopi civili e a costruire la prima centrale nucleare del mondo. Il paese è tuttora il quarto più grande produttore di energia dalla fissione. Questo settore è in rapido sviluppo con l'obiettivo di aumentare la quota complessiva dal 16,9% al 23% entro il 2020. Il governo russo prevede di stanziare 127 miliardi di rubli (5,42 miliardi di dollari) per un programma federale dedicato alla nuova generazione di tecnologie nucleari. Circa 1 miliardo di rubli (17,6 milioni di dollari) era stato assegnato al bilancio federale per l'energia nucleare e lo sviluppo del settore prima del 2015.[178]
Nel maggio 2014, durante un viaggio di due giorni a Shanghai, il presidente Putin ha firmato un accordo per conto della Gazprom per fornire la Cina di 38 miliardi di metri cubi di gas naturale all'anno. È stata inoltre concordata la costruzione di un gasdotto per facilitare l'operazione in cui la Russia contribuirà per 55 miliardi di dollari e la Cina per 22 miliardi; Putin ha descritto ciò come "il più grande progetto di costruzione del mondo per i prossimi quattro anni". Il gas naturale dovrebbe cominciare ad arrivare tra il 2018 e il 2020 e continuerà per trent'anni, a un costo finale per la Cina di 400 miliardi di dollari.[179]
Nel febbraio 2013 la produzione industriale in Russia è diminuita del 2,1% rispetto all'anno precedente. Storicamente, dal 2006 al 2013, l'industria manifatturiera russa è cresciuta in media del 2,82%, con un picco del 12,60% nel maggio 2010 e un calo massimo del 16,90% nel gennaio 2009. In Russia la produzione industriale dipende strettamente dall'andamento del settore minerario e dei trasporti.
In Russia l'industria della difesa impiega 2 milioni e mezzo di persone, che rappresentano un quinto dei dipendenti del settore manifatturiero. Il Paese è il secondo esportatore mondiale di armi convenzionali, dopo gli Stati Uniti d'America, e i prodotti più popolari del settore sono aerei militari, sistemi di difesa aerea, elicotteri, carri armati e veicoli terrestri militari.[180][181][182]
Un settore caratteristico dell'industria manifatturiera russa è la produzione di aeromobili e mezzi spaziali, che impiega circa 355 000 persone. L'industria aerospaziale russa produce soprattutto aerei ed elicotteri militari, che da soli rappresentano metà delle esportazioni del settore della difesa.[183]
In Russia è molto presente l'industria dell'automobile, che impiega circa 600 000 persone, lo 0,7% della forza lavoro nazionale. L'indotto relativo è importante, con oltre 2 milioni di occupati. Nel 2010 la Russia ha prodotto il 7% delle automobili vendute al mondo, ponendosi al quindicesimo posto nella graduatoria mondiale. Nei due anni precedenti il settore ha però dimezzato la produzione a causa della crisi economica mondiale. Notevole anche il settore dei veicoli industriali: i camion Kamaz hanno vinto per 16 volte, fino ad oggi (2019), il rally Dakar.
In Russia è in forte espansione anche la microelettronica, già presente negli anni ottanta e novanta.[184][185]
Nel 2013 i russi hanno speso il 60% del loro reddito nell'acquisto di beni e servizi, la media più alta d'Europa. Ciò è dovuto forse al fatto che molti russi non pagano affitti e possiedono case di proprietà, ereditate dalle privatizzazioni del settore edile negli anni novanta. I centri commerciali sono molto diffusi grazie a crescenti investimenti stranieri e all'ascesa della nuova classe media. In prossimità delle città maggiori sono stati costruiti 82 centri commerciali, di cui solo alcuni molto estesi.[186]
Secondo la banca centrale russa, nel 2013 erano presenti nel paese 422 compagnie di assicurazioni. Il settore è presente in tutti gli ambiti, ad eccezione dei componenti di base per auto.[187]
La gran parte del trasporto ferroviario in Russia è sotto il controllo della Rossijskie železnye dorogi, le ferrovie di Stato, che le gestisce in monopolio. L'azienda produce oltre il 3,6% del PIL del paese e gestisce il 39% del traffico totale di merci (compresi i gasdotti) e più del 42% del traffico passeggeri.[188] La lunghezza totale delle linee ferroviarie più comuni supera gli 85 500 chilometri,[188] arrivando a essere seconde solo alla rete statunitense. Oltre 44000 km di ferrovia è elettrificata,[189] la maggior lunghezza per un singolo Stato al mondo. Le ferrovie russe, a differenza di quanto avviene nella maggior parte del mondo, usano un scartamento di 1 520 millimetri, con l'eccezione di 957 km sull'isola di Sakhalin con scartamento ridotto di 1 067 millimetri. La più famosa tratta ferroviaria russa è la Transiberiana che copre il record di sette fusi orari e permette i più lunghi servizi continuativi singoli nel mondo: Mosca-Vladivostok (9259 km), Mosca-Pyongyang (10267 km)[190] e Kiev-Vladivostok (11085 km).[191]
Al 2006 la Russia possedeva 933000 km di strade, di cui 755 000 erano asfaltate.[192] Alcune di queste fanno parte del sistema autostradale federale russo. Considerando la sua vasta superficie, la densità stradale del Paese è la più bassa di tutti i Paesi del G8 e dei Paesi del BRICS.[193]
Gran parte delle vie navigabili interne della Russia, che ammontano a 102000 km, sono costituite da fiumi o laghi naturali. Nella parte europea del Paese la rete di canali collega i bacini dei grandi fiumi. La capitale della Russia, Mosca, è stata talvolta chiamata "il porto dei cinque mari", per via dei suoi collegamenti navigabile al mar Baltico, al mar Bianco, al mar Caspio, al mar d'Azov e al mar Nero.
I principali porti della Russia includono Rostov sul Don, sul mar d'Azov, Novorossijsk sul mar Nero, Astrachan' e Machačkala sul mar Caspio, Kaliningrad e San Pietroburgo sul mar Baltico, Arcangelo sul mar Bianco, Murmansk sul mare di Barents, Petropavlovsk-Kamčatskij e Vladivostok sull'oceano Pacifico. Nel 2008 il Paese possedeva 1 448 navi per la marina mercantile. La Russia possiede l'unica flotta al mondo di rompighiaccio a propulsione nucleare per lo sfruttamento economico della piattaforma continentale artica del Paese, per lo sviluppo del commercio marittimo attraverso la rotta del mare del Nord tra l'Europa e l'Asia orientale.
Per la lunghezza totale dei gasdotti la Russia è seconda solo agli Stati Uniti e molti progetti di nuove linee sono tuttora in corso di realizzazione.
La Russia ha 1 216 aeroporti,[194] di cui i più trafficati sono Šeremet'evo, Domodedovo e Vnukovo di Mosca e Pulkovo di San Pietroburgo. La lunghezza complessiva delle piste in Russia supera i 600000 km.[195]
In genere le principali città russe hanno sistemi di trasporto pubblico ben sviluppati, con diversi tipi di mezzi usati, come autobus, bus elettrici, filobus e tram. Sette città russe, in particolare Mosca, San Pietroburgo, Nižnij Novgorod, Novosibirsk, Samara, Ekaterinburg e Kazan', hanno metropolitane sotterranee. La lunghezza complessiva della rete di metropolitane russe è di 465,4 km. Le metro di Mosca e San Pietroburgo sono le più antiche del Paese, inaugurate rispettivamente nel 1935 e nel 1955; entrambe sono annoverate tra i sistemi più veloci e più trafficati del mondo e sono famosi per le pregiate decorazioni e per gli unici design delle stazioni, una tradizione comune delle metropolitane e ferrovie russe.
Le poste federali sono gestite dall'azienda statale Počta Rossii.
Secondo un'inchiesta sul tema dei mass media in Russia, la maggior parte degli intervistati recepisce le notizie attraverso la televisione.[196] I canali più frequentemente guardati sono Россия 1 (Rossija 1), Первый Канал (Pervyj Kanal), НТВ (NTV).[197]
Al secondo posto nella classifica delle fonti d'informazione appare la rete Internet con i siti Rbc.ru, Russia Today, Gazeta.ru.[198]
Le emittenti radiofoniche più ascoltate sono Европа Плюс (Europa Plus), Авторадио (Avtoradio), Дорожное Радио (Dorožnoe Radio).[199]
I quotidiani più letti sono Изветия (Izvestija), КоммерсантЪ (Kommersant), Российская Газета (Rossijskaja Gazeta).[200]
Le agenzie d'informazione più importanti sono la ИТАР-ТАСС (ITAR-TASS), РИА Новости (RIA Novosti), Интерфакс (Interfax).[201]
Fin dal periodo tardo sovietico la Russia ha visto una rapida crescita del turismo, prima quello domestico e quindi il turismo internazionale, alimentato dal ricco patrimonio culturale e dalla grande varietà naturale del Paese. I principali itinerari turistici in Russia includono un viaggio intorno all'Anello d'Oro delle città antiche, le crociere sui grandi fiumi come il Volga e lunghi viaggi sulla famosa ferrovia Transiberiana. Nel 2013 la Russia è stata visitata da 28,4 milioni di turisti, diventando il nono Paese più visitato al mondo e il settimo più visitato in Europa.
Le destinazioni più visitate della Russia sono Mosca e San Pietroburgo, rispettivamente l'attuale e l'antica capitale del Paese. Riconosciute come "città del mondo", vantano musei di fama mondiale, come la galleria Tret'jakov e l'Ermitage, teatri famosi come Bol'šoj e Mariinskij, chiese come la cattedrale di San Basilio, la cattedrale di Cristo Salvatore, la cattedrale di Sant'Isacco e la chiesa del Salvatore sul Sangue Versato, impressionanti fortificazioni come il Cremlino di Mosca e la fortezza di Pietro e Paolo, belle piazze e strade come la piazza Rossa, piazza del Palazzo e la Prospettiva Nevskij. Ricchi palazzi e parchi si trovano nelle antiche residenze imperiali in periferia di Mosca (Kolomenskoe, Parco Caricyno) e a San Pietroburgo (Peterhof, Strel'na, Oranienbaum, Gatčina, Pavlovsk e Carskoe Selo). Mosca mostra il meglio dell'architettura sovietica con moderni grattacieli, mentre San Pietroburgo, soprannominata la Venezia del nord, vanta la sua architettura classica con molti fiumi, canali e ponti.
Nižnij Novgorod è considerata la terza città più significativa della Russia. All'epoca dell'Impero russo c'era un detto: "San Pietroburgo è il capo della Russia, Mosca il cuore, e Nižnij Novgorod la tasca". È una città divisa in 2 parti: storica e sovietica. In una parte di essa (la città alta) si trovano il Cremlino, i templi, le antiche strade e le case di legno. In un'altra parte della città (la città bassa) c'è una famosa fiera, un gran numero di fabbriche (tra cui GAZ) e un centro sovietico con architettura stalinista.
La calda costa subtropicale del mar Nero della Russia è un sito di località balneari famose, come Soči che ha ospitato le Olimpiadi invernali del 2014. Le montagne del Caucaso settentrionale vantano località sciistiche famose, come Dombaj. La destinazione più famosa per il turismo naturalistico in Russia è il lago Bajkal, il cosiddetto "occhio blu" della Siberia. Questo lago unico, il più antico e profondo del mondo, gode di acque pulite e cristalline ed è circondato da montagne coperte di taiga. Altre destinazioni naturali includono la penisola di Kamčatka con i suoi vulcani e geyser, la Carelia con i suoi laghi e le rocce di granito, le montagne dell'Altai e le steppe di Tuva.
Quando verso la fine del V secolo gli antichi popoli nomadi degli Sciti e dei Sarmati, che originariamente popolavano le zone lungo il Volga e il Dnepr, cominciano a insediarsi stabilmente sul territorio, comincia un certo sviluppo dell'artigianato, legato alla produzione di armi, pellicce e oggetti di metallo lavorati a sbalzo. I rapporti commerciali con le terre vicine si fanno sempre più intensi e soprattutto con l'Impero bizantino. Affascinati dalla cultura e dallo splendore della loro capitale Costantinopoli, cominciarono gradualmente ad assumerne le caratteristiche. Se fino ad allora gli oggetti presentavano una decorazione a motivi esclusivamente geometrici e dai forti colori, man mano si va assottigliando con l'introduzione di figure zoomorfe che poi si fonderanno con motivi vegetali.
Tuttavia l'arte russa propriamente detta, sviluppatasi direttamente dall'arte bizantina, si fa partire dalla conversione del principe di Kiev, Vladimir I al cristianesimo bizantino-ortodosso nel 988. Infatti le arti applicate si sviluppano in funzione dell'adozione del cristianesimo: dalle necessità di costruire nuovi luoghi di culto (architettura russa), secondo gli stilemi importati da Costantinopoli; dall'introduzione di testi scritti, per le liturgie e l'insegnamento della nuova religione (letteratura russa), tradotti dal greco e dal bulgaro antico, di cui l'adozione dell'alfabeto cirillico; dalla figurazione dei Santi cristiani, riportando le effigi dei mosaici bizantini poi gradualmente sostituiti con affreschi e preziose immagini votive (icone).
Da questo momento in poi l'arte, fusa con il gusto e le tradizioni popolari, svilupparono quello stile tradizionale russo che caratterizzò il Paese fino alla fine del XVII secolo, quando con lo zar Pietro il Grande l'Impero russo si aprì verso l'occidente adottandone gli stilemi europei dell'architettura barocca, rococò e neoclassica.
Celebre pittore di icone fu Andrej Rublëv, vissuto tra il XIV e il XV secolo. Nel peridodo di transizione tra il neoclassicismo e il romanticismo russo nella pittura spicca la figura di Karl Pavlovič Brjullov (1799-1852), che in Italia dipinse l'opera Gli ultimi giorni di Pompei[204], oltre che quella dell'incisore Stepan Filippovič Galaktionov.[205] Nel XIX secolo spicca la figura di Pavel Andreevich Fedotov, fondatore del realismo critico[206] e si distinsero, inoltre, Ivan Konstantinovič Ajvazovskij, i cui dipinti riguardano in particolare paesaggi marini e Andrej Andreevič Popov, per i suo verismo genuino. Un altro importante pittore e scultore vissuto tra il XIX e il XX secolo fu Il'ja Efimovič Repin, esponente del gruppo dei Peredvižniki (Ambulanti),[207] e ancora Viktor Michajlovič Vasnecov, noto per i soggetti di carattere storico e mitologico. Nel XX secolo si distinse la figura di Vasilij Kandinskij (1866-1944), fondatore dell'Astrattismo e, tra gli altri, Marc Chagall, esponente della Scuola di Parigi, oltre a Ivan Nikolaevič Pavlov innovatore nell'arte dell'incisione e di Arkadij Aleksandrovič Plastov pitture anticonformista verista. Nel 1913, inoltre, venne fondata l'avanguardia artistica chiamata suprematismo da Kazimir Severinovič Malevič. Tra le pittrici che si sono distinte nel corso del XX secolo ricordiamo Zinaida Serebrjakova, naturalizzata francese.
Fin dalla conversione al cristianesimo della Rus' di Kiev per diversi secoli l'architettura russa è stata influenzata prevalentemente dall'architettura bizantina. Oltre alle fortificazioni (Cremlino), i principali e più antichi edifici in pietra che permangono ai nostri giorni, sono le chiese ortodosse con le loro numerose cupole, spesso dorate o dipinte a colori vivaci.
A partire dalla fine del XV secolo Aristotele Fioravanti e altri architetti italiani esportarono le tendenze del Rinascimento in Russia, mentre il secolo successivo vide sviluppare chiese caratterizzate da tipiche cuspidi che ricordano delle tende, che culminano nella realizzazione della cattedrale di San Basilio.[208] A quel punto l'idea della cupola a cipolla era pienamente sviluppato.[209] Nel XVII secolo l'ornamentale "stile di fuoco" fiorì a Mosca e a Jaroslavl', aprendo gradualmente la strada per il barocco moscovita. Dopo le riforme di Pietro il Grande lo stile architettonico del Paese seguì tendenzialmente i dettami dell'Europa occidentale.
Nel XVIII secolo il gusto per l'architettura rococò ha introdotto nel Paese le opere di Bartolomeo Rastrelli e dei suoi successori. I regni di Caterina la Grande e di suo nipote Alessandro I, videro il fiorire dell'architettura neoclassica e in particolare nella capitale di San Pietroburgo. La seconda metà del XIX secolo ha visto il dominio degli stili neobizantino e neorusso. Nel XX secolo sono invece prevalsi l'Art Nouveau, il costruttivismo e lo stile impero di Stalin.
Nel 1955 il nuovo leader sovietico Nikita Chruščëv ha condannato gli "eccessi" dell'architettura accademica,[210] e il tardo periodo sovietico è stato caratterizzato dall'architettura funzionale. Ciò ha contribuito molto nel risolvere il problema abitativo per la popolazione, ma ha fatto nascere una grande quantità di edifici di bassa qualità architettonica, in forte contrasto con i precedenti stili luminosi. La situazione è tuttavia migliorata nei due decenni a cavallo dell'anno 2000. Molti edifici religiosi demoliti durante l'epoca sovietica sono stati ricostruiti e questo processo è continuato con il restauro di vari edifici storici distrutti durante la seconda guerra mondiale. Un totale di 23 000 chiese ortodosse sono stati ricostruite tra il 1991 e il 2010, che di fatto ha quadruplicato il numero degli edifici di culto aperti nel Paese.[211]
Nelle città russe più popolate si può oggi assistere allo sviluppo di costruzioni moderne e innovative, prime fra tutte le città c'è la capitale Mosca con il suo Centro Internazionale di Affari,complesso di grattacieli in continua espansione che va a definire il moderno skyline della città più importante del Paese. Il grattacielo Lachta-centr di San Pietroburgo è il più alto d'Europa (462 m). Altri complessi superanti i 140 metri, ovvero l'altezza necessaria di un edificio per essere classificato come grattacielo, si trovano a Groznyj, a Ekaterinburg e a San Pietroburgo. Ad oggi nella classifica dei grattacieli più alti d'Europa compaiono 26 edifici situati nelle varie città russe.
Trenta siti russi sono iscritti nella Lista dei patrimoni dell'umanità dell'UNESCO.
La Russia possiede importanti musei, alcuni tra i più noti nel mondo, tra i quali l'Ermitage, a San Pietroburgo, fondato da Caterina II di Russia e aperto nel 1764 e, tra gli altri, il Museo Puškin delle belle arti, a Mosca, aperto nel 1912.
Nel XVIII secolo, durante l'Illuminismo russo, la letteratura del Paese andò incontro a un forte sviluppo grazie all'influenza delle opere di Michail Lomonosov e Denis Fonvizin. All'inizio del secolo successivo un florido e moderno filone di produzione letteraria emerse con l'affermarsi di alcuni dei più grandi scrittori della storia del Paese. Questo periodo, conosciuto anche come l'epoca d'oro della poesia russa, iniziò con Aleksandr Puškin, considerato il fondatore della lingua letteraria russa moderna e spesso descritto come lo "Shakespeare russo".[212] Il prosieguo del secolo ha poi visto la poesia di Michail Lermontov, rilevante figura del Romanticismo, e di Nikolaj Nekrasov; pioniere del realismo e linguista fu Vladimir Ivanovič Dal': si affermano i drammi di Aleksandr Ostrovskij e Anton Čechov, le favole di Ivan Krylov e la prosa di Nikolaj Gogol', esponente del Realismo;Ivan Aleksandrovič Gončarov, autore del romanzo Oblomov (1859), da cui deriva il termine oblomovismo, Ivan Sergeevič Turgenev, interprete del realismo russo e aurore del romanzo Padri e figli (1862), Lev Tolstoj e Fëdor Dostoevskij sono ritenuti da molti critici letterari come i più grandi romanzieri di tutti i tempi.[213][214]
Con l'anno 1880 l'età dei grandi romanzieri era finita e la narrativa breve e la poesia divennero generi dominanti, con i decenni successivi che presero il nome di età d'argento della poesia russa, e il realismo letterario dovette lasciare il posto al simbolismo. I principali autori di questa epoca sono poeti come Valerij Brjusov, Vjačeslav Ivanov, Aleksandr Aleksandrovič Blok, noto esponente della cosiddetta epoca d'argento della poesia russa, Nikolaj Gumilëv, Anna Achmatova e i romanzieri Leonid Andreev, Ivan Alekseevič Bunin, il primo russo a vincere, nel 1933, il Premio Nobel per la letteratura e Maksim Gor'kij, importante esponente del realismo socialista. E ancora è da ricordare Michail Bulgakov, (Il maestro e Margherita, (1966-1967)). Nel XX secolo importante la figura di Boris Pasternak, celebre autore de Il dottor Živago (1957), di Michail Aleksandrovič Šolochov, autore del romanzo Il placido Don, di Aleksandr Isaevič Solženicyn, che con i suoi scritti ha fatto conoscere i Gulag, di Vladimir Nabokov, autore del celebre romanzo Lolita (1955) e del poeta Evgenij Aleksandrovič Evtušenko; si afferma, inoltre, il romanzo e il racconto di fantascienza con Isaac Asimov, naturalizzato statunitense, autore, tra l'altro di Io, robot (1950). sulle tre leggi della robotica e il Ciclo delle Fondazioni.
La musica russa del XIX secolo è stata definita come la tensione tra la composizione classica di Michail Ivanovič Glinka e la produzione del Gruppo dei Cinque, che abbracciarono l'identità nazionale russa aggiungendo elementi religiosi e folcloristici alle loro composizioni, e la Società musicale russa guidata dai compositori Anton e Nikolaj Rubinštejn, musicalmente conservatori. La tradizione successiva di Pëtr Čajkovskij, uno dei più grandi compositori della musica tardo-romantica e, tra l'altro, celebre compositore del balletto Lo schiaccianoci (1892), continuò nel secolo successivo con l'esponente del postromanticismo Sergej Rachmaninov.[215]. Altri compositori di fama mondiale del XX secolo comprendono Aleksandr Skrjabin, Igor' Stravinskij, i cui lavori riguardano anche il neoclassicismo musicale, Sergej Sergeevič Prokof'ev e Dmitrij Šostakovič, tutti esponenti della musica moderna e Al'fred Šnitke.
Inoltre nel XX secolo si afferma l'attore e teorico del teatro Konstantin Sergeevič Stanislavskij, ricordato in particolare per lo stile di insegmaneto di recitazione noto come Metodo Stanislavskij e per aver fondato, nel 1898, assieme a Vladimir Ivanovič Nemirovič-Dančenko il Teatro d'arte di Mosca.
Dai conservatori sono usciti generazioni di solisti famosi in tutto il mondo. Tra i più noti sono i violinisti Jascha Heifetz, David Ojstrach, Leonid Kogan, Gidon Kremer e Maksim Vengerov, il violoncellista Mstislav Rostropovič, i pianisti Vladimir Horowitz, Svjatoslav Richter, Ėmil' Gilel's, Vladimir Sofronickij e Evgenij Kisin e i cantanti Fëdor Šaljapin, Elena Obrazcova, Galina Višnevskaja, Anna Netrebko e Dmitrij Chvorostovskij.[216]
Nel corso del XX secolo i ballerini Anna Pavlova e Vaclav Nižinskij conquistarono una fama internazionale, così come Svetlana Jur'evna Zacharova, onorata del titolo di prima ballerina assoluta, e l'impresario teatrale Sergej Djagilev portò la sua compagnia di balletto, i Balletti russi, a viaggiare all'estero influenzando lo sviluppo della danza in tutto il mondo.[217] Il balletto durante l'era sovietica conservò e perfezionò le tradizioni del secolo precedente,[218] e le scuole coreografia del tempo formarono molte stelle di fama internazionale, come Galina Ulanova, Majja Pliseckaja, Rudol'f Nureev e Michail Baryšnikov. Il balletto Bol'šoj di Mosca e il balletto Mariinskij di San Pietroburgo godono tuttora di prestigio internazionale.[219]
Tra le direttrici d'orchestra sovietiche e poi russe che si sono affermate nel corso del XX e XXI secolo possiamo citare Veronika Dudarova (1916-2009).
Nel corso del XX secolo tra i cantanti spicca quello del chitarrista Vladimir Vysockij, che fu anche poeta, e della sovietica Ljubov' Orlova.
Il moderno rock russo prende le sue radici, sia nel rock and roll sia nell'heavy metal che nelle tradizioni dei bardi russi dell'epoca sovietica, da Vladimir Vysockij e Bulat Okudžava.[220] Popolari gruppi rock russi comprendono i DDT, gli Akvarium, Alisa, Kino, Nautilus Pompilio, Aria e i Graždanskaja oborona. La musica pop russa vanta alcuni artisti che hanno guadagnato un ampio riconoscimento internazionale, come le t.A.T.u., autrici di singoli di successo come All the Things She Said (2002) e All About Us (2005), le VIA Gra, Vitas e ancora Julija Savičeva e Anastasija Karpova.
Un importante contributo culturale è rappresentato dal folclore con i suoi molteplici aspetti. Un tipico esempio del folclore russo è rappresentato da Bujan, un'isola misteriosa dell'Oceano che pare che appaia e scompaia tra le nebbie. E ancora da ricordare Sneguročka, personaggio del folclore russo spesso menzionato in fiabe e leggende popolari, e Sadko, leggendario personaggio della bylina, una tipica narrativa poetica ed eroica degli antichi slavi della Rus' di Kiev.
Il cinema russo si è affermato nel XX secolo in campo internazionale con importanti registi come il sovietico Sergej Ėjzenštejn, autore di capolavori come La corazzata Potëmkin (1925).
L'arte del video è molto popolare nella Russia moderna. La Russia è uno dei mercati prioritari per YouTube.[221] 
L'episodio più popolare della serie televisiva animata russa Masha e Orso ha oltre 3 miliardi di visualizzazioni.[222] Particolarmente popolare è lo spettacolo +100500, che ospita recensioni video per video divertenti[223][224] e BadComedian, che rende recensioni per film famosi.[225] Molti trailer cinematografici russi sono stati nominati in "Golden Trailer Awards".[226][227] Molti video di Nikolaj Kurbatov, fondatore della poetica del trailer e costruzione del dialogo del trailer sono stati caricati sui grandi canali YouTube, sono stati usati come trailer principali e inseriti nel libro dei record.[228][229][230][231]
Il XIX secolo vide anche il fiorire della filosofia russa, inizialmente basata sull'opposizione all'occidentalismo e sullo slavofilismo, che promuoveva lo sviluppo del Paese come una civiltà unica. Quest'ultimo gruppo comprese Nikolaj Danilevskij e Konstantin Leont'ev, i fondatori dell'eurasiatismo. Nel suo ulteriore sviluppo la filosofia russa è sempre stata segnata da un profondo legame con la letteratura e l'interesse per la creatività, la società, la politica e il nazionalismo; il cosmismo russo e la teologia erano anch'essi aree di studio importanti. Fra i notevoli filosofi del tardo XIX secolo e inizio del XX si annoverano Vladimir Solov'ëv, Sergej Bulgakov e Vladimir Vernadskij.
Dopo la rivoluzione russa del 1917 lasciarono il Paese molti scrittori e filosofi di primo piano, tra cui Ivan Bunin, Vladimir Nabokov e Nikolaj Berdjaev, mentre una nuova generazione di autori di talento si unì nel tentativo di creare un distintivo culturale della classe operaia per il nuovo stato sovietico. Nel 1930 iniziò un rafforzamento della censura sugli scritti, in linea con la politica del realismo socialista. Alla fine del 1950 sono state attenuate tali restrizioni e dagli anni 1970 e 1980, gli scrittori hanno sempre più ignorando le linee guida ufficiali. I principali autori dell'epoca sovietica sono romanzieri come Evgenij Zamjatin, Michail Bulgakov e Michail Šolochov e poeti come Vladimir Majakovskij, Evgenij Evtušenko e Andrej Voznesenskij.
L'Unione Sovietica è stato anche un grande produttore di fantascienza, grazie ai lavori di autori come Arkadij e Boris Strugackij, Kir Bulyčëv, Aleksandr Beljaev e Ivan Efremov.[232]
La gastronomia russa varia da regione a regione avendo subito le varie culture e tradizioni storiche che vanno dall'impero Russo, all'Unione Sovietica per arrivare alla Federazione Russa. Base preminente dell'alimentazione, per gran parte della gente, era rappresentata da cereali e ortaggi e oggi una certa rilevanza hanno le zuppe.
In Russia la scienza e la tecnologia sbocciarono nell'era illuministica quando Pietro il Grande fondò l'Accademia russa delle scienze e l'Università statale di San Pietroburgo, e il poliedrico Michail Vasil'evič Lomonosov creò l'Università Statale di Mosca, aprendo la strada a una forte tradizione per l'apprendimento e l'innovazione. Nel corso del XIX e XX secolo il Paese ha formato un gran numero di scienziati e inventori di rilievo internazionale.
La scuola di fisica russa iniziò con Lomonosov, che propose la legge di conservazione della materia e che precede la legge di conservazione dell'energia. Altre scoperte e invenzioni nel campo della fisica dei russi comprendono l'arco elettrico, la legge di Lenz, i gruppi spaziali dei cristalli, la fotocellula, l'effetto Čerenkov, la risonanza paramagnetica elettronica, l'eterogiunzione e l'olografia 3D. Aleksandr Stepanovič Popov nel campo della radiocomunicazione. Il laser e il maser sono stati co-inventati da Nikolaj Basov e Aleksandr Prochorov, mentre il ricorso al tokamak per la fusione nucleare controllata è stata ideata da Igor' Tamm, Andrej Dmitrievič Sacharov, che contribuì, nel 1953, alla realizzazione della bomba all'idrogeno e a cui venne dedicato il Premio Sakharov per la libertà di pensiero, e Lev Arcimovič.
Dal tempo di Nikolaj Lobačevskij (pioniere della geometria non-euclidea) e un insegnante prominente Pafnutij Čebyšëv la scuola matematica russa è diventata una delle più influenti al mondo.[233] Tra gli studenti di Čebyšëv vi furono Aleksandr Ljapunov, che formulò la teoria moderna della stabilità e Andrej Markov che sviluppò il processo che prende il suo nome. Tra le donne che hanno dato un fondamentale contributo alla matematica e alla fisica ricordiamo Sof'ja Vasil'evna Kovalevskaja, prima donna russa matematico e fisico. I matematici sovietici XX secolo, come Andrej Kolmogorov, Izrail' Gel'fand e Sergej Sobolev, diedero un grande contributo a diverse aree della matematica. Nove matematici sovietici/russi sono stati premiati con la medaglia Fields, il premio più prestigioso in matematica. Nel 2010 a Grigorij Perel'man è stato offerto il premio per i problemi per il millennio per la sua dimostrazione definitiva della congettura di Poincaré.[234]. Molto noti, anche per le loro produzioni didattiche adottate nelle università di tutto il mondo, il matematico Boris Demidovič e il fisico Lev Davidovič Landau.[235]
Il chimico russo Dmitrij Mendeleev formulò la tavola periodica degli elementi (6 marzo 1869), il quadro principale della chimica moderna. Aleksandr Butlerov è stato uno dei creatori della teoria della struttura chimica, giocando un ruolo centrale nella chimica organica. Biologi russi includono Dmitrij Ivanovskij che ha scoperto i virus, Ivan Pavlov che fu il primo a sperimentare il condizionamento classico e Il'ja Mečnikov che era un ricercatore pioniere del sistema immunitario e degli organismi probiotici.
In campo medico si è, tra gli altri, distinta la figura di Vera Gedrojc, prima chirurga nell'Impero russo, che ha dato un importante contributo alla medicina di guerra. Altra figura importante è quella di Ivan Pavlov e la sua scoperta sui cani del riflesso condizionato; Pavlov fu Premio Nobel per la medicina, nel 1904.
Molti scienziati e inventori russi erano emigrati, come Igor' Sikorskij, che ha costruito i primi aerei di linea e moderno tipo di elicotteri; Vladimir Zvorykin, spesso chiamato il padre della televisione; il chimico Il'ja Prigožin, noto per il suo lavoro sulle strutture dissipative e sistemi complessi; gli economisti Simon Kuznec e Vasilij Leont'ev premio Nobel; il fisico George Gamow (autore della teoria del Big Bang) e lo scienziato sociale Pitirim Sorokin. Molti stranieri hanno lavorato in Russia per un lungo periodo di tempo, come Eulero e Alfred Nobel.
Invenzioni russi comprendono saldatura ad arco da Nikolaj Benardos, ulteriormente sviluppata da Nikolaj Slavjanov, Konstantin Chrenov e altri ingegneri russi. Gleb Kotel'nikov inventò il paracadute a sacca, mentre Evgenij Čertovskij introdusse la tuta pressurizzata. Aleksandr Lodygin e Pavel Jabločkov sono stati pionieri di illuminazione elettrica e Michail Dolivo-Dobrovol'skij introdusse i primi sistemi elettrici trifase, oggi ampiamente usati. Sergej Lebedev ha inventato e prodotto in serie il primo tipo commercialmente valido di gomma sintetica. Il primo calcolatore ternario, Setun, è stato sviluppato da Nikolaj Brusencov.
Nel campo fotografico un posto preminente è occupato da Sergej Michajlovič Prokudin-Gorskij, uno dei pionieri della fotografia del XX secolo.
Nel XX secolo una serie di importanti ingegneri aerospaziali sovietici, ispirati dalle opere fondamentali di Nikolaj Žukovskij e Sergej Čaplygin, realizzarono centinaia di modelli di velivoli militari e civili e fondarono una serie di fabbriche che ora costituiscono la OAK, un raggruppamento di aziende aeronautiche e aerospaziali russe creato nel 2006 su iniziativa del governo. Famosi aeromobili russi includono i Tupolev civili, gli aerei da combattimento MiG e Sukhoi, e gli elicotteri Mil e Kamov.
I T-34 sono stati dei famosi carri armati protagonisti della seconda guerra mondiale,[236] mentre gli AK-47 e gli AK-74 di Michail Kalašnikov costituiscono il tipo più diffuso di fucile d'assalto in tutto il mondo.[237]
La corsa agli armamenti durante la guerra fredda rappresentò un grosso impulso all'innovazione tecnologica specie in ambito militare. Nonostante tutti questi successi, la Russia in era tardo-sovietica si trovò però in ritardo rispetto al mondo occidentale in una serie di prodotti tecnologici, soprattutto in quelli correlati al risparmio energetico e alla produzione di beni di consumo. La crisi degli anni novanta ha portato alla drastica riduzione del sostegno statale per la scienza e una migrazione di scienziati all'estero. Negli anni duemila, sull'onda di un nuovo boom economico, si è assistito a un miglioramento della situazione nella scienza e nella tecnologia russa e il governo ha lanciato una campagna volta alla modernizzazione e all'innovazione. Il presidente russo Dmitrij Medvedev ha formulato alcune priorità per lo sviluppo tecnologico del Paese, quali un uso efficiente dell'energia, la tecnologia dell'informazione, l'energia nucleare, la farmaceutica.[238]
La Russia ha completato il sistema di navigazione satellitare GLONASS. Il Paese sta sviluppando un proprio jet da combattimento di quinta generazione e la costruzione del primo impianto nucleare mobile di serie al mondo.
Nel campo delle esplorazioni, tra il 1803 e il 1806, avviene la prima circumnavigazione russa della terra con Adam Johann von Krusenstern e Jurij Fëdorovič Lisjanskij.
Le conquiste russe nel campo della tecnologia spaziale e l'esplorazione dello spazio sono riconducibili a Konstantin Ėduardovič Ciolkovskij, il padre teorico dell'astronautica.[239] Le sue opere hanno ispirato i principali ingegneri dei razzi sovietici, come Sergej Korolëv, Valentin Gluško e molti altri che hanno contribuito al successo del programma spaziale sovietico dalle prime fasi della corsa allo spazio, nata sempre nell'ambito della guerra fredda.
Il 4 ottobre 1957 l'URSS lanciò il primo satellite artificiale in orbita intorno alla Terra, lo Sputnik 1, mentre nel 1961 il primo uomo a viaggiare nello spazio è stato Jurij Gagarin. Successivamente seguirono altri record sovietici nell'esplorazione spaziale, tra cui la prima passeggiata spaziale eseguita da Aleksej Leonov, 16 giugno 1963 Valentina Tereškova è la prima donna ad andare nello spazio, Luna 9 è stato il primo veicolo spaziale ad atterrare sulla Luna, Venera 7 il primo ad atterrare su un altro pianeta (Venere), Mars 3 il primo ad atterrare su Marte, il primo rover lunare Lunokhod 1 e le prime stazioni spaziali Saljut 1 e Mir.
Dopo il crollo dell'Unione Sovietica alcuni programmi finanziati dal governo, tra cui il Programma Buran, furono cancellati o ritardati, mentre la partecipazione dell'industria spaziale russa nelle attività commerciali e nella cooperazione internazionale risultò intensificata.
Il 21 gennaio 1992 venne lanciato Cosmos 2175, il primo satellite della Russia dopo la dissoluzione dell'URSS.
Oggi la Russia è il più grande lanciatore di satelliti[senza fonte].[240] Dopo che il programma Space Shuttle conclusosi nel 2011 i razzi Sojuz divennero gli unici vettori in grado di trasportare gli uomini alla Stazione Spaziale Internazionale, fino al 30 Maggio 2020 quando avvenne il lancio della missione Demo 2 operata da SpaceX.
Il Campionato russo di calcio nasce nel 1992 in seguito alla dissoluzione dell'Unione Sovietica.
La massima divisione del campionato di calcio russo è chiamata Prem'er-Liga, con squadre blasonate come lo Spartak Mosca o il Lokomotiv Mosca.
La Nazionale di calcio della Russia, soprannominata Медведи (Gli orsi) o Красная армия (Armata Rossa), è la rappresentativa di calcio della Russia, considerata sia dalla FIFA che dall'UEFA unica erede dell'Unione Sovietica. Attuale capocannoniere è Aleksandr Keržakov, con 30 reti. Tra i portieri spicca Rinat Dasaev, inserito nella lista FIFA 100.
Il paese ha ospitato i Mondiali del 2018.
La Nazionale di pallavolo femminile della Russia ha conseguito per due volte il titolo mondiale, nel 2006 e nel 2010.
Nel 1913 e nel 1914 il gran premio si è disputato a San Pietroburgo. Dal 2014 il gran premio viene ospitato nell'Autodromo di Soči sempre dominato dalla Mercedes con Valtteri Bottas (nel 2017 e nel 2020), Nico Rosberg (nel 2016) e Lewis Hamilton (nel 2014, nel 2015, nel 2018 e nel 2019). Negli ultimi anni i piloti presenti nel circus sono Daniil Kvjat e Nikita Mazepin.
Altro sport molto seguito è l'hockey su ghiaccio e le squadre russe partecipano al Kontinental Hockey League. La squadra con maggior numero di vittorie è attualmente la Ak Bars Kazan'.
Tra gli atleti russi più titolati ai Giochi olimpici moderni ricordiamo Aleksej Nemov, nella ginnastica artistica, con 12 medaglie, Alina Kabaeva oro nel concorso generale di Atene 2004, Evgenija Kanaeva l'unica ginnasta ad aver vinto due ori alle olimpiadi di Pechino 2008 e Londra 2012 nella ginnastica ritmica, Aleksandr Popov, nel nuoto, con 9 medaglie, Ljubov' Egorova, nello sci di fondo, e Dmitrij Sautin, nei tuffi, con 8 medaglie conquistate. E ancora la plurimedagliata ginnasta sovietica Larisa Latynina, oggi cittadina russa. Prima medaglia olimpica per la Russia è la medaglia d'argento vinta da Aleksandr Petrov, nella lotta greco-romana, ai Giochi olimpici di Londra 1908.
Ma il primo campione olimpico russo è Nikolaj Panin-Kolomenkin, nel pattinaggio di figura, a Londra 1908.
La Russia è stata padrona di casa delle olimpiadi estive nel 1980, che si sono tenute a Mosca (allora nell'Unione Sovietica) e di quelle invernali del 2014, tenutesi a Soči.
Bangkok (in thailandese: บางกอก?), in thai ufficialmente denominata Krung Thep Maha Nakhon o Krung Thep (in thailandese: กรุงเทพมหานคร?, กรุงเทพฯ; pronuncia[?·info]), è la capitale e la città più estesa e popolosa della Thailandia, situata lungo il fiume Chao Phraya, nei pressi del golfo della Thailandia. Secondo il censimento del 2020 gli abitanti erano 10,539 milioni, il 15,3% della popolazione del paese, mentre erano oltre 14 milioni (22,2%) quelli che vivevano nella regione metropolitana nel 2010, che comprende anche le province circostanti.[2] Tra le città più popolose e trafficate del mondo,[3] nonché una delle destinazioni preferite del turismo mondiale, a partire dalla seconda metà del XX secolo ha conosciuto un rapidissimo sviluppo industriale, rappresentando una delle città economicamente più potenti del sud-est asiatico.[4] L'economia di Bangkok si è classificata come la sesta tra le città asiatiche in termini di PIL pro capite, dopo Singapore, Hong Kong, Tokyo, Osaka–Kobe e Seoul a partire dal 2010, rendendola una delle città più importanti in Asia.
Il territorio della zona amministrativa di Bangkok è quasi interamente coperto dalla città, si estende per 1568,7 km² e fa della capitale della Thailandia uno dei più grandi centri urbani del mondo. La Regione metropolitana di Bangkok (in thailandese: กรุงเทพมหานครและปริมณฑล?, traslitterato: krung thep maha nakhon lae parimonthon, letteralmente: metropoli di Bangkok e perimetro) si estende oltre i confini di Bangkok e comprende le vicine province di Samut Sakhon e Samut Prakan a sud, Nakhon Pathom a ovest, Pathum Thani e Nonthaburi a nord.[5] La municipalità di Bangkok ha uno sbocco sul mare con un tratto di costa lungo 4,4 km.[6]
La città sorge sulle rive del fiume Chao Phraya, ampio e navigabile, che assieme ai suoi affluenti settentrionali Nan e Ping costituisce il bacino idrografico comprendente il centro ed il nord del paese. Una complessa rete di canali (khlong) ha dato alla città l'appellativo di Venezia dell'est. Nella seconda metà del XX secolo, molti di questi canali sono stati coperti per far posto a nuove arterie stradali di un sempre più congestionato traffico cittadino; su quelli rimasti vi sono ancora trasporti di merci e passeggeri, nonché alcune abitazioni galleggianti.
Il governo cittadino ha cercato di arginare l'eccessiva urbanizzazione ed industrializzazione anche con la creazione di grandi parchi in alcuni quartieri periferici, ma le zone più centrali della città offrono pochi spazi verdi; tra questi vi sono in centro il parco Lumphini e Sanam Luang (letteralmente "campo reale"), e verso nord il parco Chatuchàk.
Il centro di Bangkok è situato a 2 m s.l.m. e durante la stagione delle piogge subisce frequenti allagamenti ed esondazioni del fiume e dei canali. La municipalità di Bangkok negli ultimi anni ha provveduto a creare degli argini più alti sui canali a maggior rischio, ma un altro fattore che aggrava il problema è il progressivo affossamento della città, che giace quasi esclusivamente su un terreno paludoso[7].
Bangkok ha un clima influenzato dai monsoni che caratterizzano la stagione umida. La temperatura più bassa fu registrata nel gennaio 1955, 9,9 °C, assai distante dal clima della città.[8] L'anno in media più caldo fu il 1997 (con una media di 30 °C registrata all'aeroporto Don Mueang) e il più freddo il 1975 (26,3 °C).[9]
La media delle temperature massime mensili supera sempre i 31 °C mentre la media delle minime non scende sotto i 21 °C. Le stagioni sono tre:
Bangkok era un piccolo villaggio portuale chiamato Bang Makok, in cui era stanziata una comunità di immigrati cinesi che commerciavano con la città di Ayutthaya, l'allora capitale del Siam. Questa fu rasa al suolo dai birmani nel 1767 e, nel giro di pochi mesi, il nuovo re Taksin cacciò gli invasori e stabilì la capitale a Thonburi, la cui vicinanza al mare era importante dal punto di vista strategico.[12] Thonburi si trovava sulla riva opposta del fiume Chao Phraya rispetto a Bang Makok e negli anni settanta del XX secolo sarebbe stata inglobata nel territorio di Bangkok.
Nel 1782 il re Rama I portò la capitale del regno a Bang Makok, sulla sponda orientale del fiume di fronte a Thonburi. La comunità cinese fu fatta spostare in una vicina zona, che in seguito si sarebbe sviluppata attorno alla strada Yaowarat, formando la prosperosa chinatown della capitale.[13] Il sovrano fece costruire una serie di maestosi edifici, tra cui il Grande Palazzo Reale, e Bang Makok fu ribattezzato Rattanakosin, che significa "città del gioiello di Indra",[14] la divinità-guerriera di origine induista adottata anche dal buddhismo, particolarmente venerata in Thailandia.
Nel complesso del palazzo reale fu eretto il Wat Phra Kaew, il complesso templare dove fu portato il Buddha di Smeraldo, la sacra statua che rappresenta il palladio della casa regnante e che era conservata nel Wat Arun di Thonburi dal 1779. Il re fece costruire un fossato a difesa della città creando l'isola di Rattanakosin, che è il nucleo attorno a cui si è sviluppata la capitale. Rama I diede a Bangkok anche un lunghissimo nome cerimoniale (vedi sezione specifica), che fu modificato dal re Rama IV e la cui abbreviazione, Krung Thep Maha Nakhon (letteralmente "capitale degli angeli", "grande città"), è l'attuale nome ufficiale. I thailandesi e i laosiani la chiamano semplicemente Khrung Thep, ma nel resto del mondo si è sempre continuato a chiamarla Bangkok, la contrazione del nome Bang Makok.
Il Regno di Thonburi, nato sulle ceneri di quello di Ayutthaya, divenne così il Regno di Rattanakosin. Il primo edificio ad essere costruito fu il Lak Mueang, il santuario dove è tuttora custodita la divinità tutelare della città; fu inaugurato il 21 aprile 1782, che è considerata la data di fondazione di Bangkok.[15] Durante i regni di Rama I (1782-1809) e di Rama II (1809-1824), i principali lavori pubblici riguardarono l'abbellimento della città con nuovi templi e palazzi, e la realizzazione di nuovi canali. Le opere di canalizzazione sarebbero continuate fino al regno di Rama V (1868-1910),[16] contribuendo a bonificare il terreno paludoso su cui sorge la capitale e sviluppando le vie di comunicazione, che a quei tempi erano quasi esclusivamente idrovie.
Il re Rama III (1824-1851) ingrandì il porto, adeguandolo all'esigenza siamese di espandere i traffici marittimi con l'estero. Inizialmente, la struttura divenne approdo in prevalenza di giunche cinesi, e Bangkok arrivò a competere con Singapore per quanto riguarda i traffici con la Cina. Verso la metà del XIX secolo, le nuove imponenti navi delle potenze occidentali soppiantarono le vecchie giunche cinesi ed il Siam, sentendosi minacciato, impose un regime protezionistico ai commerci e sbarrò l'accesso a Bangkok alle navi non autorizzate. Ben presto il re Rama IV (1851-1868) fu costretto a rivedere tale politica per arginare la crescente influenza europea e scongiurare il rischio della colonizzazione del Paese. Il Siam siglò con diversi Stati occidentali, in particolare col Regno Unito, importanti trattati che limitarono l'autonomia del Paese ma contribuirono ad arricchirlo con nuovi scambi commerciali. Fu lo stesso sovrano, convinto dell'importanza del progresso scientifico e tecnologico, a far costruire le prime vere strade di Bangkok.[16]
Il sistema stradale cittadino fu ampliato da re Rama V, che proseguì sulle orme del padre Rama IV sulla strada del rinnovamento del Paese.[17] Fu Rama V a far costruire in città la Scuola di Formazione per il Servizio Civile, che durante il regno del figlio Rama VI sarebbe diventata il primo ateneo del Siam, l'Università Chulalongkorn.[18] Nel 1893 fu ultimata la prima ferrovia siamese, da Bangkok a Pak Nam (il vicino villaggio dove sfocia il fiume Chao Phraya), e in seguito fu dato il via alla costruzione dell'odierna stazione principale di Bangkok, la Hua Lamphong, completata durante il regno di Rama VI.[19] Nel corso di una visita in Italia, Rama V rimase affascinato dalla monumentale bellezza dell'allora capitale Torino e, a partire dalla fine dell'Ottocento, invitò in Siam diversi ingegneri, architetti ed artisti italiani, soprattutto piemontesi, per progettare e realizzare i più grandi palazzi, ponti e monumenti che trasformarono Bangkok. Tali iniziative furono portate avanti anche dal successore Rama VI (1910-1925).[20]
La crisi economica innescata dalle spese eccessive volute da Rama VI e dalla crisi globale che seguì la grande depressione del 1929, costrinsero il re Rama VII (1925-1935) a tagliare le spese pubbliche, in particolare quelle militari, provocando crescente malumore nei vertici delle forze armate. Alcuni ufficiali di alto grado delle forze armate si unirono al progetto in favore della democrazia di alcuni studenti educati all'estero e portarono a compimento a Bangkok l'incruento colpo di Stato conosciuto come la rivoluzione siamese del 1932. Il sovrano fu costretto ad accettare le proposte dei ribelli ed ebbe inizio la monarchia costituzionale;[21] ebbe così fine il Regno di Rattanakosin, dopo l'evento lo Stato prese il nome Regno del Siam e nel 1939 Regno di Thailandia.
Gli iniziali ideali di democrazia portati avanti dai promotori della rivoluzione del 1932 vennero presto sopraffatti dalle ambizioni delle alte sfere militari, che diedero il via a una quasi ininterrotta serie di colpi di Stato e di dittature. Nel dopoguerra, dopo che il dittatore Phibun aveva trascinato il Paese nella seconda guerra mondiale a fianco dei giapponesi, vi fu un breve periodo di democrazia monopolizzato da Pridi Banomyong, uno degli studenti artefici della rivoluzione del 1932. Il colpo di Stato militare del 1947 restituì il potere a Phibun con l'avallo degli statunitensi, che scelsero la Thailandia come baluardo nella lotta al comunismo dilagante in Sud-est asiatico.[22] Quando ebbe inizio il suo declino, Phibun cercò di riprendere l'egemonia aprendo alla democrazia e, segretamente, alla Cina di Mao, prendendo le distanze dagli Stati Uniti e nel settembre 1957 vi fu il colpo di Stato organizzato dal generale Sarit Thanarat, che pose fine alla carriera di Phibun, costretto a rifugiarsi in esilio.[23]
Durante la dittatura di Thanarat vi fu un ulteriore avvicinamento del Paese agli Stati Uniti nonché il ritorno della monarchia Chakri a una posizione di potere,[24] il re Bhumibol Adulyadej conseguì notevoli vantaggi, recuperando gran parte dei privilegi perduti dalla monarchia nel 1932. Thanarat promosse lo sviluppo economico del Paese in accordo con gli statunitensi e la sua dittatura esercitò sulle opposizioni una repressione senza precedenti.[25] Vi furono ingenti investimenti dall'estero; l'incremento demografico e l'urbanesimo ingrandirono enormemente in questo periodo la popolazione di Bangkok. Si venne a creare una consistente classe media ed ebbe grande sviluppo l'istruzione pubblica, con la formazione di una generazione di studenti aperti e informati sulla politica e sull'economia.
Con lo scoppio della guerra del Vietnam, Thanarat fornì supporto militare e logistico agli americani, ai quali concesse l'uso delle basi aeree del nord-est per i bombardamenti del Vietnam. Alla sua morte, nel 1963, prese il potere il suo vice, il generale Thanom Kittikachorn, che ne continuò la politica filo-americana e anti-comunista. La durezza della repressione e la grave corruzione che caratterizzarono i suoi governi alimentarono il pubblico malcontento. La tensione crebbe e vennero organizzate imponenti dimostrazioni anti-governative. La rivolta studentesca a Bangkok del 1973 pose fine alla sua egemonia politica; al termine di tre giorni di scontri tra le forze dell'ordine e un numero enorme di dimostranti fu costretto dal re Rama IX a rassegnare le dimissioni e ad andare in esilio.[26] I successivi governi democraticamente eletti si alternarono fino al 6 ottobre 1976, quando il brutale massacro dell'Università Thammasat, compiuto dalla polizia e da gruppi paramilitari a Bangkok, favorì un colpo di Stato che riportò una dittatura militare al governo.[27] Una nuova sommossa popolare a Bangkok fu soffocata nel sangue anche nel cosiddetto maggio nero del 1992, quando furono uccisi diversi manifestanti che contestavano il governo del generale Suchinda Kraprayoon.[28]
Negli anni settanta la piccola ma densamente popolata Provincia di Thonburi fu conglobata nell'area metropolitana di Bangkok. La superficie cittadina è passata dai 13 km² del 1900 ai 330 del 2000,[16] mentre l'area metropolitana misura oggi 1.568,7 km². L'incremento demografico nella capitale era stato graduale fin dai tempi della fondazione, ma si era fatto drammatico negli anni cinquanta e sessanta a causa della rapida industrializzazione e della centralizzazione delle attività di governo; le infrastrutture cittadine sono diventate insufficienti a soddisfare le esigenze dei nuovi arrivati. Anche a causa della mancanza di programmazione governativa, si sono progressivamente aggravati una serie di disagi che vanno dalla crisi abitativa, con diverse baraccopoli disseminate ovunque, alla congestione del traffico cittadino, dall'eccessivo accumulo di spazzatura (7.000 tonnellate al giorno) fino al deterioramento ambientale.[29]
Il conflitto cominciato all'inizio del XXI secolo tra la vecchia oligarchia militare e gli emergenti gruppi finanziari, ha vissuto i suoi episodi più drammatici a Bangkok. La nomina a primo ministro nel 2001 del magnate dei media Thaksin Shinawatra ha creato una spaccatura nel Paese tra la fazione che rappresenta i militari, il ceto medio e i lavoratori di Bangkok e della Thailandia del Sud e quella in cui si riconoscono le classi meno abbienti che appoggiano i governi e le coalizioni vicine a Thaksin, le cui roccaforti sono nel nord e nel nord-est del Paese. Si sono quindi registrati i colpi di Stato militari incruenti del 2006 e 2014 contro i governi della famiglia Shinawatra, ma soprattutto la crescente ingerenza della magistratura nella politica in opposizione al populismo con cui Thaksin e i suoi alleati si sono garantiti i voti degli elettori. In questo periodo vi sono stati grandi scontri tra queste fazioni che hanno contribuito a incrinare l'unità nazionale, in particolare quelli verificatisi a Bangkok.[30][31]
Lo stemma della città mostra il dio della folgore Indra che cavalca tra le nuvole Erawan, una creatura mitologica simile ad un elefante (rappresentata a volte con tre teste). Nella mano destra Indra impugna la vajra, la sua tradizionale arma da cui scaturisce la folgore. Lo stemma si ispira a un dipinto del principe Naris, un artista figlio del re Rama IV. La pianta simbolo di Bangkok è il ficus beniamino.
La città è ricca di templi buddhisti, conosciuti in Thailandia con il nome wat. Tra i più famosi vi sono:
Tra le decine di musei presenti a Bangkok vi sono:
Vi sono in città oltre trenta università, tra le quali:
Bangkok è anche il maggiore centro thailandese per la pubblicazione di mass media nazionali. Tra i più importanti quotidiani che hanno sede a Bangkok vi sono Thai Rath (il più venduto),[36] Khao Sod, Daily News, Matichon e Krungthep Thurakij. I maggiori quotidiani in lingua inglese sono il Bangkok Post e The Nation. Nella capitale vengono anche pubblicate varie riviste settimanali e mensili.
Anche le maggiori rete televisive hanno sede e principali studi a Bangkok, tra cui tutti e sei i canali terrestri: Canale 3, Canale 5, Canale 7, Modernine TV, NBT e Thai PBS. A parte alcuni notiziari locali che la NBT prepara nelle province, tutta la programmazione di queste reti viene fatta a Bangkok. Vi sono anche molte TV via cavo che hanno base a Bangkok, tra le quali la maggiore è TrueVisions. Diverse decine di stazioni radio trasmettono dalla capitale sia in FM che in AM.[37]
Anche l'industria cinematografica nazionale ha per centro Bangkok, dove si trovano i più importanti studi cinematografici del Paese, oltre a dozzine di cinema tra cui molti multisala. In città si tengono inoltre i due più importanti festival cinematografici nazionali, il Bangkok International Film Festival e il World Film Festival of Bangkok.
Bangkok è suddivisa in 50 distretti chiamati khet , che sono a loro volta suddivisi in 169 sottodistretti detti khwaeng (แขวง) (nelle altre province i distretti sono chiamati amphoe e i sottodistretti muban).[38]
Bangkok è il centro economico della Thailandia e vi hanno sede le maggiori banche e istituzioni finanziarie del Paese. Sono presenti molte filiali di banche straniere e diverse multinazionali vi hanno stabilito il loro quartier generale per il Sud-est asiatico. La Borsa thailandese ha la sua sede in centro città.
Il porto è situato lungo il fiume Chao Phraya vicino al centro nel distretto di Khlong Toei, enormi chiatte solcano le acque del fiume trasportando ingenti quantitativi di materiale. A causa dei bassi fondali, questo vecchio porto non permette l'attracco di navi mercantili ad alto tonnellaggio, che venivano quindi dirottate su Singapore e Hong Kong. Il problema è stato ovviato con la costruzione nel 1981 nella vicina provincia di Chonburi del porto di Laem Chabang,[39] che da allora ha spedito e ricevuto la maggior parte dei container internazionali diventando il più trafficato della Thailandia. Negli anni successivi a Laem Chabang è transitato un crescente numero di navi mercantili e nel 2016 era il 22º più trafficato al mondo.[40]
La costruzione del porto fa parte del piano di sviluppo della fascia costiera a sud-est di Bangkok, nella vasta zona compresa tra la provincia di Samut Prakan e la provincia di Rayong, dove è stata anche potenziata la rete stradale e ferroviaria, in particolare per quanto riguarda il trasporto merci. Le vecchie zone industriali di Bangkok sorgono nelle periferie a sud e ad ovest e questo piano di sviluppo, a partire dagli anni ottanta, ha concentrato a sud-est la maggior parte delle nuove industrie. Il decentramento ha anche evitato l'aumento dell'inquinamento e del traffico di automezzi pesanti nella capitale legati alla crescita economica del Paese.[39][41]
Una ricerca del 2008 effettuata da MasterCard ha classificato Bangkok al 42º posto tra le città più importanti al mondo come centri di commercio.[42] Con l'espandersi delle attività commerciali e finanziarie che hanno fatto della Thailandia una delle tigri asiatiche dell'economia, c'è stato un boom nella costruzione di grattacieli, se ne contano a Bangkok oltre 1.000, che la piazzano al 17º posto fra le città con più grattacieli al mondo.
Accanto alle classi privilegiate e a un ceto medio le cui entrate sono buone se proporzionate al costo della vita, vi sono larghi strati di popolazione che vivono sotto la soglia di povertà. Con il miraggio di sfuggire alla miseria delle aree più depresse della Thailandia e dei paesi confinanti, c'è sempre più gente ed immigrati clandestini che arrivano e ingrandiscono le numerose baraccopoli disseminate in città.[43]
La città è anche un famoso centro di gioielleria, ricco di botteghe artigianali che lavorano l'argento e il bronzo. Molti commercianti stranieri ed esportatori vengono per comprare tali prodotti, oltre a capi di vestiario e oggettistica. per il buon rapporto tra qualità e prezzo. Tra le zone cittadine commercialmente più vive ci sono Yaowarat, che è la Chinatown di Bangkok, e Phahurat, l'adiacente quartiere indiano.
Il turismo è una delle fonti principali di ricchezza. Oltre ad essere lo scalo thailandese principale per i turisti diretti in altre località del Paese, Bangkok offre edifici storici di sontuosa architettura (vedi paragrafo monumenti e luoghi d'interesse), vasti mercati, un'ampia scelta di raffinate cucine, un'affascinante vita notturna, una fiorente industria del sesso ecc. Secondo una stima del 2007, 14,5 milioni di turisti hanno visitato la Thailandia in quell'anno, facendone il 14º Paese più visitato al mondo. Nello stesso anno il turismo ha rappresentato il 6.7% del prodotto interno lordo thailandese. Bangkok rappresenta il polo di attrazione principale del settore. L'instabilità politica e i sanguinosi scontri di piazza che si sono verificati a partire dal 2008 hanno frenato il crescente numero di turisti in arrivo.
L'enorme varietà di strutture ricettive richiama a Bangkok ogni tipo di turista, da quello che viaggia in economia e che pernotta nella zona di thanon Khaosan, a quello che cerca alberghi lussuosi, molti dei quali si trovano lungo il Chao Phraya e a Sukhumvit. Tra i diversi mercati di forte richiamo turistico vi sono:
È possibile effettuare escursioni di una giornata in località di grande interesse culturale non distanti da Bangkok: l'antica capitale thailandese Ayutthaya è raggiungibile anche via fiume, oltre che con treni e autobus; il celebre mercato ferroviario di Maeklong che è raggiungibile con un viaggio in treno fra le risaie; il celebre ponte sul fiume Kwai presso Kanchanaburi è un'importante meta turistica ed è raggiungibile anche con la ferrovia.
Numerose autostrade sopraelevate e un anello autostradale, che circonda l'intera città, stanno per essere completate. L'autostrada 7 collega il centro città con l'aeroporto. Queste infrastrutture dovrebbero attenuare il problema del traffico della città. Altri progetti autostradali sono stati abbandonati per mancanza di fondi, in seguito alla crisi finanziaria asiatica degli scorsi anni. Nell'area metropolitana i dodici ponti che collegano le due sponde del fiume nelle ore di punta sono intasati e gli ingorghi che si creano bloccano il traffico per diversi km. Il più nuovo è il ponte Rama VIII, è situato in centro ed è un mirabile esempio di ingegneria moderna.
Dalla città si diparte anche l'Autostrada 81 che la collega alla città di Kanchanaburi.
Nel 1999 sono state aperte le due linee ferroviarie sopraelevate Bangkok Skytrain, chiamate ufficialmente BTS Skytrain, che si snodano per un totale di 55 km. La linea Sukhumvit congiunge Morchit a nord con la provincia di Samut Prakan a sud-est. La linea Silom collega lo stadio nazionale in centro con la stazione di Bang Wa, nel distretto di Phasi Charoen a Thonburi. Sono previsti altri prolungamenti di entrambe le linee.
La stazione centrale della Ferrovia di Stato della Thailandia è la Hua Lamphong, si trova in centro e vi partono i treni per Chiang Mai verso il nord, per la Malaysia verso il sud, per Nong Khai verso il nord-est e il Laos centrale, per Ubon Ratchathani verso est e il Laos meridionale, e per Aranya Prathet verso il sud est e la Cambogia. Ci sono poi diverse altre stazioni minori tra le quali quella di Thonburi a ovest da cui partono i treni per Kanchanaburi e l'ovest. A Bangkok vi sono diverse stazioni della Ferrovia di Stato, i cui treni vengono usati dai pendolari per spostarsi in città.
Il 23 agosto 2010 la Ferrovie di Stato ha inaugurato l'Airport Rail Link, una linea ferroviaria veloce sopraelevata della lunghezza di 49,5 chilometri che collega l'aeroporto Suvarnabhumi con il centro e in particolare:
La prima linea della metropolitana di Bangkok è quella blu, che è stata inaugurata nel luglio del 2004 e collega la stazione ferroviaria Bang Sue con la periferia di sud-ovest della capitale. Nel 2016 è stata inaugurata la linea viola, che collega il centro di Bangkok con la vicina Nonthaburi. Per entrambe le linee sono previsti prolungamenti. È inoltre prevista la costruzione di altre quattro linee: l'arancione, la gialla, la marrone e la rosa.
La città dispone di quattro linee ferroviarie sopraelevate che la attraversano: le due linee del Bangkok Skytrain, quella dell'Airport Rail Link, che collega il centro all'aeroporto Suvarnabhumi, e il poeple mover della Linea Oro, che compie un breve tragitto a Thonburi. Alla fine di maggio 2010 è stato inaugurato il BRT ("Bus Rapid Transit"), un sistema di bus navetta che collega thanon Sathon (nei pressi di Chong Nonsi) a Ratchaphruek.
Questi mezzi di spostamento rapido hanno ridotto il traffico cittadino, ma la situazione è sempre più caotica perché con il miglioramento del tenore di vita di una parte degli abitanti di Bangkok sono aumentate anche le auto private che si affiancano alle migliaia di taxi, ai tuk-tuk, ai songthaew nonché agli scooter che effettuano servizio taxi su percorsi relativamente brevi.
La rete degli autobus urbani è molto sviluppata, vi sono moltissime linee che a prezzi ridotti permettono di raggiungere ogni zona della città. Un altro modo economico di viaggiare a Bangkok è rappresentato da pulmini che hanno capienza fino a un massimo di quattordici persone e consentono di arrivare a destinazione più velocemente rispetto al tempo impiegato dagli ingombranti autobus. Il songthaew, che significa due panche, è un pick-up coperto autorizzato a trasportare passeggeri recante sul retro due panche sui lati, anche questo mezzo di trasporto è molto economico e di solito percorre tragitti non coperti dagli autobus.
Le principali stazioni di autobus e minivan per trasporti extraurbani sono le seguenti:
Il porto di Bangkok si trova nel khet Khlong Toei e fu il principale scalo internazionale del Paese dal 1947, quando fu inaugurato, fino al 1991, quando fu aperto il porto di Laem Chabang sulla costa est della baia di Bangkok. A causa dei bassi fondali, il vecchio porto di Bangkok non permette l'attracco di navi mercantili ad alto tonnellaggio che transitavano quindi in altri porti del Sud-est asiatico.[46] Il porto di Laem Chabang fu costruito anche per alleviare il traffico fluviale di Bangkok, che era troppo intenso.[40] Nonostante la drastica riduzione del traffico, dal porto di Klong Toey continuano le spedizioni di una discreta quantità di container.[47]
Sul fiume Chao Phraya è attivo l'efficace ed economico servizio di motobattelli della compagnia Chao Phraya Express Boat, che consente ai passeggeri di eludere il traffico stradale e di ammirare il paesaggio cittadino; vi sono anche numerosi traghetti per passeggeri per l'attraversamento del fiume nelle zone lontane dai ponti e diverse imbarcazioni taxi di compagnie private. Su alcuni canali è attivo un servizio analogo a quello della Chao Praya Express Boat, eseguito con imbarcazioni di dimensioni più ridotte, le barche passeggeri Khlong Saen Saep, che trasportano fino a 60 000 persone ogni giorno.[48]
L'unico aeroporto di Bangkok, uno dei più trafficati del sud est asiatico, è stato sino al 2006 Don Muang, situato nel nord della città. La costruzione del nuovo aeroporto Suvarnabhumi, nel distretto di Bang Phli della provincia di Samut Prakan, nel sud-est della città, è iniziata nel 2002 ed è terminata nel 2006. Quest'opera costata cifre ingenti generò gravi accuse di corruzione da parte del quotidiano The Nation contro l'amministrazione del primo ministro Thaksin Shinawatra, il quale fu quindi rimosso dall'incarico con il colpo di Stato del 2006. Tali accuse furono ritrattate nel 2008 da The Nations, che si scusò per il grave danno all'immagine dell'ex premier.[49] Dopo un primo periodo, sino a fine 2006, tutti i voli interni e internazionali furono ospitati nel nuovo aeroporto Suvarnabhumi, a partire dal 2007, per questioni logistiche, parte dei voli fu riportata nel vecchio aeroporto Don Muang, in particolare quelli delle compagnie a basso costo.
Dal punto di vista amministrativo, Bangkok è una delle due zone a statuto speciale della Thailandia insieme a Pattaya. Dal 1975 ha acquisito lo status di metropoli ed è stata posta sotto la giurisdizione della locale Amministrazione metropolitana. Viene considerata la 77ª provincia del paese in quanto il livello di amministrazione viene equiparato a quello delle 76 province (changwat) nazionali.
Il governo metropolitano si divide in due organi principali:[50]
A tutto l'aprile del 2014, Bangkok era gemellata con le seguenti 27 città:[51]
La Mecca[1][2] (AFI: /ˈmɛkka/[3]; in arabo: ﻣكة المكرّمة‎, Makka al-mukarrama, lett. "Makka l'onorata") è una città dell'attuale Arabia Saudita occidentale, situata nella regione dell'Hegiaz. Capoluogo della provincia omonima, è per antonomasia la città santa (prima ancora di Medina e Gerusalemme) per i musulmani. È la città in cui, per la tradizione musulmana, è nato Maometto, ricordato come profeta e rifondatore[4] dell'Islam. Contiene la più grande moschea del mondo, il Masjid al-Haram. Ai non musulmani è vietato entrare in città.[5][6]
La Mecca si trova al centro di sette colli: Jabal Abū Siba', Jabal Safa, Jabal Marwa, Jabal Abū Milhah, Jabal Abū Ma'aya, Jabal Abū Hulaya e Jabal Abū Ghuzlan.
Di essa non si sa molto prima dell'Islam. Secondo alcuni Claudio Tolomeo la ricorderebbe col nome di Macoraba, sebbene non sia certo che si riferisse alla Mecca attuale. Il Corano la cita nella Sūra XLVIII:24. La tradizione islamica la descrive come centro di importanti scambi commerciali (mawṣim) e di raduno spirituale: la Mecca sarebbe stata dominata dalla tribù dei Banu Quraysh che l'avevano strappata ai Banū Khuzāʿa originari dello Yemen, a loro volta diventati signori del centro urbano ai danni dei B. Jurhum e dei Qatūrā.[7] La rilevanza commerciale sarebbe dipesa dal fatto che - secondo il Corano - i Quraysh organizzavano ogni anno almeno due gigantesche carovane che univano il meridione arabo (oasi di Najrān) al settentrione siro-palestinese (centro di Gaza). Queste carovane, che avrebbero raggiunto a volte la consistenza di quasi 2.000 dromedari e un numero imprecisato di asini, percorrevano l'intera tratta lungo la cosiddetta "via del Ḥijāz" in poco più di 60 giorni e sostavano lì dove era possibile far abbeverare bestie e uomini. Una di queste soste era appunto la città della Mecca, nella spianata che ospitava il santuario preislamico della Kaʿba.
Importanza spirituale era leggermente collegabile proprio a questo edificio sacro. Inizialmente esso custodiva il simulacro della divinità tribale urbana di Hubal ma presto, per agevolare la sosta dei carovanieri e dei pellegrini, nella Kaʿba furono accolti numerosissimi altri idoli, venerati dalla maggior parte delle popolazioni arabe peninsulari, che furono distrutti nel 630 dal profeta Maometto subito dopo aver conquistato la sua città natale. Secondo la tradizione islamica il santuario avrebbe avuto fondazione abramitica, ma di questo fatto non vi è riscontro né nella tradizione ebraica, né in quella araba preislamica, che mai fa riferimento a un'origine ismaelita per la propria nazione.[8]
Il Corano la indica col nome che avrebbe portato in epoca preislamica di Bakka,[9] Maometto aveva circa quarant'anni quando, rifugiatosi in meditazione in una grotta del vicino monte Ḥirāʾ (detta Ghār Ḥirāʾ), avrebbe avuto la prima esperienza soprannaturale con l'apparizione dell'arcangelo Gabriele che gli avrebbe ingiunto - usando l'imperativo "iqrāʾ", ovvero "leggi!" (dal verbo arabo qaraʾa) - di proclamare il nuovo messaggio divino, riassunto nell'incipit della Sura 96 del Corano:
«Leggi! In nome del tuo Signore che ha creato, / ha creato l'uomo da un grumo di sangue! / Leggi, ché il tuo Signore è il Generosissimo, / Colui che ha insegnato l'uso del calamo, / ha insegnato all'uomo quello che non sapeva.»
(Traduzione di Alessandro Bausani)Il problema principale del collocamento della città santa coranica nella Mecca attuale è la totale assenza di evidenze archeologiche o ambientali, in aggiunta alla sostanziale assenza di una città che si vorrebbe antichissima nella letteratura preislamica. Dan Gibson ha contestato in maniera piuttosto convincente le tradizioni da un punto di vista archeologico.[10] Diversi altri storici non musulmani, fra i quali Patricia Crone, Tom Holland o Edouard Marie Gallez hanno messo in dubbio la versione tradizionale islamica che vede la Mecca come la culla dell'Islam. Le tradizioni musulmane che descrivono in modo estremamente dettagliato la vita di Maometto alla Mecca sono infatti di molto posteriori, circa due secoli dopo la presunta data della sua morte.
La città inoltre non è nominata dalle fonti coeve, e ciò fa sorgere molti dubbi sul fatto che essa potesse in effetti essere un importante centro carovaniero e di pellegrinaggio quale è considerata nella tradizione islamica. Inoltre le descrizioni ambientali presenti nel Corano, come nella sura VI "Il bestiame", parlano di un paesaggio con bestiame e vegetazione mediterranea (ulivi, vigne, melograni) che non corrisponde affatto al clima desertico, e talmente carente d'acqua da permettere solo assai limitatamente l'allevamento di ovini, caprini, cavalli, asini e dromedari, nonché la crescita di piante mediterranee. Anche il contenuto del Corano, ricco di polemiche religiose derivate da temi e personaggi biblici, ha fatto pensare che il testo sacro dei musulmani fosse rivolto a un pubblico giudaico e cristiano in grado di cogliere i riferimenti alla tradizione biblica. Invece la posteriore, ed ormai unanime, tradizione musulmana sostiene che gli abitanti della Mecca fossero politeisti e pagani.
Secondo queste moderne ipotesi storiografiche storico-critiche, il Corano e lo sviluppo dell'islam sarebbero avvenuti altrove, più a nord, ai confini meridionali dell'Impero romano, tra la Siria e la Giordania attuali. La localizzazione della Mecca come primo luogo della rivelazione di Allah sarebbe avvenuta solo successivamente, già quando esisteva il Califfato arabo nel VII e VIII secolo, e il fine sarebbe stato quello di distinguere la nuova religione dall'ebraismo e dal cristianesimo da cui l'islam sarebbe derivato, e la sua collocazione nel lontano deserto arabico sarebbe avvenuta per preservare la purezza e l'originalità della nuova rivelazione.
La Mecca è meta annuale di visite da parte di pellegrini musulmani. Secondo quanto prescritto dal Corano, tutti coloro che se lo possono permettere fisicamente ed economicamente sono tenuti a visitarla almeno una volta nella vita per il pellegrinaggio canonico detto ḥajj.
La sua sacralità comporta che in essa (e nel territorio circostante, come avviene a Medina) sia categoricamente interdetto l'ingresso a chi non è musulmano.
La nisba portata con orgoglio dai concittadini di Maometto era al-Qurashī (il Coreiscita), ma con l'andar del tempo, una volta dispersisi i Coreisciti in tutto l'ecumene islamico, la nisba divenne la più generica "al-Makkī" (il Meccano).
Il Mar Glaciale Artico[1] è una massa d'acqua situata interamente nella regione boreale dell'Artide, circondata dalle estreme regioni settentrionali di Europa, Asia e America.[2] 
L'Organizzazione Idrografica Internazionale, massima autorità internazionale in ambito idrografico, considera questo mare un oceano, definendolo: Oceano Artico[3], talassonimo però non usato in Italia, dove si considera questa distesa acquea un mare dipendente dall'Oceano Atlantico[2].
I motivi delle due diverse definizioni sono dovuti principalmente all'estensione, avendo una superficie intermedia tra i tre oceani e i più grandi mari mediterranei, pur essendo molto più vicina a questi ultimi (Pacifico: 179 milioni di km²; Atlantico: 120 milioni di km²; Indiano: 73 milioni di km²; Mar Glaciale Artico: 14 milioni di km²; Mediterraneo Australasiatico: 9,08 milioni di km²[4]).
Caratteristica principale di questo mare è il fatto di avere, nella sua parte centrale attorno al polo nord, la superficie permanentemente ghiacciata; da ciò deriva il suo nome: si tratta della banchisa artica, che subisce variazioni stagionali estendendosi verso sud durante i mesi invernali e viceversa ritirandosi verso nord nei mesi estivi.
La denominazione "Mar Glaciale Artico" venne data da Charles Pierre Claret de Fleurieu nel 1797. Nel 1845 la Royal Geographical Society di Londra adottò la denominazione "Arctic Glacial Ocean" (in italiano "Oceano Glaciale Artico").[5]
Il Mar Glaciale Artico occupa un bacino approssimativamente circolare e occupa un'area di circa 14090000 km².
Quasi racchiuso dalla terraferma e quindi rientrante tra i mari mediterranei, il Mar Glaciale Artico è circondato dalle terre di Europa, Asia, America. Essa si affaccia con la Groenlandia e l'Arcipelago artico. Le sue coste si sviluppano per un totale di 45389 km; al suo interno si trovano numerose isole. Ai suoi bordi si trovano alcuni mari periferici: Mare di Barents, Mar di Beaufort, Mare dei Ciukci, Mare di Kara, Mare di Laptev, Mar della Siberia Orientale, Mare di Lincoln, Mare di Wandel, Mare di Groenlandia, Mar Bianco e il Mare di Norvegia.
Una dorsale sottomarina, la dorsale di Lomonosov, divide il Mar Glaciale Artico in due bacini: quello euroasiatico (con il bacino di Nansen), che è profondo da 4 000 a 5450 m, e quello nordamericano, profondo circa 4000 m. La topografia del fondo oceanico è segnata da dorsali, piane abissali, fosse e bacini.
Il maggior flusso di acqua in entrata viene dall'Oceano Atlantico, grazie alla corrente norvegese, che scorre lungo la costa dell'Eurasia. Altra acqua entra dall'Oceano Pacifico attraverso lo stretto di Bering. La maggior parte dell'acqua in uscita passa attraverso la corrente della Groenlandia orientale. La temperatura e la salinità variano stagionalmente, seguendo la formazione e lo scioglimento dei ghiacci.
Il ghiaccio galleggia sulla superficie dell'acqua, con uno spessore medio di 3 m (con punte occasionali di 10 m). La coltre di ghiaccio raddoppia le proprie dimensioni in inverno, inglobando parte della terraferma circostante. Gli iceberg si staccano dal confine della banchisa, e navigano lentamente verso sud sciogliendosi.
Nel Mar Glaciale Artico sono presenti specie a rischio tra cui il tricheco e la balena,[6] oltre ad altri mammiferi (pinnipedi) e pesci; tra gli invertebrati è nota la grande medusa criniera di leone, presente nel mondo non al di sotto del 42º parallelo Nord.[7] L'ecosistema è comunque fragile e lento a ricostituirsi in seguito a sconvolgimenti.
La vegetazione maggiormente diffusa è quella del fitoplancton, che utilizza i nutrienti portati al mare dai fiumi e dalle correnti pacifiche e oceaniche. L'assenza di luce nel periodo invernale e lo strato di ghiaccio presente sopra l'acqua rendono difficile lo sviluppo delle piante; tuttavia in estate è possibile per le piante crescere ed effettuare la fotosintesi per periodi più prolungati.[8]
Le temperature sono sottozero per la maggior parte del tempo di conseguenza il ghiaccio copre la maggior parte della superficie del mare per tutto l'anno. L'Artico è una forte sorgente di aria fredda che si muove verso l'equatore, incontrando nel suo passaggio aria più calda alle medie latitudini e provocando piogge e nevicate. La sua posizione polare fa sì che l'inverno sia lungo e per la maggior parte nell'oscurità. In tale periodo, il tempo è freddo stabile e il cielo generalmente pulito. In estate, la notte si riduce quasi a zero, ma la maggiore radiazione solare non fa alzare di molto le temperature, poiché il suo angolo di incidenza al suolo è comunque molto piccolo. Il tempo è nebbioso, con deboli cicloni che portano pioggia e neve.
Con l'aumento della concentrazione di anidride carbonica nell'atmosfera terrestre e il conseguente fenomeno di riscaldamento globale sotto forma di effetto serra, a partire dal secolo scorso e a tutt'oggi si sta verificando una progressiva fusione dei ghiacci artici in volume e un loro ritiro in estensione. Tra il 1979 e il 2006 l'estensione dei ghiacci artici si è complessivamente ridotta del 25%, mediamente ogni anno 100000 km² di ghiaccio si fondono e non si riformano durante l'inverno. Nel 2009 un'équipe di scienziati utilizzando un moderno modello climatico e seguendo uno scenario di inquinamento medio ha stimato che entro il 2100 nel mare Artico tutti i ghiacciai saranno fusi.[9][10]
Il polo nord soffre di un buco nell'ozono simile a quello più conosciuto del polo sud, ma più piccolo.
I porti principali di questo mare sono le città di Murmansk e Arcangelo in Russia, Churchill in Canada, e Prudhoe Bay in Alaska (USA). La navigazione spesso è possibile solo d'estate, quando il ghiaccio lascia libera una parte dell'acqua. Sono spesso necessarie speciali navi rompighiaccio, che sono capaci di aprirsi la via in uno strato di ghiaccio galleggiante, finché questo è abbastanza sottile. Il passaggio a nord-ovest (sulle coste nord del Canada e dell'Alaska) è stato teatro di famose esplorazioni.
Il Mar Glaciale Artico è anche strategicamente importante, essendo la via più corta tra il Nordamerica e la Russia; esistono stazioni e basi scientifiche nella zona a Ny Ålesund nelle isole Svalbard, Norvegia.
Il Mare del Nord (in danese Nordsøen; in francese Mer du Nord; in inglese North Sea; in norvegese Nordsjøen; in olandese Noordzee; in tedesco Nordsee) è un mare epicontinentale dell'Europa nord-occidentale che comunica con l'oceano Atlantico tramite il mare di Norvegia a nord e la Manica a sud; suo tributario è il Mar Baltico, ad esso collegato tramite gli stretti scandinavi di Skagerrak e Kattegat. Si estende per circa 970 km di lunghezza in direzione nord-sud e 560 km di larghezza in direzione est-ovest, e ha una superficie totale di circa 570000 km²[1]. Accoglie una considerevole parte dei bacini idrografici dell'Unione europea.
La profondità media è di 100 m; quella massima misurata è di circa 700 m ma si incontrano secche in mare aperto profonde meno di 15 m.
Si trova sopra quello che era il punto di giunzione fra tre placche tettoniche continentali nel primo periodo dell'Era Paleozoica; movimenti delle faglie associate a questi fenomeni possono ancor oggi causare terremoti e piccoli tsunami.
Le caratteristiche della costa sono però il risultato di movimenti glaciali, piuttosto che tettonici.
I profondi fiordi sono la caratteristica più comune delle coste settentrionali, mentre le coste meridionali sono costituite maggiormente da spiagge sabbiose e distese fangose.
Queste aree pianeggianti sono particolarmente esposte al rischio di inondazioni, soprattutto a causa della tempeste associate alle maree.
Elaborati sistemi di dighe sono stati costruiti nel tempo per proteggere le zone costiere.
Lo sviluppo della civiltà europea è stato fortemente influenzato dal traffico marittimo nel Mare del Nord.
I Romani prima e i Vichinghi poi cercarono di estendere i loro territori in tutto il mare.
Più tardi, sia la Lega Anseatica che i Paesi Bassi tentarono di dominarne il commercio marittimo e utilizzarlo come ponte per accedere ai mercati del resto del mondo.
Lo sviluppo della stessa Gran Bretagna nel passato come potenza marittima dipendeva fortemente dalla sua posizione dominante sul Mare del Nord, in cui si affacciavano alcune delle potenze sue rivali, in primo luogo i Paesi Bassi e la Germania, ma anche le nazioni scandinave e, in misura minore, la Russia attraverso il vicino mar Baltico. Le imprese commerciali, l'aumento della popolazione e la presenza di risorse limitate sono tutti fattori che hanno portato le nazioni che si affacciavano sul Mare del Nord a desiderarne il controllo degli accessi per interessi commerciali, militari o come collegamento indispensabile verso le colonie d'oltremare. La sua importanza è andata in seguito trasformandosi da militare a economica. Le attività economiche tradizionali, quali la pesca e il trasporto marittimo, hanno continuato a crescere e altre di nuove si sono aggiunte e sono state sviluppate, come, ad esempio, le estrazioni di combustibili fossili e l'energia eolica.
Il nome di “Mare del Nord” deriva originariamente dal suo rapporto alla terra dei frisoni. La Frisia si trova immediatamente a sud del Mare del Nord, a ovest del Mare Orientale (Oostzee, il Mar Baltico), a nord dell'ex Mare Meridionale (Zuiderzee, l'odierno Lago d'IJssel, la propaggine interna dei Paesi Bassi del Mare del Nord). Il nome "Mare del Nord" venne utilizzato nelle regioni centro-settentrionali della Germania (che effettivamente possiede parti delle coste meridionali del mare), probabilmente mutuando il termine dato dai Frisoni. Anche fra i primi nomi dati dagli spagnoli vi fu Mar del Norte.[2]
Dal punto di vista della città anseatiche tedesche del Medioevo, il mare ad est era chiamato il "Mare Orientale" (il mar Baltico in tedesco è letteralmente l'Ostsee), così come il mare a nord era il Mare del Nord. La diffusione delle mappe utilizzate da mercanti anseatici favorì il diffondersi di questo nome nel resto dell'Europa.
Altri nomi comuni in uso per lunghi periodi furono Mare di Frisia (o latino Mare Frisicum), o Oceanus Germanicus (Mare Germanicum), così come i loro equivalenti nelle lingue dei paesi che su di esso si affacciavano (in lingua inglese Frisian Sea e German Ocean).
"German Sea" o "Germanic Sea"[3] (dal latino Mare Germanicum) fu usato comunemente in inglese e in altre lingue assieme a "Mare del Nord" fino agli inizi del XVIII secolo. Dalla fine del XIX secolo questi termini divennero via via più rari, e relegati ad un uso accademico.
Il primo uso intensivo storicamente documentato del Mare del Nord come via di trasporto fu quello dei Romani. Giulio Cesare invase la Britannia nel 55 e nel 54 a.C.. Nel 12 a.C., Druso fece costruire una flotta di oltre 1000 navi che attraversò il Reno e navigò nel Mare del Nord. I Frisoni e i Cauci non potevano competere con la superiorità numerica, tattica e tecnologica dei Romani e, quando questi ultimi avanzarono verso le foci dei fiumi Weser ed Ems, le tribù che vi abitavano furono costrette ad arrendersi. [4]
Nel 5 a.C., la conoscenza romana del Mare del Nord fu estesa in modo significativo fino all'Elba nell'ambito di un'avanzata militare sotto Tiberio: Plinio il Vecchio descrive che le unità navali romane superarono l'isola di Helgoland e si spinsero fino alla costa nord-orientale della Danimarca. Con la conquista della Britannia da parte di Aulo Plauzio (43 d.C.), iniziò un vivace e regolare traffico marittimo tra i porti della Gallia (Portus Itius) e quelli dell'Inghilterra. L'era romana durò poco meno di 350 anni e si concluse con il ritiro delle legioni romane intorno all'anno 400.
Nel vuoto di potere rimasto nelle isole britanniche, i Sassoni, gli Angli e gli Juti, originari dell'attuale Germania settentrionale e della Danimarca, avanzarono attraverso il Mare del Nord con la successiva migrazione fino alla Britannia. Già utilizzati come mercenari durante l'occupazione romana della Britannia nell'ultima fase dell'Impero romano, attraversarono in gran numero il Mare del Nord durante i secoli della migrazione dei popoli e si stabilirono nel sud e nell'est dell'Inghilterra, spingendo i romano-britanni che vi abitavano originariamente nelle zone dell'attuale Scozia e Galles. Intorno al VII secolo, i Frisoni, originari dell'attuale Olanda, migrarono attraverso il Mare del Nord verso le isole frisone settentrionali di Sylt, Amrum e Föhr. In una seconda ondata di immigrazione, nell'XI secolo, fu colonizzata anche la terraferma dello Jutland, tra i fiumi Eider e Wiedau, nello Jutland meridionale, dove i Frisoni incontrarono gli Juti. L'area di insediamento della Frisia settentrionale costituisce oggi gran parte del distretto di Nordfriesland.
La successiva grande ondata migratoria attraverso il Mare del Nord portò gli "uomini del Nord", provenienti principalmente dalle attuali Danimarca e Norvegia, nelle isole britanniche. L'incursione a Lindisfarne nel 793 segnò l'inizio delle campagne di saccheggio dei Vichinghi, che nei cento anni successivi si dedicarono principalmente a pirati e saccheggiatori. Saccheggiarono monasteri, fattorie e città della costa e navigarono nell'entroterra sui fiumi. Secondo la Cronaca anglosassone, anche loro iniziarono a insediarsi a partire dall'851. Queste migrazioni dalla Scandinavia continuarono fino al 1050 circa. Alfredo il Grande del Wessex fu il primo re sassone a resistere ai Vichinghi con una propria flotta. Riuscì a liberare la zona dai danesi ed è considerato il primo re inglese. Mentre il mare separava gli anglosassoni britannici dalle tribù germaniche, gli scandinavi si mantenevano in contatto con l'antica patria attraverso il Mare del Nord. Così, la maggior parte delle isole britanniche e la parte settentrionale del mare appartenevano saldamente al dominio dei re scandinavi, i Vichinghi.
Canuto II fu l'ultimo re danese-britannico, dopo la sua morte l'Impero del Mare del Nord si disintegrò a causa di conflitti interni, l'unione politica tra scandinavi e britannici attraverso il Mare del Nord fu separata. Dopo questa separazione, il Mare del Nord cominciò a perdere la sua importanza per il momento. Dall'invasione di Guglielmo il Conquistatore dalla Normandia, nell'attuale Francia, le isole britanniche, come le regioni costiere occidentali del Mare del Nord, si sono orientate verso sud, lungo i principali fiumi europei, in direzione del Mediterraneo e dell'Oriente.
Il collegamento più importante con il mondo esterno per la Germania settentrionale e la Scandinavia era invece il Mar Baltico, dove fiorì la Lega Anseatica. L'unica via commerciale più importante attraverso il Mare del Nord conduceva dalle Fiandre ai porti delle città anseatiche, passando per il golfo tedesco. 
Sebbene la Lega anseatica avesse il suo centro di gravità nel Mar Baltico, importanti uffici si trovavano anche a Bergen in Norvegia, a Londra, in Inghilterra ed a Bruges.
L'ascesa di Bruges iniziò, non a caso nel Mare del Nord, con un'ondata di tempesta che strappò un profondo canale di navigazione, lo Zwin, nel 1134, permettendo alle navi mercantili più grandi di entrare in città. Tra Bruges e Londra iniziò a svilupparsi un vivace commercio di lana inglese e di tessuti delle Fiandre. A partire dal XIII secolo, i mercanti anseatici tedeschi si recavano regolarmente a Bruges e a Londra e iniziarono a stabilire una rotta commerciale regolare verso queste città. Bruges divenne il capolinea della linea commerciale est-ovest con Novgorod in Russia e allo stesso tempo fu collegata via mare con Francia, Italia, Spagna e Paesi Bassi.
Dal 1441 i Paesi Bassi, da un punto di vista economico e navale, iniziarono a configurarsi come la potenza rivale della Lega. Nel XVI secolo erano la principale potenza economica e il Mare del Nord divenne crocevia del commercio tra le lontane colonie e i mercati di tutta Europa.
Il potere olandese durante la sua epoca di massimo splendore fu ragione di crescente preoccupazione per l'Inghilterra, che vedeva il suo futuro nella marina mercantile e nelle colonie d'oltremare. Ciò fu alla base delle primi tre guerre anglo-olandesi tra il 1652 e il 1673. Alla fine della Guerra di successione spagnola nel 1714, gli olandesi non erano più un attore fondamentale della politica europea.
La supremazia navale della Gran Bretagna, prima del XX secolo, vedeva come unici seri contendenti solo la Francia napoleonica e i suoi alleati continentali. Nel 1800 un'unione di potenze navali minori, chiamata Lega di neutralità armata, si formò per proteggere il commercio neutrale nel corso del conflitto tra Gran Bretagna e Francia. La Marina britannica sconfisse le forze unite della Lega di neutralità armata nella battaglia di Copenaghen del 1801 nel Kattegat. La Gran Bretagna successivamente sconfisse la marina francese nella battaglia di Trafalgar al largo delle coste della Spagna.
Le tensioni nel Mare del Nord si aggravarono nel 1904 con l'incidente del Dogger Bank, in cui in navi da guerra russe scambiarono delle navi da pesca britanniche per navi giapponesi e spararono su di esse. L'incidente, che avveniva in uno scenario caratterizzato da un'alleanza tra la Gran Bretagna e il Giappone combinato con una guerra russo-giapponese in atto, portò ad un'intensa crisi diplomatica. La crisi si ridimensionò con la sconfitta russa ad opera dei giapponesi e il pagamento di indennizzi per i pescatori.
Durante la prima guerra mondiale la marina della Gran Bretagna e quella della Germania (la Kaiserliche Marine) si fronteggiarono sul Mare del Nord facendolo diventare il principale teatro della guerra per superficie di azione. La marina britannica, con una flotta maggiore, fu in grado di stabilire un efficace blocco navale per la maggior parte del periodo bellico, limitando così l'approvvigionamento di risorse indispensabili agli Imperi centrali. Le principali battaglie furono la Battaglia di Helgoland, la Battaglia di Dogger Bank, la Battaglia dello Jutland e la Seconda Battaglia di Helgoland.
Anche la seconda guerra mondiale ha visto operazioni nel Mare del Nord, anche se prevalentemente limitato alla caccia con sottomarini e a navi di più ridotte dimensioni.[5] Il 9 aprile 1940 i tedeschi avviarono l'Operazione Weserübung in cui la quasi totalità del flotta tedesca si concentrò a nord verso la Scandinavia tra lo Skagerrak e il Kattegat. Durante l'occupazione tedesca della Norvegia, l'operazione Shetland Bus collegò segretamente la Gran Bretagna alla Norvegia.
Negli ultimi anni della guerra e nell'anno immediatamente successivo, enormi quantità di armi furono smaltite o affondate nelle acque del Mare del Nord, rappresentate principalmente da granate, mine terrestri e navali, bazooka, cartucce, e armi chimiche. Anche se le stime variano ampiamente, centinaia di migliaia di tonnellate di munizioni furono qui disperse.[6]
Dopo la guerra il Mare del Nord perse molto del suo significato militare, perché circondato esclusivamente da paesi membri della NATO. Acquisì però una notevole importanza economica a partire dagli anni sessanta con l'inizio dello sfruttamento petrolifero e dei giacimenti di gas metano.
Per la maggior parte il mare si trova sulla piattaforma continentale europea. L'unica eccezione è una ristretta zona settentrionale del Mare del Nord al largo della Norvegia. Il Mare del Nord è delimitato dalla Gran Bretagna a ovest, e la parte continentale dell'Europa centrale e settentrionale sia a est che a sud, includendo Norvegia, Danimarca, Germania, Paesi Bassi, Belgio e Francia.
Nel sud-ovest il Mare del Nord diventa il Canale della Manica al di là dello Stretto di Dover (Passo di Calais). A est, si connette al Mar Baltico tramite lo Skagerrak e il Kattegat. A nord si apre con un'ampia forna imbuto verso il Mare di Norvegia, che si trova nella regione nord-orientale dell'Oceano Atlantico.
A parte gli ovvi confini formati dalle coste dei paesi che su di esso si affacciano, il Mare del Nord, generalmente si considera delimitato ad est da una linea immaginaria che collega Lindesnes in Norvegia con Hanstholm in Danimarca correndo lungo confine con lo Skagerrak. Tuttavia a fini statistici lo Skagerrak e il Kattegat a volte sono inclusi come parte del Mare del Nord. Il limite settentrionale è meno definito. Tradizionalmente una linea immaginaria collega il nord della Scozia verso le isole Shetland fino ad unirsi a Ålesund in Norvegia. Secondo la Convenzione per la protezione dell'ambiente marino dell'Atlantico nord-orientale[7] del 1962, il limite è posto più a ovest e più a nord, tra il 5° di longitudine ovest e 62° di latitudine Nord, alla latitudine di Geirangerfjord in Norvegia, in corrispondenza della penisola di Stad[8].
L'area della superficie del Mare del Nord pertanto è di circa 575.000 chilometri quadrati, con un volume di circa 54.000 chilometri cubi d'acqua.[1] Ciò pone il Mare del Nord al 13º posto come mare più grande del pianeta.[9]
Il letto del Mare del Nord forma due bacini. Il più settentrionale si trova a nord di un crinale tra Norfolk e la Frisia, e ha avuto la sua origine nel Devoniano. Il bacino meridionale si spinge verso lo Stretto di Dover e da là verso il Canale della Manica. Questo bacino risale al Carbonifero[10].
Nel corso della più recente glaciazione gran parte del bacino settentrionale fu coperto dai ghiacci, e il resto, compreso il bacino meridionale, si ricoprì di tundra. Durante il periodo interglaciale si creò una diga naturale di gesso, il “Weald-Artois Anticline”.[11] Anche se la cresta probabilmente collassò, costituito la parte più alta del ponte di terra che collegò momentaneamente l'Europa continentale con la Gran Bretagna.
Gli Storegga Slides furono una serie di frane sottomarine, in cui un pezzo della piattaforma continentale norvegese scivolò nel Mare di Norvegia. Le immense frane si verificarono tra il 8150 a.C. e 6000 a.C., e provocarono uno tsunami alto fino a 20 metri che attraversò il Mare del Nord abbattendosi maggiormente sulla Scozia e sulle Isole Fær Øer.[12]
Il Mare del Nord si trova sopra quello che era la giunzione fra tre placche tettoniche continentali risalenti all'inizio dell'Era Paleozoica. Successivamente, nel Mesozoico, si formò una faglia con andamento nord-sud al centro del Mare del Nord. Questa faglia che corre dal Canale della Manica causa terremoti occasionali, che possono anche provocare danni alle strutture sulla terraferma.[13] Il terremoto che avvenne nello Stretto di Dover del 1580 è tra i primi terremoti storici registrati che provocarono ingenti danni sia in Francia che in Inghilterra, a cui si associò anche un maremoto. Il più grande terremoto mai registrato nel Regno Unito avvenne nel 1931 al largo delle sue coste verso il Dogger Bank, e misurò 6,1° sulla scala Richter e ha provocato uno tsunami che inondò parti della costa britannica.
Le tre placche continentali formate nel corso dell'Era Paleozoica sono l'Avalonia, la Laurentia e la Baltica.[14] La placca Baltica forma ora la costa orientale, e s'affaccia verso i paesi scandinavi; Avalonia consiste nella costa meridionale e occidentale del Mare del Nord lungo l'Inghilterra, il nord della Germania e la Francia; Laurentia segna il perimetro settentrionale del Mare del Nord con l'Oceano Atlantico.
La salinità dell'acqua varia sia da luogo a luogo che nel corso degli anni, ma generalmente è compresa tra le 15 e le 25 parti per mille nei pressi degli estuari dei fiumi, per arrivare fino alle 32-35 parti per mille[9] nelle zone settentrionali del Mare del Nord; restano in linea generale inferiore alla salinità media del Nord Atlantico, che è nell'ordine delle 35 parti per mille.
La temperatura dell'acqua varia a seconda della influenza delle correnti atlantiche che della profondità, raggiungendo i 21 °C in estate e 6 °C in inverno, anche se le correnti artiche possono essere più fredde. Il lato orientale è sia il più caldo in estate che il più freddo in inverno. Nel Mare del Nord più settentrionale l'acqua rimane costantemente nell'ordine dei 10 °C durante tutto l'arco dell'anno a causa dei continui scambi con l'Oceano Atlantico. Le più grandi variazioni di temperatura sono registrate lungo le coste meridionali prossime alle Isole Frisone nel mare dei Wadden, dove si può presentare anche ghiaccio negli inverni particolarmente freddi.[9]
Lo scambio di acqua salata tra il Mare del Nord e Atlantico si verifica attraverso il Canale della Manica, come pure nella zona settentrionale del Mare del Nord, lungo la costa scozzese e attraverso il Mare di Norvegia. Il Mare del Nord riceve acqua dolce non solo dal flusso dei fiumi, ma anche dalla bassa salinità del Mar Baltico che ne è collegato attraverso lo Skagerrak. Il bacino idrografico dei fiumi che si gettano nel Mare del Nord misura una superficie di 841.500 km² e fornisce un volume di 296–354 km³ di acqua dolce ogni anno. Il bacino idrografico che getta nel Mar Baltico misura una superficie quasi doppia (1.650.000 km²) e contribuisce con 470 km³ di acqua dolce ogni anno.[9]
Circa 185 milioni di persone vivono nei bacini idrografici dei fiumi che si gettano nel Mare del Nord[15]. Questi bacini ricoprono gran parte dell'Europa occidentale: un quarto della Francia, tre quarti di Germania, quasi tutta la Svizzera, una piccolissima porzione d'Italia, metà dello Jutland, la totalità dei Paesi Bassi e del Belgio, la parte meridionale della Norvegia, il bacino del Reno dell'Austria occidentale, e la parte orientale della Gran Bretagna.[15] Questa area contiene una delle più grandi concentrazioni industriali del pianeta.
Il principale movimento delle acque all'interno del Mare del Nord è in senso anti-orario lungo le coste.[16] L'acqua dalla Corrente del Golfo entra nel mare attraverso due direzioni: per il Canale della Manica verso la Norvegia, e aggirando a nord la Gran Bretagna e seguendone successivamente le coste verso sud. Questi movimenti generano altre piccole correnti che si dirigono verso est nella parte centrale del Mare del Nord. Un'altra corrente spazia a sud nella parte orientale del mare. Questa trasporta acqua fredda dal Nord Atlantico e nel periodo tra primavera e inizio dell'estate rinfresca le acque superficiali al largo dell'Inghilterra, mentre al largo delle Paesi Bassi e della Germania inizia una fase di riscaldamento. L'acqua che esce del Mar Baltico sale verso nord lungo la costa norvegese ritornando nell'Atlantico in quello che è chiamata Corrente norvegese.
Il tempo di permanenza medio dell'acqua all'interno del Mare del Nord è compresa tra 1 e due anni.[17] Le acque più a nord sono scambiate più rapidamente, mentre per quelle meridionali possono passare anni prima di raggiungere le regioni settentrionali e fuoriuscirne verso l'Atlantico.
Fronti d'acqua basati sulla temperatura, salinità, nutrienti, e inquinamento possono essere chiaramente identificate, anche se con più facilità nel periodo estivo rispetto a quello invernale. Fra i principali si identificano il Fronte delle Frisone, che divide l'acqua proveniente dal Nord Atlantico da quella originaria della Manica, e il Fronte danese, che divide le acque costiere meridionali da quelle della parte centrale del Mare del Nord.
L'afflusso di acqua proveniente dai grandi fiumi si mescola molto lentamente con l'acqua marina. Le acque del Reno e dell'Elba, ad esempio, possono ancora essere chiaramente distinte in mare al largo della costa nord-ovest della Danimarca.
Le maree sono causate dall'onda di marea proveniente dal Nord Atlantico, siccome il Mare del Nord è troppo piccolo e troppo poco profondo per disporre di una propria marea consistente. Il flusso alternato è in un ciclo di 12,5 ore. L'ondata di marea lungo le coste della Scozia che scorre in senso anti-orario lungo la costa inglese, raggiunge la costa tedesca circa 12 ore dopo.
L'ampiezza della marea è al suo picco massimo a The Wash sulla costa inglese, dove raggiunge 6,80 metri. L'ampiezza però è fortemente influenzata da una serie di fattori, come ad esempio la posizione della costa, il vento e l'azione dovuta a tempeste. Negli estuari fluviali, alti livelli d'acqua possono amplificare notevolmente l'effetto di alta marea.
Le mareggiate minacciano in particolare le coste dei Paesi Bassi, Belgio, Germania e Danimarca. Queste coste sono piuttosto piatte e ciò comporta che un aumento relativamente piccolo del livello delle acque sia sufficiente a porre grandi distese di terra sotto il livello dell'acqua. Le tempeste da ovest sono particolarmente forti. Nel corso dei millenni le inondazioni causate dalle tempeste sono costate centinaia di migliaia di vite e hanno notevolmente contribuito a modellare la costa. Fino agli inizi dei tempi moderni il numero di vittime causate da una singola tempesta arrivava a causare anche migliaia di morti, benché stime più precise siano rilevabili con difficoltà.
La prima mareggiata che produsse un'alluvione, di cui si abbia notizia registrata, fu la Julianenflut il 17 febbraio 1164. Un forte alluvione si verificò nel 1219. Una tempesta associata ad un innalzamento della marea nel 1228 provocò secondo le stime più di 100.000 morti. La Grote Mandrenke nel 1362 colpì l'intera costa meridionale del Mare del Nord. Le cronache del tempo registrano ancora più di 100.000 morti e parte della costa inghiottita dal mare, inclusa l'ormai leggendaria città di Rungholt.
Nel XX secolo tra le alluvioni provenienti dal mare si segnala quella del 1953 che inondò le coste di diverse nazioni e costò più di 2.000 vite umane. 315 cittadini di Amburgo morirono nell'alluvione del 1962. Con l'alluvione del 1976 e del 1981 si toccò il record del livello dell'acqua sulla costa del Mare del Nord, ma le dighe costruite e poi migliorate dopo l'alluvione del 1962 comportarono soltanto danni materiali. Una tempesta si è verificata il 9 novembre 2007 causando una serie di inondazioni.
Le coste occidentali sono frastagliate, risultato dell'azione dei ghiacci durante le ere glaciali. I litorali lungo la parte meridionale sono più morbidi, ricoperti con i resti di depositati morenici che sono stati a loro volta scaricati in mare. Le montagne norvegesi si tuffano direttamente in mare e le coste sono caratterizzati da numerosi fiordi e arcipelaghi. A sud di Stavanger la costa si ammorbidisce e le isole si presentano in numero inferiore. La costa orientale scozzese è simile, anche se meno marcata rispetto a quella della Norvegia. A partire da Flamborough Head nel nord-est dell'Inghilterra, le scogliere diventano più basse e sono composte da minori depositi morenici, e le coste, erose più facilmente si presentano con contorni più arrotondati. Nei Paesi Bassi, nel Belgio e nell'Inghilterra orientale (East Anglia) il litorale è basso e paludoso. La costa orientale e sud-orientale del Mare del Nord (mare dei Wadden) hanno coste che sono principalmente di tipo sabbioso.
Le coste settentrionali portano ancora il segno degli immensi ghiacciai le ricoprivano durante le ere glaciali, creando il frastagliato paesaggio costiero. I fiordi sono nati dall'azione dei ghiacciai, che nel loro lento movimento verso il mare hanno raschiato e scavato profonde fenditure nel suolo. Con il ritirarsi dei ghiacci, l'innalzamento del livello dell'acqua tali solchi sono stati invasi dal mare. Il paesaggio si presenta spesso con coste ripide e le insenature marine possono essere anche profonde. I fiordi sono particolarmente comuni nella costa della Norvegia.[18]
I firths sono simili ai fiordi, ma sono generalmente poco profondi e presentano baie più ampie all'interno delle quali possono essere presenti piccole isole. I ghiacciai hanno insistito qui su un'area più estesa e hanno scavato aree più ampie. I firths si trovano soprattutto nella Scozia settentrionale e lungo le coste inglesi.
Verso sud i firths cedono il passo alle scogliere, formatesi dalle morene glaciali. L'impatto delle onde sulla costa dà luogo a fenomeni di erosione.[19] Il materiale eroso diviene fonte importante di sedimenti per la distese fangose che si trovano dall'altra parte del Mare del Nord.[20] Il paesaggio delle scogliere è interrotta dai grandi estuari fluviali con i loro corrispondenti depositi di detriti, in particolare modo quelli del fiume Humber e Tamigi nel sud dell'Inghilterra.
Nel sud della Norvegia, come pure sulla costa svedese dello Skagerrak, si trovano fenomeni simili ai fiordi e ai firths.[21] Qui l'azione dei ghiacci ha insistito e scavato su regioni ancora più vaste. Verso le coste si trovano dolci declivi che scendono dalle montagne e che si estendono per chilometri, tuffandosi poi sotto il mare, ma rimanendo ad una profondità di soli pochi metri.
Le scarsa profondità delle acque e la linea della coste meridionali e orientali fino alla Danimarca sebbene formate anch'esse dall'azione dei ghiacci nelle ere glaciali, devono maggiormente la loro forma all'azione del mare e al deposito dei sedimenti.[22] Il mare dei Wadden che si estende tra Esbjerg nella Danimarca del nord e Den Helder nei Paesi Bassi deve la conformazione del suo paesaggio alla forte influenza esercitata dall'azione delle maree. La zona costiera presenta acque poco profonde e il costante apporto di sedimenti. Grandi opere di bonifica hanno interessato questa regione, soprattutto ad opera degli olandesi. Il più grande progetto di questo tipo è stata la bonifica del IJsselmeer.
Le zone costiere meridionali, inizialmente, erano soggette ai capricci del mare. I territori limitrofi alle coste, costituite da un innumerevole intrico di canali, isolotti, delta fluviali e zone umide venivano regolarmente allagati e sommersi. In settori particolarmente vulnerabili alle mareggiate, le persone tendevano allora ad insediarsi su terreni rialzati e più protetti. Già nel 500 a.C., gli insediamenti iniziarono ad essere costruiti su delle colline artificiali, alte anche diversi metri. Fu solo intorno agli inizi del Medioevo nel 1200 che si è iniziato a collegare tra loro piccole dighe in linea lungo l'intera costa, rendendo quindi permanenti e definite le zone di terra da quelle di mare.
Dighe in senso moderno hanno iniziato a prendere forma nel XVII e XVIII secolo, costruite da imprese private nei Paesi Bassi. I costruttori olandesi hanno quindi esportato i loro disegni e modelli verso altre regioni del Mare del Nord.
Le alluvioni verificatesi sulle coste del Mare del Nord nel 1953 e nel 1962 sono state ulteriore impulso per l'innalzamento delle dighe, la sostituzione delle vecchie dighe in linea, il recupero di terreni e sbarramenti fluviali, in modo da ottenere da poca superficie interessata un grande risultato nella lotta contro il mare e le tempeste.[23] Attualmente il 27% dei Paesi Bassi è sotto il livello del mare e protetto da argini e dune.[24]
La conservazione costiera oggi consiste di vari livelli. La pendenza delle dighe riduce l'energia del mare in entrata, in modo che la diga stessa non riceva il pieno impatto. Alcune dighe che si trovano direttamente in mare e queste sono particolarmente rafforzata. Nel corso degli anni sono state più volte sollevate, a volte anche di 10 m, e sono diventate più orizzontali, al fine di meglio ridurre l'erosione delle onde. Le moderne dighe possono raggiungere un'altezza anche di 100 m. Dietro la diga solitamente è presente una strada di accesso e, in generale, l'area più prossima è scarsamente abitata. In molti luoghi un altro sistema di dighe è presente verso l'entroterra dopo diversi chilometri.
Dove le dune sono sufficienti per proteggere la terra dall'avanzata del mare viene seminata dell'erba che cresca nella sabbia, in modo da proteggere le dune stesse dall'erosione del vento, dell'acqua e dal traffico a piedi.[25]
Tra le specie che popolano questo mare e che per riprodursi risalgono i fiumi che sfociano in esso è da ricordare la cheppia (Alosa fallax).
Nel 1958 i geologi scoprirono un giacimento di gas naturale a Slochteren nella provincia dei Paesi Bassi di Groninga e si iniziò a sospettare la presenza di petrolio nel Mare del Nord. Tuttavia in questa data i diritti di sfruttamento delle risorse naturali in alto mare erano ancora in fase di controversia.[26]
Nel 1962 i geologi scoprirono i primi giacimenti di petrolio in questo mare.
Prove di perforazione iniziarono nel 1966 e successivamente nel 1969 quando la Phillips Petroleum Company scoprì la Ekofisk (ora norvegese), che all'epoca era uno dei 20 più grandi giacimenti del mondo e si rivelò caratterizzata da una bassa presenza di zolfo. Lo sfruttamento commerciale iniziò nel 1971 con le navi cisterna e dal 1975 con oleodotti diretti a Cleveland in Inghilterra e dal 1977 anche a Emden in Germania.
Lo sfruttamento delle riserve del Mare del Nord ha avuto inizio poco prima della crisi petrolifera del 1973, e la successiva salita dei prezzi internazionali del petrolio hanno fatto sì che i grandi investimenti necessari per l'estrazione divenissero molto più interessanti e possibili in questa regione. Negli anni ‘80 e ‘90 seguirono ulteriori scoperte dei grandi campi petroliferi. Anche se i costi di produzione erano relativamente elevati, la qualità del petrolio, la stabilità politica della regione, e la vicinanza di importanti mercati in Europa occidentale ha fatto del Mare del Nord un'importante area di produzione. La più grande catastrofe ambientale fu la distruzione della piattaforma off-shore di Piper Alpha nel 1988 in cui 167 persone persero la vita.
Con più di 450 piattaforme petrolifere, il Mare del Nord è la più importante regione del mondo per la perforazione offshore. La sezione britannica del Mare del Nord è quella che possiede più piattaforme, seguita in ordine da quella norvegese, olandese e danese. Il più grande campo di gas naturale nel Mare del Nord, “Troll”, si trova sotto la giurisdizione norvegese ad una profondità di 345 metri. Una piattaforma gigante è stata necessaria per accedervi. La sezione tedesca possiede solo due piattaforme petrolifere (la più grande delle due è il Mittelplate) e si presenta come il paese meno dotato per le estrazioni minerarie in questo mare.
Nel 1999 le estrazioni raggiunsero il picco di tutti i tempi con quasi 6 milioni di barili (950.000 m³) di petrolio greggio e 28.000.000 m³ di gas naturale al giorno.[27] Oggi la risorsa nel Mare del Nord è ben sviluppata. Tutte le grandi compagnie petrolifere sono state coinvolte nelle operazioni di estrazione. Ma negli ultimi anni alcune grandi società ne hanno interrotto l'estrazione e da quel 1999 l'importo estratto è diminuito continuamente a causa dell'esaurimento delle riserve.
Il prezzo del Brent Crude, uno dei primi tipi di petrolio estratto dal Mare del Nord, è utilizzato oggi come un prezzo standard di confronto per il petrolio greggio dal resto del mondo.
Il pescato annuale è cresciuto ogni anno fino al 1980, quando si è raggiunto il punto massimo con più di 3 milioni di tonnellate di pesce. Da allora i numeri sono scesi a circa 2,3 milioni di tonnellate, con notevoli differenze tra i vari anni. Oltre al pesce commercializzabile si stima che 150.000 tonnellate di pescato senza mercato venga catturato e che circa 85.000 tonnellate sia la quantità di invertebrati che viene coinvolto o ributtato in mare ferito o morto.[28]
Negli ultimi decenni lo sfruttamento eccessivo ha reso meno produttiva la pesca, alterando la catena alimentare marina e la dinamica dei costi e dei posti di lavoro nel settore della pesca. La pesca di aringhe, merluzzi e passera di mare potrebbe presto affrontare la stessa situazione della pesca allo sgombro cessata negli anni ‘70 a causa di sovra-sfruttamento.[29]
In aggiunta al petrolio, gas naturale e alla pesca, gli Stati che si affacciano sul Mare del Nord estraggono milioni di metri cubi annui di sabbie e ghiaia. Questi sono poi utilizzati per progetti di costruzione, per rinforzare le spiagge e per proteggere le coste. Il più grandi Paesi estrattori di sabbia e ghiaia nel 2003 furono i Paesi Bassi (circa 30 milioni di m³) e la Danimarca (circa 10 milioni di m³).[30]
A causa dei forti venti, i paesi sul Mare del Nord, in particolare l'Inghilterra e la Danimarca, hanno utilizzato le aree vicino alla costa del mare per lo sfruttamento eolico per la produzione di energia elettrica a partire dagli anni ‘90. La prima turbina a vento è apparsa al largo della costa inglese vicino Blyth nel 2000 e poi al largo della costa danese nel 2002 vicino a Horns Rev.
I paesi che affacciano sul Mare del Nord rivendicano tutti le dodici miglia nautiche di acque territoriali in cui hanno i diritti esclusivi di pesca. L'Islanda, tuttavia, a causa della guerra del merluzzo ha diritti esclusivi di pesca per 200 miglia (320 km) al largo delle sue coste, toccando le acque del Mare del Nord. La politica comune della pesca dell'Unione europea esiste per coordinare i diritti di pesca e per assistere alle controversie tra i Paesi membri dell'Unione europea sulla frontiera con la Norvegia.
Dopo la scoperta delle risorse minerarie la Norvegia ha reclamato i suoi diritti ai sensi della Convenzione della piattaforma continentale. Gli altri paesi hanno seguito l'esempio. Questi diritti sono stati divisi in gran parte lungo una linea mediana che a “seconda dell'ampiezza della base di ogni mare territoriale di ciascun Paese si tenesse comunque equidistante dai linee meridiani dei Paesi prossimi”.[31] Il confine delle acque tra Germania, Paesi Bassi, e la Danimarca è stato ridefinito solo dopo lunghi negoziati e una sentenza della Corte internazionale di giustizia.[32]
Preoccupazioni di tipo ambientale hanno portato alla Accordi Marpol 73/78, che ha creato una zona di protezione larga 25 miglia (40 km) e lunga 50 mi (80 km). La Convenzione per la protezione dell'ambiente marino dell'Atlantico nord-orientale è stata siglata per la conservazione del mare in questa regione. Germania, Danimarca e Paesi Bassi hanno un accordo trilaterale per la protezione del mare dei Wadden, distese prevalentemente fangose che si snodano lungo le coste dei tre paesi sul bordo meridionale del Mare del Nord.
Le spiagge e le acque costiere del Mare del Nord sono popolari destinazioni per il turismo balneare. In particolare modo le attività sono sviluppate lungo la costa belga, olandese, tedesca e danese, come pure su quella britannica.
Il windsurf e la vela sono sport popolari favoriti dai forti venti, ma anche la pesca sportiva e le immersioni subacquee. Un'altra attività praticata è la camminata nel fango ovvero l'escursionismo praticato sul fango che viene a galla dal mare durante i periodi di bassa marea in alcune zone geografiche particolari.
Il Mare del Nord è molto importante per il traffico marittimo e presenta fra le più alte concentrazione di navi di tutto il mondo. Grandi porti di rilievo internazionale si trovano lungo le sue coste: Rotterdam, il terzo porto del mondo per movimentazione, Anversa e Amburgo (compresi nei top 25), così come Brema/Bremerhaven e Felixstowe.
Tutti i principali porti hanno facile accesso alle varie rotte sul Mare del Nord. Ma il traffico è particolarmente difficile, con un'elevata presenza di barche da pesca, piattaforme petrolifere e mercantile. La possibilità di colli di bottiglia è elevata, come presso il Canale della Manica, che vede 400 navi al giorno e il Canale di Kiel con in media più di 100 navi al giorno.
Alcuni porti sono collegati da importanti canali come il Canale del Nord, che abbreviato il collegamento tra il porto di Amsterdam ed il mare, e il canale di Kiel, che collega il Mare del Nord al Mar Baltico.
I principali fiumi che sfociano nel Mare del Nord sono:
Testi da poter leggere riferiti a questo argomento sul petrolio e i gas: "Storia di una gabbianella e del gatto che le insegnò a volare". Firenze 1997 L.Sepu'lveda.
